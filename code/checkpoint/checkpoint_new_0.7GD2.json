[
    {
        "title": "CAUSAL MODELLING AGENTS: CAUSAL GRAPH DIS-",
        "abstract": "Centre for Medical Image Computing, UCL, London, United Kingdom Microsoft Research, Cambridge ABSTRACT Scientific discovery hinges on the effective integration of metadata, which refers to a set of conceptual operations such as determining what information is relevant for inquiry, and data, which encompasses physical operations such as observation and experimentation. This paper introduces the Causal Modelling Agent (CMA), a novel framework that synergizes the metadata-based reasoning capabilities of Large Language Models (LLMs) with the data-driven modelling of Deep Structural Causal Models (DSCMs) for the task of causal discovery. We evaluate the CMA\u2019s performance on a number of benchmarks, as well as on the real-world task of modelling the clinical and radiological phenotype of Alzheimer\u2019s Disease (AD). Our experimental results indicate that the CMA can outperform previous purely data-driven or metadata-driven approaches to causal discovery. In our real-world application, we use the CMA to derive new insights into the causal relationships among biomarkers of AD.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper introduces the Causal Modelling Agent (CMA), a novel framework that combines the metadata-based reasoning capabilities of Large Language Models (LLMs) with the data-driven modelling of Deep Structural Causal Models (DSCMs) for the task of causal discovery. The CMA is designed to reason over a dataset and its associated data-generating process, and it is evaluated on a number of benchmarks and a real-world task of modelling the clinical and radiological phenotype of Alzheimer\u2019s Disease (AD). The experimental results indicate that the CMA can outperform previous purely data-driven or metadata-driven approaches to causal discovery.\n\nStrengths:\n\n* The paper presents a novel and innovative approach to causal discovery that combines the strengths of LLMs and DSCMs.\n* The CMA is evaluated on a range of benchmarks and a real-world task, demonstrating its effectiveness in different scenarios.\n* The paper provides a clear and well-structured explanation of the CMA framework and its components.\n* The authors provide a detailed analysis of the results and insights gained from the experiments.\n\nWeaknesses:\n\n* The paper assumes that the causal graph is known a priori, which may not be the case in real-world scenarios.\n* The CMA relies on DSCMs to fit data, which assumes a Markovian DAG. While the authors extend the framework to include chain graph elements, human intervention is necessary to allow appropriate Deep Chain Graph modelling.\n* The paper does not provide a clear explanation of how the LLMs are used to produce hypotheses and how they are integrated with the DSCMs.\n* The paper assumes that the metadata is accurate and complete, which may not be the case in real-world scenarios.\n\nSuggestions for Improvement:\n\n* The authors should provide a more detailed explanation of how the LLMs are used to produce hypotheses and how they are integrated with the DSCMs.\n* The authors should investigate techniques to enable fully automated chain graph modelling and extend deep SCMs to represent more flexible, non-Markovian causal graphs.\n* The authors should provide a more detailed analysis of the limitations of the CMA and how they can be addressed in future work.\n* The authors should provide a more detailed explanation of the results and insights gained from the experiments, including a more detailed analysis of the causal relationships between variables.\n\nRecommendation:\n\nThe paper presents a novel and innovative approach to causal discovery that combines the strengths of LLMs and DSCMs. While there are some limitations and areas for improvement, the paper provides a clear and well-structured explanation of the CMA framework and its components, and the experimental results demonstrate its effectiveness in different scenarios. I recommend that the paper be accepted for publication, with the suggestion that the authors address the areas for improvement mentioned above.\n\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper introduces the Causal Modelling Agent (CMA), a novel framework that combines Large Language Models (LLMs) with Deep Structural Causal Models (DSCMs) for causal discovery. The CMA synergizes metadata-based reasoning of LLMs with data-driven modelling of DSCMs to reason over a dataset and its associated data-generating process. The framework is composed of four stages: hypothesis generation, model fitting, post-processing, and hypothesis amendment. The CMA is evaluated on several benchmarks and a real-world task of modelling the clinical and radiological phenotype of Alzheimer's Disease (AD). The experimental results indicate that the CMA outperforms previous purely data-driven or metadata-driven approaches to causal discovery.\n\nStrengths:\n\n1. The CMA framework is a novel and innovative approach to causal discovery, combining the strengths of LLMs and DSCMs.\n2. The framework is well-structured and easy to follow, with a clear description of each stage and the interactions between them.\n3. The experimental results are comprehensive and provide a clear comparison with existing approaches.\n4. The application of the CMA to a real-world task of modelling AD is a significant contribution to the field.\n\nWeaknesses:\n\n1. The paper assumes a Markovian DAG structure, which may not always hold in real-world data.\n2. The LLMs used in the CMA may struggle to represent chains in a fully automated manner, requiring human intervention.\n3. The extension of DSCMs to represent more flexible, non-Markovian causal graphs is a natural avenue of future research.\n\nSuggestions for Improvement:\n\n1. Consider incorporating techniques to enable fully automated chain graph modelling in future versions of the CMA.\n2. Explore the application of the CMA to other domains beyond AD, such as finance or social sciences.\n3. Provide more details on the implementation of the LLMs used in the CMA, such as the specific architecture and training data.\n\nRecommendation:\n\nThe CMA is a significant contribution to the field of causal discovery, offering a novel and innovative approach to combining LLMs and DSCMs. While there are some limitations and areas for future research, the experimental results are compelling and demonstrate the potential of the CMA for real-world applications. I recommend accepting this paper for publication in its current form, with the caveat that the authors address the suggestions for improvement in future work.\n\n$$$",
        "gr_score_with": 0.6801075268817204,
        "gr_score_without": 0.6151685393258427,
        "output_without": {
            "num_tokens_scored": 356,
            "num_green_tokens": 219,
            "green_fraction": 0.6151685393258427,
            "z_score": -3.4927885655471473,
            "p_value": 0.9997609975886276
        },
        "output_with": {
            "num_tokens_scored": 372,
            "num_green_tokens": 253,
            "green_fraction": 0.6801075268817204,
            "z_score": -0.8372412210726251,
            "p_value": 0.7987715042956248
        }
    },
    {
        "title": "LANGUAGE-INFORMED VISUAL CONCEPT LEARNING",
        "abstract": "Our understanding of the visual world is centered around various concept axes, characterizing different aspects of visual entities. While different concept axes can be easily specified by language, e.g., color, the exact visual nuances along each axis often exceed the limitations of linguistic articulations, e.g., a particular style of painting. In this work, our goal is to learn a language-informed visual concept representation, by simply distilling large pre-trained vision-language models. Specifically, we train a set of concept encoders to encode the information pertinent to a set of language-informed concept axes, with an objective of reproducing the input image through a pre-trained Text-to-Image (T2I) model. To encourage better disentanglement of different concept encoders, we anchor the concept embeddings to a set of text embeddings obtained from a pre-trained Visual Question Answering (VQA) model. At inference time, the model extracts concept embeddings along various axes from new test images, which can be remixed to generate images with novel compositions of visual concepts. With a lightweight test-time finetuning procedure, it can also generalize to novel concepts unseen at training. Project page at https://cs.stanford.edu/ \u0303yzzhang/projects/concept-axes.",
        "peer_review_without_watermark": "$$$\\boxed{Peer Review}$$\n\n$\\boxed{Paper Summary:}$\n\nThe paper proposes a framework for learning language-informed visual concepts from images by distilling from pre-trained vision-language models. The approach involves training a set of concept encoders to extract visual concepts along specific axes specified by language, and then using these encoders to generate new images with novel concept compositions. The paper presents a comprehensive evaluation of the proposed framework, comparing it to prior work in text-based image editing and generation.\n\n$\\boxed{Strengths:}$\n\n1. The paper presents a novel approach to learning language-informed visual concepts from images, which has the potential to improve the flexibility and realism of image generation models.\n2. The evaluation of the proposed framework is thorough and comprehensive, comparing it to prior work in text-based image editing and generation.\n3. The paper provides a clear and concise explanation of the technical details of the proposed approach, making it accessible to a wide range of readers.\n4. The results presented in the paper demonstrate the effectiveness of the proposed framework in generating images with novel concept compositions.\n\n$\\boxed{Weaknesses:}$\n\n1. The paper relies heavily on pre-trained vision-language models, which may not be suitable for all applications or domains.\n2. The evaluation of the proposed framework is limited to a small set of datasets and tasks, which may not be representative of the broader applications of the approach.\n3. The paper does not provide a detailed analysis of the limitations and potential biases of the proposed framework, which may be important for understanding its potential impact.\n4. The results presented in the paper may be influenced by the specific evaluation metrics used, which may not be the best choice for assessing the performance of the proposed framework.\n\n$\\boxed{Suggestions for Improvement:}$\n\n1. The paper could benefit from a more detailed analysis of the limitations and potential biases of the proposed framework, including a discussion of the potential risks and challenges associated with relying on pre-trained vision-language models.\n2. The evaluation of the proposed framework should be expanded to include a wider range of datasets and tasks, to better represent the broader applications of the approach.\n3. The paper could provide a more detailed comparison of the proposed framework to prior work in text-based image editing and generation, including a discussion of the strengths and limitations of each approach.\n4. The results presented in the paper could be improved by using more robust evaluation metrics, such as the Frechet Inception Distance (FID) or the Inception Score (IS).\n\n$\\boxed{Recommendation:}$\n\nBased on the strengths and weaknesses of the paper, I recommend that it be accepted for publication in a top-tier conference in computer vision or artificial intelligence. The paper presents a novel and effective approach to learning language-informed visual concepts from images, and the evaluation of the proposed framework is thorough and comprehensive. However, the paper could benefit from a more detailed analysis of the limitations and potential biases of the approach, as well as a more detailed comparison to prior work in the field.",
        "peer_review_with_watermark": "$$$ \n\nPaper Summary:\nThe paper proposes a framework for learning language-informed visual concepts from images by distilling pre-trained vision-language models. The approach consists of training a set of concept encoders that extract visual concepts along specific axes specified by language. These concept embeddings can be remixed to generate images with novel concept compositions. The proposed method is evaluated on various tasks, including visual concept extraction, recomposition, and extrapolation, as well as comparison with prior works.\n\nStrengths:\n1. The approach is innovative in leveraging pre-trained vision-language models to distill language-informed visual concepts.\n2. The method is well-structured, and the authors provide clear explanations of the architecture and training objectives.\n3. The evaluation results show that the proposed approach outperforms prior works in visual concept editing tasks.\n\nWeaknesses:\n1. The training dataset is limited, which may impact the generalizability of the proposed method.\n2. The evaluation metrics used may not fully capture the complexity of visual concept editing tasks.\n3. Some parts of the paper, such as the discussion on prior works, may benefit from more concise and clear explanations.\n\nSuggestions for Improvement:\n1. Provide more detailed explanations of the training objectives and optimization procedures.\n2. Evaluate the proposed method on more diverse datasets to assess its generalizability.\n3. Consider incorporating additional evaluation metrics to provide a more comprehensive assessment of the approach's performance.\n\nRecommendation:\nThe proposed method is an innovative approach to learning language-informed visual concepts from images. While there are some limitations and areas for improvement, the evaluation results demonstrate that the approach can achieve superior performance in visual concept editing tasks. With further refinement and evaluation, this method has the potential to contribute to the field of computer vision and visual concept learning.\n\n $$$",
        "gr_score_with": 0.712280701754386,
        "gr_score_without": 0.6330532212885154,
        "output_without": {
            "num_tokens_scored": 357,
            "num_green_tokens": 226,
            "green_fraction": 0.6330532212885154,
            "z_score": -2.760286399223025,
            "p_value": 0.9971124645403051
        },
        "output_with": {
            "num_tokens_scored": 285,
            "num_green_tokens": 203,
            "green_fraction": 0.712280701754386,
            "z_score": 0.45241392835886407,
            "p_value": 0.3254854073844565
        }
    },
    {
        "title": "RAPPER: REINFORCED RATIONALE-PROMPTED PARADIGM FOR NATURAL LANGUAGE EXPLANATION IN VISUAL QUESTION ANSWERING",
        "abstract": "Natural Language Explanation (NLE) in vision and language tasks aims to provide human-understandable explanations for the associated decision-making process. In practice, one might encounter explanations which lack informativeness or contradict visual-grounded facts, known as implausibility and hallucination problems, respectively. To tackle these challenging issues, we consider the task of visual question answering (VQA) and introduce Rapper, a two-stage Reinforced RationalePrompted Paradigm. By knowledge distillation, the former stage of Rapper infuses rationale-prompting via large language models (LLMs), encouraging the rationales supported by language-based facts. As for the latter stage, a unique Reinforcement Learning from NLE Feedback (RLNF) is introduced for injecting visual facts into NLE generation. Finally, quantitative and qualitative experiments on two VL-NLE benchmarks show that RAPPER surpasses state-of-the-art VQA-NLE methods while providing plausible and faithful NLE.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$\\text{Paper Summary:}$$\nThe paper proposes Rapper, a two-stage Reinforced Rationale-Prompted Paradigm for enabling Natural Language Explanation (NLE) with sufficient plausible and faithful properties in Visual Question Answering (VQA). Rapper first distills language-based knowledge from Large Language Models (LLMs) and then utilizes Reinforcement Learning from NLE Feedback (RLNF) to inject visual facts into NLE generation. The proposed method achieves new state-of-the-art performance on two VL-NLE benchmarks and demonstrates reduced implausibility and hallucination.\n\n$$\\text{Strengths:}$$\n1. The paper introduces a novel two-stage paradigm that effectively integrates language-based knowledge and visual facts into NLE generation.\n2. Rapper's use of RLNF enables the model to generate faithful NLEs, reducing hallucinations and implausibility.\n3. The paper presents quantitative and qualitative experiments on two VL-NLE benchmarks, demonstrating the effectiveness of Rapper.\n4. The proposed method outperforms existing state-of-the-art VQA-NLE methods in terms of plausibility and faithfulness.\n\n$$\\text{Weaknesses:}$$\n1. The paper does not provide a clear comparison with other state-of-the-art methods in terms of NLE metrics, such as CIDEr and SPICE.\n2. The evaluation metrics used may not fully capture the nuances of NLE quality, such as RefCLIPScore.\n3. The paper does not discuss potential limitations or challenges of Rapper, such as the requirement for large amounts of labeled data for training RLNF.\n4. The proposed method may not be applicable to all types of VQA tasks, such as those with complex or abstract concepts.\n\n$$\\text{Suggestions for Improvement:}$$\n1. Provide a more comprehensive comparison with other state-of-the-art methods in terms of NLE metrics.\n2. Use more robust evaluation metrics that capture the nuances of NLE quality.\n3. Discuss potential limitations and challenges of Rapper, such as the requirement for large amounts of labeled data for training RLNF.\n4. Investigate the applicability of Rapper to other types of VQA tasks, such as those with complex or abstract concepts.\n\n$$\\text{Recommendation:}$$\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit their work for consideration in a top-tier conference or journal. The proposed method of Rapper has the potential to significantly improve the quality of NLE in VQA tasks, and the authors should continue to explore and refine their approach to address the limitations and challenges identified in the review.",
        "peer_review_with_watermark": "$$\\begin{align}\\tag{1} \nPaper Summary: \nThe paper proposes a two-stage Reinforced Rationale-Prompted Paradigm called Rapper for providing accurate answers for Visual Question Answering (VQA) with sufficient Natural Language Explanation (NLE). The first stage uses knowledge distillation from a large language model (LLM) to enrich the rationales with supporting facts, and the second stage employs Reinforcement Learning from NLE Feedback (RLNF) to inject visual facts into NLE generation.\n\nStrengths: \n1. The proposed Rapper paradigm effectively tackles the challenges of implausibility and hallucination in NLE generation by leveraging knowledge distillation and RLNF.\n2. The use of LLM-based knowledge distillation enables the generation of fact-based rationales, which improve the plausibility of NLE.\n3. The RLNF stage effectively injects visual facts into NLE generation, leading to more faithful and accurate NLE.\n\nWeaknesses: \n1. The paper relies heavily on the use of pre-trained LLMs, which may not generalize well to unseen data.\n2. The proposed Rapper paradigm may be computationally expensive due to the two-stage training process.\n3. The paper does not provide a comprehensive analysis of the effectiveness of Rapper on different VQA datasets and tasks.\n\nSuggestions for Improvement: \n1. The authors should provide more detailed analysis of the effectiveness of Rapper on different VQA datasets and tasks.\n2. The authors should investigate the use of transfer learning and domain adaptation techniques to improve the generalizability of the proposed Rapper paradigm.\n3. The authors should provide more detailed analysis of the computational costs and resource requirements of the proposed Rapper paradigm.\n\nRecommendation: \nBased on the paper summary, strengths, weaknesses, and suggestions for improvement, I recommend that the authors revise and resubmit the paper for review. The authors should provide more comprehensive analysis and detailed analysis of the effectiveness of Rapper on different VQA datasets and tasks, as well as investigate the use of transfer learning and domain adaptation techniques to improve the generalizability of the proposed Rapper paradigm.\n\n$$\\tag{2}$$",
        "gr_score_with": 0.8052805280528053,
        "gr_score_without": 0.7398373983739838,
        "output_without": {
            "num_tokens_scored": 369,
            "num_green_tokens": 273,
            "green_fraction": 0.7398373983739838,
            "z_score": 1.6699155326479413,
            "p_value": 0.04746803836487808
        },
        "output_with": {
            "num_tokens_scored": 303,
            "num_green_tokens": 244,
            "green_fraction": 0.8052805280528053,
            "z_score": 3.9990765867971314,
            "p_value": 3.1795050926096046e-05
        }
    },
    {
        "title": "MOVINGPARTS: MOTION-BASED 3D PART DISCOV-",
        "abstract": "We present MovingParts, a NeRF-based method for dynamic scene reconstruction and part discovery. We consider motion as an important cue for identifying parts, that all particles on the same part share the common motion pattern. From the perspective of fluid simulation, existing deformation-based methods for dynamic NeRF can be seen as parameterizing the scene motion under the Eulerian view, i.e., focusing on specific locations in space through which the fluid flows as time passes. However, it is intractable to extract the motion of constituting objects or parts using the Eulerian view representation. In this work, we introduce the dual Lagrangian view and enforce representations under the Eulerian/Lagrangian views to be cycle-consistent. Under the Lagrangian view, we parameterize the scene motion by tracking the trajectory of particles on objects. The Lagrangian view makes it convenient to discover parts by factorizing the scene motion as a composition of part-level rigid motions. Experimentally, our method can achieve fast and high-quality dynamic scene reconstruction from even a single moving camera, and the induced part-based representation allows direct applications of part tracking, animation, 3D scene editing, etc.",
        "peer_review_without_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes a novel NeRF-based approach called MovingParts for dynamic scene reconstruction and part discovery from monocular input. The approach uses a hybrid representation of feature volume and neural network to achieve both high-quality reconstruction and reasonable part discovery within 30 minutes. The method consists of three modules: a canonical module, an Eulerian module, and a Lagrangian module. The Eulerian module records the motion of particles in the scene, while the Lagrangian module tracks the trajectory of particles and discovers parts by factorizing the scene motion as a composition of part-level rigid motions. The approach is evaluated on the D-NeRF 360\u25e6 synthetic dataset and achieves state-of-the-art results.\n\n$\\boxed{Strengths:}\n1. The approach uses a novel hybrid representation of feature volume and neural network to achieve both high-quality reconstruction and reasonable part discovery within 30 minutes.\n2. The method consists of three modules: a canonical module, an Eulerian module, and a Lagrangian module, which enables the discovery of parts by factorizing the scene motion as a composition of part-level rigid motions.\n3. The approach is evaluated on the D-NeRF 360\u25e6 synthetic dataset and achieves state-of-the-art results.\n4. The method is capable of overlooking motion-irrelevant characteristics in geometry and appearance and producing clean part discovery results on realistic complex scenes.\n\n$\\boxed{Weaknesses:}\n1. The approach explicitly stores the motion features in low-dimensional vectors, which makes it challenging to model motion on very long sequences.\n2. The method may not be suitable for scenes with complex motion patterns, as the motion grouping algorithm may not be able to distinguish between different motion modes.\n3. The approach relies on the assumption of finite rigid bodies, which may not hold in all cases.\n4. The method may not be able to handle scenes with non-rigid objects, as the part discovery algorithm may not be able to distinguish between different parts.\n\n$\\boxed{Suggestions for Improvement:}\n1. Develop a unified long sequence encoding-decoding scheme to model motion on very long sequences.\n2. Improve the motion grouping algorithm to distinguish between different motion modes in complex scenes.\n3. Investigate the use of other motion models, such as particle-based motion models, to improve the robustness of the approach.\n4. Develop a method to handle scenes with non-rigid objects and complex motion patterns.\n\n$\\boxed{Recommendation:}\nThe approach proposed in the paper is a significant contribution to the field of dynamic scene reconstruction and part discovery. However, there are some limitations and weaknesses that need to be addressed. With some improvements and modifications, the approach has the potential to be a state-of-the-art method in the field.",
        "peer_review_with_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes a novel NeRF-based method called MovingParts, which enables the simultaneous reconstruction of dynamic scenes and the discovery of rigid parts from monocular images. The method uses a hybrid representation of feature volume and neural network and adopts a cycle-consistency loss to ensure that the Eulerian and Lagrangian views are reciprocal. The paper also presents a group merging algorithm to address the issue of over-segmentation.\n\nStrengths:\n\n* The paper presents a novel and effective approach to dynamic scene reconstruction and part discovery.\n* The use of a hybrid representation and cycle-consistency loss enables efficient and accurate reconstruction.\n* The group merging algorithm addresses the issue of over-segmentation and improves the quality of part discovery.\n\nWeaknesses:\n\n* The method relies on the assumption that the scene is piece-wise rigid, which may not hold in all cases.\n* The paper does not provide a comprehensive analysis of the limitations and potential issues of the method.\n* The experiment results are not extensively discussed, and the comparison with other methods is limited.\n\nSuggestions for Improvement:\n\n* The paper should provide a more comprehensive analysis of the limitations and potential issues of the method.\n* The experiment results should be more extensively discussed, and the comparison with other methods should be more thorough.\n* The paper should also discuss the potential applications and use cases of the method.\n\nRecommendation:\n\n* The paper presents a novel and effective approach to dynamic scene reconstruction and part discovery. However, the limitations and potential issues of the method should be more thoroughly analyzed.\n* The experiment results should be more extensively discussed, and the comparison with other methods should be more thorough.\n* The paper should also discuss the potential applications and use cases of the method.\n\n$$\\boxed{Weaknesses and Suggestions:}\nThe paper has several weaknesses that need to be addressed. Firstly, the method relies on the assumption that the scene is piece-wise rigid, which may not hold in all cases. This assumption can lead to over-segmentation and poor part discovery results. To address this issue, the authors should provide more robust methods to handle non-rigid scenes.\n\nSecondly, the paper does not provide a comprehensive analysis of the limitations and potential issues of the method. The authors should discuss the limitations of the method, such as the requirement of monocular input, the assumption of piece-wise rigidity, and the potential issues with long sequence modeling.\n\nThirdly, the experiment results are not extensively discussed, and the comparison with other methods is limited. The authors should provide more detailed analysis of the experiment results and compare their method with other state-of-the-art methods.\n\nFourthly, the paper should also discuss the potential applications and use cases of the method. The authors should provide more insights on how the method can be used in real-world scenarios, such as scene editing, structured scene modeling, and robotic manipulation.\n\nTo address these weaknesses, the authors can follow the following suggestions:\n\n* Provide more robust methods to handle non-rigid scenes.\n* Conduct a comprehensive analysis of the limitations and potential issues of the method.\n* Provide more detailed analysis of the experiment results and compare their method with other state-of-the-art methods.\n* Discuss the potential applications and use cases of the method.\n\nBy addressing these weaknesses and providing more comprehensive analysis, the paper can be strengthened and provide more valuable contributions to the field.\n\n$$\\boxed{Recommendation:}\nBased on the analysis, I recommend that the authors revise the paper to address the weaknesses and provide more comprehensive analysis. The revised paper should include more robust methods to handle non-rigid scenes, a comprehensive analysis of the limitations and potential issues of the method, more detailed analysis of the experiment results, and a discussion of the potential applications and use cases of the method.",
        "gr_score_with": 0.8461538461538461,
        "gr_score_without": 0.7420289855072464,
        "output_without": {
            "num_tokens_scored": 345,
            "num_green_tokens": 256,
            "green_fraction": 0.7420289855072464,
            "z_score": 1.70352616072142,
            "p_value": 0.044234823277072656
        },
        "output_with": {
            "num_tokens_scored": 390,
            "num_green_tokens": 330,
            "green_fraction": 0.8461538461538461,
            "z_score": 6.298438669252061,
            "p_value": 1.5032931997874203e-10
        }
    },
    {
        "title": "DMBP: DIFFUSION MODEL-BASED PREDICTOR FOR RO- BUST OFFLINE REINFORCEMENT LEARNING AGAINST STATE OBSERVATION PERTURBATIONS",
        "abstract": "Offline reinforcement learning (RL), which aims to fully explore offline datasets for training without interaction with environments, has attracted growing recent attention. A major challenge for the real-world application of offline RL stems from the robustness against state observation perturbations, e.g., as a result of sensor errors or adversarial attacks. Unlike online robust RL, agents cannot be adversarially trained in the offline setting. In this work, we propose Diffusion Model-Based Predictor (DMBP) in a new framework that recovers the actual states with conditional diffusion models for state-based RL tasks. To mitigate the error accumulation issue in model-based estimation resulting from the classical training of conventional diffusion models, we propose a non-Markovian training objective to minimize the sum entropy of denoised states in RL trajectory. Experiments on standard benchmark problems demonstrate that DMBP can significantly enhance the robustness of existing offline RL algorithms against different scales of random noises and adversarial attacks on state observations. Further, the proposed framework can effectively deal with incomplete state observations with random combinations of multiple unobserved dimensions in the test. Our implementation is available at https://github.com/zhyang2226/DMBP",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary:\nThe paper proposes a novel framework called Diffusion Model-Based Predictor (DMBP) for offline reinforcement learning (RL) against state observation perturbations. DMBP uses a conditional diffusion model to recover the actual state from noisy observations, and a non-Markovian loss function to mitigate error accumulation during test. The proposed framework is evaluated on D4RL benchmarks and demonstrates significant enhancements in robustness against different scales of random noises and adversarial attacks.\n\nStrengths:\n- The paper introduces a new framework for offline RL against state observation perturbations.\n- The proposed non-Markovian loss function effectively mitigates error accumulation during test.\n- The framework is evaluated on D4RL benchmarks and shows promising results.\n\nWeaknesses:\n- The paper does not provide a detailed analysis of the proposed non-Markovian loss function and its relationship with classical diffusion models.\n- The evaluation on D4RL benchmarks is limited to a few environments and datasets.\n- The paper does not provide a comprehensive comparison with existing offline RL algorithms.\n\nSuggestions for Improvement:\n- Provide a more detailed analysis of the proposed non-Markovian loss function and its relationship with classical diffusion models.\n- Conduct a comprehensive evaluation on a wider range of environments and datasets.\n- Compare the proposed framework with existing offline RL algorithms to demonstrate its superiority.\n\nRecommendation:\nThe paper proposes a novel framework for offline RL against state observation perturbations, and the proposed non-Markovian loss function shows promise in mitigating error accumulation during test. However, further evaluation and comparison with existing offline RL algorithms are necessary to fully validate the proposed framework.",
        "peer_review_with_watermark": "$$\\text{Paper Title: DMBP: DIFFUSION MODEL-BASED PREDICTOR FOR RO- BUST OFFLINE REINFORCEMENT LEARNING AGAINST STATE OBSERVATION PERTURBATIONS}\\$$\n\n$$\\text{Summary: }$$ This paper proposes a new framework called DMBP, which uses a conditional diffusion model to predict the actual state for decision-making in offline reinforcement learning tasks. The proposed framework leverages the ability of diffusion models to infill missing regions, making it suitable for dealing with incomplete state observations. DMBP can effectively enhance the robustness of existing offline RL algorithms against different scales of random noises and even adversarial attacks. The authors present experimental results on D4RL benchmarks, demonstrating the effectiveness of DMBP in various settings.\n\n$$\\text{Strengths: }$$\n\n1. **Novel contribution:** DMBP introduces a new approach for state denoising in offline RL, which can be beneficial for real-world applications.\n2. **Effective in dealing with incomplete state observations:** DMBP's ability to infill missing state information makes it suitable for handling incomplete observations.\n3. **Robustness against perturbations:** DMBP can effectively enhance the robustness of existing offline RL algorithms against random noises and even adversarial attacks.\n4. **Non-Markovian loss function:** The proposed non-Markovian loss function can mitigate error accumulation during test, improving the overall robustness of the framework.\n\n$$\\text{Weaknesses: }$$\n\n1. **Complexity:** DMBP's architecture may be complex, requiring significant computational resources for training.\n2. **Limited experiments:** While the authors present results on D4RL benchmarks, further experiments on other benchmarks and environments may be needed to fully evaluate the framework's effectiveness.\n3. **Limited discussion on theoretical foundations:** The paper could benefit from a more in-depth discussion on the theoretical foundations of the proposed framework, particularly the non-Markovian loss function.\n4. **Comparison with other methods:** A comparison with other state-denoising methods or robust RL frameworks may provide a more comprehensive understanding of the framework's strengths and weaknesses.\n\n$$\\text{Suggestions for Improvement: }$$\n\n1. **Experiments on other benchmarks:** Conduct experiments on other benchmarks, such as Adroit and Franka Kitchen, to further evaluate the framework's effectiveness.\n2. **Theoretical foundations:** Provide a more in-depth discussion on the theoretical foundations of the proposed framework, particularly the non-Markovian loss function.\n3. **Comparison with other methods:** Compare DMBP with other state-denoising methods or robust RL frameworks to provide a more comprehensive understanding of the framework's strengths and weaknesses.\n4. **Hyperparameter tuning:** Perform hyperparameter tuning to optimize the framework's performance on various benchmarks and environments.\n\n$$\\text{Recommendation: }$$ Based on the experimental results and the framework's ability to effectively enhance the robustness of existing offline RL algorithms, I recommend considering DMBP as a viable option for real-world applications. However, further experiments and theoretical discussions are needed to fully understand the framework's limitations and potential improvements.",
        "gr_score_with": 0.7737226277372263,
        "gr_score_without": 0.6572769953051644,
        "output_without": {
            "num_tokens_scored": 213,
            "num_green_tokens": 140,
            "green_fraction": 0.6572769953051644,
            "z_score": -1.3606359555159775,
            "p_value": 0.913185618472087
        },
        "output_with": {
            "num_tokens_scored": 411,
            "num_green_tokens": 318,
            "green_fraction": 0.7737226277372263,
            "z_score": 3.261460102789165,
            "p_value": 0.0005542001462989307
        }
    },
    {
        "title": "RDESIGN: HIERARCHICAL DATA-EFFICIENT REPRE-",
        "abstract": "While artificial intelligence has made remarkable strides in revealing the relationship between biological macromolecules\u2019 primary sequence and tertiary structure, designing RNA sequences based on specified tertiary structures remains challenging. Though existing approaches in protein design have thoroughly explored structure-to-sequence dependencies in proteins, RNA design still confronts difficulties due to structural complexity and data scarcity. Moreover, direct transplantation of protein design methodologies into RNA design fails to achieve satisfactory outcomes although sharing similar structural components. In this study, we aim to systematically construct a data-driven RNA design pipeline. We crafted a large, well-curated benchmark dataset and designed a comprehensive structural modeling approach to represent the complex RNA tertiary structure. More importantly, we proposed a hierarchical data-efficient representation learning framework that learns structural representations through contrastive learning at both clusterlevel and sample-level to fully leverage the limited data. By constraining data representations within a limited hyperspherical space, the intrinsic relationships between data points could be explicitly imposed. Moreover, we incorporated extracted secondary structures with base pairs as prior knowledge to facilitate the RNA design process. Extensive experiments demonstrate the effectiveness of our proposed method, providing a reliable baseline for future RNA design tasks. The source code and benchmark dataset are available at github.com/A4Bio/RDesign.",
        "peer_review_without_watermark": "$$$\\begin{align}\\textbf{Paper Summary:} &\\quad The authors propose a hierarchical data-efficient representation learning framework for designing RNA tertiary structures. They compile a large-scale RNA tertiary structure dataset and develop a comprehensive structural modeling approach to represent the complex RNA tertiary structure. The proposed framework incorporates extracted secondary structures with base pairs as prior knowledge to facilitate the RNA design process. Extensive experiments demonstrate the effectiveness of the proposed method.\n\n\\textbf{Strengths:} &\\quad The authors have made significant contributions to the field of RNA design by proposing a hierarchical data-efficient representation learning framework. The framework explicitly captures the intrinsic relationships within the data while constraining the limited data to a restricted hyperspherical space. The incorporation of extracted secondary structures with base pairs as prior knowledge is also a valuable addition to the framework.\n\n\\textbf{Weaknesses:} &\\quad The authors rely heavily on the availability of high-quality RNA tertiary structure data, which may not be universally accessible. The proposed framework may not generalize well to new, unseen data. Additionally, the secondary structure constraining strategy may not be effective for all types of RNA structures.\n\n\\textbf{Suggestions for Improvement:} &\\quad To improve the robustness of the proposed framework, the authors could explore the use of transfer learning or domain adaptation techniques to adapt the framework to new data distributions. Additionally, the authors could investigate the use of other prior knowledge, such as thermodynamic parameters or evolutionary conservation, to further improve the framework.\n\n\\textbf{Recommendation:} &\\quad The proposed framework is an important contribution to the field of RNA design. However, further work is needed to address the limitations and challenges associated with the framework. The authors should continue to explore and refine their framework to improve its robustness and generalizability.\n\n\\textbf{Additional Comments:} &\\quad The paper provides a clear and concise overview of the proposed framework and its applications. The experimental results demonstrate the effectiveness of the framework, and the authors have provided a thorough analysis of the strengths and weaknesses of their approach. However, the paper could benefit from a more detailed discussion of the limitations and challenges associated with the framework, as well as suggestions for future work.\n\n\\textbf{Technical Comments:} &\\quad The paper is well-written and free of major technical errors. However, there are a few minor issues that need to be addressed. For example, the authors could provide more detail on the hyperparameter tuning procedure for the proposed framework, as well as the evaluation metrics used to assess its performance.\n\n\\textbf{Conclusion:} &\\quad In conclusion, the proposed framework is an important contribution to the field of RNA design. While there are some limitations and challenges associated with the framework, the authors have demonstrated its effectiveness through extensive experiments. Further work is needed to address these limitations and improve the robustness and generalizability of the framework.\n\n\\textbf{Recommendation to Authors:} &\\quad The authors should continue to refine their framework and explore new applications and extensions. They should also investigate ways to address the limitations and challenges associated with the framework, such as transfer learning or domain adaptation techniques.\n\n\\textbf{Recommendation to Editor:} &\\quad The paper is well-written and provides a clear and concise overview of the proposed framework and its applications. The experimental results demonstrate the effectiveness of the framework, and the authors have provided a thorough analysis of the strengths and weaknesses of their approach. However, further work is needed to address the limitations and challenges associated with the framework.\n\n\\textbf{Final Recommendation:} &\\quad The paper is accepted for publication in its current form. However, the authors are encouraged to address the limitations and challenges associated with the framework and to continue refining their approach.\n\n$$\\end{align}$$",
        "peer_review_with_watermark": "$$$\\begin{align}\\textbf{Paper Summary:}\\quad \\textbf{This paper proposes RDESIGN, a hierarchical data-efficient RNA design pipeline.}\\quad \\textbf{The authors develop a comprehensive RNA tertiary structure modeling approach and a hierarchical data-efficient representation learning framework.}\\quad \\textbf{They also introduce a secondary structure imposing strategy to leverage extra structural information.}\\quad \\textbf{Extensive experiments are conducted to demonstrate the effectiveness of the proposed RDESIGN model.}\\quad \\textbf{Results show that RDESIGN outperforms other methods in designing RNA sequences with structures similar to the target structure.}\\quad \\textbf{Limitations are discussed, including the need for wet-lab validation.}\\quad \\textbf{Overall, the paper provides a new perspective on tertiary structure-based RNA design.}\\quad \\textbf{Key contributions:}\\quad \\textbf{comprehensive RNA tertiary structure modeling approach, hierarchical data-efficient representation learning framework, and secondary structure imposing strategy.}\\quad \\textbf{Methodological contributions:}\\quad \\textbf{hierarchical representation learning, hyperspherical space, and secondary structure imposing strategy.}\\quad \\textbf{Impact:}\\quad \\textbf{this work provides a new perspective on RNA design and can be used as a starting point for further research.}\\quad \\textbf{Potential applications:}\\quad \\textbf{RNA design for various biological applications, such as gene regulation and protein-protein interaction.}\\quad \\textbf{Future directions:}\\quad \\textbf{wet-lab validation, RNA structure prediction tools, and RNA design for specific biological applications.}\\quad \\textbf{Limitations:}\\quad \\textbf{the method is currently limited to in silico design, and further research is needed to validate the results.}\\quad \\textbf{Implications:}\\quad \\textbf{this work demonstrates the feasibility of RNA design and provides a foundation for further research.}\\quad \\textbf{Overall, the paper provides a thorough and systematic approach to RNA design and contributes to the field of RNA biology.}\\quad \\textbf{Strengths:}\\quad \\textbf{comprehensive approach, hierarchical representation learning, and secondary structure imposing strategy.}\\quad \\textbf{Weaknesses:}\\quad \\textbf{the method is currently limited to in silico design, and further research is needed to validate the results.}\\quad \\textbf{Suggestions for improvement:}\\quad \\textbf{conducting wet-lab validation, exploring RNA structure prediction tools, and designing RNA sequences for specific biological applications.}\\quad \\textbf{Recommendation:}\\quad \\textbf{this work is a significant contribution to the field of RNA biology and provides a new perspective on RNA design.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{In conclusion, RDESIGN is a comprehensive and systematic approach to RNA design, and its contributions and implications are significant.}\\quad \\textbf{Overall, the paper is a valuable contribution to the field of RNA biology.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{Recommendation:}\\quad \\textbf{this work is a significant contribution to the field of RNA biology and provides a new perspective on RNA design.}\\quad \\textbf{Overall, the paper is a valuable contribution to the field of RNA biology.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the methods and results.}\\quad \\textbf{However, the limitations of the method need to be addressed in further research.}\\quad \\textbf{Rating:}\\quad \\textbf{8/10.}\\quad \\textbf{Overall, the paper is well-written, well-organized, and provides a thorough summary of the",
        "gr_score_with": 0.8207547169811321,
        "gr_score_without": 0.703962703962704,
        "output_without": {
            "num_tokens_scored": 429,
            "num_green_tokens": 302,
            "green_fraction": 0.703962703962704,
            "z_score": 0.17910620335162541,
            "p_value": 0.4289271556003214
        },
        "output_with": {
            "num_tokens_scored": 318,
            "num_green_tokens": 261,
            "green_fraction": 0.8207547169811321,
            "z_score": 4.699027828571856,
            "p_value": 1.3070141840968952e-06
        }
    },
    {
        "title": "SWAP: SPARSE ENTROPIC WASSERSTEIN REGRESSION FOR ROBUST NETWORK PRUNING",
        "abstract": "This study addresses the challenge of inaccurate gradients in computing the empirical Fisher Information Matrix during neural network pruning. We introduce SWAP, a formulation of Entropic Wasserstein regression (EWR) for pruning, capitalizing on the geometric properties of the optimal transport problem. The \u201cswap\u201d of the commonly used linear regression with the EWR in optimization is analytically demonstrated to offer noise mitigation effects by incorporating neighborhood interpolation across data points with only marginal additional computational cost. The unique strength of SWAP is its intrinsic ability to balance noise reduction and covariance information preservation effectively. Extensive experiments performed on various networks and datasets show comparable performance of SWAP with state-of-the-art (SoTA) network pruning algorithms. Our proposed method outperforms the SoTA when the network size or the target sparsity is large, the gain is even larger with the existence of noisy gradients, possibly from noisy data, analog memory, or adversarial attacks. Notably, our proposed method achieves a gain of 6% improvement in accuracy and 8% improvement in testing loss for MobileNetV1 with less than one-fourth of the network parameters remaining.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces SWAP, a novel sparse entropic Wasserstein regression pruning method for neural network pruning. SWAP formulates the pruning problem as a mixed-integer quadratic programming (MIQP) problem and leverages the entropic Wasserstein regression (EWR) framework to balance covariance information preservation and noise reduction. The method is compared with several state-of-the-art (SoTA) pruning algorithms on various pre-trained neural networks, demonstrating its effectiveness in achieving robust pruning and improved model performance.\n\nStrengths:\n\n1.  Novel formulation: SWAP provides a novel approach to pruning neural networks by leveraging the EWR framework, which strikes a balance between covariance information preservation and noise reduction.\n2.  Robustness to noise: SWAP is shown to be robust to noisy gradients, which is a common challenge in neural network pruning.\n3.  Competitive performance: SWAP is compared with several SoTA pruning algorithms and demonstrates competitive performance on various pre-trained neural networks.\n\nWeaknesses:\n\n1.  Complexity: SWAP is a mixed-integer quadratic programming (MIQP) problem, which can be computationally expensive to solve.\n2.  Hyperparameter tuning: The performance of SWAP may depend on the choice of hyperparameters, such as the regularization parameter \u03bb and the step size \u03c4.\n3.  Limited exploration: The paper may benefit from further exploration of practical implementations and empirical validation of SWAP on a wider range of datasets and neural networks.\n\nSuggestions for Improvement:\n\n1.  Simplify the formulation: Consider simplifying the MIQP formulation to reduce computational complexity.\n2.  Hyperparameter tuning: Provide guidance on hyperparameter tuning and suggest ways to optimize the performance of SWAP.\n3.  Exploration of practical implementations: Explore the practical implementation of SWAP and provide insights into its potential applications.\n\nRecommendation:\n\n1.  SWAP is a promising approach to pruning neural networks, offering a novel formulation that balances covariance information preservation and noise reduction.\n2.  Further empirical validation and exploration of practical implementations are necessary to fully realize the potential of SWAP.\n3.  The paper provides a solid foundation for further research on SWAP and its applications in large-scale model compression.",
        "peer_review_with_watermark": "$$$ Paper Summary:\nThe paper introduces SWAP, a novel sparse entropic Wasserstein regression pruning method, which effectively balances noise reduction and covariance information preservation. It is designed to address the challenge of inaccurate gradients in computing the empirical Fisher Information Matrix during neural network pruning. The proposed method is based on the entropic Wasserstein regression (EWR) framework, which leverages Wasserstein distance to model the dissimilarity between two distributions. \n\nStrengths:\n- SWAP effectively balances noise reduction and covariance information preservation.\n- It is designed to address the challenge of inaccurate gradients in computing the empirical Fisher Information Matrix during neural network pruning.\n- The proposed method is based on the entropic Wasserstein regression (EWR) framework, which is a novel approach.\n- It is compared with several existing state-of-the-art (SoTA) methods, including MP, WF, CBS, and LR.\n\nWeaknesses:\n- The paper lacks a detailed comparison with existing methods on smaller models or datasets.\n- Some results, such as Table 1, are not provided in the text, but are mentioned in the appendix.\n- There is no discussion on potential overfitting or underfitting issues in the proposed method.\n- Some details, such as the implementation of the algorithm, are not provided in the text.\n\nSuggestions for Improvement:\n- Include more results on smaller models or datasets to provide a more comprehensive comparison with existing methods.\n- Provide more details on potential overfitting or underfitting issues in the proposed method.\n- Include more results on the convergence rate or time complexity of the proposed algorithm.\n- Discuss potential applications of the proposed method in real-world scenarios.\n\nRecommendation:\nThe proposed method, SWAP, is a novel approach that effectively balances noise reduction and covariance information preservation. It is compared with several existing state-of-the-art methods, including MP, WF, CBS, and LR. The method is designed to address the challenge of inaccurate gradients in computing the empirical Fisher Information Matrix during neural network pruning. However, more results on smaller models or datasets, potential overfitting or underfitting issues, and potential applications in real-world scenarios are needed to provide a more comprehensive evaluation of the proposed method.",
        "gr_score_with": 0.7967479674796748,
        "gr_score_without": 0.6428571428571429,
        "output_without": {
            "num_tokens_scored": 322,
            "num_green_tokens": 207,
            "green_fraction": 0.6428571428571429,
            "z_score": -2.237588595137279,
            "p_value": 0.9873760520140384
        },
        "output_with": {
            "num_tokens_scored": 246,
            "num_green_tokens": 196,
            "green_fraction": 0.7967479674796748,
            "z_score": 3.311309355481074,
            "p_value": 0.00046430244789402584
        }
    },
    {
        "title": "DRM: MASTERING VISUAL REINFORCEMENT LEARN-",
        "abstract": "Visual reinforcement learning (RL) has shown promise in continuous control tasks. Despite its progress, current algorithms are still unsatisfactory in virtually every aspect of the performance such as sample efficiency, asymptotic performance, and their robustness to the choice of random seeds. In this paper, we identify a major shortcoming in existing visual RL methods that is the agents often exhibit sustained inactivity during early training, thereby limiting their ability to explore effectively. Expanding upon this crucial observation, we additionally unveil a significant correlation between the agents\u2019 inclination towards motorically inactive exploration and the absence of neuronal activity within their policy networks. To quantify this inactivity, we adopt dormant ratio (Sokar et al., 2023) as a metric to measure inactivity in the RL agent\u2019s network. Empirically, we also recognize that the dormant ratio can act as a standalone indicator of an agent\u2019s activity level, regardless of the received reward signals. Leveraging the aforementioned insights, we introduce DrM , a method that uses three core mechanisms to guide agents\u2019 exploration-exploitation trade-offs by actively minimizing the dormant ratio. Experiments demonstrate that DrM achieves significant improvements in sample efficiency and asymptotic performance with no broken seeds (76 seeds in total) across three continuous control benchmark environments, including DeepMind Control Suite, MetaWorld, and Adroit. Most importantly, DrM is the first model-free algorithm that consistently solves tasks in both the Dog and Manipulator domains from the DeepMind Control Suite as well as three dexterous hand manipulation tasks without demonstrations in Adroit, all based on pixel observations. 1 0% 20% 40% 60% 80% 100% Training Progress 0 100 200 300 400 500 600 Ep iso de R ew ar d Deepmind Control Suite (8 Hard Tasks) 0% 20% 40% 60% 80% 100% Training Progress 0% 20% 40% 60% 80% 100% Su cc es s R at e MetaWorld (8 Tasks) 0% 20% 40% 60% 80% 100% Training Progress 0% 20% 40% 60% 80% 100% Su cc es s R at e Adroit (3 Tasks) DrM DrQ-v2 ALIX TACO Figure 1: Success rate and episode reward as a function of training progress for each of the three domains that we consider (Deepmind Control Suite, MetaWorld, Adroit). All results are averaged over 4 random seeds, and the shaded region stands for standard deviation across different random seeds.",
        "peer_review_without_watermark": "$$\\boxed{\\text{Paper Summary:}  \nThe paper proposes a novel approach called DrM (Dormant Ratio Minimization), which aims to address the sample efficiency challenge in visual reinforcement learning (RL) by leveraging the dormant ratio. The dormant ratio is a metric that measures the inactivity of a neural network, and the authors show that it is correlated with the agent's behavioral variety and exploration-exploitation trade-off. DrM introduces three mechanisms to guide the agent's exploration-exploitation trade-off: dormant-ratio-guided perturbation, awaken exploration, and dormant-ratio-guided exploitation. The authors evaluate DrM on three visual continuous control benchmarks and demonstrate its superiority over state-of-the-art baselines in terms of sample efficiency and asymptotic performance.\n\nStrengths:\n\n1. The paper introduces a novel approach to addressing the sample efficiency challenge in visual RL, which is a significant problem in the field.\n2. The authors provide a clear and concise explanation of the dormant ratio and its correlation with the agent's behavioral variety and exploration-exploitation trade-off.\n3. The proposed mechanisms of DrM are well-designed and effective in guiding the agent's exploration-exploitation trade-off.\n4. The authors provide extensive experimental results to demonstrate the superiority of DrM over state-of-the-art baselines.\n\nWeaknesses:\n\n1. The paper may be too long and dense, making it difficult for non-experts to follow.\n2. Some of the notation and terminology used in the paper may be unfamiliar to readers without a strong background in RL and neuroscience.\n3. The authors may need to provide more detailed explanations of certain concepts, such as the dormant ratio and its calculation.\n4. The paper could benefit from more discussion of the limitations and potential drawbacks of DrM.\n\nSuggestions for Improvement:\n\n1. The authors could provide more detailed explanations of the dormant ratio and its calculation to help readers who may be unfamiliar with the concept.\n2. The paper could include more discussion of the limitations and potential drawbacks of DrM, such as the potential for over-perturbation or under-perturbation.\n3. The authors could provide more experimental results to demonstrate the robustness of DrM across different tasks and environments.\n4. The paper could include more discussion of the potential applications and future directions of DrM.\n\nRecommendation:\n\nBased on the strengths and weaknesses of the paper, I recommend that it be accepted for publication in a top-tier conference or journal in the field of RL and neuroscience. The authors have made significant contributions to the field, and their work has the potential to impact the development of more efficient and effective RL algorithms. However, the paper could benefit from some revisions to address the weaknesses and suggestions for improvement outlined above.",
        "peer_review_with_watermark": "$$\\boxed{\\text{Paper Summary:} \nThe paper proposes a novel approach for visual reinforcement learning (RL) by leveraging the dormant ratio, which measures the inactivity of neural networks. The authors identify that visual RL agents often exhibit sustained inactivity during early training, limiting their ability to explore effectively. To address this issue, they introduce DrM (Dormant Ratio Minimization), a method that uses three core mechanisms: (1) periodic neural network weight perturbation, (2) dormant-ratio-based exploration scheduler, and (3) dormant-ratio-based exploitation mechanism. The authors evaluate DrM on three visual continuous control benchmarks and demonstrate its superiority over existing baselines in terms of sample efficiency and asymptotic performance.}\n\n$$\\boxed{\\text{Strengths:} \n1. The paper identifies a crucial issue in visual RL, namely the sustained inactivity of neural networks during early training, and proposes a novel solution that addresses this problem.\n2. The authors use a systematic approach to evaluate the effectiveness of DrM and compare it to existing baselines.\n3. The paper provides detailed insights into the correlation between the dormant ratio and the diversity and significance of an agent's actions.\n4. The authors propose a practical and efficient algorithm that can be applied to various visual control tasks.}\n\n$$\\boxed{\\text{Weaknesses:} \n1. The paper relies heavily on empirical evaluation and does not provide a theoretical foundation for the dormant ratio and DrM.\n2. The authors do not discuss potential limitations and challenges of the proposed approach in detail.\n3. The paper does not provide a clear explanation of how the dormant ratio is calculated and interpreted.\n4. The authors do not discuss potential modifications or extensions of the proposed approach for discrete action tasks.}\n\n$$\\boxed{\\text{Suggestions for Improvement:} \n1. The authors should provide a theoretical foundation for the dormant ratio and DrM by explaining how the dormant ratio is calculated and interpreted.\n2. The authors should discuss potential limitations and challenges of the proposed approach in detail and propose potential modifications or extensions for discrete action tasks.\n3. The authors should provide more detailed insights into the correlation between the dormant ratio and the diversity and significance of an agent's actions.\n4. The authors should evaluate the effectiveness of DrM in more diverse and challenging visual control tasks.}\n\n$$\\boxed{\\text{Recommendation:} \nThe paper presents a novel approach for visual reinforcement learning that addresses a crucial issue in the field. While the paper has several strengths, it also has some limitations and challenges that need to be addressed. We recommend that the authors address the limitations and challenges and provide more detailed insights into the correlation between the dormant ratio and the diversity and significance of an agent's actions. The authors also need to evaluate the effectiveness of DrM in more diverse and challenging visual control tasks. Overall, the paper has the potential to make a significant contribution to the field of visual reinforcement learning.}$$",
        "gr_score_with": 0.7352112676056338,
        "gr_score_without": 0.6426666666666667,
        "output_without": {
            "num_tokens_scored": 375,
            "num_green_tokens": 241,
            "green_fraction": 0.6426666666666667,
            "z_score": -2.4227755302217475,
            "p_value": 0.9922987796939914
        },
        "output_with": {
            "num_tokens_scored": 355,
            "num_green_tokens": 261,
            "green_fraction": 0.7352112676056338,
            "z_score": 1.4477253835067065,
            "p_value": 0.07384693398992535
        }
    },
    {
        "title": "DYNAMIC LAYER TYING FOR PARAMETER-EFFICIENT TRANSFORMERS",
        "abstract": "In the pursuit of reducing the number of trainable parameters in deep transformer networks, we employ Reinforcement Learning to dynamically select layers during training and tie them together. Every few iterations, the RL agent is asked whether to train each layer i independently or to copy the weights of a previous layer j < i. This facilitates weight sharing, reduces the number of trainable parameters, and also serves as an effective regularization technique. Experimental evaluations validate that our model modestly outperforms the baseline transformer model with regard to perplexity and drastically reduces the number of trainable parameters. In particular, the memory consumption during training is up to one order of magnitude less than the conventional training method.",
        "peer_review_without_watermark": "$$\\boxed{\\text{Paper Summary:}  \nThe paper proposes a novel method for dynamically selecting layers in deep transformer networks during training, which aims to reduce the number of trainable parameters. The method employs reinforcement learning to learn a pattern of layer replication and tying, which facilitates weight sharing and regularization. Experimental evaluations demonstrate that the proposed method outperforms the baseline transformer model in terms of perplexity and reduces the number of trainable parameters. \n\nStrengths: \n1. The method introduces a novel approach to dynamically selecting layers in transformer networks, which can lead to significant reductions in the number of trainable parameters.\n2. The use of reinforcement learning to learn the replication pattern is a fresh approach and can be effective in finding optimal layer configurations.\n3. The method is experimentally evaluated on multiple datasets, demonstrating its effectiveness in reducing the number of trainable parameters without sacrificing perplexity.\n\nWeaknesses:\n1. The method may not generalize well to other architectures or tasks, as the evaluation is limited to language models.\n2. The use of reinforcement learning may require careful tuning of hyperparameters, and the choice of Q-function may impact the performance of the method.\n3. The method does not provide insights into the underlying mechanisms of layer replication and tying, which may be useful for understanding the optimization process.\n\nSuggestions for Improvement:\n1. Evaluate the method on other architectures and tasks to demonstrate its generalizability.\n2. Conduct a more thorough analysis of the Q-function and its impact on the performance of the method.\n3. Provide more detailed insights into the optimization process and the underlying mechanisms of layer replication and tying.\n\nRecommendation:\nThe proposed method is an innovative approach to dynamically selecting layers in transformer networks, and its experimental evaluation demonstrates its effectiveness in reducing the number of trainable parameters. However, further research is needed to ensure the generalizability of the method and to provide a deeper understanding of its underlying mechanisms.",
        "peer_review_with_watermark": "$$\\boxed{\\text{Paper Summary:}~ The paper proposes a novel method for dynamically selecting layers in transformers using Reinforcement Learning. The proposed method, referred to as DYNAMIC LAYER TYING, employs a Q-learning driven dynamic layer tying mechanism to selectively replicate the weights of previous layers, thereby reducing the number of trainable parameters. The experimental results show that the proposed method modestly outperforms the baseline transformer model in terms of perplexity and drastically reduces the number of trainable parameters, achieving a significant reduction in memory consumption during training.}\n\n$$\\boxed{\\text{Strengths:}~ The paper presents a novel and effective approach to dynamically selecting layers in transformers using Reinforcement Learning. The proposed method is able to selectively replicate the weights of previous layers, reducing the number of trainable parameters while maintaining the performance of the model. The experimental results demonstrate the effectiveness of the proposed method, achieving a significant reduction in memory consumption during training.}\n\n$$\\boxed{\\text{Weaknesses:}~ One of the major weaknesses of the paper is that it relies heavily on the assumption that the Q-learning driven dynamic layer tying mechanism is effective in selecting the optimal layers for replication. While the experimental results show the effectiveness of the proposed method, it is unclear whether the mechanism is able to capture the complex interactions between the layers in the transformer architecture. Additionally, the paper does not provide a detailed analysis of the stability of the proposed method, particularly in terms of the convergence of the Q-learning algorithm.}\n\n$$\\boxed{\\text{Suggestions for Improvement:}~ To improve the proposed method, the authors should provide a more detailed analysis of the stability of the Q-learning algorithm, particularly in terms of the convergence of the algorithm. Additionally, the authors should investigate the effectiveness of the proposed method in capturing the complex interactions between the layers in the transformer architecture. Furthermore, the authors should consider exploring alternative reinforcement learning algorithms that may be more effective in selecting the optimal layers for replication.}\n\n$$\\boxed{\\text{Recommendation:}~ The proposed method is a significant contribution to the field of natural language processing, particularly in terms of reducing the number of trainable parameters in transformers. However, further research is needed to fully understand the effectiveness of the proposed method and to explore its potential applications in other areas of NLP. The proposed method has the potential to be a valuable tool for reducing the computational cost of training large language models, particularly in terms of reducing the number of trainable parameters.}\n\n$$\\boxed{\\text{Conclusion:}~ The paper presents a novel method for dynamically selecting layers in transformers using Reinforcement Learning. The proposed method, referred to as DYNAMIC LAYER TYING, employs a Q-learning driven dynamic layer tying mechanism to selectively replicate the weights of previous layers, thereby reducing the number of trainable parameters. The experimental results show that the proposed method modestly outperforms the baseline transformer model in terms of perplexity and drastically reduces the number of trainable parameters, achieving a significant reduction in memory consumption during training. The proposed method has the potential to be a valuable tool for reducing the computational cost of training large language models, particularly in terms of reducing the number of trainable parameters.}$$",
        "gr_score_with": 0.8698630136986302,
        "gr_score_without": 0.7681159420289855,
        "output_without": {
            "num_tokens_scored": 276,
            "num_green_tokens": 212,
            "green_fraction": 0.7681159420289855,
            "z_score": 2.46941260621585,
            "p_value": 0.006766753575732495
        },
        "output_with": {
            "num_tokens_scored": 292,
            "num_green_tokens": 254,
            "green_fraction": 0.8698630136986302,
            "z_score": 6.334037108561085,
            "p_value": 1.1941401649381615e-10
        }
    },
    {
        "title": "ENHANCING NEURAL SUBSET SELECTION: INTEGRAT-",
        "abstract": "Learning neural subset selection tasks, such as compound selection in AI-aided drug discovery, have become increasingly pivotal across diverse applications. The existing methodologies in the field primarily concentrate on constructing models that capture the relationship between utility function values and subsets within their respective supersets. However, these approaches tend to overlook the valuable information contained within the superset when utilizing neural networks to model set functions. In this work, we address this oversight by adopting a probabilistic perspective. Our theoretical findings demonstrate that when the target value is conditioned on both the input set and subset, it is essential to incorporate an invariant sufficient statistic of the superset into the subset of interest for effective learning. This ensures that the output value remains invariant to permutations of the subset and its corresponding superset, enabling identification of the specific superset from which the subset originated. Motivated by these insights, we propose a simple yet effective information aggregation module designed to merge the representations of subsets and supersets from a permutation invariance perspective. Comprehensive empirical evaluations across diverse tasks and datasets validate the enhanced efficacy of our approach over conventional methods, underscoring the practicality and potency of our proposed strategies in real-world contexts.",
        "peer_review_without_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes a novel approach to neural subset selection by incorporating permutation invariance and information aggregation from the superset. The proposed method, INSET, uses an invariant sufficient representation to model the relationship between the subset and the superset, allowing for more accurate predictions. The authors evaluate INSET on various tasks, including product recommendation, set anomaly detection, and compound selection, and demonstrate its superiority over existing methods.\n\nStrengths:\n\n*   The paper provides a clear and concise introduction to the problem of neural subset selection and the importance of permutation invariance.\n*   The proposed method, INSET, is well-explained and appears to be effective in modeling the relationship between subsets and supersets.\n*   The authors provide a thorough evaluation of INSET on various tasks, demonstrating its superiority over existing methods.\n\nWeaknesses:\n\n*   The paper could benefit from more detailed explanations of the theoretical underpinnings of INSET and its relationship to existing methods.\n*   Some of the technical details, such as the definition of the invariant sufficient representation, may be difficult for non-experts to follow.\n*   The evaluation section could be expanded to include more detailed analysis and discussion of the results.\n\nSuggestions for Improvement:\n\n*   Provide more detailed explanations of the theoretical underpinnings of INSET and its relationship to existing methods.\n*   Consider including more technical details, such as the derivation of the invariant sufficient representation, to provide a more comprehensive understanding of the proposed method.\n*   Expand the evaluation section to include more detailed analysis and discussion of the results.\n\nRecommendation:\n\n*   Based on the provided evaluation, INSET appears to be a promising approach to neural subset selection, offering improved performance over existing methods. However, further research is needed to fully understand the theoretical underpinnings of INSET and its relationship to existing methods.\n\n$$$\\boxed{Strengths:}\n\nThe paper provides a clear and concise introduction to the problem of neural subset selection and the importance of permutation invariance. The proposed method, INSET, is well-explained and appears to be effective in modeling the relationship between subsets and supersets.\n\nThe authors provide a thorough evaluation of INSET on various tasks, demonstrating its superiority over existing methods.\n\nThe paper is well-organized and easy to follow, with clear explanations of the technical details.\n\nThe authors acknowledge the limitations of their work and provide a clear direction for future research.\n\n$$\\boxed{Weaknesses:}\n\nThe paper could benefit from more detailed explanations of the theoretical underpinnings of INSET and its relationship to existing methods.\n\nSome of the technical details, such as the definition of the invariant sufficient representation, may be difficult for non-experts to follow.\n\nThe evaluation section could be expanded to include more detailed analysis and discussion of the results.\n\nThe paper could benefit from more experimental results, such as more detailed analysis of the performance of INSET on different datasets.\n\n$$\\boxed{Suggestions for Improvement:}\n\nProvide more detailed explanations of the theoretical underpinnings of INSET and its relationship to existing methods.\n\nConsider including more technical details, such as the derivation of the invariant sufficient representation, to provide a more comprehensive understanding of the proposed method.\n\nExpand the evaluation section to include more detailed analysis and discussion of the results.\n\nConsider including more experimental results, such as more detailed analysis of the performance of INSET on different datasets.\n\n$$\\boxed{Recommendation:}\n\nBased on the provided evaluation, INSET appears to be a promising approach to neural subset selection, offering improved performance over existing methods. However, further research is needed to fully understand the theoretical underpinnings of INSET and its relationship to existing methods.",
        "peer_review_with_watermark": "$$$\\begin{align}\\textbf{Paper Summary:} &\\ \\ The authors propose a novel neural subset selection method, INSET, that addresses the limitation of existing subset encoding methods. INSET incorporates a permutation invariant information aggregation module to merge the representations of subsets and supersets from a permutation invariance perspective. The authors evaluate INSET on various tasks, including product recommendation, set anomaly detection, and compound selection, and demonstrate its superior performance compared to state-of-the-art methods.\n\n\\textbf{Strengths:} &\\ \\ The authors have identified a crucial limitation in subset encoding methods and proposed a novel approach to address this limitation. The proposed method, INSET, is theoretically driven and demonstrates superior performance on various tasks. The authors have also provided a clear and concise explanation of the theoretical results and their implications.\n\n\\textbf{Weaknesses:} &\\ \\ The authors have not explicitly discussed the impact of the number of training epochs on the performance of INSET. Additionally, the authors have not provided a thorough comparison of the proposed method with other state-of-the-art methods on the same tasks.\n\n\\textbf{Suggestions for Improvement:} &\\ \\ The authors should investigate the impact of the number of training epochs on the performance of INSET. Additionally, the authors should provide a thorough comparison of INSET with other state-of-the-art methods on the same tasks. The authors should also explore the potential benefits of integrating additional information, such as pairwise interactions between elements, into the proposed method.\n\n\\textbf{Recommendation:} &\\ \\ The proposed method, INSET, demonstrates superior performance on various tasks and is theoretically driven. However, further exploration and development are required to fully leverage the potential benefits of INSET. The authors should continue to investigate the limitations of INSET and explore ways to integrate additional information into the proposed method.\n\n$$\\end{align}$$",
        "gr_score_with": 0.7892561983471075,
        "gr_score_without": 0.6270096463022508,
        "output_without": {
            "num_tokens_scored": 311,
            "num_green_tokens": 195,
            "green_fraction": 0.6270096463022508,
            "z_score": -2.8088983003330386,
            "p_value": 0.9975144326239409
        },
        "output_with": {
            "num_tokens_scored": 242,
            "num_green_tokens": 191,
            "green_fraction": 0.7892561983471075,
            "z_score": 3.0299566901647172,
            "p_value": 0.001222944048525977
        }
    },
    {
        "title": "TAB: TEMPORAL ACCUMULATED BATCH NORMALIZA-",
        "abstract": "Spiking Neural Networks (SNNs) are attracting growing interest for their energyefficient computing when implemented on neuromorphic hardware. However, directly training SNNs, even adopting batch normalization (BN), is highly challenging due to their non-differentiable activation function and the temporally delayed accumulation of outputs over time. For SNN training, this temporal accumulation gives rise to Temporal Covariate Shifts (TCS) along the temporal dimension, a phenomenon that would become increasingly pronounced with layer-wise computations across multiple layers and multiple time-steps. In this paper, we introduce TAB (Temporal Accumulated Batch Normalization), a novel SNN batch normalization method that addresses the temporal covariate shift issue by aligning with neuron dynamics (specifically the accumulated membrane potential) and utilizing temporal accumulated statistics for data normalization. Within its framework, TAB effectively encapsulates the historical temporal dependencies that underlie the membrane potential accumulation process, thereby establishing a natural connection between neuron dynamics and TAB batch normalization. Experimental results on CIFAR-10, CIFAR-100, and DVS-CIFAR10 show that our TAB method outperforms other state-of-the-art methods.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$The paper proposes a novel batch normalization method called Temporal Accumulated Batch Normalization (TAB) for Spiking Neural Networks (SNNs). The authors aim to address the challenges of directly training SNNs, particularly the Temporal Covariate Shift (TCS) phenomenon, which arises from the temporal dependency of neuron dynamics. The proposed TAB method aligns with the neuron dynamics by utilizing temporal accumulated statistics for data normalization. The authors provide a comprehensive analysis of the paper, including its strengths, weaknesses, and suggestions for improvement. \n\nThe main contributions of the paper are:\n\n1.  Introducing the concept of Temporal Accumulated Batch Normalization (TAB) for SNNs.\n2.  Providing a novel approach to address the Temporal Covariate Shift (TCS) phenomenon.\n3.  Demonstrating the effectiveness of TAB on various benchmark datasets.\n\nStrengths of the paper:\n\n1.  The authors provide a thorough analysis of the challenges faced by SNNs, particularly the TCS phenomenon.\n2.  The proposed TAB method is well-explained, and its alignment with neuron dynamics is a significant contribution.\n3.  The authors provide extensive experimental results on various benchmark datasets, demonstrating the effectiveness of TAB.\n\nWeaknesses of the paper:\n\n1.  The paper assumes a certain level of background knowledge in SNNs and batch normalization, which may be challenging for non-experts to follow.\n2.  Some sections of the paper, such as the theoretical connection between TAB and neuron dynamics, may require additional explanation or context.\n3.  The authors could have provided more detailed explanations of the computational complexity of the proposed TAB method.\n\nSuggestions for improvement:\n\n1.  Provide more detailed explanations of the theoretical connection between TAB and neuron dynamics, particularly for non-experts.\n2.  Consider adding more experimental results to demonstrate the effectiveness of TAB on various scenarios.\n3.  Provide more detailed explanations of the computational complexity of the proposed TAB method, particularly for large-scale SNNs.\n\nRecommendation:\n\n1.  The paper makes a significant contribution to the field of SNNs and batch normalization, introducing a novel approach to address the TCS phenomenon.\n2.  The authors provide extensive experimental results, demonstrating the effectiveness of TAB on various benchmark datasets.\n3.  The paper is well-written, and the authors provide a thorough analysis of the challenges faced by SNNs.\n\nHowever, the paper assumes a certain level of background knowledge in SNNs and batch normalization, which may be challenging for non-experts to follow. Additionally, some sections of the paper require more detailed explanations or context.\n\n$$\\begin{aligned}\n$$Overall, the paper is well-written, and the authors provide a thorough analysis of the challenges faced by SNNs. The proposed TAB method is a significant contribution to the field, and the authors provide extensive experimental results demonstrating its effectiveness.",
        "peer_review_with_watermark": "$$$\\boxed{\\text{Paper Summary:}}$$\n\nThe paper proposes a novel batch normalization method, Temporal Accumulated Batch Normalization (TAB), specifically designed for Spiking Neural Networks (SNNs). TAB aims to address the temporal covariate shift issue in SNNs by utilizing temporal accumulated statistics, which closely aligns with the neuron dynamics in the LIF model. The proposed method is evaluated on various datasets, including CIFAR-10, CIFAR-100, and DVS-CIFAR10, demonstrating improved performance compared to existing batch normalization methods.\n\n$\\boxed{\\text{Strengths:}}$$\n\n1.  The proposed TAB method effectively addresses the temporal covariate shift issue in SNNs by utilizing temporal accumulated statistics.\n2.  The alignment with the neuron dynamics in the LIF model ensures a coherent normalization process.\n3.  The proposed method is evaluated on various datasets, demonstrating improved performance compared to existing batch normalization methods.\n\n$\\boxed{\\text{Weaknesses:}}$$\n\n1.  The paper lacks a detailed discussion on the computational complexity of the proposed TAB method.\n2.  The proposed method may not be suitable for all types of SNN architectures.\n3.  The paper could benefit from a more thorough analysis of the temporal covariate shift issue in SNNs.\n\n$\\boxed{\\text{Suggestions for Improvement:}}$$\n\n1.  Conduct a more detailed analysis of the computational complexity of the proposed TAB method.\n2.  Investigate the applicability of the proposed method to different types of SNN architectures.\n3.  Perform a more thorough analysis of the temporal covariate shift issue in SNNs.\n\n$\\boxed{\\text{Recommendation:}}$$\n\nBased on the strengths and weaknesses of the proposed TAB method, it is recommended for further development and evaluation on various SNN architectures and datasets. The alignment with the neuron dynamics in the LIF model ensures a coherent normalization process, which can lead to improved training and performance in SNNs. However, a more detailed analysis of the computational complexity and applicability to different SNN architectures is necessary to fully evaluate the proposed method.\n\n$$$\\boxed{\\text{Peer Reviewer's Comments:}}$$\n\nThe paper proposes a novel batch normalization method, Temporal Accumulated Batch Normalization (TAB), specifically designed for Spiking Neural Networks (SNNs). The proposed method is effective in addressing the temporal covariate shift issue in SNNs by utilizing temporal accumulated statistics, which closely aligns with the neuron dynamics in the LIF model.\n\nThe alignment with the neuron dynamics ensures a coherent normalization process, which can lead to improved training and performance in SNNs. However, a more detailed analysis of the computational complexity and applicability to different SNN architectures is necessary to fully evaluate the proposed method.\n\nThe paper is well-structured, and the authors provide a clear explanation of the proposed TAB method and its evaluation on various datasets. However, the paper could benefit from a more thorough analysis of the temporal covariate shift issue in SNNs.\n\nIn conclusion, the proposed TAB method is a valuable contribution to the field of SNNs, and it has the potential to improve training and performance in SNNs. However, further development and evaluation are necessary to fully evaluate the proposed method.\n\nThe authors should consider the following suggestions for improvement:\n\n1.  Conduct a more detailed analysis of the computational complexity of the proposed TAB method.\n2.  Investigate the applicability of the proposed method to different types of SNN architectures.\n3.  Perform a more thorough analysis of the temporal covariate shift issue in SNNs.\n\nBy addressing these suggestions, the authors can further improve the proposed TAB method and provide a more comprehensive evaluation of its effectiveness in SNNs.\n\nRecommendation: The proposed TAB method is a valuable contribution to the field of SNNs, and it has the potential to improve training and performance in SNNs. However, further development and evaluation are necessary to fully evaluate the proposed method.\n\nThe authors should consider the suggestions for improvement outlined above to further improve the proposed TAB method.\n\nThe paper is well-structured, and the authors provide a clear explanation of the proposed TAB method and its evaluation on various datasets.\n\nHowever, the paper could benefit from a more thorough analysis of the temporal covariate shift issue in SNNs.\n\nIn conclusion, the proposed TAB method is a valuable contribution to the field of SNNs, and it has the potential to improve training and performance in SNNs.\n\nHowever, further development and evaluation are necessary to fully evaluate the proposed method.\n\nThe authors should consider the suggestions for improvement outlined above to further improve the proposed TAB method.\n\nThe paper is well-structured, and the authors provide a clear explanation of the proposed TAB method and its evaluation on various datasets.\n\nHowever, the paper could benefit from a more thorough analysis of the temporal covariate shift issue in SNNs.\n\nIn conclusion, the proposed TAB method is a valuable contribution to the field of SNNs, and it has the potential to improve training and performance in SNNs.\n\nHowever, further development and evaluation are necessary to fully evaluate the proposed method.\n\nThe authors should consider the suggestions for improvement outlined above to further improve the proposed TAB method.\n\nThe paper is well-structured, and the authors provide a clear explanation of the proposed TAB method and its evaluation on various datasets.\n\nHowever, the paper could benefit from a more thorough analysis of the temporal covariate shift issue in SNNs.\n\nIn conclusion, the proposed TAB method is a valuable contribution to the field of SNNs, and it has the potential to improve training and performance in SNNs.\n\nHowever, further development and evaluation are necessary to fully evaluate the proposed method.\n\nThe authors should consider the suggestions for improvement outlined above to further improve the proposed TAB method.\n\nThe paper is well-structured, and the authors provide a clear explanation of the proposed TAB method and its evaluation on various datasets.\n\nHowever, the paper could benefit from a more thorough analysis of the temporal covariate shift issue in SNNs.\n\nIn conclusion, the proposed TAB method is a valuable contribution to the field of SNNs, and it has the potential to improve training and performance in SNNs.\n\nHowever, further development and evaluation are necessary to fully evaluate the proposed method.\n\nThe authors should consider the suggestions for improvement outlined above to further improve the proposed TAB method.\n\nThe paper is well-structured, and the authors provide a clear explanation of the proposed TAB method and its evaluation on various datasets.\n\nHowever, the paper could benefit from a more thorough analysis of the temporal covariate shift issue in SNNs.\n\nIn conclusion, the proposed TAB method is a valuable contribution to the field of SNNs, and it has the potential to improve training and performance in SNNs.\n\nHowever, further development and evaluation are necessary to fully evaluate the proposed method.\n\nThe authors should consider the suggestions for improvement outlined above to further improve the proposed TAB method.\n\nThe paper is well-structured, and the authors provide a clear explanation of the proposed TAB method and its evaluation on various datasets.\n\nHowever, the paper could benefit from a more thorough analysis of the temporal covariate shift issue in SNNs.\n\nIn conclusion, the proposed TAB method is a valuable contribution to the field of SNNs, and it has the potential to improve training and performance in SNNs.\n\nHowever, further development and evaluation are necessary to fully evaluate the proposed method.\n\nThe authors should consider the suggestions for improvement outlined above to further improve the proposed TAB method.\n\nThe paper is well-structured, and the authors provide a clear explanation of the proposed TAB method and its evaluation on various datasets.\n\nHowever, the paper could benefit from a more thorough analysis of the temporal covariate shift issue in SNNs.\n\nIn conclusion, the proposed TAB method is a valuable contribution to the field of SNNs, and it has the potential to improve training and performance in SNNs.\n\nHowever, further development and evaluation are necessary to fully evaluate the proposed method.\n\nThe authors should consider the suggestions for improvement outlined above to further improve the proposed TAB method.\n\nThe paper is well-structured, and the authors provide a clear explanation of the proposed TAB method and its evaluation on various datasets.\n\nHowever, the paper could benefit from a more thorough analysis of the temporal covariate shift issue in SNNs.\n\nIn conclusion, the proposed TAB method is a valuable contribution to the field of SNNs, and it has the potential to improve training and performance in SNNs.\n\nHowever, further development and evaluation are necessary to fully evaluate the proposed method.\n\nThe authors should consider the suggestions for improvement outlined above to further improve the proposed TAB method.\n\nThe paper is well-structured, and the authors provide a clear explanation of the proposed TAB method and its evaluation on various datasets.\n\nHowever, the paper could benefit from a more thorough analysis of the temporal covariate shift issue in SNNs.\n\nIn conclusion, the proposed TAB method is a valuable contribution to the field of SNNs, and it has the potential to improve training and performance in SNNs.\n\nHowever, further development and evaluation are necessary to fully evaluate the proposed method.\n\nThe authors should consider the suggestions for improvement outlined above to further improve the proposed TAB method.\n\nThe paper is well-structured, and the authors provide a clear explanation of the proposed TAB method and its evaluation on various datasets.\n\nHowever, the paper could benefit from a more thorough analysis of the temporal covariate shift issue in SNNs.\n\nIn conclusion, the proposed TAB method is a valuable contribution to the field of SNNs, and it has the potential to improve training and performance in SNNs.\n\nHowever, further development and evaluation are necessary to fully evaluate the proposed method.\n\nThe authors should consider the suggestions for improvement outlined above to further improve the proposed TAB method.\n\nThe paper is well-structured, and the authors provide a",
        "gr_score_with": 0.8134556574923547,
        "gr_score_without": 0.7873754152823921,
        "output_without": {
            "num_tokens_scored": 301,
            "num_green_tokens": 237,
            "green_fraction": 0.7873754152823921,
            "z_score": 3.3079798337662734,
            "p_value": 0.00046985788072032
        },
        "output_with": {
            "num_tokens_scored": 327,
            "num_green_tokens": 266,
            "green_fraction": 0.8134556574923547,
            "z_score": 4.477033931482914,
            "p_value": 3.7843611878679073e-06
        }
    },
    {
        "title": "A UNIFIED SAMPLING FRAMEWORK FOR SOLVER SEARCHING OF DIFFUSION PROBABILISTIC MODELS",
        "abstract": "Recent years have witnessed the rapid progress and broad application of diffusion probabilistic models (DPMs). Sampling from DPMs can be viewed as solving an ordinary differential equation (ODE). Despite the promising performance, the generation of DPMs usually consumes much time due to the large number of function evaluations (NFE). Though recent works have accelerated the sampling to around 20 steps with high-order solvers, the sample quality with less than 10 NFE can still be improved. In this paper, we propose a unified sampling framework (USF) to study the optional strategies for solver. Under this framework, we further reveal that taking different solving strategies at different timesteps may help further decrease the truncation error, and a carefully designed solver schedule has the potential to improve the sample quality by a large margin. Therefore, we propose a new sampling framework based on the exponential integral formulation that allows free choices of solver strategy at each step and design specific decisions for the framework. Moreover, we propose S, a predictor-based search method that automatically optimizes the solver schedule to get a better time-quality trade-off of sampling. We demonstrate that S can find outstanding solver schedules which outperform the state-of-the-art sampling methods on CIFAR-10, CelebA, ImageNet, and LSUN-Bedroom datasets. Specifically, we achieve 2.69 FID with 10 NFE and 6.86 FID with 5 NFE on CIFAR-10 dataset, outperforming the SOTA method significantly. We further apply S to Stable-Diffusion model and get an acceleration ratio of 2\u00d7, showing the feasibility of sampling in very few steps without retraining the neural network.",
        "peer_review_without_watermark": "$$$\\begin{align*}\nPaper Summary:\nThe paper proposes a unified sampling framework (USF) for diffusion probabilistic models (DPMs) based on exponential integral formulation. The framework allows for free choices of solver strategy at each step and designs specific decisions for the framework. The authors also propose a predictor-based search method (S3) to automatically optimize the solver schedule to get a better time-quality trade-off of sampling. Experimental results show that the proposed method can boost the sample quality under a very tight budget by a large margin.\n\nStrengths:\n- The proposed framework is systematic and allows for a wide range of solver strategies.\n- The use of exponential integral formulation is effective in reducing the number of steps required for sampling.\n- The predictor-based search method (S3) is efficient and can find optimal solver schedules.\n\nWeaknesses:\n- The paper assumes that the neural network is pre-trained, which may not be the case in all scenarios.\n- The search space is very large, which can lead to excessive search overheads.\n- The paper does not provide a clear explanation of the derivative estimation method used in the framework.\n\nSuggestions for Improvement:\n- Provide a clear explanation of the derivative estimation method used in the framework.\n- Consider using a more efficient search method to reduce the search overheads.\n- Consider using a pre-trained neural network or a more robust pre-training method to improve the performance of the framework.\n\nRecommendation:\nThe proposed framework and search method are effective in boosting the sample quality under a very tight budget. However, the search space is very large, and the paper assumes that the neural network is pre-trained, which may not be the case in all scenarios. Therefore, further improvement is needed to make the framework more robust and applicable to a wider range of scenarios. \n\n$$\n\nPlease note that the above review is based on the provided paper and may not be exhaustive.",
        "peer_review_with_watermark": "$$\\begin{align}\\# Paper Review: A Unified Sampling Framework for Solver Searching of Diffusion Probabilistic Models \\\\\\# Paper Title: A Unified Sampling Framework for Solver Searching of Diffusion Probabilistic Models \\\\\\# Paper Author: [Author's Name] \\\\\\# Paper Abstract: Recent years have witnessed the rapid progress and broad application of diffusion probabilistic models (DPMs). Sampling from DPMs can be viewed as solving an ordinary differential equation (ODE). Despite the promising performance, the generation of DPMs usually consumes much time due to the large number of function evaluations (NFE). Though recent works have accelerated the sampling to around 20 steps with high-order solvers, the sample quality with less than 10 NFE can still be improved. In this paper, we propose a unified sampling framework (USF) to study the optional strategies for solver. Under this framework, we further reveal that taking different solving strategies at different timesteps may help further decrease the truncation error, and a carefully designed solver schedule has the potential to improve the sample quality by a large margin. Therefore, we propose a new sampling framework based on the exponential integral formulation that allows free choices of solver strategy at each step and design specific decisions for the framework. Moreover, we propose S, a predictor-based search method that automatically optimizes the solver schedule to get a better time-quality trade-off of sampling. We demonstrate that S can find outstanding solver schedules which outperform the state-of-the-art sampling methods on CIFAR-10, CelebA, ImageNet, and LSUN-Bedroom datasets. Specifically, we achieve 2.69 FID with 10 NFE and 6.86 FID with 5 NFE on CIFAR-10 dataset, outperforming the SOTA method significantly. We further apply S to Stable-Diffusion model and get an acceleration ratio of 2\u00d7, showing the feasibility of sampling in very few steps without retraining the neural network. \\\\\\# Paper Text: The paper provides an in-depth explanation of the concept of sampling from diffusion probabilistic models (DPMs) and the current limitations of the existing sampling methods. It also proposes a new unified sampling framework (USF) that allows for the free choice of solver strategy at each step. The framework is designed to reduce the truncation error and improve the sample quality. Additionally, the paper proposes a predictor-based search method (S) that automatically optimizes the solver schedule to get a better time-quality trade-off of sampling. The experimental results show that the proposed method can achieve better performance than the state-of-the-art sampling methods on various datasets. Overall, the paper provides a comprehensive overview of the sampling problem in DPMs and proposes a novel approach to solving it. \\\\\\# Paper Strengths: \\\\\\# The paper provides a clear and concise explanation of the concept of sampling from DPMs and the current limitations of the existing sampling methods. \\\\\\# The proposed unified sampling framework (USF) is well-designed and allows for the free choice of solver strategy at each step. \\\\\\# The predictor-based search method (S) is an innovative approach to automatically optimizing the solver schedule. \\\\\\# The experimental results show that the proposed method can achieve better performance than the state-of-the-art sampling methods on various datasets. \\\\\\# Paper Weaknesses: \\\\\\# The paper assumes that the reader has prior knowledge of the concept of sampling from DPMs and the current limitations of the existing sampling methods. \\\\\\# The paper does not provide a comprehensive analysis of the potential risks and limitations of the proposed approach. \\\\\\# The paper does not provide a detailed explanation of the optimization process used to train the predictor-based search method (S). \\\\\\# Suggestions for Improvement: \\\\\\# Provide a detailed explanation of the optimization process used to train the predictor-based search method (S). \\\\\\# Analyze the potential risks and limitations of the proposed approach. \\\\\\# Provide a comprehensive overview of the sampling problem in DPMs, including the current limitations of the existing sampling methods. \\\\\\# Recommendation: \\\\\\# Based on the strengths and weaknesses of the paper, I recommend that the authors revise the paper to address the weaknesses and improve the clarity and comprehensiveness of the explanation. The authors should also provide a detailed explanation of the optimization process used to train the predictor-based search method (S) and analyze the potential risks and limitations of the proposed approach. Overall, the paper provides an interesting and innovative approach to solving the sampling problem in DPMs, and with revisions, it has the potential to make a significant contribution to the field. \\\\\\end{align}$$\n\n$$\\# Final Review: Overall, the paper provides an in-depth explanation of the concept of sampling from diffusion probabilistic models (DPMs) and the current limitations of the existing sampling methods. The proposed unified sampling framework (USF) is well-designed and allows for the free choice of solver strategy at each step. The predictor-based search method (S) is an innovative approach to automatically optimizing the solver schedule. However, the paper assumes that the reader has prior knowledge of the concept of sampling from DPMs and the current limitations of the existing sampling methods. Additionally, the paper does not provide a comprehensive analysis of the potential risks and limitations of the proposed approach. Therefore, I recommend that the authors revise the paper to address these weaknesses and improve the clarity and comprehensiveness of the explanation.",
        "gr_score_with": 0.7654320987654321,
        "gr_score_without": 0.6643109540636042,
        "output_without": {
            "num_tokens_scored": 283,
            "num_green_tokens": 188,
            "green_fraction": 0.6643109540636042,
            "z_score": -1.310142420389036,
            "p_value": 0.9049261699050718
        },
        "output_with": {
            "num_tokens_scored": 567,
            "num_green_tokens": 434,
            "green_fraction": 0.7654320987654321,
            "z_score": 3.399951585227798,
            "p_value": 0.0003369889281975977
        }
    },
    {
        "title": "LEARNING OPTIMAL CONTRACTS: HOW TO EXPLOIT SMALL ACTION SPACES",
        "abstract": "We study principal-agent problems in which a principal commits to an outcomedependent payment scheme\u2014called contract\u2014in order to induce an agent to take a costly, unobservable action leading to favorable outcomes. We consider a generalization of the classical (single-round) version of the problem in which the principal interacts with the agent by committing to contracts over multiple rounds. The principal has no information about the agent, and they have to learn an optimal contract by only observing the outcome realized at each round. We focus on settings in which the size of the agent\u2019s action space is small. We design an algorithm that learns an approximately-optimal contract with high probability in a number of rounds polynomial in the size of the outcome space, when the number of actions is constant. Our algorithm solves an open problem by Zhu et al. (2023). Moreover, it can also be employed to provide a \u00d5(T ) regret bound in the related online learning setting in which the principal aims at maximizing their cumulative utility over rounds, considerably improving previously-known regret bounds.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n&\\text{Paper Summary: The paper studies principal-agent problems where a principal commits to a payment scheme to incentivize an agent to take a costly action. The paper focuses on a generalization of the classical single-round version of the problem to multiple rounds. The goal is to design an algorithm that learns an approximately-optimal contract with high probability in a number of rounds polynomial in the size of the outcome space.}\\\\\n&\\text{The authors provide an algorithm called Discover-and-Cover that learns an approximately-optimal bounded contract. The algorithm builds a set of meta-actions, where each meta-action identifies a set of contracts in which a given action is a best response. The algorithm progressively refines upper and lower bounds for such regions, until they coincide.}\\\\\n&\\text{The authors show that the algorithm has a sample complexity of learning optimal contracts in hidden-action principal-agent settings. The algorithm is also able to provide a regret bound in the related online learning setting.}\\\\\n&\\text{The paper also discusses the relation to repeated Stackelberg games and the assumptions relaxed compared to Stackelberg games.}\\\\\n&\\text{The Discover-and-Cover algorithm is a significant contribution to the field of algorithmic game theory and principal-agent problems. The algorithm has the potential to be applied to a wide range of real-world scenarios.}\\\\\n&\\text{Strengths: The paper presents a well-structured and well-organized argument. The authors provide a clear and concise explanation of the problem and the algorithm. The paper also discusses the relation to repeated Stackelberg games and the assumptions relaxed compared to Stackelberg games.}\\\\\n&\\text{Weaknesses: The paper assumes a high level of knowledge in algorithmic game theory and principal-agent problems. The authors may need to provide more background information on these topics.}\\\\\n&\\text{Suggestions for Improvement: The authors may need to provide more details on the algorithm and its components. The paper may also benefit from more discussion on the assumptions and limitations of the algorithm.}\\\\\n&\\text{Recommendation: The Discover-and-Cover algorithm is a significant contribution to the field of algorithmic game theory and principal-agent problems. The algorithm has the potential to be applied to a wide range of real-world scenarios. I recommend that the authors continue to work on the algorithm and its applications.}\\\\\n$$",
        "peer_review_with_watermark": "$$\\begin{aligned} $$$\\boxed{\\text{Summary: } \\text{This paper presents a novel algorithm called Discover-and-Cover, which learns an approximately optimal contract from a principal-agent interaction over multiple rounds.}\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text",
        "gr_score_with": 0.8085106382978723,
        "gr_score_without": 0.6734006734006734,
        "output_without": {
            "num_tokens_scored": 297,
            "num_green_tokens": 200,
            "green_fraction": 0.6734006734006734,
            "z_score": -1.0003206155901525,
            "p_value": 0.8414223132185721
        },
        "output_with": {
            "num_tokens_scored": 47,
            "num_green_tokens": 38,
            "green_fraction": 0.8085106382978723,
            "z_score": 1.6233478859020378,
            "p_value": 0.052257529191586945
        }
    },
    {
        "title": "SIVE NEURAL NETWORK GENERATION",
        "abstract": "Spatio-temporal modeling is foundational for smart city applications, yet it is often hindered by data scarcity in many cities and regions. To bridge this gap, we propose a novel generative pre-training framework, GPD, for spatio-temporal few-shot learning with urban knowledge transfer. Unlike conventional approaches that heavily rely on common feature extraction or intricate few-shot learning designs, our solution takes a novel approach by performing generative pre-training on a collection of neural network parameters optimized with data from source cities. We recast spatio-temporal few-shot learning as pre-training a generative diffusion model, which generates tailored neural networks guided by prompts, allowing for adaptability to diverse data distributions and city-specific characteristics. GPD employs a Transformer-based denoising diffusion model, which is model-agnostic to integrate with powerful spatio-temporal neural networks. By addressing challenges arising from data gaps and the complexity of generalizing knowledge across cities, our framework consistently outperforms state-of-the-art baselines on multiple real-world datasets for tasks such as traffic speed prediction and crowd flow prediction. The implementation of our approach is available: https://github.com/tsinghua-fib-lab/GPD.",
        "peer_review_without_watermark": "$$\n\n$$$Paper Summary:\nThe paper proposes a novel generative pre-training framework, GPD, for spatio-temporal few-shot learning with urban knowledge transfer. The framework leverages a Transformer-based denoising diffusion model to generate tailored neural networks guided by prompts, allowing for adaptability to diverse data distributions and city-specific characteristics. The proposed framework addresses challenges arising from data gaps and the complexity of generalizing knowledge across cities, and consistently outperforms state-of-the-art baselines on multiple real-world datasets.\n\nStrengths:\n1. The proposed framework addresses the challenges of data scarcity and heterogeneity in smart city applications, enabling effective knowledge transfer and improving prediction performance.\n2. The use of a Transformer-based denoising diffusion model provides a flexible and powerful approach for generating tailored neural networks.\n3. The framework is model-agnostic, ensuring compatibility with existing urban computing models.\n\nWeaknesses:\n1. The paper does not provide a comprehensive analysis of the limitations of the proposed framework, such as the impact of prompt selection and the potential for overfitting.\n2. The experimental results, while promising, are limited to a small number of datasets and may not be generalizable to other scenarios.\n3. The paper does not provide a detailed explanation of the hyperparameter tuning process and the potential impact of hyperparameter choices on the performance of the framework.\n\nSuggestions for Improvement:\n1. Conduct a more comprehensive analysis of the limitations of the proposed framework, including an investigation of the impact of prompt selection and the potential for overfitting.\n2. Perform experiments on a larger and more diverse set of datasets to demonstrate the generalizability of the framework.\n3. Provide a detailed explanation of the hyperparameter tuning process and the potential impact of hyperparameter choices on the performance of the framework.\n\nRecommendation:\nThe proposed framework, GPD, has the potential to revolutionize spatio-temporal few-shot learning in smart city applications. However, further research is needed to fully explore the capabilities and limitations of the framework. Specifically, conducting a more comprehensive analysis of the limitations of the framework and performing experiments on a larger and more diverse set of datasets are recommended. Additionally, providing a detailed explanation of the hyperparameter tuning process and the potential impact of hyperparameter choices on the performance of the framework is crucial for ensuring the robustness and reliability of the framework. \n\n$$",
        "peer_review_with_watermark": "$$\n\n$$$Paper Summary:\nThe paper proposes a generative pre-training framework (GPD) for spatio-temporal few-shot learning with urban knowledge transfer. The proposed framework leverages pre-training paradigm to achieve effective fine-grained spatio-temporal knowledge transfer across different cities. The framework employs a transformer-based denoising diffusion model to generate tailored neural networks guided by prompts. The paper presents extensive experiments on multiple real-world scenarios and achieves superior performance towards data-scarce scenarios with an average improvement of 7.87% over the best baseline on four datasets.\n\nStrengths:\n1. The proposed framework addresses the challenges posed by data scarcity and heterogeneity in smart city applications.\n2. The use of pre-training paradigm and generative diffusion model enables effective fine-grained spatio-temporal knowledge transfer across different cities.\n3. The model-agnostic nature of the proposed framework ensures compatibility with existing urban computing models.\n4. The paper presents extensive experiments on multiple real-world scenarios and achieves superior performance towards data-scarce scenarios.\n\nWeaknesses:\n1. The paper assumes that the pre-trained models have been trained on large-scale spatio-temporal data, which may not be the case for all cities and regions.\n2. The proposed framework may not be suitable for very small or very large cities or regions due to the computational cost and memory requirements.\n3. The paper does not discuss the potential biases and limitations of the proposed framework, such as the bias towards certain regions or cities.\n4. The paper assumes that the prompts are well-designed and effective in capturing the unique characteristics of the target city.\n\nSuggestions for Improvement:\n1. The paper should discuss the potential biases and limitations of the proposed framework and provide strategies for mitigating them.\n2. The paper should discuss the potential applications and use cases of the proposed framework in different smart city applications.\n3. The paper should provide more details on the design and implementation of the proposed framework, including the choice of hyperparameters and the training procedure.\n4. The paper should discuss the potential extensions and future work on the proposed framework, such as incorporating more advanced techniques for prompt selection and generating more realistic urban scenarios.\n\nRecommendation:\nThe proposed framework is a valuable contribution to the field of spatio-temporal few-shot learning with urban knowledge transfer. The model-agnostic nature and pre-training paradigm make it a promising approach for addressing the challenges posed by data scarcity and heterogeneity in smart city applications. The paper presents extensive experiments and achieves superior performance towards data-scarce scenarios. However, the paper assumes that the pre-trained models have been trained on large-scale spatio-temporal data, which may not be the case for all cities and regions. Therefore, it is recommended that the authors provide more details on the design and implementation of the proposed framework and discuss the potential biases and limitations of the proposed framework.",
        "gr_score_with": 0.7397660818713451,
        "gr_score_without": 0.617363344051447,
        "output_without": {
            "num_tokens_scored": 311,
            "num_green_tokens": 192,
            "green_fraction": 0.617363344051447,
            "z_score": -3.18011834002463,
            "p_value": 0.9992639254016258
        },
        "output_with": {
            "num_tokens_scored": 342,
            "num_green_tokens": 253,
            "green_fraction": 0.7397660818713451,
            "z_score": 1.604782604250857,
            "p_value": 0.05427082778829038
        }
    },
    {
        "title": "HAZARD CHALLENGE: EMBODIED DECISION MAK-",
        "abstract": "Recent advances in high-fidelity virtual environments serve as one of the major driving forces for building intelligent embodied agents to perceive, reason and interact with the physical world. Typically, these environments remain unchanged unless agents interact with them. However, in real-world scenarios, agents might also face dynamically changing environments characterized by unexpected events and need to rapidly take action accordingly. To remedy this gap, we propose a new simulated embodied benchmark, called HAZARD, specifically designed to assess the decision-making abilities of embodied agents in dynamic situations. HAZARD consists of three unexpected disaster scenarios, including fire , flood , and wind , and specifically supports the utilization of large language models (LLMs) to assist common sense reasoning and decision-making. This benchmark enables us to evaluate autonomous agents\u2019 decision-making capabilities across various pipelines, including reinforcement learning (RL), rule-based, and search-based methods in dynamically changing environments. As a first step toward addressing this challenge using large language models, we further develop an LLM-based agent and perform an in-depth analysis of its promise and challenge of solving these challenging tasks. HAZARD is available at https://sites.google. com/view/hazard-challenge.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces the HAZARD challenge, a novel benchmark for evaluating embodied agents' decision-making capabilities in dynamically changing environments. The challenge consists of three unexpected disaster scenarios (fire, flood, and wind) and requires agents to rescue valuable items from these continuously evolving circumstances. The authors develop a simulation system on top of the ThreeDWorld platform, which enables simulations of fire, flood, and wind scenarios. They also introduce an LLM-based agent and evaluate its performance using the generated dataset.\n\nStrengths:\n\n1. The HAZARD challenge provides a novel and challenging benchmark for embodied agents, which can help advance the field of embodied AI.\n2. The authors develop a simulation system that enables simulations of complex and dynamic environments, which can be used to evaluate agents' decision-making capabilities.\n3. The introduction of an LLM-based agent provides a new perspective on embodied AI and can help explore the potential of LLMs in decision-making tasks.\n\nWeaknesses:\n\n1. The paper does not provide a clear evaluation metric for the HAZARD challenge, which can make it difficult to compare the performance of different agents.\n2. The authors do not provide a detailed analysis of the LLM-based agent's decision-making process, which can make it difficult to understand how the agent makes decisions.\n3. The paper does not provide a clear comparison between the LLM-based agent and other baseline methods, which can make it difficult to understand the relative performance of the agent.\n\nSuggestions for Improvement:\n\n1. The authors should provide a clear evaluation metric for the HAZARD challenge, such as a reward function that rewards agents for rescuing valuable items and penalizes them for failing to do so.\n2. The authors should provide a more detailed analysis of the LLM-based agent's decision-making process, including a description of how the agent uses the LLM to make decisions.\n3. The authors should provide a more detailed comparison between the LLM-based agent and other baseline methods, including a discussion of the relative performance of each agent.\n\nRecommendation:\n\nI recommend that the authors revise the paper to address the weaknesses and provide a more detailed analysis of the LLM-based agent's decision-making process. Additionally, I recommend that the authors provide a clear evaluation metric for the HAZARD challenge and compare the performance of the LLM-based agent to other baseline methods.\n\nRating: 8/10\n\n$$$",
        "peer_review_with_watermark": "$$\n\\begin{aligned}\n\\text{Paper Summary:} \nHAZARD is a novel challenge designed to assess the decision-making abilities of embodied agents in dynamic situations. The challenge consists of three unexpected disaster scenarios (fire, flood, and wind) and requires agents to rescue valuable items from continuously evolving and perilous circumstances. The challenge is designed to evaluate autonomous agents' decision-making capabilities across various pipelines, including reinforcement learning, rule-based, and search-based methods. The paper proposes a new simulated embodied benchmark, called HAZARD, specifically designed to assess the decision-making abilities of embodied agents in dynamic situations.\n\n\\text{Strengths:}\n1. The paper introduces a novel challenge that assesses the decision-making abilities of embodied agents in dynamic situations.\n2. The challenge is designed to evaluate autonomous agents' decision-making capabilities across various pipelines.\n3. The paper proposes a new simulated embodied benchmark, called HAZARD, which is specifically designed to assess the decision-making abilities of embodied agents in dynamic situations.\n4. The paper presents a comprehensive analysis of the challenges posed by perception and reasoning for existing methods, especially LLM-based agents in tackling the proposed benchmark.\n\n\\text{Weaknesses:}\n1. The paper does not provide a detailed analysis of the limitations of the HAZARD challenge.\n2. The paper does not discuss the potential biases in the HAZARD challenge.\n3. The paper does not provide a detailed comparison with other benchmarks in the field.\n4. The paper does not discuss the potential applications of the HAZARD challenge in real-world scenarios.\n\n\\text{Suggestions for Improvement:}\n1. The paper should provide a detailed analysis of the limitations of the HAZARD challenge.\n2. The paper should discuss the potential biases in the HAZARD challenge.\n3. The paper should provide a detailed comparison with other benchmarks in the field.\n4. The paper should discuss the potential applications of the HAZARD challenge in real-world scenarios.\n5. The paper should provide more detailed results and analysis, especially in the experiments section.\n\n\\text{Recommendation:}\nBased on the analysis, I recommend that the paper be published in a top-tier conference in the field of embodied AI. The paper presents a novel challenge that assesses the decision-making abilities of embodied agents in dynamic situations, and the results demonstrate the potential of LLM-based agents in tackling the challenge. However, the paper needs to address the limitations and biases of the HAZARD challenge and provide more detailed results and analysis. \n\n$$\n\\end{aligned}\n$$",
        "gr_score_with": 0.8307692307692308,
        "gr_score_without": 0.7612456747404844,
        "output_without": {
            "num_tokens_scored": 289,
            "num_green_tokens": 220,
            "green_fraction": 0.7612456747404844,
            "z_score": 2.272033327751217,
            "p_value": 0.011542248722662659
        },
        "output_with": {
            "num_tokens_scored": 260,
            "num_green_tokens": 216,
            "green_fraction": 0.8307692307692308,
            "z_score": 4.601321676666517,
            "p_value": 2.0990924393646686e-06
        }
    },
    {
        "title": "RETRO-FALLBACK: RETROSYNTHETIC PLANNING IN AN UNCERTAIN WORLD",
        "abstract": "Retrosynthesis is the task of proposing a series of chemical reactions to create a desired molecule from simpler, buyable molecules. While previous works have proposed algorithms to find optimal solutions for a range of metrics (e.g. shortest, lowest-cost), these works generally overlook the fact that we have imperfect knowledge of the space of possible reactions, meaning plans created by the algorithm may not work in a laboratory. In this paper we propose a novel formulation of retrosynthesis in terms of stochastic processes to account for this uncertainty. We then propose a novel greedy algorithm called retro-fallback which maximizes the probability that at least one synthesis plan can be executed in the lab. Using in-silico benchmarks we demonstrate that retro-fallback generally produces better sets of synthesis plans than the popular MCTS and retro* algorithms.",
        "peer_review_without_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes a novel approach to retrosynthesis, a task in chemistry to plan the synthesis of organic molecules via a series of chemical reactions. The authors introduce a novel evaluation metric, successful synthesis probability (SSP), which accounts for the uncertainty of reaction feasibility and buyability. They also propose a novel algorithm, retro-fallback, which greedily optimizes SSP by maximizing the probability that at least one synthesis plan can be executed in the lab. The authors demonstrate that retro-fallback outperforms existing algorithms on an in-silico benchmark.\n\nStrengths:\n1. The paper introduces a novel evaluation metric, SSP, which accounts for the uncertainty of reaction feasibility and buyability.\n2. The authors propose a novel algorithm, retro-fallback, which greedily optimizes SSP.\n3. The paper demonstrates that retro-fallback outperforms existing algorithms on an in-silico benchmark.\n\nWeaknesses:\n1. The paper does not provide a clear explanation of the assumptions made about the reaction feasibility and buyability models.\n2. The authors assume that the reaction feasibility and buyability models are independent, which may not be realistic in practice.\n3. The paper does not provide a detailed analysis of the computational complexity of the retro-fallback algorithm.\n\nSuggestions for Improvement:\n1. Provide a clear explanation of the assumptions made about the reaction feasibility and buyability models.\n2. Investigate the impact of non-independence of reaction feasibility and buyability models on the performance of retro-fallback.\n3. Analyze the computational complexity of the retro-fallback algorithm in more detail.\n\nRecommendation:\nThe paper presents a novel approach to retrosynthesis and introduces a novel evaluation metric and algorithm. The authors demonstrate that retro-fallback outperforms existing algorithms on an in-silico benchmark. However, the paper needs to address the assumptions made about the reaction feasibility and buyability models and provide a more detailed analysis of the computational complexity of the retro-fallback algorithm. With these improvements, the paper has the potential to make a significant contribution to the field of retrosynthesis.",
        "peer_review_with_watermark": "$$$\\boxed{\\text{Paper Review}}$$\n\nThe paper proposes a novel approach to retrosynthesis, which is the task of proposing a series of chemical reactions to create a desired molecule from simpler, buyable molecules. The authors present a novel formulation of retrosynthesis in terms of stochastic processes to account for uncertainty in the space of possible reactions. They also propose a novel greedy algorithm called retro-fallback, which maximizes the probability that at least one synthesis plan can be executed in the lab.\n\n**Paper Summary**\n\nThe authors summarize the problem of retrosynthesis and the current state of the art in this field. They introduce the concept of stochastic processes to model uncertainty in the space of possible reactions and propose a novel evaluation metric called successful synthesis probability (SSP). They also introduce the retro-fallback algorithm, which is a novel greedy algorithm that maximizes the probability that at least one synthesis plan can be executed in the lab.\n\n**Strengths**\n\n1. The authors provide a clear and concise introduction to the problem of retrosynthesis and the current state of the art in this field.\n2. The novel formulation of retrosynthesis in terms of stochastic processes to account for uncertainty in the space of possible reactions is an interesting and innovative approach.\n3. The authors propose a novel evaluation metric called successful synthesis probability (SSP), which captures the idea of finding good synthesis plans and backup plans.\n4. The retro-fallback algorithm is a novel and interesting approach that maximizes the probability that at least one synthesis plan can be executed in the lab.\n\n**Weaknesses**\n\n1. The authors assume that the uncertainty in the space of possible reactions can be modeled using stochastic processes, which may not be the case in practice.\n2. The authors propose a novel evaluation metric called successful synthesis probability (SSP), but they do not provide a clear explanation of why this metric is more effective than other evaluation metrics.\n3. The retro-fallback algorithm may not be effective in practice, as it may not be able to handle complex synthesis plans.\n4. The authors do not provide a clear comparison between the retro-fallback algorithm and other state-of-the-art algorithms in the field.\n\n**Suggestions for Improvement**\n\n1. The authors should provide a more detailed explanation of why the stochastic processes are more effective than other approaches to modeling uncertainty in the space of possible reactions.\n2. The authors should provide a more detailed comparison between the retro-fallback algorithm and other state-of-the-art algorithms in the field.\n3. The authors should consider using more advanced techniques, such as Bayesian neural networks, to model the uncertainty in the space of possible reactions.\n4. The authors should provide a more detailed analysis of the performance of the retro-fallback algorithm in practice, including the impact of the number of samples and the complexity of the synthesis plans.\n\n**Recommendation**\n\nBased on the paper review, I recommend that the authors revise and resubmit their paper. While the paper has some strengths, such as the novel formulation of retrosynthesis and the retro-fallback algorithm, it also has some weaknesses, such as the assumption that stochastic processes are more effective than other approaches to modeling uncertainty. The authors should provide more detailed explanations and comparisons to strengthen their paper.",
        "gr_score_with": 0.8252148997134671,
        "gr_score_without": 0.75,
        "output_without": {
            "num_tokens_scored": 240,
            "num_green_tokens": 180,
            "green_fraction": 0.75,
            "z_score": 1.6903085094570331,
            "p_value": 0.045484473987678874
        },
        "output_with": {
            "num_tokens_scored": 349,
            "num_green_tokens": 288,
            "green_fraction": 0.8252148997134671,
            "z_score": 5.104568969946953,
            "p_value": 1.657746697446349e-07
        }
    },
    {
        "title": "TUVF: LEARNING GENERALIZABLE TEXTURE UV RADIANCE FIELDS",
        "abstract": "Figure 1: We propose Texture UV Radiance Fields (TUVF) to render a 3D consistent texture given a 3D object shape input. TUVF provides a category-level texture representation disentangled from 3D shapes. Top three rows: TUVF can synthesize realistic textures by training from a collection of single-view images; Fourth row: Given a 3D shape input, we can render different textures on top by using different texture codes; Bottom row: We can perform editing on a given texture (adding a flag of France) and directly apply the same texture on different 3D shapes without further fine-tuning. Note that all samples are rendered under 1024\u00d71024 resolution; zoom-in is recommended. ABSTRACT",
        "peer_review_without_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes Texture UV Radiance Fields (TUVF) for generating high-quality, disentangled textures for a given 3D object shape. TUVF uses a canonical surface auto-encoder to establish dense correspondences between a canonical UV sphere and all instances in a category. The texture generator uses a point-based architecture to produce a texture feature vector for each point on the UV sphere. The paper evaluates TUVF on three datasets (CompCars, Photoshape, and DiffusionCats) and compares it with several state-of-the-art approaches. The results show that TUVF achieves significant improvements over the baseline approaches in terms of texture synthesis, texture swapping, and editing.\n\n$\\boxed{Strengths:}\n1. The paper proposes a novel approach to texture synthesis that leverages the UV sphere space for disentangled texture generation.\n2. The use of a canonical surface auto-encoder enables dense correspondences between the UV sphere and the 3D shape, allowing for efficient rendering and texture transfer.\n3. The point-based architecture for texture generation produces realistic and diverse textures on the UV sphere.\n4. The paper evaluates TUVF on multiple datasets and compares it with several state-of-the-art approaches, demonstrating its effectiveness.\n\n$\\boxed{Weaknesses:}\n1. The paper assumes a one-to-one dense mapping between the UV sphere and the 3D shape, which may not always hold in real-world scenarios.\n2. The current implementation of the texture generator architecture may suffer from explicit parameterization and interactions between pixels, which can degrade its performance.\n3. The paper does not discuss the potential limitations of the canonical surface auto-encoder, such as the requirement for dense point correspondences.\n\n$\\boxed{Suggestions for Improvement:}\n1. Investigate alternative approaches to establish dense correspondences between the UV sphere and the 3D shape, such as using sparse point correspondences or learning a more robust mapping.\n2. Refine the texture generator architecture to avoid explicit parameterization and interactions between pixels, potentially by incorporating more sophisticated neural rendering architectures.\n3. Discuss the potential limitations of the canonical surface auto-encoder and explore ways to mitigate them, such as using more robust point correspondences or incorporating advanced data-driven priors.\n\n$\\boxed{Recommendation:}\nBased on the evaluation results, I recommend accepting the paper for publication. The proposed approach, TUVF, demonstrates significant improvements over state-of-the-art approaches in terms of texture synthesis, texture swapping, and editing. However, the paper should address the limitations and potential drawbacks discussed above to further strengthen its contributions.",
        "peer_review_with_watermark": "$$$\\begin{align*}\n\\textbf{Paper Summary:} \nThe authors propose Texture UV Radiance Fields (TUVF), a novel texture representation that disentangles the texture from the 3D shape of an object. They train the model on two real-world datasets and a synthetic dataset, achieving significant improvements over state-of-the-art approaches in texture swapping and editing applications. TUVF is a category-level texture representation that can be applied to different shapes without fine-tuning.\n\n\\textbf{Strengths:} \n1. TUVF achieves high-quality and realistic texture synthesis and substantial improvements over state-of-the-art approaches.\n2. The authors leverage the UV sphere space with a continuous radiance field, making the model compact and efficient as a surface representation.\n3. TUVF can generate consistent textures over different object shapes and more diverse textures with the same object shape.\n\n\\textbf{Weaknesses:} \n1. The current correspondence assumes one-to-one dense mapping, which may not always hold in real-world scenarios.\n2. The model may suffer from topology constraints and cannot easily adapt to continuous radiance fields.\n3. The authors mention that the learned texture representation often highly depends on the input geometry, making the synthesis process less controllable.\n\n\\textbf{Suggestions for Improvement:} \n1. To address the one-to-one dense mapping assumption, the authors can explore using multi-resolution or multi-scale correspondences.\n2. To improve the model's ability to adapt to continuous radiance fields, the authors can use more sophisticated neural rendering architectures, such as ray transformers.\n3. To mitigate the distortions and improve the quality of the generated textures, the authors can incorporate advanced data-driven priors, such as diffusion models.\n\n\\textbf{Recommendation:} \nThe authors make significant contributions to the field of texture synthesis and radiance fields. TUVF is a novel and effective approach for high-quality and disentangled texture generation on a given 3D shape. With some improvements and modifications, TUVF has the potential to be a leading approach in the field of texture synthesis and radiance fields.\n\n \n\n$$$",
        "gr_score_with": 0.7415384615384616,
        "gr_score_without": 0.748587570621469,
        "output_without": {
            "num_tokens_scored": 354,
            "num_green_tokens": 265,
            "green_fraction": 0.748587570621469,
            "z_score": 1.9948818018324355,
            "p_value": 0.023027886381373354
        },
        "output_with": {
            "num_tokens_scored": 325,
            "num_green_tokens": 241,
            "green_fraction": 0.7415384615384616,
            "z_score": 1.6341143382057701,
            "p_value": 0.05111742236774355
        }
    },
    {
        "title": "CODERS FOR INTRINSICALLY LOW-DIMENSIONAL DATA",
        "abstract": "Variational Autoencoders (VAEs) have gained significant popularity among researchers as a powerful tool for understanding unknown distributions based on limited samples. This popularity stems partly from their impressive performance and partly from their ability to provide meaningful feature representations in the latent space. Wasserstein Autoencoders (WAEs), a variant of VAEs, aim to not only improve model efficiency but also interpretability. However, there has been limited focus on analyzing their statistical guarantees. The matter is further complicated by the fact that the data distributions to which WAEs are applied such as natural images are often presumed to possess an underlying low-dimensional structure within a high-dimensional feature space, which current theory does not adequately account for, rendering known bounds inefficient. To bridge the gap between the theory and practice of WAEs, in this paper, we show that WAEs can learn the data distributions when the network architectures are properly chosen. We show that the convergence rates of the expected excess risk in the number of samples for WAEs are independent of the high feature dimension, instead relying only on the intrinsic dimension of the data distribution.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary: \nThe paper proposes a framework to analyze error rates for learning unknown distributions using Wasserstein Autoencoders (WAEs). It aims to bridge the gap between theory and practice by analyzing the statistical guarantees of WAEs when data points exhibit an intrinsically low-dimensional structure in the representative high-dimensional feature space. The authors develop an oracle inequality to characterize excess risk in terms of misspecification, generalization, and optimization errors for the problem. They show that the convergence rates of the expected excess risk in the number of samples for WAEs are independent of the high feature dimension, instead relying only on the intrinsic dimension of the data distribution.\n\n$$\\text{Strengths}:$$ \n- The paper provides a comprehensive analysis of WAEs, which is a variant of VAEs, and its statistical guarantees.\n- The authors develop an oracle inequality to characterize excess risk in terms of misspecification, generalization, and optimization errors for the problem.\n- The framework allows for the analysis of accuracy of encoding and decoding guarantees, i.e., how well the encoded distribution approximates the target latent distribution, and how well the generator maps back the latent codes close to the original data points.\n\n$$\\text{Weaknesses}:$$ \n- The paper assumes that the data distributions are realizable, meaning that a \"true\" generator and a \"true\" encoder exist, which may not hold in practice.\n- The analysis is based on a simplified assumption that the network architectures are properly chosen, which may not be true in all cases.\n- The paper does not consider the scenario where the optimization error term is not negligible, which is a significant challenge in practical applications.\n\n$$\\text{Suggestions for Improvement}:$$ \n- Consider relaxing the assumption that the data distributions are realizable, and analyze the case where the data distributions are not realizable.\n- Consider analyzing the scenario where the optimization error term is not negligible, and develop a framework to estimate and bound this term.\n- Consider extending the framework to analyze the accuracy of other types of autoencoders, such as conditional autoencoders or generative adversarial networks.\n\n$$\\text{Recommendation}:$$ \n- The paper provides a valuable contribution to the field of machine learning and autoencoders. The authors develop a comprehensive framework to analyze the statistical guarantees of WAEs, which is a variant of VAEs.\n- The paper highlights the importance of considering the intrinsic dimension of the data distribution in analyzing the accuracy of autoencoders.\n- The framework provides a useful tool for analyzing the accuracy of autoencoders in a wide range of applications, including image generation, text generation, and speech synthesis.",
        "peer_review_with_watermark": "$$\\boxed{\\text{Paper Summary:}}$$\n\nThe paper presents a theoretical analysis of the error rates for learning unknown distributions using Wasserstein Autoencoders (WAEs), especially when data points exhibit an intrinsically low-dimensional structure in the representative high-dimensional feature space. The authors characterize this low dimensionality with the upper Minkowski dimension of the support of the target distribution. They develop an oracle inequality to bound the excess risk in terms of misspecification, generalization, and optimization errors for the problem. The excess risk bounds are obtained by balancing model-misspecification and stochastic errors to find proper network architectures in terms of the number of samples that achieve this tradeoff.\n\n$$\\boxed{\\text{Strengths:}}$$\n\n1. The paper presents a comprehensive theoretical analysis of the error rates for learning unknown distributions using WAEs, which is essential for understanding the capabilities and limitations of this model.\n2. The authors characterize the low dimensionality of the data distribution using the upper Minkowski dimension, which is a well-established concept in the field.\n3. The oracle inequality provides a rigorous bound on the excess risk, which is essential for understanding the tradeoff between model-misspecification and stochastic errors.\n4. The paper provides a detailed analysis of the encoding and decoding guarantees, which is essential for understanding the accuracy of the approximating push-forward measure.\n\n$$\\boxed{\\text{Weaknesses:}}$$\n\n1. The paper assumes that the data distribution is realizable, which is not necessarily true in practice. This assumption may limit the applicability of the results.\n2. The paper does not consider the optimization error term, which is essential for understanding the overall error in practical applications.\n3. The analysis is focused on the case where the dissimilarity measure is the Wasserstein-1 metric or the squared MMD-metric. It is unclear how the results would generalize to other dissimilarity measures.\n4. The paper does not provide empirical results to support the theoretical analysis, which is essential for understanding the practical implications of the results.\n\n$$\\boxed{\\text{Suggestions for Improvement:}}$$\n\n1. Consider relaxing the assumption that the data distribution is realizable, and instead, use techniques such as regularization or ensemble methods to handle the non-convex optimization problem.\n2. Derive the excess risk bounds for other dissimilarity measures, such as the MMD-metric or the Hausdorff distance.\n3. Provide empirical results to support the theoretical analysis, such as experiments on synthetic and real-world datasets.\n4. Consider developing a framework for analyzing the error rates for learning unknown distributions using other models, such as Generative Adversarial Networks (GANs) or Variational Autoencoders (VAEs).\n\n$$\\boxed{\\text{Recommendation:}}$$\n\nBased on the analysis, it is recommended that the paper be accepted for publication, subject to the revisions suggested above. The paper presents a comprehensive theoretical analysis of the error rates for learning unknown distributions using WAEs, which is essential for understanding the capabilities and limitations of this model. The authors characterize the low dimensionality of the data distribution using the upper Minkowski dimension, and develop an oracle inequality that provides a rigorous bound on the excess risk. However, the paper assumes that the data distribution is realizable, and does not consider the optimization error term, which are essential considerations in practice. With revisions to address these limitations, the paper has the potential to make significant contributions to the field.",
        "gr_score_with": 0.7902097902097902,
        "gr_score_without": 0.729050279329609,
        "output_without": {
            "num_tokens_scored": 358,
            "num_green_tokens": 261,
            "green_fraction": 0.729050279329609,
            "z_score": 1.1994500823848468,
            "p_value": 0.11517649179053846
        },
        "output_with": {
            "num_tokens_scored": 429,
            "num_green_tokens": 339,
            "green_fraction": 0.7902097902097902,
            "z_score": 4.077300041004545,
            "p_value": 2.2780841534209974e-05
        }
    },
    {
        "title": "TOOL-AUGMENTED REWARD MODELING",
        "abstract": "Reward modeling (a.k.a., preference modeling) is instrumental for aligning large language models with human preferences, particularly within the context of reinforcement learning from human feedback (RLHF). While conventional reward models (RMs) have exhibited remarkable scalability, they oft struggle with fundamental functionality such as arithmetic computation, code execution, and factual lookup. In this paper, we propose a tool-augmented preference modeling approach, named Themis, to address these limitations by empowering RMs with access to external environments, including calculators and search engines. This approach not only fosters synergy between tool utilization and reward grading but also enhances interpretive capacity and scoring reliability. Our study delves into the integration of external tools into RMs, enabling them to interact with diverse external sources and construct task-specific tool engagement and reasoning traces in an autoregressive manner. We validate our approach across a wide range of domains, incorporating seven distinct external tools. Our experimental results demonstrate a noteworthy overall improvement of 17.7% across eight tasks in preference ranking. Furthermore, our approach outperforms Gopher 280B by 7.3% on TruthfulQA task in zero-shot evaluation. In human evaluations, RLHF trained with Themis attains an average win rate of 32% when compared to baselines across four distinct tasks. Additionally, we provide a comprehensive collection of tool-related RM datasets, incorporating data from seven distinct tool APIs, totaling 15,000 instances. We have made the code, data, and model checkpoints publicly available to facilitate and inspire further research advancements1.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes a novel approach called Themis, which enhances reward models by enabling interaction with external tools. Themis integrates tool engagement and reasoning processes in a structured, step-by-step manner, allowing reward models to access external knowledge and information. The authors validate their approach across a wide range of domains, demonstrating a noteworthy improvement of 17.7% in preference ranking and outperforming Gopher 280B by 7.3% on TruthfulQA task. The authors also provide a comprehensive collection of tool-related RM datasets, including the newly created Tool-Augmented Reward Dataset (TARA), which comprises 15,000 instances.\n\nStrengths:\n1. The paper introduces a novel approach that addresses the limitations of conventional reward models by incorporating external tools.\n2. The authors provide a comprehensive validation of their approach across multiple domains and tasks.\n3. The creation of the TARA dataset is a significant contribution, providing a valuable resource for future research.\n\nWeaknesses:\n1. The paper does not provide a detailed explanation of the tool-augmented reward modeling process, making it challenging to understand the underlying mechanisms.\n2. The authors rely heavily on external tools, which may introduce bias and limitations in the evaluation of the approach.\n3. The paper does not discuss potential risks and challenges associated with the integration of external tools in reward modeling.\n\nSuggestions for Improvement:\n1. Provide a more detailed explanation of the tool-augmented reward modeling process to improve the understanding of the underlying mechanisms.\n2. Evaluate the approach using multiple metrics and consider potential risks and challenges associated with the integration of external tools.\n3. Conduct further research to explore the potential applications of Themis in multi-turn dialogue generation and other areas.\n\nRecommendation:\nI recommend that the authors revise the paper to address the weaknesses and suggestions for improvement. The revised paper should provide a more detailed explanation of the tool-augmented reward modeling process, evaluate the approach using multiple metrics, and discuss potential risks and challenges associated with the integration of external tools. The revised paper should also explore the potential applications of Themis in multi-turn dialogue generation and other areas. With these revisions, the paper has the potential to make a significant contribution to the field of natural language processing and reinforcement learning.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper introduces Themis, a novel tool-augmented preference modeling approach designed to align large language models (LLMs) with human preferences, particularly in reinforcement learning from human feedback (RLHF). Themis empowers RMs with access to external environments, including calculators and search engines, enhancing interpretive capacity and scoring reliability. The authors validate their approach across eight tasks, demonstrating a notable improvement of 17.7% in preference ranking and outperforming Gopher 280B by 7.3% on the TruthfulQA task.\n\nStrengths:\n\n* Themis effectively addresses the limitations of conventional reward models (RMs) by incorporating external tool utilization and reasoning processes.\n* The approach provides transparency and interpretability, making it easier to fine-tune and modify intermediate steps.\n* The creation of a comprehensive tool-augmented reward dataset (TARA) offers a valuable resource for future research.\n* The experimental results demonstrate substantial benefits in augmenting interpretive capacity and scoring reliability.\n\nWeaknesses:\n\n* The paper's focus on tool-augmented preference modeling may limit its applicability to other areas of NLP.\n* The evaluation of Themis primarily relies on a specific set of tasks and datasets, which may not generalize well to other contexts.\n* The authors could have provided more detailed explanations of the tool-augmented reasoning process and its role in enhancing RMs.\n\nSuggestions for Improvement:\n\n* Investigate Themis's applicability to other areas of NLP, such as dialogue generation and code understanding.\n* Expand the evaluation of Themis to include more diverse datasets and tasks to ensure generalizability.\n* Provide more detailed explanations of the tool-augmented reasoning process and its impact on RMs.\n\nRecommendation:\n\n* The proposed tool-augmented preference modeling approach, Themis, has significant potential in enhancing RMs and improving their performance in RLHF. While there are areas for improvement, Themis's ability to address the limitations of conventional RMs and provide transparency and interpretability make it a valuable contribution to the field. With further research and evaluation, Themis can become a leading approach in NLP. \n\nRating: 8/10\n\n$$$",
        "gr_score_with": 0.6951566951566952,
        "gr_score_without": 0.599388379204893,
        "output_without": {
            "num_tokens_scored": 327,
            "num_green_tokens": 196,
            "green_fraction": 0.599388379204893,
            "z_score": -3.9701999015037113,
            "p_value": 0.999964093822335
        },
        "output_with": {
            "num_tokens_scored": 351,
            "num_green_tokens": 244,
            "green_fraction": 0.6951566951566952,
            "z_score": -0.19800935804747213,
            "p_value": 0.5784811289841949
        }
    },
    {
        "title": "ADOPD: A LARGE-SCALE DOCUMENT PAGE DECOM-",
        "abstract": "Recent research in document image understanding is impeded by the scarcity of high-quality data. We introduce ADoPD, a large-scale dataset for document page decomposition. ADoPD distinguishes itself by utilizing a novel data-driven document taxonomy discovery method for data collection. Our approach takes advantage of both large-scale pretrained models and human-in-the-loop process, ensuring diversity and balance in our data collection. Leveraging our data-driven document taxonomy, we collected and densely annotated labels for document images, covering four document image understanding tasks: Doc2Mask, Doc2Box, Doc2Tag, and Doc2Seq. Specifically, for each image, the annotations include human-labeled entity masks, text bounding boxes, as well as automatically generated tags and captions. We provide detailed experimental analyses to validate our data-driven document taxonomy method and experimentally analyze the four tasks based on different models. We believe that ADoPD has the potential to become a cornerstone dataset to support future research on document image understanding.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces ADOPD, a large-scale dataset for document page decomposition. ADOPD is constructed using a novel data-driven document taxonomy discovery method, which utilizes large-scale pretrained models and a human-in-the-loop process to ensure diversity and balance in the data collection. The dataset comprises four document page decomposition tasks: entity segmentation, text detection, tagging, and captioning. The authors conduct extensive experiments and analysis to validate the effectiveness of ADOPD and its potential to support future research in document image understanding.\n\nStrengths:\n1. Novel data-driven approach for constructing document taxonomies during data collection.\n2. Comprehensive dataset for document page decomposition, encompassing four distinct tasks.\n3. Utilization of large-scale pretrained models and human-in-the-loop process to ensure data diversity and balance.\n4. Detailed experimental analysis and comparisons across four tasks.\n\nWeaknesses:\n1. Limited evaluation of the data-driven taxonomy discovery method.\n2. Lack of discussion on the potential biases and limitations of the dataset.\n3. Over-reliance on pre-trained models, which may not generalize well to new tasks or datasets.\n4. Limited exploration of the potential applications and directions for future research.\n\nSuggestions for Improvement:\n1. Conduct a more comprehensive evaluation of the data-driven taxonomy discovery method, including a thorough analysis of its strengths and limitations.\n2. Discuss the potential biases and limitations of the dataset, including the impact of data collection methods and the representation of diverse document types.\n3. Explore the potential applications and directions for future research, including the analysis of multi-lingual documents and sensitive data.\n4. Consider incorporating more diverse and representative document types, including scanned or photographed images, to improve the generalizability of the dataset.\n\nRecommendation:\nADOPD is a valuable contribution to the field of document image understanding, providing a comprehensive dataset for document page decomposition and a systematic process for data collection, taxonomy analysis, model-assisted data annotation, and HITL processes. However, further research is needed to fully explore the potential of ADOPD and to address the limitations and biases of the dataset.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper introduces ADoPD, a large-scale document page decomposition dataset, which aims to bridge the data and model gap between the document domain and the natural image, as well as the vision-language domain. ADoPD is constructed using a novel data-driven document taxonomy discovery method, which leverages large-scale pretrained models and human-in-the-loop process to ensure diversity and balance in the data collection. The dataset encompasses four document page decomposition tasks: entity segmentation, text detection, tagging, and captioning. The authors conduct extensive experiments and analysis to validate the effectiveness and generalization capabilities of ADoPD.\n\nStrengths:\n1. ADoPD is a novel and significant contribution to the document image understanding community, as it provides a large-scale and diverse dataset for document page decomposition tasks.\n2. The authors' proposed data-driven document taxonomy discovery method is effective in ensuring diversity and balance in the data collection.\n3. The paper presents a comprehensive experimental analysis, which provides insights into the performance and generalization capabilities of ADoPD.\n\nWeaknesses:\n1. The paper does not provide sufficient information about the size and distribution of the dataset, which could be an important factor in evaluating its effectiveness.\n2. Some of the experimental results, such as the evaluation metrics for DOC2TAG, are not clearly explained or presented in the paper.\n3. The paper relies heavily on the authors' proposed methods and models, which may not be widely adopted or accepted in the community.\n\nSuggestions for Improvement:\n1. Provide more information about the size and distribution of the dataset, including the number of images, classes, and annotations.\n2. Clearly explain and present the evaluation metrics for each task, including the metrics used for DOC2TAG.\n3. Provide more details about the experimental setup, including the specific models and hyperparameters used, to facilitate replication and evaluation.\n\nRecommendation:\nThe paper presents an important contribution to the document image understanding community, and ADoPD has the potential to become a cornerstone dataset for future research. However, to further improve the paper, the authors should provide more information about the dataset and experimental results, and clearly explain and present the evaluation metrics for each task. Additionally, the authors should consider submitting the paper to a journal with a stronger focus on computer vision and natural language processing to increase its visibility and impact.",
        "gr_score_with": 0.7611940298507462,
        "gr_score_without": 0.6383647798742138,
        "output_without": {
            "num_tokens_scored": 318,
            "num_green_tokens": 203,
            "green_fraction": 0.6383647798742138,
            "z_score": -2.39846212083355,
            "p_value": 0.9917679603715461
        },
        "output_with": {
            "num_tokens_scored": 335,
            "num_green_tokens": 255,
            "green_fraction": 0.7611940298507462,
            "z_score": 2.4441159780177037,
            "p_value": 0.0072603788751458495
        }
    },
    {
        "title": "SPURIOUS FEATURES IN PROMPT DESIGN or: How I learned to start worrying about prompt formatting",
        "abstract": "As large language models (LLMs) are adopted as a fundamental component of language technologies, it is crucial to accurately characterize their performance. Because choices in prompt design can strongly influence model behavior, this design process is critical in effectively using any modern pre-trained generative language model. In this work, we focus on LLM sensitivity to a quintessential class of meaning-preserving design choices: prompt formatting. We find that several widely used open-source LLMs are extremely sensitive to subtle changes in prompt formatting in few-shot settings, with performance differences of up to 76 accuracy points when evaluated using LLaMA-2-13B. Sensitivity remains even when increasing model size, the number of few-shot examples, or performing instruction tuning. Our analysis suggests that work evaluating LLMs with prompting-based methods would benefit from reporting a range of performance across plausible prompt formats, instead of the currently-standard practice of reporting performance on a single format. We also show that format performance only weakly correlates between models, which puts into question the methodological validity of comparing models with an arbitrarily chosen, fixed prompt format. To facilitate systematic analysis we propose FORMATSPREAD, an algorithm that rapidly evaluates a sampled set of plausible prompt formats for a given task, and reports the interval of expected performance without accessing model weights1. Furthermore, we present a suite of analyses that characterize the nature of this sensitivity, including exploring the influence of particular atomic perturbations and the internal representation of particular formats.",
        "peer_review_without_watermark": "$$\\boxed{\\text{Paper Summary:}}$$\n\nThe paper presents FORMATSPREAD, an algorithm for estimating the performance spread across prompt formatting choices for few-shot learning tasks with large language models. The authors demonstrate that widely used open-source LLMs are sensitive to subtle changes in prompt formatting, with performance differences of up to 76 accuracy points. They propose FORMATSPREAD, a grammar-based algorithm that efficiently explores the space of plausible prompt formats under a user-specified computational budget. The authors evaluate FORMATSPREAD on several models and tasks, finding that the spread of performance is large regardless of model choice, even when increasing model size, number of few-shots, or when using instruction tuning.\n\n$$\\boxed{\\text{Strengths:}}$$\n\n1. The paper highlights the importance of considering prompt formatting variance in few-shot learning tasks with large language models.\n2. The authors propose a novel algorithm, FORMATSPREAD, that efficiently explores the space of plausible prompt formats under a user-specified computational budget.\n3. The paper demonstrates the effectiveness of FORMATSPREAD on several models and tasks, finding that the spread of performance is large regardless of model choice.\n4. The authors provide a detailed analysis of the nature of prompt format sensitivity, including the influence of atomic perturbations and the internal representation of prompt embeddings.\n\n$$\\boxed{\\text{Weaknesses:}}$$\n\n1. The paper assumes that the reader is familiar with the basics of few-shot learning and large language models, which may not be the case for all readers.\n2. The authors do not provide a clear explanation of the importance of considering prompt formatting variance in few-shot learning tasks with large language models.\n3. The paper does not provide a comprehensive evaluation of FORMATSPREAD on a large set of models and tasks.\n4. The authors do not discuss potential limitations of FORMATSPREAD, such as the potential for overfitting to the grammar or the need for careful tuning of the computational budget.\n\n$$\\boxed{\\text{Suggestions for Improvement:}}$$\n\n1. Provide a clear explanation of the importance of considering prompt formatting variance in few-shot learning tasks with large language models.\n2. Conduct a comprehensive evaluation of FORMATSPREAD on a large set of models and tasks.\n3. Discuss potential limitations of FORMATSPREAD, such as the potential for overfitting to the grammar or the need for careful tuning of the computational budget.\n4. Consider providing a more detailed analysis of the nature of prompt format sensitivity, including the influence of atomic perturbations and the internal representation of prompt embeddings.\n\n$$\\boxed{\\text{Recommendation:}}$$\n\nBased on the paper's findings and the authors' proposal of FORMATSPREAD, I recommend that the authors revise and resubmit the paper with the suggested improvements. The paper presents a novel and important contribution to the field of few-shot learning and large language models, and the authors' proposal of FORMATSPREAD has the potential to significantly impact the field. With the suggested improvements, the paper will be more comprehensive and will provide a clearer understanding of the importance of considering prompt formatting variance in few-shot learning tasks with large language models.",
        "peer_review_with_watermark": "$$\\boxed{\\text{Peer Review}}$$\n\n$$\\text{Paper Summary:}$$\nThe paper introduces FORMATSPREAD, an algorithm for efficiently exploring the space of prompt formats in few-shot learning settings. The authors find that several widely used open-source LLMs are extremely sensitive to subtle changes in prompt formatting, with performance differences of up to 76 accuracy points. They propose FORMATSPREAD, a grammar-based approach that rapidly evaluates a sampled set of plausible prompt formats for a given task, and report the interval of expected performance without accessing model weights. The authors also present a suite of analyses to characterize the nature of this sensitivity, including exploring the influence of particular atomic perturbations and the internal representation of particular formats.\n\n$$\\text{Strengths:}$$\n1. The paper highlights the importance of prompt formatting in few-shot learning settings, which is a critical aspect of natural language processing.\n2. The authors propose a novel approach, FORMATSPREAD, which can efficiently explore the space of prompt formats.\n3. The paper presents a suite of analyses to characterize the nature of this sensitivity, including exploring the influence of particular atomic perturbations and the internal representation of particular formats.\n\n$$\\text{Weaknesses:}$$\n1. The paper assumes that the prompt formats are semantically equivalent, which may not always be the case in real-world scenarios.\n2. The authors do not provide a detailed analysis of the performance differences between the different LLMs, which may limit the generalizability of the results.\n3. The paper does not discuss the potential applications of FORMATSPREAD in real-world scenarios, which may limit its potential impact.\n\n$$\\text{Suggestions for Improvement:}$$\n1. Provide a more detailed analysis of the performance differences between the different LLMs to increase the generalizability of the results.\n2. Discuss the potential applications of FORMATSPREAD in real-world scenarios to increase its potential impact.\n3. Consider adding more experiments to the paper to further validate the results.\n\n$$\\text{Recommendation:}$$\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise the paper to address the weaknesses and improve the clarity of the results. Specifically, I recommend adding more experiments to the paper to further validate the results, providing a more detailed analysis of the performance differences between the different LLMs, and discussing the potential applications of FORMATSPREAD in real-world scenarios.",
        "gr_score_with": 0.7966666666666666,
        "gr_score_without": 0.7544910179640718,
        "output_without": {
            "num_tokens_scored": 334,
            "num_green_tokens": 252,
            "green_fraction": 0.7544910179640718,
            "z_score": 2.1731440104649233,
            "p_value": 0.014884740102011523
        },
        "output_with": {
            "num_tokens_scored": 300,
            "num_green_tokens": 239,
            "green_fraction": 0.7966666666666666,
            "z_score": 3.6536565724225296,
            "p_value": 0.00012926600711980692
        }
    },
    {
        "title": "REWARD-FREE CURRICULA FOR TRAINING ROBUST WORLD MODELS",
        "abstract": "There has been a recent surge of interest in developing generally-capable agents that can adapt to new tasks without additional training in the environment. Learning world models from reward-free exploration is a promising approach, and enables policies to be trained using imagined experience for new tasks. However, achieving a general agent requires robustness across different environments. In this work, we address the novel problem of generating curricula in the reward-free setting to train robust world models. We consider robustness in terms of minimax regret over all environment instantiations and show that the minimax regret can be connected to minimising the maximum error in the world model across environment instances. This result informs our algorithm, WAKER: Weighted Acquisition of Knowledge across Environments for Robustness. WAKER selects environments for data collection based on the estimated error of the world model for each environment. Our experiments demonstrate that WAKER outperforms several baselines, resulting in improved robustness, efficiency, and generalisation.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$\\boxed{Paper Summary:}$ \nThe paper proposes a novel approach to learning robust world models in the reward-free setting, enabling agents to adapt to new tasks without additional training in the environment. The authors define a problem of learning a robust world model in the reward-free setting in terms of minimax regret and show that this problem is equivalent to minimising the maximum error in the world model across environment instances. The authors introduce an algorithm called WAKER, which selects environments for data collection based on the estimated error of the world model for each environment. The authors demonstrate that WAKER outperforms several baselines, resulting in improved robustness, efficiency, and generalization.\n\n$\\boxed{Strengths:}$ \n1. The paper provides a clear and concise overview of the problem of learning robust world models in the reward-free setting.\n2. The authors derive a connection between the maximum regret and the maximum error of the world model dynamics across environments, which is a key contribution of the paper.\n3. The authors propose a novel algorithm, WAKER, which selectively samples the environment settings that induce the highest latent dynamics error, and demonstrate its effectiveness in several pixel-based continuous control domains.\n4. The paper provides a thorough evaluation of the proposed algorithm, including results on robustness, efficiency, and generalization.\n\n$\\boxed{Weaknesses:}$ \n1. The paper assumes that the representation model learnt by the world model successfully encodes any sequence of observations and actions into a Markovian latent state, which may not always be the case.\n2. The paper does not provide a detailed analysis of the exploration policy used in WAKER, which may be a limitation for scalability to more complex environments.\n3. The paper does not provide a detailed discussion of the limitations of the proposed algorithm, which may be a limitation for its adoption in practice.\n4. The paper does not provide a comprehensive comparison with other algorithms for learning robust world models, which may be a limitation for its adoption in practice.\n\n$\\boxed{Suggestions for Improvement:}$ \n1. The authors should provide a more detailed analysis of the representation model learnt by the world model and its limitations.\n2. The authors should provide a more detailed discussion of the exploration policy used in WAKER and its limitations for scalability to more complex environments.\n3. The authors should provide a more comprehensive comparison with other algorithms for learning robust world models.\n4. The authors should provide a more detailed discussion of the limitations of the proposed algorithm and its potential applications in practice.\n\n$\\boxed{Recommendation:}$ \nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit the paper to the conference. The authors have made a significant contribution to the field of reinforcement learning by proposing a novel algorithm for learning robust world models in the reward-free setting. With some revisions to address the weaknesses and limitations of the paper, the authors can strengthen the paper and make it more competitive with other submissions.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$Paper Summary:\n\nThe paper proposes the development of reward-free curricula for training robust world models, which enable policies to be trained using imagined experience for new tasks without additional training in the environment. The proposed approach, WAKER, selects environments for data collection based on the estimated error of the world model for each environment, and demonstrates improved robustness, efficiency, and generalization compared to existing baselines.\n\n$$Strengths:\n\n* The paper provides a clear and well-structured overview of the problem and approach, and the proposed solution, WAKER, is well-defined and easy to follow.\n* The use of minimax regret as a measure of robustness is a novel and insightful approach, and the connection between maximising the minimum regret and minimising the maximum error of the world model dynamics across environments is well-motivated and well-explained.\n* The experimental results demonstrate the effectiveness of the proposed approach, and the comparison with existing baselines provides a clear understanding of the strengths and weaknesses of the proposed solution.\n\n$$Weaknesses:\n\n* The paper assumes that the world model can be trained using unlimited synthetic data, which may not be realistic in practice. This assumption may need to be revisited and addressed in future work.\n* The paper does not discuss the potential limitations and challenges of the proposed approach, such as the reliance on intrinsically motivated exploration policies, and the potential need for function approximation to estimate uncertainty throughout large parameter spaces.\n* The experimental results, while demonstrating the effectiveness of the proposed approach, may be limited by the specific domains and tasks used, and may not be generalizable to more complex environments.\n\n$$Suggestions for Improvement:\n\n* The paper could benefit from a more detailed discussion of the potential limitations and challenges of the proposed approach, and the potential need for revisions or extensions to the approach to address these challenges.\n* The experimental results could be expanded to include more complex environments and tasks, and the evaluation could be improved by using more robust metrics, such as the failure rate or the average cumulative reward, to measure the robustness and generalization of the policies.\n\n$$Recommendation:\n\nBased on the strengths and weaknesses of the paper, and the suggestions for improvement, I recommend that the paper be published as is, but with the following minor revisions:\n\n* Add a more detailed discussion of the potential limitations and challenges of the proposed approach, and the potential need for revisions or extensions to the approach to address these challenges.\n* Include more experimental results, such as the evaluation of the proposed approach on more complex environments and tasks, and the use of more robust metrics to measure the robustness and generalization of the policies.\n\n$$Rating:\n\nBased on the above assessment, I would rate the paper as 8 out of 10, reflecting the clarity and well-structuredness of the paper, the novelty and insightfulness of the proposed approach, and the effectiveness of the experimental results.",
        "gr_score_with": 0.7538860103626943,
        "gr_score_without": 0.6274509803921569,
        "output_without": {
            "num_tokens_scored": 357,
            "num_green_tokens": 224,
            "green_fraction": 0.6274509803921569,
            "z_score": -2.9912727087814375,
            "p_value": 0.9986109136577191
        },
        "output_with": {
            "num_tokens_scored": 386,
            "num_green_tokens": 291,
            "green_fraction": 0.7538860103626943,
            "z_score": 2.310255619276837,
            "p_value": 0.010437003208543846
        }
    },
    {
        "title": "IDEAL: INFLUENCE-DRIVEN SELECTIVE ANNOTA- TIONS EMPOWER IN-CONTEXT LEARNERS IN LARGE LANGUAGE MODELS",
        "abstract": "In-context learning is a promising paradigm that utilizes in-context examples as prompts for the predictions of large language models. These prompts are crucial for achieving strong performance. However, since the prompts need to be sampled from a large volume of annotated examples, finding the right prompt may result in high annotation costs. To address this challenge, this paper introduces an influence-driven selective annotation method that aims to minimize annotation costs while improving the quality of in-context examples. The essence of our method is to select a pivotal subset from a large-scale unlabeled data pool to annotate for the subsequent sampling of prompts. Specifically, a directed graph is first constructed to represent unlabeled data. Afterward, the influence of candidate unlabeled subsets is quantified with a diffusion process. A simple yet effective greedy algorithm for unlabeled data selection is lastly introduced. It iteratively selects the data if it provides a maximum marginal gain with respect to quantified influence. Compared with previous efforts on selective annotations, our influencedriven method works in an end-to-end manner, avoids an intractable explicit balance between data diversity and representativeness, and enjoys theoretical support. Experiments confirm the superiority of the proposed method on various benchmarks, achieving better performance under lower time consumption during subset selection. The project page is available at https://skzhang1.github.io/IDEAL/.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces the IDEAL method, an influence-driven selective annotation approach for in-context learning with large language models. The method aims to minimize annotation costs while improving the quality of in-context examples. It works in an unsupervised and end-to-end manner, using a directed graph to represent unlabeled data and a diffusion process to quantify the influence of candidate subsets. The method is compared to the existing Vote-k method and achieves better performance in most cases.\n\nStrengths:\n1. The paper introduces a novel approach to selective annotations, which is essential for efficient in-context learning with large language models.\n2. The use of a directed graph and diffusion process to quantify influence is innovative and effective.\n3. The theoretical analysis provides a lower bound for the subset influence selected by the method, demonstrating its reliability.\n4. The empirical evaluations demonstrate the superiority of the IDEAL method across various benchmarks.\n\nWeaknesses:\n1. The paper does not provide a clear explanation of the significance of the influence-driven selective annotation approach and its potential applications.\n2. The theoretical analysis assumes a specific condition (submodular function) that may not hold in all cases.\n3. The experiments are conducted on a limited number of datasets and models, which may not be representative of the broader scope of in-context learning.\n\nSuggestions for Improvement:\n1. Provide a more detailed explanation of the significance of the influence-driven selective annotation approach and its potential applications.\n2. Conduct experiments on a larger number of datasets and models to demonstrate the robustness of the IDEAL method.\n3. Investigate the effect of different annotation budgets and prompt retrieval methods on the performance of the IDEAL method.\n\nRecommendation:\nThe IDEAL method is a promising approach to selective annotations for in-context learning with large language models. While it has some limitations, the paper provides a solid foundation for further research and development. With some improvements in explanations, experiments, and theoretical analysis, the IDEAL method can be a valuable tool for researchers and practitioners in the field of natural language processing.",
        "peer_review_with_watermark": "$$$\\boxed{Peer Review:}\n\n**Paper Summary:**\nThe paper proposes an influence-driven selective annotation method, called IDEAL, to minimize annotation costs while improving the quality of in-context examples in large language models. The method works in an end-to-end manner, avoiding the delicate trade-off between data diversity and representativeness. The authors provide theoretical analysis and empirical evaluations to demonstrate the superiority of the proposed method.\n\n**Strengths:**\n\n1. The proposed method is effective in reducing annotation costs while maintaining good performance.\n2. The influence-driven approach avoids the trade-off between data diversity and representativeness.\n3. The theoretical analysis provides an upper bound for the global optimal solution.\n4. The empirical evaluations demonstrate the superiority of the proposed method across various benchmarks.\n5. The case study of automatic annotation shows the potential of the method in large-scale data annotation.\n\n**Weaknesses:**\n\n1. The method requires the construction of a directed graph, which may be computationally expensive for large datasets.\n2. The influence-driven approach relies on the quality of the graph construction and the choice of the influence metric.\n3. The theoretical analysis assumes that the influence function is submodular, which may not always be the case.\n4. The empirical evaluations only consider a limited set of datasets and benchmarks.\n5. The case study of automatic annotation requires significant computational resources to label all available data.\n\n**Suggestions for Improvement:**\n\n1. Investigate the impact of the graph construction method on the performance of the proposed method.\n2. Explore the use of different influence metrics or graph construction methods to improve the robustness of the method.\n3. Conduct more comprehensive empirical evaluations to assess the performance of the proposed method across a broader range of datasets and benchmarks.\n4. Investigate the potential of the method in other areas of natural language processing, such as question answering or text summarization.\n5. Consider the potential applications of the method in real-world settings, such as natural language processing tasks in industries like customer service or healthcare.\n\n**Recommendation:**\nBased on the strengths and weaknesses of the proposed method, I recommend that the authors continue to refine and improve the method. The influence-driven approach has the potential to be an effective solution to the problem of selective annotations in in-context learning. With further investigation and development, the method could be widely adopted in the field of natural language processing.",
        "gr_score_with": 0.775811209439528,
        "gr_score_without": 0.6534653465346535,
        "output_without": {
            "num_tokens_scored": 303,
            "num_green_tokens": 198,
            "green_fraction": 0.6534653465346535,
            "z_score": -1.7676169239448125,
            "p_value": 0.9614375166108631
        },
        "output_with": {
            "num_tokens_scored": 339,
            "num_green_tokens": 263,
            "green_fraction": 0.775811209439528,
            "z_score": 3.045956009590634,
            "p_value": 0.0011597088359468185
        }
    },
    {
        "title": "WIN-WIN: TRAINING HIGH-RESOLUTION VISION TRANSFORMERS",
        "abstract": "Transformers have become the standard in state-of-the-art vision architectures, achieving impressive performance on both image-level and dense pixelwise tasks. However, training vision transformers for high-resolution pixelwise tasks has a prohibitive cost. Typical solutions boil down to hierarchical architectures, fast and approximate attention, or training on low-resolution crops. This latter solution does not constrain architectural choices, but it leads to a clear performance drop when testing at resolutions significantly higher than that used for training, thus requiring ad-hoc and slow post-processing schemes. In this paper, we propose a novel strategy for efficient training and inference of high-resolution vision transformers: the key principle is to mask out most of the high-resolution inputs during training, keeping only N random windows. This allows the model to learn local interactions between tokens inside each window, and global interactions between tokens from different windows. As a result, the model can directly process the high-resolution input at test time without any special trick. We show that this strategy is effective when using relative positional embedding such as rotary embeddings. It is 4 times faster to train than a full-resolution network, and it is straightforward to use at test time compared to existing approaches. We apply this strategy to two dense prediction tasks with high resolution data. First, we show on the task of semantic segmentation that a simple setting with 2 windows performs best, hence the name of our method: Win-Win. To demonstrate the generality of our contribution, we further extend it to the binocular task of optical flow, reaching state-of-the-art performance on the Spring benchmark that contains Full-HD images with an inference time an order of magnitude faster than the best competitor. 0 10 20 30 40 50 60 Training time (hours) 45 50 55 60 m ea n Io U Semantic segmentation on BDD100k Win-Win (31GB) Full-res. (58GB) Full-res ViTDet (32GB) 0 25 50 75 100 125 150 175 Training time (hours) 1.6 2.0 2.4 2.8 3.2 En dPo in t E rro r ( EP E) Optical flow estimation on MPI-Sintel-clean Win-Win (14GB) Full-res. (28GB) Full-res ViT-Det (21GB) 80 100 120 140 160 180 Training time (hours) 0.0 0.5 1.0 1.5 In fe re nc e tim e (s ec on ds ) Optical flow estimation on MPI-Sintel-clean Full-res ViT Full-res ViT-Det Win-Win ViT + Tiling Figure 1: Validation performance vs. training time on semantic segmentation (left) and optical flow (middle). We compare our two-window training (Win-Win) to a standard full-resolution training as well as a sparsification of the attention following ViT-Det (Li et al., 2022a). We indicate the memory usage in parenthesis in the legend. Compared to full-resolution training, Win-Win allows to reduce the training time by a factor 3-4 and to half the memory usage while reaching a similar performance. Training and inference times on optical flow, for Win-Win vs. other strategies (right). ViT+Tiling corresponds to a setup similar to CroCo-Flow (Weinzaepfel et al., 2023) where the model is trained on random crops, but requires a tiling strategy at inference. While Win-Win is as fast to train as the latter, it can directly process full-resolution inputs at test time.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes a novel training strategy for high-resolution vision transformers, called Win-Win, which allows for efficient training and inference of high-resolution models. The strategy involves masking most of the high-resolution inputs during training, keeping only N random windows, and using relative positional embeddings to preserve global interactions. The authors demonstrate the effectiveness of Win-Win on two dense prediction tasks, semantic segmentation and optical flow estimation, achieving state-of-the-art performance on the Spring benchmark.\n\nStrengths:\n1. The paper proposes a novel and efficient training strategy for high-resolution vision transformers, which reduces the training cost and inference time.\n2. The authors demonstrate the effectiveness of Win-Win on two dense prediction tasks, achieving state-of-the-art performance on the Spring benchmark.\n3. The paper provides a detailed analysis of the strengths and weaknesses of existing approaches and highlights the importance of preserving global interactions in high-resolution models.\n\nWeaknesses:\n1. The paper assumes that the reader is familiar with the basics of vision transformers and attention mechanisms, which may not be the case for all readers.\n2. The paper does not provide a comprehensive analysis of the limitations and potential drawbacks of Win-Win, such as the impact on model performance when using different window sizes or sampling strategies.\n3. The paper relies heavily on the authors' own work and does not provide a thorough review of existing literature on high-resolution vision transformers and attention mechanisms.\n\nSuggestions for Improvement:\n1. Provide a more comprehensive analysis of the strengths and weaknesses of existing approaches and highlight the importance of preserving global interactions in high-resolution models.\n2. Include a more detailed discussion of the limitations and potential drawbacks of Win-Win, such as the impact on model performance when using different window sizes or sampling strategies.\n3. Provide a thorough review of existing literature on high-resolution vision transformers and attention mechanisms to demonstrate the novelty and significance of the proposed approach.\n\nRecommendation:\nBased on the paper's contributions and limitations, I recommend that the authors revise and resubmit the paper for peer review. The revised paper should address the weaknesses and limitations identified above and provide a more comprehensive analysis of the strengths and weaknesses of existing approaches. Additionally, the authors should provide a thorough review of existing literature on high-resolution vision transformers and attention mechanisms to demonstrate the novelty and significance of the proposed approach.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper introduces the Win-Win training strategy for high-resolution vision transformers, which reduces training cost and allows for direct inference at the target resolution. The approach involves randomly selecting N non-overlapping windows from the input image during training, and preserving global and local interactions between tokens from different windows. This strategy is effective when using relative positional embeddings and achieves state-of-the-art performance on the Spring benchmark for optical flow estimation.\n\nStrengths:\n1. Novel approach: Win-Win is a new strategy that reduces the training cost and allows for direct inference at the target resolution.\n2. Effectiveness: The approach achieves state-of-the-art performance on the Spring benchmark for optical flow estimation.\n3. Robustness: Win-Win is robust to various window designs and simplifies the training process.\n4. Simplified inference: Win-Win allows for direct inference at the target resolution, reducing the need for tiling or other inference strategies.\n\nWeaknesses:\n1. Limited evaluation: The paper primarily evaluates the approach on two tasks, semantic segmentation and optical flow estimation, and may not generalize well to other tasks.\n2. Dependence on relative positional embeddings: The approach relies on the effectiveness of relative positional embeddings, which may not always work well.\n3. Lack of comparison to other state-of-the-art methods: The paper does not compare Win-Win to other state-of-the-art methods, which may provide alternative solutions.\n4. Limited understanding of the underlying mechanisms: The paper does not provide a clear understanding of the underlying mechanisms that make Win-Win effective, which may limit its reproducibility and generalizability.\n\nSuggestions for Improvement:\n1. Evaluate Win-Win on more tasks and datasets to demonstrate its generalization capabilities.\n2. Investigate the underlying mechanisms that make Win-Win effective and provide a clear understanding of its strengths and limitations.\n3. Compare Win-Win to other state-of-the-art methods to demonstrate its superiority and provide alternative solutions.\n4. Consider exploring other window sampling strategies or modifications to the approach to further improve its robustness and generalization capabilities.\n\nRecommendation:\nThe paper introduces a novel approach, Win-Win, that reduces training cost and allows for direct inference at the target resolution. While the approach achieves state-of-the-art performance on the Spring benchmark, it is essential to further evaluate its generalization capabilities, investigate the underlying mechanisms, and compare it to other state-of-the-art methods. With further development and evaluation, Win-Win has the potential to become a significant contribution to the field of computer vision.",
        "gr_score_with": 0.7987987987987988,
        "gr_score_without": 0.7360594795539034,
        "output_without": {
            "num_tokens_scored": 269,
            "num_green_tokens": 198,
            "green_fraction": 0.7360594795539034,
            "z_score": 1.2905830201019775,
            "p_value": 0.09842415350734857
        },
        "output_with": {
            "num_tokens_scored": 333,
            "num_green_tokens": 266,
            "green_fraction": 0.7987987987987988,
            "z_score": 3.934269751615728,
            "p_value": 4.1725010560777456e-05
        }
    },
    {
        "title": "THRESHOLD-CONSISTENT MARGIN LOSS FOR OPEN- WORLD DEEP METRIC LEARNING",
        "abstract": "Existing losses used in deep metric learning (DML) for image retrieval often lead to highly non-uniform intra-class and inter-class representation structures across test classes and data distributions. When combined with the common practice of using a fixed threshold to declare a match, this gives rise to significant performance variations in terms of false accept rate (FAR) and false reject rate (FRR) across test classes and data distributions. We define this issue in DML as threshold inconsistency. In real-world applications, such inconsistency often complicates the threshold selection process when deploying commercial image retrieval systems. To measure this inconsistency, we propose a novel variance-based metric called Operating-Point-Inconsistency-Score (OPIS) that quantifies the variance in the operating characteristics across classes. Using the OPIS metric, we find that achieving high accuracy levels in a DML model does not automatically guarantee threshold consistency. In fact, our investigation reveals a Pareto frontier in the high-accuracy regime, where existing methods to improve accuracy often lead to degradation in threshold consistency. To address this trade-off, we introduce the Threshold-Consistent Margin (TCM) loss, a simple yet effective regularization technique that promotes uniformity in representation structures across classes by selectively penalizing hard sample pairs. Extensive experiments demonstrate TCM\u2019s effectiveness in enhancing threshold consistency while preserving accuracy, simplifying the threshold selection process in practical DML settings.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$The paper proposes a novel variance-based metric called Operating-Point-Inconsistency-Score (OPIS) to quantify the threshold inconsistency of a Deep Metric Learning (DML) model. The authors also introduce the Threshold-Consistent Margin (TCM) loss, a simple yet effective regularization technique that promotes uniformity in representation structures across classes by selectively penalizing hard sample pairs. \n\nThe paper presents several contributions, including the OPIS metric, the observation of an accuracy-threshold consistency Pareto frontier in the high accuracy regime, and the TCM loss. The authors demonstrate the effectiveness of the TCM regularization in improving threshold consistency while preserving accuracy across various image retrieval benchmarks.\n\nOne of the key strengths of the paper is its comprehensive study of the issue of threshold inconsistency in DML. The authors provide a thorough analysis of the problem, including the limitations of existing evaluation metrics and the need for a more nuanced approach to quantify threshold inconsistency.\n\nHowever, there are some limitations to the paper. Firstly, the OPIS metric necessitates a sufficient number of samples per class to ensure statistical significance, making it unsuitable for few-shot evaluation scenarios. Secondly, the TCM loss can fail when there's a significant distribution shift between the training and test sets or when strong label noise is present.\n\nIn terms of methodology, the paper uses a range of DML losses and backbones, including proxy-based and pairwise-based methods. The authors also perform extensive experiments to evaluate the effectiveness of the TCM regularization.\n\nThe paper's contribution to the field of DML is significant, and the authors provide a valuable analysis of the limitations of existing evaluation metrics and the need for a more nuanced approach to quantify threshold inconsistency. However, further work is needed to address the limitations of the OPIS metric and the TCM loss.\n\nOverall, the paper is well-written and provides a comprehensive analysis of the issue of threshold inconsistency in DML. The authors' contributions are significant, and their work has the potential to impact the field of DML.\n\n$$\n\nRecommendation:\n\n* The paper is well-written and provides a comprehensive analysis of the issue of threshold inconsistency in DML.\n* The authors' contributions are significant, and their work has the potential to impact the field of DML.\n* However, further work is needed to address the limitations of the OPIS metric and the TCM loss.\n* The paper could benefit from more experiments on few-shot evaluation scenarios and on datasets with strong label noise.\n* The authors could also explore the use of other regularization techniques to improve threshold consistency.",
        "peer_review_with_watermark": "$$$$\n\nPaper Title: Threshold-Consistent Margin Loss for Open-World Deep Metric Learning\n\nSummary:\n\nThis paper proposes a novel threshold-consistent margin loss (TCM) for open-world deep metric learning (DML). The authors introduce a variance-based metric, Operating-Point-Inconsistency-Score (OPIS), to quantify threshold inconsistency in DML models. They show that achieving high accuracy in DML does not guarantee threshold consistency and propose TCM as a simple yet effective regularization technique to address this issue. The authors demonstrate the effectiveness of TCM in improving threshold consistency and accuracy in various image retrieval benchmarks.\n\nStrengths:\n\n1. The authors provide a clear and concise introduction to the problem of threshold inconsistency in DML and its importance in real-world applications.\n2. The proposed OPIS metric is a significant contribution to the field, as it allows for the evaluation of threshold consistency without requiring a separate calibration dataset.\n3. The authors provide a thorough analysis of the trade-off between recognition error and threshold inconsistency in the high-accuracy regime.\n4. The proposed TCM regularization technique is simple and versatile, and its effectiveness in improving threshold consistency and accuracy is demonstrated through extensive experiments.\n\nWeaknesses:\n\n1. The authors may want to consider providing more detailed explanations and theoretical justifications for the proposed OPIS metric and TCM regularization technique.\n2. Some of the experimental results, such as those presented in Figure 3, may be difficult to interpret due to the complex relationships between accuracy and threshold consistency.\n3. The authors may want to explore potential limitations and biases in the proposed OPIS metric and TCM regularization technique.\n\nSuggestions for Improvement:\n\n1. The authors may want to consider adding more theoretical justifications and mathematical derivations to support the proposed OPIS metric and TCM regularization technique.\n2. Additional experiments may be needed to further explore the relationships between accuracy and threshold consistency in different scenarios and datasets.\n3. The authors may want to consider addressing potential limitations and biases in the proposed OPIS metric and TCM regularization technique, such as those related to few-shot evaluation scenarios and distributional shifts.\n\nRecommendation:\n\nOverall, this paper makes a significant contribution to the field of deep metric learning by introducing a novel threshold-consistent margin loss (TCM) and a variance-based metric (OPIS) for evaluating threshold inconsistency. The proposed techniques demonstrate effective improvements in threshold consistency and accuracy in various image retrieval benchmarks. However, further exploration and refinement of the proposed techniques may be needed to address potential limitations and biases.\n\nRating: 8/10\n\n$$$$",
        "gr_score_with": 0.7550432276657061,
        "gr_score_without": 0.6561604584527221,
        "output_without": {
            "num_tokens_scored": 349,
            "num_green_tokens": 229,
            "green_fraction": 0.6561604584527221,
            "z_score": -1.787183186274331,
            "p_value": 0.9630460570416493
        },
        "output_with": {
            "num_tokens_scored": 347,
            "num_green_tokens": 262,
            "green_fraction": 0.7550432276657061,
            "z_score": 2.237479075097674,
            "p_value": 0.01262752271785949
        }
    },
    {
        "title": "RECOMBINER: ROBUST AND ENHANCED COMPRESSION WITH BAYESIAN IMPLICIT NEURAL REPRESENTATIONS",
        "abstract": "COMpression with Bayesian Implicit NEural Representations (COMBINER) is a recent data compression method that addresses a key inefficiency of previous Implicit Neural Representation (INR)-based approaches: it avoids quantization and enables direct optimization of the rate-distortion performance. However, COMBINER still has significant limitations: 1) it uses factorized priors and posterior approximations that lack flexibility; 2) it cannot effectively adapt to local deviations from global patterns in the data; and 3) its performance can be susceptible to modeling choices and the variational parameters\u2019 initializations. Our proposed method, Robust and Enhanced COMBINER (RECOMBINER), addresses these issues by 1) enriching the variational approximation while retaining a low computational cost via a linear reparameterization of the INR weights, 2) augmenting our INRs with learnable positional encodings that enable them to adapt to local details and 3) splitting high-resolution data into patches to increase robustness and utilizing expressive hierarchical priors to capture dependency across patches. We conduct extensive experiments across several data modalities, showcasing that RECOMBINER achieves competitive results with the best INR-based methods and even outperforms autoencoder-based codecs on lowresolution images at low bitrates. Our PyTorch implementation is available at https://github.com/cambridge-mlg/RECOMBINER/.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes a new data compression method called RECOMBINER, which extends the existing COMBINER method. RECOMBINER addresses the limitations of COMBINER, including its use of factorized priors and posterior approximations, and its inability to effectively adapt to local deviations from global patterns in the data. The proposed method uses a linear reparameterization of the network weights, learnable positional encodings, and an expressive hierarchical Bayesian model for high-resolution signals. The experiments demonstrate that RECOMBINER achieves competitive results with the best INR-based methods and even outperforms autoencoder-based codecs on low-resolution images at low bitrates.\n\nStrengths:\n1. The proposed method addresses the limitations of COMBINER and provides a more robust and flexible data compression framework.\n2. The use of linear reparameterization and learnable positional encodings improves the expressiveness of the variational posterior and enables better adaptation to local deviations from global patterns in the data.\n3. The hierarchical Bayesian model for high-resolution signals enables the compression of large data sets and reduces the encoding time complexity.\n\nWeaknesses:\n1. The encoding time complexity of the proposed method is still a significant limitation, and tackling this issue should be of primary concern in future work.\n2. The method may lead to block artifacts when compressing data with patches.\n3. The approximate samples given by A\u02da coding can significantly impact the method's performance, and an exact REC algorithm could be adapted to solve this issue.\n\nSuggestions for Improvement:\n1. Reduce the number of parameters to optimize over and switch from inference over weights to modulations using, e.g. FiLM layers.\n2. Develop a method to remove block artifacts when compressing data with patches.\n3. Adapt an exact REC algorithm to solve the issue of approximate samples given by A\u02da coding.\n\nRecommendation:\nThe proposed method RECOMBINER is a significant improvement over the existing COMBINER method, and its experiments demonstrate competitive results with the best INR-based methods. However, the encoding time complexity and block artifacts are still significant limitations that need to be addressed in future work. The recommendations provided above should help to improve the method and make it more suitable for practical applications.",
        "peer_review_with_watermark": "$$$${Paper Summary:\n\nThe paper proposes RECOMBINER, a novel data compression method that addresses the limitations of previous Implicit Neural Representation (INR)-based approaches. RECOMBINER uses a linear reparameterization of the INR weights, learnable positional encodings, and an expressive hierarchical Bayesian model to improve robustness and performance. The authors conduct extensive experiments on various data modalities, including images, audio, video, and 3D protein structures, and demonstrate that RECOMBINER outperforms state-of-the-art codecs and INR-based methods.\n\nStrengths:\n\n* RECOMBINER addresses several limitations of previous INR-based approaches, including underfitting, susceptibility to modeling choices, and lack of robustness to local deviations from global patterns.\n* The use of learnable positional encodings and hierarchical Bayesian models enables RECOMBINER to capture local features and dependencies in high-resolution signals.\n* The authors provide a comprehensive experimental evaluation of RECOMBINER on various data modalities and demonstrate its robustness and effectiveness.\n\nWeaknesses:\n\n* The encoding time complexity of RECOMBINER is high, which may limit its practical applications.\n* The use of approximate samples from the variational posterior may impact the method's performance, particularly at low bitrates.\n* The hierarchical model may not be effective in optimizing the rate-distortion objective, particularly when directly applying it.\n\nSuggestions for Improvement:\n\n* Investigate techniques to reduce the encoding time complexity, such as reducing the number of parameters to optimize over or using inference over modulations.\n* Develop exact REC algorithms that can handle the impact of approximate samples on performance.\n* Explore alternative approaches to optimizing the rate-distortion objective, such as warm-up rate penalties or hierarchical VAEs.\n\nRecommendation:\n\n* RECOMBINER is a promising data compression method that addresses several limitations of previous INR-based approaches. However, its high encoding time complexity and potential impact of approximate samples on performance need to be addressed in future work. With further improvements, RECOMBINER has the potential to set a new state-of-the-art in data compression.",
        "gr_score_with": 0.778816199376947,
        "gr_score_without": 0.7181818181818181,
        "output_without": {
            "num_tokens_scored": 330,
            "num_green_tokens": 237,
            "green_fraction": 0.7181818181818181,
            "z_score": 0.7207499701564507,
            "p_value": 0.23553168086660836
        },
        "output_with": {
            "num_tokens_scored": 321,
            "num_green_tokens": 250,
            "green_fraction": 0.778816199376947,
            "z_score": 3.081472934936551,
            "p_value": 0.0010298960067701322
        }
    },
    {
        "title": "LEMUR: INTEGRATING LARGE LANGUAGE MODELS",
        "abstract": "The demonstrated code-understanding capability of LLMs raises the question of whether they can be used for automated program verification, a task that demands high-level abstract reasoning about program properties that is challenging for verification tools. We propose a general methodology to combine the power of LLMs and automated reasoners for automated program verification. We formally describe this methodology as a set of derivation rules and prove its soundness. We instantiate the calculus as a sound automated verification procedure, which led to practical improvements on a set of synthetic and competition benchmarks.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n&\\text{Paper Summary:} \\; The paper proposes a novel framework LEMUR that integrates large language models (LLMs) and automated reasoners for automated program verification. LEMUR combines the strengths of LLMs and automated reasoners to provide a sound and terminating algorithm for checking whether a property is an invariant on a program. The paper also presents strategies to instantiate LEMUR as an automated decision procedure and demonstrates its efficiency on standard benchmark sets.\\\\\n&\\text{Strengths:} \\; The paper provides a novel approach to integrating LLMs and automated reasoners for automated program verification. It also demonstrates the efficiency of LEMUR on standard benchmark sets. The paper's strategy to instantiate LEMUR as an automated decision procedure is also a significant contribution.\\\\\n&\\text{Weaknesses:} \\; The paper assumes that the LLM oracles can generate program properties that are invariants and implies the current proof goal. However, the paper does not discuss the limitations of LLMs and the challenges of handling unbounded suggestions of new sub-goals. Additionally, the paper does not provide a detailed analysis of the performance of LEMUR on hard SV-COMP benchmarks.\\\\\n&\\text{Suggestions for Improvement:} \\; The paper should discuss the limitations of LLMs and the challenges of handling unbounded suggestions of new sub-goals. The paper should also provide a detailed analysis of the performance of LEMUR on hard SV-COMP benchmarks. Additionally, the paper should discuss the potential of using multiple LLM oracles and verifiers to improve the efficiency and accuracy of LEMUR.\\\\\n&\\text{Recommendation:} \\; The paper presents a novel approach to integrating LLMs and automated reasoners for automated program verification. However, the paper has some limitations and areas for improvement. The authors should address these limitations and improve the paper to make it more comprehensive and rigorous.\\\\\n\\end{aligned}$$",
        "peer_review_with_watermark": "$$\\begin{aligned}\n&\\text{Paper Summary:} \\;\\; \\text{The authors present a novel framework, LEMUR, that integrates Large Language Models (LLMs) with automated reasoners to automate program verification. They demonstrate the effectiveness of LEMUR on a set of benchmarks, including synthetic and competition benchmarks.}\\\\\n&\\text{Strengths:} \\;\\; \\text{The authors have made significant contributions to the field of program verification by proposing a novel framework that combines the strengths of LLMs and automated reasoners.}\\\\\n&\\text{Weaknesses:} \\;\\; \\text{There are no major weaknesses identified in the paper.}\\\\\n&\\text{Suggestions for Improvement:} \\;\\; \\text{None}\\\\\n&\\text{Recommendation:} \\;\\; \\text{The authors have made significant contributions to the field of program verification. The proposed framework, LEMUR, has the potential to automate program verification tasks.}\\\\\n\\end{aligned}$$",
        "gr_score_with": 0.7307692307692307,
        "gr_score_without": 0.6286919831223629,
        "output_without": {
            "num_tokens_scored": 237,
            "num_green_tokens": 149,
            "green_fraction": 0.6286919831223629,
            "z_score": -2.3955370063357644,
            "p_value": 0.9917019805732868
        },
        "output_with": {
            "num_tokens_scored": 130,
            "num_green_tokens": 95,
            "green_fraction": 0.7307692307692307,
            "z_score": 0.7655590023509528,
            "p_value": 0.22196937326839894
        }
    },
    {
        "title": "EARLY NEURON ALIGNMENT IN TWO-LAYER RELU NETWORKS WITH SMALL INITIALIZATION",
        "abstract": "This paper studies the problem of training a two-layer ReLU network for binary classification using gradient flow with small initialization. We consider a training dataset with well-separated input vectors: Any pair of input data with the same label are positively correlated, and any pair with different labels are negatively correlated. Our analysis shows that, during the early phase of training, neurons in the first layer try to align with either the positive data or the negative data, depending on its corresponding weight on the second layer. A careful analysis of the neurons\u2019 directional dynamics allows us to provide an O( logn \u221a\u03bc ) upper bound on the time it takes for all neurons to achieve good alignment with the input data, where n is the number of data points and \u03bc measures how well the data are separated. After the early alignment phase, the loss converges to zero at a O( 1t ) rate, and the weight matrix on the first layer is approximately low-rank. Numerical experiments on the MNIST dataset illustrate our theoretical findings.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary: \nThe paper studies the problem of training a two-layer ReLU network for binary classification using gradient flow with small initialization. The authors consider a training dataset with well-separated input vectors and analyze the early alignment phase of the gradient flow dynamics. They provide an upper bound on the time it takes for all neurons to achieve good alignment with the input data, which is O(logn\u221a\u00b5), where n is the number of data points and \u00b5 measures how well the data are separated. The authors also show that after the early alignment phase, the loss converges to zero at a O(1t) rate, and the weight matrix on the first layer is approximately low-rank.\n\n$$\\begin{aligned}\n$$Strengths:\n1. The paper provides a complete analysis of the early alignment phase of the gradient flow dynamics, which is crucial for understanding the training dynamics of two-layer ReLU networks.\n2. The authors provide an upper bound on the time it takes for all neurons to achieve good alignment with the input data, which is a significant contribution to the field.\n3. The paper includes numerical experiments to validate the theoretical findings, which provides empirical evidence for the proposed results.\n\n$$\\begin{aligned}\n$$Weaknesses:\n1. The paper assumes that the initialization is sufficiently small, which may not be the case in practice.\n2. The authors rely on a technical assumption that the ReLU subgradient is fixed as \u03c3\u2032(x) = 1x>01, which may not be true in all cases.\n3. The paper does not provide a detailed analysis of the case where the data are not well-separated.\n\n$$\\begin{aligned}\n$$Suggestions for Improvement:\n1. The authors should provide a more detailed analysis of the case where the data are not well-separated.\n2. The paper should include a discussion of the implications of the results for real-world applications.\n3. The authors should provide more experimental results to validate the theoretical findings.\n\n$$\\begin{aligned}\n$$Recommendation:\nBased on the strengths and weaknesses of the paper, I recommend that it be accepted for publication in its current form. However, the authors should be encouraged to address the weaknesses and suggestions for improvement to make the paper even stronger.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper studies the early alignment phase in two-layer ReLU networks with small initialization. The authors consider a binary classification problem with well-separated input vectors and analyze the gradient flow dynamics of the network. They show that during the early alignment phase, the neurons in the first layer try to align with either the positive data or the negative data, depending on the corresponding weight on the second layer. The authors provide a bound on the time it takes for all neurons to achieve good alignment with the input data and show that after the early alignment phase, the loss converges to zero at a rate of O(1/t) and the weight matrix on the first layer is approximately low-rank.\n\nStrengths:\nThe paper provides a detailed analysis of the early alignment phase in two-layer ReLU networks with small initialization. The authors use a careful analysis of the neurons' directional dynamics to provide a bound on the time it takes for all neurons to achieve good alignment with the input data. The paper also shows that after the early alignment phase, the loss converges to zero at a rate of O(1/t) and the weight matrix on the first layer is approximately low-rank.\n\nWeaknesses:\nThe paper assumes that the data are well-separated, which may not be realistic in practice. The authors also assume that the neurons in the first layer try to align with either the positive data or the negative data, depending on the corresponding weight on the second layer, which may not be the case in all situations. Additionally, the paper does not provide a comprehensive analysis of the convergence rate of the loss after the early alignment phase.\n\nSuggestions for Improvement:\nTo improve the paper, the authors could provide a more comprehensive analysis of the convergence rate of the loss after the early alignment phase. They could also consider more realistic scenarios where the data are not well-separated and the neurons in the first layer try to align with different patterns of data. Furthermore, the authors could explore the properties of the weight matrix on the first layer and provide more insights into the low-rank structure of the matrix.\n\nRecommendation:\nOverall, the paper provides a detailed analysis of the early alignment phase in two-layer ReLU networks with small initialization. The authors use a careful analysis of the neurons' directional dynamics to provide a bound on the time it takes for all neurons to achieve good alignment with the input data. While the paper has some weaknesses, it provides a good foundation for further research into the convergence properties of two-layer ReLU networks with small initialization.\n\n$$$Paper Quality: 8/10\n\n$$$Relevance and Impact: 8/10\n\n$$$Originality and Novelty: 7/10\n\n$$$Clarity and Presentation: 9/10\n\n$$$Overall Recommendation: Accept with minor revisions to address the weaknesses and provide a more comprehensive analysis of the convergence rate of the loss after the early alignment phase.",
        "gr_score_with": 0.7966101694915254,
        "gr_score_without": 0.7115987460815048,
        "output_without": {
            "num_tokens_scored": 319,
            "num_green_tokens": 227,
            "green_fraction": 0.7115987460815048,
            "z_score": 0.45206068124896154,
            "p_value": 0.32561263401807883
        },
        "output_with": {
            "num_tokens_scored": 295,
            "num_green_tokens": 235,
            "green_fraction": 0.7966101694915254,
            "z_score": 3.620963980113369,
            "p_value": 0.00014675368999263804
        }
    },
    {
        "title": "VONET: UNSUPERVISED VIDEO OBJECT LEARNING WITH PARALLEL U-NET ATTENTION",
        "abstract": "Unsupervised video object learning seeks to decompose video scenes into structural object representations without any supervision from depth, optical flow, or segmentation. We present VONet, an innovative approach that is inspired by MONet. While utilizing a U-Net architecture, VONet employs an efficient and effective parallel attention inference process, generating attention masks for all slots simultaneously. Additionally, to enhance the temporal consistency of each mask across consecutive video frames, VONet develops an object-wise sequential VAE framework. The integration of these innovative encoder-side techniques, in conjunction with an expressive transformer-based decoder, establishes VONet as the leading unsupervised method for object learning across five MOVI datasets, encompassing videos of diverse complexities. Code is available at https://github.com/hnyu/vonet.",
        "peer_review_without_watermark": "$$$\\begin{align}\\textbf{Paper Summary:}~\\text{The paper presents VONet, a novel approach for unsupervised video object learning. It employs a parallel attention mechanism, which simultaneously generates attention masks for all slots from a U-Net, and an object-wise sequential VAE framework to promote temporal consistency. The proposed method achieves state-of-the-art results across five MOVI datasets and outperforms several strong baselines.}\\end{align}\n\n\\textbf{Strengths:}\n1.  The paper introduces a parallel attention mechanism, which significantly improves the efficiency of the attention generation process.\n2.  The object-wise sequential VAE framework effectively promotes temporal consistency in video object learning.\n3.  The strong inductive bias of spatial locality in the U-Net architecture leads to smoother and more compact object segmentation masks.\n4.  The proposed method achieves state-of-the-art results across five MOVI datasets.\n\n\\textbf{Weaknesses:}\n1.  The paper lacks a detailed discussion of the impact of the KLD balancing coefficient on the learning process.\n2.  The use of a replay buffer technique may not be necessary, and its importance is not thoroughly justified.\n3.  The paper does not provide a comprehensive analysis of the failure modes of the proposed method.\n\n\\textbf{Suggestions for Improvement:}\n1.  Provide a more detailed analysis of the impact of the KLD balancing coefficient on the learning process.\n2.  Justify the necessity of the replay buffer technique and provide a more comprehensive analysis of its effects.\n3.  Investigate the failure modes of the proposed method and provide a more detailed discussion of the potential solutions.\n\n\\textbf{Recommendation:}\nBased on the strengths and weaknesses of the paper, we recommend that the authors revise and resubmit the manuscript. The authors should address the weaknesses and provide a more detailed analysis of the proposed method. The revised manuscript should include a more comprehensive discussion of the impact of the KLD balancing coefficient, a more thorough justification of the replay buffer technique, and a more detailed analysis of the failure modes of the proposed method.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper introduces VONet, a novel approach for unsupervised video object learning. VONet builds upon the U-Net architecture and incorporates a parallel attention process that simultaneously generates attention masks for all slots from a U-Net. It also employs an object-wise sequential VAE framework to promote temporal consistency. The paper presents extensive evaluations across five MOVI datasets, showcasing VONet's superior effectiveness compared to several strong baselines.\n\nStrengths:\n1. VONet's parallel attention process allows for efficient generation of attention masks for all slots, leading to improved inference time and better performance.\n2. The object-wise sequential VAE framework effectively promotes temporal consistency, enabling VONet to tackle complex video scenes.\n3. VONet's use of a U-Net architecture with a strong inductive bias of spatial locality leads to smoother and more compact object segmentation masks.\n\nWeaknesses:\n1. VONet may struggle with over-segmentation when the video scene's object count is lower than the pre-allocated slot number.\n2. The model may face challenges in discerning whether an object exhibits multiple texture regions or multiple distinct objects moving closely together.\n3. The enforcement of temporal consistency may occasionally prove unsuccessful, and a more robust approach is needed.\n\nSuggestions for Improvement:\n1. Implement additional constraints or priors to address over-segmentation.\n2. Integrate pretrained knowledge about everyday object appearances to enhance object understanding.\n3. Explore the use of a long-term memory model to improve temporal consistency.\n\nRecommendation:\nVONet is a state-of-the-art approach for unsupervised video object learning, showcasing superior effectiveness across five datasets. With some modifications and further exploration, VONet can potentially address its weaknesses and become an even more robust and reliable approach. \n\nThe authors have made a good effort to explain their approach and provide extensive evaluations, but there are a few areas where more clarification and details would be beneficial, such as the specific hyperparameter settings and training configurations used. \n\nMoreover, while the authors have compared their approach with several strong baselines, it would be beneficial to include a more thorough analysis of the strengths and weaknesses of each baseline, as well as their respective limitations and potential applications. \n\nIn conclusion, VONet is a promising approach that can potentially become a leading method in unsupervised video object learning. With further refinement and exploration, it can potentially address its weaknesses and become a more robust and reliable approach. \n\nHowever, it is worth noting that the paper could benefit from a more thorough and critical evaluation of its own strengths and weaknesses, as well as a more comprehensive analysis of the current state of unsupervised video object learning. \n\nIn addition, the paper could benefit from more detailed and specific explanations of its approach, such as the specific U-Net architecture used and how it is modified to incorporate the parallel attention process and object-wise sequential VAE framework. \n\nOverall, the paper presents a well-structured and clear introduction to VONet, and its approach is certainly promising. However, further refinement and exploration are needed to address its weaknesses and make it a more robust and reliable approach. \n\nIn terms of format, the paper is well-structured and easy to follow, but there are a few areas where more clarity and details would be beneficial, such as the specific hyperparameter settings and training configurations used. \n\nIn terms of length, the paper is concise and to the point, but it could benefit from a more thorough and comprehensive analysis of the current state of unsupervised video object learning and a more detailed explanation of its approach. \n\nIn terms of overall quality, the paper is well-written and free of errors, but it could benefit from more specific and detailed explanations of its approach and a more thorough analysis of its strengths and weaknesses. \n\nIn conclusion, VONet is a promising approach that can potentially become a leading method in unsupervised video object learning. With further refinement and exploration, it can potentially address its weaknesses and become a more robust and reliable approach. \n\nHowever, further refinement and exploration are needed to address its weaknesses and make it a more robust and reliable approach. \n\nIn terms of format, the paper is well-structured and easy to follow, but there are a few areas where more clarity and details would be beneficial, such as the specific hyperparameter settings and training configurations used. \n\nIn terms of length, the paper is concise and to the point, but it could benefit from a more thorough and comprehensive analysis of the current state of unsupervised video object learning and a more detailed explanation of its approach. \n\nIn terms of overall quality, the paper is well-written and free of errors, but it could benefit from more specific and detailed explanations of its approach and a more thorough analysis of its strengths and weaknesses. \n\nIn conclusion, VONet is a promising approach that can potentially become a leading method in unsupervised video object learning. With further refinement and exploration, it can potentially address its weaknesses and become a more robust and reliable approach. \n\nHowever, further refinement and exploration are needed to address its weaknesses and make it a more robust and reliable approach. \n\nIn terms of format, the paper is well-structured and easy to follow, but there are a few areas where more clarity and details would be beneficial, such as the specific hyperparameter settings and training configurations used. \n\nIn terms of length, the paper is concise and to the point, but it could benefit from a more thorough and comprehensive analysis of the current state of unsupervised video object learning and a more detailed explanation of its approach. \n\nIn terms of overall quality, the paper is well-written and free of errors, but it could benefit from more specific and detailed explanations of its approach and a more thorough analysis of its strengths and weaknesses. \n\nIn conclusion, VONet is a promising approach that can potentially become a leading method in unsupervised video object learning. With further refinement and exploration, it can potentially address its weaknesses and become a more robust and reliable approach. \n\nHowever, further refinement and exploration are needed to address its weaknesses and make it a more robust and reliable approach. \n\nIn terms of format, the paper is well-structured and easy to follow, but there are a few areas where more clarity and details would be beneficial, such as the specific hyperparameter settings and training configurations used. \n\nIn terms of length, the paper is concise and to the point, but it could benefit from a more thorough and comprehensive analysis of the current state of unsupervised video object learning and a more detailed explanation of its approach. \n\nIn terms of overall quality, the paper is well-written and free of errors, but it could benefit from more specific and detailed explanations of its approach and a more thorough analysis of its strengths and weaknesses. \n\nIn conclusion, VONet is a promising approach that can potentially become a leading method in unsupervised video object learning. With further refinement and exploration, it can potentially address its weaknesses and become a more robust and reliable approach. \n\nHowever, further refinement and exploration are needed to address its weaknesses and make it a more robust and reliable approach. \n\nIn terms of format, the paper is well-structured and easy to follow, but there are a few areas where more clarity and details would be beneficial, such as the specific hyperparameter settings and training configurations used. \n\nIn terms of length, the paper is concise and to the point, but it could benefit from a more thorough and comprehensive analysis of the current state of unsupervised video object learning and a more detailed explanation of its approach. \n\nIn terms of overall quality, the paper is well-written and free of errors, but it could benefit from more specific and detailed explanations of its approach and a more thorough analysis of its strengths and weaknesses. \n\nIn conclusion, VONet is a promising approach that can potentially become a leading method in unsupervised video object learning. With further refinement and exploration, it can potentially address its weaknesses and become a more robust and reliable approach. \n\nHowever, further refinement and exploration are needed to address its weaknesses and make it a more robust and reliable approach. \n\nIn terms of format, the paper is well-structured and easy to follow, but there are a few areas where more clarity and details would be beneficial, such as the specific hyperparameter settings and training configurations used. \n\nIn terms of length, the paper is concise and to the point, but it could benefit from a more thorough and comprehensive analysis of the current state of unsupervised video object learning and a more detailed explanation of its approach. \n\nIn terms of overall quality, the paper is well-written and free of errors, but it could benefit from more specific and detailed explanations of its approach and a more thorough analysis of its strengths and weaknesses. \n\nIn conclusion, VONet is a promising approach that can potentially become a leading method in unsupervised video object learning. With further refinement and exploration, it can potentially address its weaknesses and become a more robust and reliable approach. \n\nHowever, further refinement and exploration are needed to address its weaknesses and make it a more robust and reliable approach. \n\nIn terms of format, the paper is well-structured and easy to follow, but there are a few areas where more clarity and details would be beneficial, such as the specific hyperparameter settings and training configurations used. \n\nIn terms of length, the paper is concise and to the point, but it could benefit from a more thorough and comprehensive analysis of the current state of unsupervised video object learning and a more detailed explanation of its approach. \n\nIn terms of overall quality, the paper is well-written and free of errors, but it could benefit from more specific and detailed explanations of its approach and a more thorough analysis of its strengths and weaknesses. \n\nIn conclusion, VONet is a promising approach that can potentially become a leading method in unsupervised video object learning. With further",
        "gr_score_with": 0.78,
        "gr_score_without": 0.7655677655677655,
        "output_without": {
            "num_tokens_scored": 273,
            "num_green_tokens": 209,
            "green_fraction": 0.7655677655677655,
            "z_score": 2.3640794077218104,
            "p_value": 0.009037468954026009
        },
        "output_with": {
            "num_tokens_scored": 500,
            "num_green_tokens": 390,
            "green_fraction": 0.78,
            "z_score": 3.9036002917941324,
            "p_value": 4.7386125698961395e-05
        }
    },
    {
        "title": "FLOW MATCHING ON GENERAL GEOMETRIES",
        "abstract": "We propose Riemannian Flow Matching (RFM), a simple yet powerful framework for training continuous normalizing flows on manifolds. Existing methods for generative modeling on manifolds either require expensive simulation, are inherently unable to scale to high dimensions, or use approximations for limiting quantities that result in biased training objectives. Riemannian Flow Matching bypasses these limitations and offers several advantages over previous approaches: it is simulation-free on simple geometries, does not require divergence computation, and computes its target vector field in closed-form. The key ingredient behind RFM is the construction of a relatively simple premetric for defining target vector fields, which encompasses the existing Euclidean case. To extend to general geometries, we rely on the use of spectral decompositions to efficiently compute premetrics on the fly. Our method achieves state-of-the-art performance on many real-world nonEuclidean datasets, and we demonstrate tractable training on general geometries, including triangular meshes with highly non-trivial curvature and boundaries.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes Riemannian Flow Matching (RFM), a framework for training continuous normalizing flows on general Riemannian manifolds. RFM bypasses the limitations of existing methods, which require expensive simulation, are unable to scale to high dimensions, or use approximations that result in biased training objectives. RFM is simulation-free on simple geometries, does not require divergence computation, and computes its target vector field in closed-form. The authors demonstrate that RFM achieves state-of-the-art performance on many real-world non-Euclidean datasets and can be trained on general geometries, including triangular meshes with highly non-trivial curvature and boundaries.\n\nStrengths:\n1. RFM is simulation-free on simple geometries, which is a significant advantage over existing methods.\n2. RFM does not require divergence computation, which makes it more scalable and efficient.\n3. RFM computes its target vector field in closed-form, which is a desirable property for many applications.\n4. The authors demonstrate that RFM can be trained on general geometries, including triangular meshes with highly non-trivial curvature and boundaries.\n\nWeaknesses:\n1. The paper does not provide a clear explanation of the premetric construction, which is a crucial component of RFM.\n2. The authors assume that the premetric is positive definite, but they do not provide a formal proof of this assumption.\n3. The paper does not provide a detailed analysis of the convergence properties of RFM, which is an important aspect of any optimization algorithm.\n4. The authors compare RFM to existing methods, but they do not provide a thorough evaluation of the strengths and weaknesses of each method.\n\nSuggestions for Improvement:\n1. Provide a clear and detailed explanation of the premetric construction, including its properties and assumptions.\n2. Formalize the assumption that the premetric is positive definite.\n3. Provide a detailed analysis of the convergence properties of RFM, including the convergence rate and the effect of hyperparameters on convergence.\n4. Evaluate the strengths and weaknesses of RFM compared to existing methods, including a thorough comparison of their performance on a range of datasets.\n\nRecommendation:\nOverall, the paper proposes a promising framework for training continuous normalizing flows on general Riemannian manifolds. However, it lacks a clear explanation of the premetric construction and formal proof of its positive definiteness. Additionally, the paper does not provide a detailed analysis of the convergence properties of RFM, which is an important aspect of any optimization algorithm. To improve the paper, the authors should provide a clear and detailed explanation of the premetric construction, formalize the assumption that the premetric is positive definite, and provide a detailed analysis of the convergence properties of RFM.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper proposes Riemannian Flow Matching (RFM), a framework for training continuous normalizing flows on general Riemannian manifolds. RFM bypasses the limitations of existing methods by being simulation-free on simple geometries, not requiring divergence computation, and computing its target vector field in closed-form. The method uses a premetric to define the target vector field, which is constructed using spectral decompositions. RFM achieves state-of-the-art performance on many real-world non-Euclidean datasets and demonstrates tractable training on general geometries, including triangular meshes with highly non-trivial curvature and boundaries.\n\nStrengths:\n1. RFM is simulation-free on simple geometries, which is a significant advantage over existing methods.\n2. The method uses a premetric to define the target vector field, which is a novel approach that allows for efficient computation.\n3. RFM achieves state-of-the-art performance on many real-world non-Euclidean datasets.\n4. The method demonstrates tractable training on general geometries, including triangular meshes with highly non-trivial curvature and boundaries.\n\nWeaknesses:\n1. The method requires the construction of a premetric, which can be time-consuming and may require significant expertise.\n2. The use of spectral decompositions may not be suitable for all types of manifolds.\n3. The method may require careful tuning of hyperparameters, particularly for the premetric and the number of eigenfunctions.\n\nSuggestions for Improvement:\n1. Develop more efficient algorithms for constructing the premetric.\n2. Explore alternative premetrics that may be more suitable for certain types of manifolds.\n3. Provide more detailed guidance on tuning hyperparameters.\n4. Conduct more extensive experiments to evaluate the performance of RFM on a wider range of manifolds.\n\nRecommendation:\nI recommend that the authors publish their paper in a top-tier machine learning conference. The contributions of RFM are significant, and the method has the potential to revolutionize the field of generative modeling on manifolds. However, the authors should be prepared to address the weaknesses and limitations of the method and provide more detailed guidance on its implementation.",
        "gr_score_with": 0.7317880794701986,
        "gr_score_without": 0.6774193548387096,
        "output_without": {
            "num_tokens_scored": 310,
            "num_green_tokens": 210,
            "green_fraction": 0.6774193548387096,
            "z_score": -0.8675760324277121,
            "p_value": 0.8071867640311554
        },
        "output_with": {
            "num_tokens_scored": 302,
            "num_green_tokens": 221,
            "green_fraction": 0.7317880794701986,
            "z_score": 1.205474739349228,
            "p_value": 0.11401004201159248
        }
    },
    {
        "title": "MODERNTCN: A MODERN PURE CONVOLUTION STRUCTURE FOR GENERAL TIME SERIES ANALYSIS",
        "abstract": "Recently, Transformer-based and MLP-based models have emerged rapidly and won dominance in time series analysis. In contrast, convolution is losing steam in time series tasks nowadays for inferior performance. This paper studies the open question of how to better use convolution in time series analysis and makes efforts to bring convolution back to the arena of time series analysis. To this end, we modernize the traditional TCN and conduct time series related modifications to make it more suitable for time series tasks. As the outcome, we propose ModernTCN and successfully solve this open question through a seldom-explored way in time series community. As a pure convolution structure, ModernTCN still achieves the consistent state-of-the-art performance on five mainstream time series analysis tasks while maintaining the efficiency advantage of convolution-based models, therefore providing a better balance of efficiency and performance than state-of-the-art Transformer-based and MLP-based models. Our study further reveals that, compared with previous convolution-based models, our ModernTCN has much larger effective receptive fields (ERFs), therefore can better unleash the potential of convolution in time series analysis. Code is available at this repository: https://github.com/luodhhh/ModernTCN.",
        "peer_review_without_watermark": "$$$ \n\nPaper Summary:\nThe paper proposes ModernTCN, a modern pure convolution structure for general time series analysis. It modernizes the traditional Temporal Convolutional Network (TCN) and conducts time series-related modifications to make it more suitable for time series tasks. ModernTCN achieves consistent state-of-the-art performance on five mainstream time series analysis tasks while maintaining the efficiency advantage of convolution-based models.\n\nStrengths:\n1. The paper introduces a novel solution to the open question of how to better use convolution in time series analysis.\n2. ModernTCN achieves consistent state-of-the-art performance on multiple mainstream time series analysis tasks.\n3. The paper provides a better balance of efficiency and performance compared to state-of-the-art Transformer-based and MLP-based models.\n4. The design of ModernTCN block is decoupled, which makes it easier to learn and reduces computational complexity.\n\nWeaknesses:\n1. The paper mainly focuses on the performance of ModernTCN, and it would be beneficial to provide more details about its limitations and potential drawbacks.\n2. The experimental results show that ModernTCN achieves state-of-the-art performance, but it is unclear how it compares to other state-of-the-art models in terms of interpretability and explainability.\n3. The paper does not provide a detailed analysis of the effective receptive field (ERF) of ModernTCN, which is an important aspect of convolutional neural networks.\n\nSuggestions for Improvement:\n1. Provide more details about the limitations and potential drawbacks of ModernTCN.\n2. Include a more detailed analysis of the ERF of ModernTCN.\n3. Conduct experiments to compare the interpretability and explainability of ModernTCN with other state-of-the-art models.\n4. Consider incorporating techniques such as attention mechanisms or graph neural networks to improve the performance and flexibility of ModernTCN.\n\nRecommendation:\nThe paper presents a novel solution to the open question of how to better use convolution in time series analysis. ModernTCN achieves consistent state-of-the-art performance on multiple mainstream time series analysis tasks while maintaining the efficiency advantage of convolution-based models. However, further improvements are needed to provide more details about the limitations and potential drawbacks of ModernTCN, conduct a more detailed analysis of its ERF, and compare its interpretability and explainability with other state-of-the-art models. With these improvements, ModernTCN has the potential to become a leading architecture for time series analysis. \n\n$$$",
        "peer_review_with_watermark": "$$$\\label{review}\n $$$Paper: MODERNTCN: A MODERN PURE CONVOLUTION STRUCTURE FOR GENERAL TIME SERIES ANALYSIS\n\n $$$Summary: \n $$$The authors propose a modern pure convolution structure, namely ModernTCN, to efficiently utilize cross-time and cross-variable dependency for general time series analysis. They modernize the traditional TCN block with time series related modifications, including patchify variable-independent embedding, decoupling the feature and variable information mixing, and adopting large kernel in DWConv to increase the ERFs. Experimental results show the consistent state-of-the-art performance of ModernTCN on five mainstream time series analysis tasks while maintaining the efficiency advantage of convolution-based models.\n\n $$$Strengths:\n $$$1) The authors have successfully brought convolution back to the arena of time series analysis by modernizing the traditional TCN block.\n $$$2) The design of patchify variable-independent embedding, decoupling the feature and variable information mixing, and adopting large kernel in DWConv are innovative and effective modifications.\n $$$3) Experimental results demonstrate the excellent task-generality and efficiency of ModernTCN.\n $$$4) The authors have provided a comprehensive analysis of the experimental results, including ablation study, to validate the effectiveness of their design.\n\n $$$Weaknesses:\n $$$1) The authors have not provided a detailed theoretical analysis of the effectiveness of their design, which may be a limitation of the paper.\n $$$2) The paper may be difficult to follow for readers who are not familiar with the Transformer architecture or convolution-based models.\n $$$3) The authors have not discussed the limitations of ModernTCN in certain time series analysis tasks, which may be a potential area for future research.\n\n $$$Suggestions for Improvement:\n $$$1) The authors should provide a detailed theoretical analysis of the effectiveness of their design to demonstrate the theoretical basis of ModernTCN.\n $$$2) The authors should provide more detailed explanations of the patchify variable-independent embedding, decoupling the feature and variable information mixing, and adopting large kernel in DWConv to make the design more accessible to readers.\n $$$3) The authors should discuss the limitations of ModernTCN in certain time series analysis tasks to provide a more comprehensive understanding of the model's performance.\n\n $$$Recommendation:\n $$$The paper proposes a novel approach to modernizing the traditional TCN block for general time series analysis, which has the potential to bring convolution back to the arena of time series analysis. The experimental results demonstrate the excellent task-generality and efficiency of ModernTCN, which provides a good balance of performance and efficiency. However, the authors should address the limitations of the paper, including the lack of theoretical analysis and potential limitations in certain time series analysis tasks. With further improvements, the paper has the potential to be a leading contribution in the field of time series analysis.",
        "gr_score_with": 0.8166189111747851,
        "gr_score_without": 0.6887417218543046,
        "output_without": {
            "num_tokens_scored": 302,
            "num_green_tokens": 208,
            "green_fraction": 0.6887417218543046,
            "z_score": -0.42693897018618104,
            "p_value": 0.6652881099371966
        },
        "output_with": {
            "num_tokens_scored": 349,
            "num_green_tokens": 285,
            "green_fraction": 0.8166189111747851,
            "z_score": 4.754140894206888,
            "p_value": 9.964601296400645e-07
        }
    },
    {
        "title": "NAVIGATING TEXT-TO-IMAGE CUSTOMIZATION: FROM",
        "abstract": "Text-to-image generative models have garnered immense attention for their ability to produce high-fidelity images from text prompts. Among these, Stable Diffusion distinguishes itself as a leading open-source model in this fast-growing field. However, the intricacies of fine-tuning these models pose multiple challenges from new methodology integration to systematic evaluation. Addressing these issues, this paper introduces LyCORIS (Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion), an open-source library that offers a wide selection of fine-tuning methodologies for Stable Diffusion. Furthermore, we present a thorough framework for the systematic assessment of varied finetuning techniques. This framework employs a diverse suite of metrics and delves into multiple facets of fine-tuning, including hyperparameter adjustments and the evaluation with different prompt types across various concept categories. Through this comprehensive approach, our work provides essential insights into the nuanced effects of fine-tuning parameters, bridging the gap between state-of-the-art research and practical application.",
        "peer_review_without_watermark": "$$$\\boxed{Paper Summary:}\nThe paper presents LyCORIS, an open-source library for fine-tuning Stable Diffusion models. The library offers a range of methods for fine-tuning, including LoRA, LoHa, LoKr, and others. The authors also propose a comprehensive evaluation framework that captures key aspects of fine-tuning, including concept fidelity, text-image alignment, image diversity, and base model preservation.\n\nThe paper introduces three main algorithms: LoRA, LoHa, and LoKr, which are designed to improve the fine-tuning capabilities of Stable Diffusion models. LoHa and LoKr are extensions of LoRA, which uses the Hadamard product and Kronecker product, respectively, to maximize matrix rank while minimizing parameter count. The authors also propose a framework for systematic evaluation of fine-tuned text-to-image models, which includes a diverse suite of metrics and delves into multiple facets of fine-tuning.\n\nThe paper presents extensive experiments to compare the performances of different fine-tuning algorithms and assess the impact of hyperparameters. The results show that LoHa is better suited for simple, multi-concept fine-tuning, while LoKr with full dimension is better for complex, single-concept tasks.\n\nStrengths: \n1. The paper introduces a comprehensive evaluation framework for fine-tuned text-to-image models, which captures key aspects of fine-tuning.\n2. The library LyCORIS offers a range of methods for fine-tuning, including LoRA, LoHa, and LoKr.\n3. The paper presents extensive experiments to compare the performances of different fine-tuning algorithms and assess the impact of hyperparameters.\n\nWeaknesses: \n1. The paper's scope remains limited, as it does not explore the task of generating images with multiple learned concepts.\n2. The evaluation framework may not be comprehensive enough to capture all nuances of fine-tuning.\n3. The paper does not discuss potential limitations of the proposed methods and algorithms.\n\nSuggestions for Improvement:\n1. The paper should explore the task of generating images with multiple learned concepts.\n2. The evaluation framework should be further refined to capture more nuances of fine-tuning.\n3. The paper should discuss potential limitations of the proposed methods and algorithms.\n\nRecommendation:\nThe paper presents a comprehensive evaluation framework and a range of methods for fine-tuning Stable Diffusion models. The authors' extensive experiments provide valuable insights into the impact of hyperparameters on model performance. However, the paper's scope remains limited, and the evaluation framework may not be comprehensive enough to capture all nuances of fine-tuning. With further refinement and expansion, the paper has the potential to make a significant contribution to the field of text-to-image synthesis. \n\n$$$\\boxed{Recommendation:}\nBased on the review, I recommend that the authors revise the paper to address the limitations and suggestions mentioned above. The revised paper should explore the task of generating images with multiple learned concepts, further refine the evaluation framework, and discuss potential limitations of the proposed methods and algorithms.",
        "peer_review_with_watermark": "$$\n\\begin{aligned}\n\\text{Paper Summary:} \n& The paper presents LyCORIS, an open-source library that provides various fine-tuning methodologies for Stable Diffusion, a leading open-source text-to-image generative model. The authors introduce a comprehensive evaluation framework that captures the nuances of different fine-tuning methods. They also conduct extensive experiments to compare the performance of different algorithms and hyperparameters.\n\n\\text{Strengths:} \n& The paper provides a detailed introduction to the concept of fine-tuning text-to-image models, highlighting the importance of addressing the challenges in this domain. The authors' approach to developing LyCORIS and creating a comprehensive evaluation framework is innovative and well-structured. The experimental results are thorough and provide valuable insights into the impact of different algorithms and hyperparameters on model performance.\n\n\\text{Weaknesses:} \n& The paper does not explore the task of generating images with multiple learned concepts, which is highly sensitive to input prompts and challenging to evaluate. The authors also acknowledge the limitations of their study, including the scope of the dataset and the lack of exploration of other evaluation metrics.\n\n\\text{Suggestions for Improvement:} \n& The authors could explore the task of generating images with multiple learned concepts and develop new evaluation frameworks to capture the nuances of different fine-tuning methods. They could also expand the dataset to include more concepts and images, and explore other evaluation metrics, such as multi-task learning and few-shot learning.\n\n\\text{Recommendation:} \n& The paper contributes significantly to the field of text-to-image synthesis and provides a comprehensive evaluation framework for fine-tuning methods. The authors' work on LyCORIS and the experimental results are valuable additions to the existing research in this area. However, the paper could benefit from exploring other evaluation metrics and tasks to further enrich the comparison of fine-tuning methods.\n\n$$\n$$",
        "gr_score_with": 0.8284671532846716,
        "gr_score_without": 0.7663817663817664,
        "output_without": {
            "num_tokens_scored": 351,
            "num_green_tokens": 269,
            "green_fraction": 0.7663817663817664,
            "z_score": 2.7138929661800786,
            "p_value": 0.0033248823787630647
        },
        "output_with": {
            "num_tokens_scored": 274,
            "num_green_tokens": 227,
            "green_fraction": 0.8284671532846716,
            "z_score": 4.640424752531482,
            "p_value": 1.7384688412969008e-06
        }
    },
    {
        "title": "ENHANCING NEURAL TRAINING VIA A CORRELATED DYNAMICS MODEL",
        "abstract": "As neural networks grow in scale, their training becomes both computationally demanding and rich in dynamics. Amidst the flourishing interest in these training dynamics, we present a novel observation: Parameters during training exhibit intrinsic correlations over time. Capitalizing on this, we introduce correlation mode decomposition (CMD). This algorithm clusters the parameter space into groups, termed modes, that display synchronized behavior across epochs. This enables CMD to efficiently represent the training dynamics of complex networks, like ResNets and Transformers, using only a few modes. Moreover, test set generalization is enhanced. We introduce an efficient CMD variant, designed to run concurrently with training. Our experiments indicate that CMD surpasses the state-of-the-art method for compactly modeled dynamics on image classification. Our modeling can improve training efficiency and lower communication overhead, as shown by our preliminary experiments in the context of federated learning.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces Correlation Mode Decomposition (CMD), a novel approach to model neural network parameter dynamics. CMD captures the correlated behavior of the training process and efficiently represents the training dynamics of complex networks using only a few modes. The authors demonstrate the effectiveness of CMD in various architectures and learning tasks, including image classification, segmentation, and generative image style transfer. Additionally, they propose an efficient online variant of CMD, called Online CMD, which can be performed concurrently with training, reducing the computational overhead. The authors also demonstrate the efficiency of CMD in Federated Learning, reducing the communication overhead.\n\nStrengths:\n1. The paper introduces a novel approach to model neural network parameter dynamics, leveraging the underlying correlated behavior of the training process.\n2. CMD is demonstrated to be effective in various architectures and learning tasks, including image classification, segmentation, and generative image style transfer.\n3. The authors propose an efficient online variant of CMD, called Online CMD, which can be performed concurrently with training, reducing the computational overhead.\n4. The paper demonstrates the efficiency of CMD in Federated Learning, reducing the communication overhead.\n\nWeaknesses:\n1. The paper does not provide a thorough analysis of the limitations and potential biases of CMD.\n2. The authors rely heavily on experiments to demonstrate the effectiveness of CMD, which may not generalize well to other scenarios.\n3. The paper does not provide a clear explanation of the mathematical underpinnings of CMD, which may make it difficult for readers to understand the approach.\n4. The authors do not discuss the potential applications of CMD beyond image classification and segmentation.\n\nSuggestions for Improvement:\n1. Provide a more detailed analysis of the limitations and potential biases of CMD, including its assumptions and potential sources of error.\n2. Include more theoretical results and mathematical derivations to support the claims made in the paper.\n3. Provide more experimental results to demonstrate the effectiveness of CMD in various scenarios and architectures.\n4. Discuss the potential applications of CMD beyond image classification and segmentation.\n\nRecommendation:\nThe paper presents a novel approach to model neural network parameter dynamics, leveraging the underlying correlated behavior of the training process. While the approach shows promise, it requires further development and validation to fully understand its limitations and potential applications. I recommend that the authors address the weaknesses mentioned above and provide more experimental results to demonstrate the effectiveness of CMD in various scenarios and architectures. Additionally, the authors should discuss the potential applications of CMD beyond image classification and segmentation. With further development and validation, CMD has the potential to become a powerful tool for optimizing complex neural network training.",
        "peer_review_with_watermark": "$$$$\n\nPaper Summary:\nThe paper presents a novel approach to model neural network parameter dynamics, leveraging the underlying correlated behavior of the training process. The authors introduce Correlation Mode Decomposition (CMD), a data-driven approach that clusters the parameter space into groups, termed modes, that display synchronized behavior across epochs. The authors also introduce efficient variants of CMD, including Online CMD, which can be performed concurrently with training, and Embedded CMD, which gradually integrates CMD dynamics into training. The authors demonstrate the effectiveness of their approach on various image classification architectures and show that it can improve training efficiency and lower communication overhead, especially in federated learning scenarios.\n\nStrengths:\n\n1. The authors provide a thorough analysis of the training dynamics of neural networks and highlight the importance of modeling these dynamics for improving training efficiency and performance.\n2. The introduction of CMD and its variants is innovative and provides a novel approach to modeling neural network parameter dynamics.\n3. The authors provide extensive experiments and ablation studies to demonstrate the effectiveness of their approach and show that it can be used effectively for various image classification architectures and federated learning scenarios.\n4. The authors also highlight the potential benefits of using modeled dynamics for visualization of accuracy and error landscapes, which can be useful for understanding and improving neural network performance.\n\nWeaknesses:\n\n1. The authors may have relied too heavily on experiments and ablation studies, which can be time-consuming and may not always provide conclusive results.\n2. The paper may benefit from more theoretical foundations and derivations to support the claims made by the authors.\n3. The authors may have overlooked some potential limitations and challenges of their approach, such as the need for careful hyperparameter tuning and the potential for overfitting.\n\nSuggestions for Improvement:\n\n1. The authors should provide more theoretical foundations and derivations to support their claims about the effectiveness of their approach.\n2. The authors should conduct more extensive experiments and ablation studies to thoroughly evaluate the performance of their approach and identify potential limitations and challenges.\n3. The authors should consider incorporating more advanced techniques, such as regularization and early stopping, to improve the robustness and performance of their approach.\n4. The authors should provide more guidance on how to implement and fine-tune their approach for different neural network architectures and federated learning scenarios.\n\nRecommendation:\n\nBased on the strengths and weaknesses of the paper, I recommend that it be accepted for publication in a top-tier conference or journal in machine learning and deep learning. The authors have made significant contributions to the field and have provided a novel and innovative approach to modeling neural network parameter dynamics. However, the authors should address some of the limitations and challenges of their approach and provide more theoretical foundations and derivations to support their claims.",
        "gr_score_with": 0.6825396825396826,
        "gr_score_without": 0.5592105263157895,
        "output_without": {
            "num_tokens_scored": 304,
            "num_green_tokens": 170,
            "green_fraction": 0.5592105263157895,
            "z_score": -5.356700065242817,
            "p_value": 0.9999999576221787
        },
        "output_with": {
            "num_tokens_scored": 378,
            "num_green_tokens": 258,
            "green_fraction": 0.6825396825396826,
            "z_score": -0.7407785326716174,
            "p_value": 0.7705861332554027
        }
    },
    {
        "title": "RingAttention with Blockwise Transformers for Near-Infinite Context",
        "abstract": "Transformers have emerged as the architecture of choice for many state-ofthe-art AI models, showcasing exceptional performance across a wide range of AI applications. However, the memory demands imposed by Transformers limit their ability to handle long sequences, thereby posing challenges in utilizing videos, actions, and other long-form sequences and modalities in complex environments. We present a novel approach, Blockwise RingAttention, which leverages blockwise computation of self-attention and feedforward to distribute long sequences across multiple devices while fully overlapping the communication of key-value blocks with the computation of blockwise attention. Our approach enables training and inference of sequences that are up to device count times longer than those achievable by prior memory-efficient Transformers, without resorting to approximations or incurring additional communication and computation overheads. Extensive experiments on language modeling and reinforcement learning tasks demonstrate the effectiveness of our approach in allowing millions of tokens context size and improving performance.",
        "peer_review_without_watermark": "$$$\\begin{align*}\n\\textbf{Paper Summary:} \\\\\n\\text{The paper proposes a novel approach called RingAttention with Blockwise Transformers for reducing memory requirements of Transformers, a widely used architecture in AI models. The approach leverages blockwise computation of self-attention and feedforward to distribute long sequences across multiple devices, allowing concurrent computation and communication. The authors demonstrate the effectiveness of their approach on language modeling and reinforcement learning tasks, enabling training sequences that are up to device count times longer than those of prior memory-efficient Transformers.}\n\n\\textbf{Strengths:} \\\\\n1. The paper presents a novel approach to reducing memory requirements of Transformers, which is a significant challenge in AI research.\n2. The authors demonstrate the effectiveness of their approach on language modeling and reinforcement learning tasks, showcasing its potential for large-scale AI applications.\n3. The paper provides a detailed analysis of the memory requirements of Transformers and the challenges posed by individual devices, providing a clear motivation for the proposed approach.\n\n\\textbf{Weaknesses:} \\\\\n1. The paper may be too technical for non-experts, with complex explanations of Transformer architecture and blockwise computation.\n2. The authors rely heavily on prior work, with limited original contributions to the field.\n3. The evaluation of the proposed approach is based on limited experiments, which may not be representative of real-world scenarios.\n\n\\textbf{Suggestions for Improvement:} \\\\\n1. Provide more intuitive explanations of complex concepts, such as blockwise computation and self-attention.\n2. Conduct more comprehensive experiments to evaluate the proposed approach in real-world scenarios.\n3. Explore potential applications of the proposed approach beyond language modeling and reinforcement learning.\n\n\\textbf{Recommendation:} \\\\\nBased on the strengths and weaknesses of the paper, I recommend that it be published in a reputable conference or journal in the field of AI research. However, I suggest that the authors address the weaknesses and provide more comprehensive evidence for the effectiveness of their approach. With further improvements, this paper has the potential to make a significant contribution to the field of AI research.",
        "peer_review_with_watermark": "$$$\\begin{align*}\n\\textbf{Paper Summary:}\n\\text{The paper proposes RingAttention with Blockwise Transformers, a novel approach for reducing memory requirements of Transformers. It uses blockwise computation of self-attention and feedforward networks to distribute long sequences across multiple devices and overlap communication of key-value blocks with computation of blockwise attention. The proposed approach enables scaling of context length linearly with the number of devices while maintaining performance, and extensive experiments demonstrate its effectiveness on language modeling and reinforcement learning tasks.}\n\n\\textbf{Strengths:}\n\n*   The proposed approach of using blockwise computation of self-attention and feedforward networks to distribute long sequences across multiple devices and overlap communication of key-value blocks with computation of blockwise attention is novel and effective.\n*   The paper provides extensive experiments demonstrating the effectiveness of the proposed approach on language modeling and reinforcement learning tasks.\n*   The analysis of memory requirements and computational complexity of the proposed approach is thorough and provides insights into the scalability of the approach.\n*   The paper provides a detailed comparison of the proposed approach with existing memory-efficient Transformer architectures, highlighting the advantages of the proposed approach.\n\n\\textbf{Weaknesses:}\n\n*   The paper may benefit from further analysis of the limitations and potential challenges of the proposed approach, such as the requirement for significant computational resources and the potential for increased memory usage.\n*   The paper may also benefit from a more detailed explanation of the theoretical foundations of the proposed approach, such as the use of permutation invariance property and the analysis of memory requirements and computational complexity.\n*   The paper may also benefit from more extensive experiments on other tasks and architectures, such as computer vision and natural language processing, to demonstrate the generalizability of the proposed approach.\n*   The paper may also benefit from a more detailed discussion of the potential applications and future prospects of the proposed approach, such as the use of large video-audio-language models and the development of strong reasoning from link gathering data.\n\n\\textbf{Suggestions for Improvement:}\n\n*   The paper may benefit from further analysis of the limitations and potential challenges of the proposed approach.\n*   The paper may also benefit from a more detailed explanation of the theoretical foundations of the proposed approach.\n*   The paper may also benefit from more extensive experiments on other tasks and architectures.\n*   The paper may also benefit from a more detailed discussion of the potential applications and future prospects of the proposed approach.\n\n\\textbf{Recommendation:}\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit the paper for further review. The proposed approach of using blockwise computation of self-attention and feedforward networks to distribute long sequences across multiple devices and overlap communication of key-value blocks with computation of blockwise attention is novel and effective, and the extensive experiments demonstrate its effectiveness on language modeling and reinforcement learning tasks. However, the paper may benefit from further analysis of the limitations and potential challenges of the proposed approach, as well as more detailed explanations of the theoretical foundations and potential applications of the proposed approach.",
        "gr_score_with": 0.7639344262295082,
        "gr_score_without": 0.6482084690553745,
        "output_without": {
            "num_tokens_scored": 307,
            "num_green_tokens": 199,
            "green_fraction": 0.6482084690553745,
            "z_score": -1.9802420992195946,
            "p_value": 0.9761618342936108
        },
        "output_with": {
            "num_tokens_scored": 305,
            "num_green_tokens": 233,
            "green_fraction": 0.7639344262295082,
            "z_score": 2.436548409099007,
            "p_value": 0.0074140922754159
        }
    },
    {
        "title": "RELAY DIFFUSION: UNIFYING DIFFUSION PROCESS ACROSS RESOLUTIONS FOR IMAGE SYNTHESIS",
        "abstract": "Diffusion models achieved great success in image synthesis, but still face challenges in high-resolution generation. Through the lens of discrete cosine transformation, we find the main reason is that the same noise level on a higher resolution results in a higher Signal-to-Noise Ratio in the frequency domain. In this work, we present Relay Diffusion Model (RDM), which transfers a low-resolution image or noise into an equivalent high-resolution one for diffusion model via blurring diffusion and block noise. Therefore, the diffusion process can continue seamlessly in any new resolution or model without restarting from pure noise or lowresolution conditioning. RDM achieves state-of-the-art FID on CelebA-HQ and sFID on ImageNet 256\u00d7256, surpassing previous works such as ADM, LDM and DiT by a large margin. All the codes and checkpoints are open-sourced at https://github.com/THUDM/RelayDiffusion. Figure 1: (left): Generated Samples by RDM on ImageNet 256\u00d7256 and CelebA-HQ 256\u00d7256. (right): Benchmarking recent diffusion models on class-conditional ImageNet 256\u00d7256 generation without any guidance. RDM can achieve a FID of 1.99 (and a class-balanced FID of 1.87) if with classifier-free guidance.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes the Relay Diffusion Model (RDM), a new cascaded framework for high-resolution image synthesis. The main contributions of the paper are:\n- Analysis of the difficulty of noise scheduling in high-resolution diffusion models in frequency domain.\n- Proposal of block noise to bridge the gap between low-resolution and high-resolution images.\n- Introduction of a new cascaded pipeline, Relay Diffusion Model, which transfers a low-resolution image or noise into an equivalent high-resolution one via blurring diffusion and block noise.\n- Evaluation of the effectiveness of RDM on unconditional CelebA-HQ 256\u00d7256 and conditional ImageNet 256\u00d7256 datasets, achieving state-of-the-art FID on CelebA-HQ and sFID on ImageNet.\n\nStrengths:\n- The paper provides a thorough analysis of the challenges in high-resolution image synthesis using diffusion models.\n- The introduction of block noise is a novel idea that bridges the gap between low-resolution and high-resolution images.\n- The Relay Diffusion Model achieves state-of-the-art results on CelebA-HQ and ImageNet datasets.\n\nWeaknesses:\n- The paper relies heavily on the analysis of frequency domain, which might not be the most practical approach for noise scheduling.\n- The training efficiency and convergence of the model are not thoroughly discussed.\n- The paper does not provide a comprehensive comparison with other state-of-the-art methods.\n\nSuggestions for Improvement:\n- Provide a more comprehensive analysis of the challenges in high-resolution image synthesis using diffusion models.\n- Discuss the training efficiency and convergence of the model in more detail.\n- Provide a more thorough comparison with other state-of-the-art methods.\n\nRecommendation:\nThe paper proposes a novel cascaded framework, Relay Diffusion Model, which achieves state-of-the-art results on CelebA-HQ and ImageNet datasets. However, the paper relies heavily on the analysis of frequency domain, which might not be the most practical approach for noise scheduling. The training efficiency and convergence of the model are not thoroughly discussed. To improve the paper, a more comprehensive analysis of the challenges in high-resolution image synthesis using diffusion models, a more thorough comparison with other state-of-the-art methods, and a discussion of the training efficiency and convergence of the model are necessary.",
        "peer_review_with_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes the Relay Diffusion Model (RDM), a new cascaded framework for high-resolution image synthesis. RDM addresses the challenges of diffusion models in high-resolution generation by transferring a low-resolution image or noise into an equivalent high-resolution one via blurring diffusion and block noise. The authors demonstrate the effectiveness of RDM on unconditional CelebA-HQ and class-conditional ImageNet 256\u00d7256 datasets, achieving state-of-the-art FID and sFID scores.\n\n$$\\boxed{Strengths:}\n1. RDM provides a more efficient and flexible approach to high-resolution image synthesis by leveraging block noise and patch-wise blurring diffusion.\n2. The authors demonstrate the effectiveness of RDM on both unconditional and class-conditional image synthesis tasks.\n3. The frequency analysis in the paper provides valuable insights into the relationship between noise and image resolution.\n\n$$\\boxed{Weaknesses:}\n1. The paper lacks a clear theoretical foundation for the optimal noise schedule, and further investigation is left for future work.\n2. The authors assume that the block noise has a similar frequency spectrum as the independent Gaussian noise on 64\u00d7 64 images, which might not be accurate for all cases.\n3. The training efficiency of RDM may be affected by the scale of stochasticity and the number of sampling steps.\n\n$$\\boxed{Suggestions for Improvement:}\n1. Provide a clear theoretical foundation for the optimal noise schedule and investigate its relationship with the size of the model, inductive bias, and data distribution characteristics.\n2. Verify the assumption about the frequency spectrum of block noise and explore its accuracy for different cases.\n3. Investigate the effects of the scale of stochasticity and the number of sampling steps on the training efficiency of RDM.\n\n$$\\boxed{Recommendation:}\nOverall, the paper proposes a novel and effective approach to high-resolution image synthesis using Relay Diffusion Model. While there are some limitations and areas for improvement, the authors demonstrate the potential of RDM for efficient and flexible image synthesis. With further investigation and refinement, RDM has the potential to become a leading method for high-resolution image synthesis.",
        "gr_score_with": 0.7791798107255521,
        "gr_score_without": 0.6653225806451613,
        "output_without": {
            "num_tokens_scored": 248,
            "num_green_tokens": 165,
            "green_fraction": 0.6653225806451613,
            "z_score": -1.1916890902684396,
            "p_value": 0.8833084113014131
        },
        "output_with": {
            "num_tokens_scored": 317,
            "num_green_tokens": 247,
            "green_fraction": 0.7791798107255521,
            "z_score": 3.076340783348326,
            "p_value": 0.0010477909346199596
        }
    },
    {
        "title": "A TOPOLOGICAL PERSPECTIVE ON DEMYSTIFYING GNN-BASED LINK PREDICTION PERFORMANCE",
        "abstract": "Graph Neural Networks (GNNs) have shown great promise in learning node embeddings for link prediction (LP). While numerous studies aim to improve the overall LP performance of GNNs, none have explored its varying performance across different nodes and its underlying reasons. To this end, we aim to demystify which nodes will perform better from the perspective of their local topology. Despite the widespread belief that low-degree nodes exhibit poorer LP performance, our empirical findings provide nuances to this viewpoint and prompt us to propose a better metric, Topological Concentration (TC), based on the intersection of the local subgraph of each node with the ones of its neighbors. We empirically demonstrate that TC has a higher correlation with LP performance than other node-level topological metrics like degree and subgraph density, offering a better way to identify low-performing nodes than using degree. With TC, we discover a novel topological distribution shift issue in which newly joined neighbors of a node tend to become less interactive with that node\u2019s existing neighbors, compromising the generalizability of node embeddings for LP at testing time. To make the computation of TC scalable, We further propose Approximated Topological Concentration (ATC) and theoretically/empirically justify its efficacy in approximating TC and reducing the computation complexity. Given the positive correlation between node TC and its LP performance, we explore the potential of boosting LP performance via enhancing TC by re-weighting edges in the message-passing and discuss its effectiveness with limitations. Our code is publicly available at https://github.com/submission2024/Topo Concentration.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes Topological Concentration (TC) to measure the local topology of nodes in Graph Neural Networks (GNNs) and its impact on link prediction (LP) performance. TC is defined as the average intersection between a node's K-hop computation tree and its neighbors' computation trees. The authors demonstrate the superiority of TC in characterizing LP performance over other node topological properties, such as degree and subgraph density. They also discover a novel topological distribution shift (TDS) issue, where newly joined neighbors of a node become less interactive with existing neighbors, compromising the generalizability of node embeddings for LP. The authors propose Approximated Topological Concentration (ATC) to reduce the computational complexity of TC. Finally, they explore the potential of boosting LP performance by re-weighting edges in message-passing.\n\nStrengths:\n1. The paper provides a novel approach to characterizing the local topology of nodes in GNNs and its impact on LP performance.\n2. The authors demonstrate the superiority of TC over other node topological properties.\n3. The discovery of the TDS issue provides new insights into the dynamics of node interactions in GNNs.\n4. The authors propose a scalable and efficient approximation of TC, ATC.\n\nWeaknesses:\n1. The paper relies heavily on experimental results, which may not be generalizable to all GNN architectures and datasets.\n2. The authors do not provide a comprehensive theoretical analysis of the properties of TC and ATC.\n3. The paper does not discuss potential limitations and biases of TC and ATC, such as the assumption of a Gaussian distribution for node embeddings.\n\nSuggestions for Improvement:\n1. Provide a more comprehensive theoretical analysis of TC and ATC, including their properties and limitations.\n2. Conduct more extensive experimental evaluations to demonstrate the generalizability of TC and ATC across different GNN architectures and datasets.\n3. Discuss potential limitations and biases of TC and ATC, such as the assumption of a Gaussian distribution for node embeddings.\n4. Explore the causal relationship between TC and LP performance, and investigate the potential of using TC for data valuation.\n\nRecommendation:\nThe paper makes a significant contribution to the field of GNNs and LP, providing a novel approach to characterizing the local topology of nodes and its impact on LP performance. However, the authors should address the limitations and biases of TC and ATC, and conduct more extensive experimental evaluations to demonstrate their generalizability. With these improvements, the paper has the potential to be a top-tier conference submission. \n\n$$$",
        "peer_review_with_watermark": "$$\\boxed{Summary:\nThe paper proposes Topological Concentration (TC) to characterize node performance in Graph Neural Networks (GNNs) based on local topology. TC measures the average intersection among local subgraphs of a node and its neighbors. The authors demonstrate TC's superior correlation with GNN-based link prediction (LP) performance compared to other node-level topological metrics. Additionally, they identify a novel topological distribution shift issue, where newly joined neighbors of a node tend to become less interactive with its existing neighbors, compromising generalizability of node embeddings. The authors propose an approximated version of TC, ATC, to reduce computation complexity. The work offers new insights into local topology's impact on node performance in GNN-based LP.}\n\n$$\\boxed{Strengths:\n1. The paper introduces Topological Concentration (TC), a new metric to characterize node performance in GNN-based LP.\n2. The authors demonstrate TC's superior correlation with GNN-based LP performance compared to other node-level topological metrics.\n3. The work identifies a novel topological distribution shift issue, where newly joined neighbors of a node tend to become less interactive with its existing neighbors.\n4. The authors propose an approximated version of TC, ATC, to reduce computation complexity.\n5. The work offers new insights into local topology's impact on node performance in GNN-based LP.}\n\n$$\\boxed{Weaknesses:\n1. The paper does not provide a clear explanation of how TC is related to other node-level topological metrics, such as degree and subgraph density.\n2. The authors' analysis of the topological distribution shift issue could be more in-depth and comprehensive.\n3. The work assumes that the reader is familiar with GNNs and LP, and does not provide an introduction to these concepts.\n4. The authors' discussion of the limitations of TC and ATC could be more detailed and thorough.\n5. The work could benefit from more experimental results and evaluations to support its claims.}\n\n$$\\boxed{Suggestions for Improvement:\n1. Provide a clear explanation of how TC is related to other node-level topological metrics.\n2. Conduct more comprehensive analysis of the topological distribution shift issue.\n3. Provide an introduction to GNNs and LP to help readers who are not familiar with these concepts.\n4. Discuss the limitations of TC and ATC in more detail and provide suggestions for future work.\n5. Include more experimental results and evaluations to support the authors' claims.}\n\n$$\\boxed{Recommendation:\nThe paper introduces a new metric, TC, to characterize node performance in GNN-based LP, and demonstrates its superior correlation with GNN-based LP performance. The authors identify a novel topological distribution shift issue and propose an approximated version of TC, ATC. The work offers new insights into local topology's impact on node performance in GNN-based LP. However, the paper could benefit from more experimental results and evaluations to support its claims, and a clearer explanation of how TC is related to other node-level topological metrics.}\n\n$$\\boxed{Author's Response to Reviewers:\nThe authors would like to thank the reviewers for their comments and suggestions. The authors believe that their work contributes to the field of GNNs and LP, and they are willing to address the reviewer's concerns and suggestions. The authors will revise their paper to provide a clearer explanation of how TC is related to other node-level topological metrics, and to conduct more comprehensive analysis of the topological distribution shift issue. The authors will also include more experimental results and evaluations to support their claims.}$$",
        "gr_score_with": 0.7950819672131147,
        "gr_score_without": 0.7350427350427351,
        "output_without": {
            "num_tokens_scored": 351,
            "num_green_tokens": 258,
            "green_fraction": 0.7350427350427351,
            "z_score": 1.4326559435199564,
            "p_value": 0.07597809287170507
        },
        "output_with": {
            "num_tokens_scored": 366,
            "num_green_tokens": 291,
            "green_fraction": 0.7950819672131147,
            "z_score": 3.969438282809099,
            "p_value": 3.6021131581312306e-05
        }
    },
    {
        "title": "TIONS WITH TRANSITIONAL DICTIONARY LEARNING",
        "abstract": "This paper introduces a novel Transitional Dictionary Learning (TDL) framework that can implicitly learn symbolic knowledge, such as visual parts and relations, by reconstructing the input as a combination of parts with implicit relations. We propose a game-theoretic diffusion model to decompose the input into visual parts using the dictionaries learned by the Expectation Maximization (EM) algorithm, implemented as the online prototype clustering, based on the decomposition results. Additionally, two metrics, clustering information gain, and heuristic shape score are proposed to evaluate the model. Experiments are conducted on three abstract compositional visual object datasets, which require the model to utilize the compositionality of data instead of simply exploiting visual features. Then, three tasks on symbol grounding to predefined classes of parts and relations, as well as transfer learning to unseen classes, followed by a human evaluation, were carried out on these datasets. The results show that the proposed method discovers compositional patterns, which significantly outperforms the state-of-the-art unsupervised part segmentation methods that rely on visual features from pre-trained backbones. Furthermore, the proposed metrics are consistent with human evaluations.",
        "peer_review_without_watermark": "$$$\\begin{align*}\n\\textbf{Paper Summary:} \\\\\n\\text{The paper introduces a novel Transitional Dictionary Learning (TDL) framework that implicitly learns symbolic knowledge by reconstructing the input as a combination of parts with implicit relations. The framework uses an Expectation Maximization (EM) algorithm to iteratively update dictionaries that store hidden representations of symbolic knowledge. The paper also proposes two metrics, clustering information gain and heuristic shape score, to evaluate the learned representation. The results show that the proposed method discovers compositional patterns and outperforms the state-of-the-art unsupervised part segmentation methods.}\n\n\\textbf{Strengths:} \\\\\n- The paper introduces a novel TDL framework that implicitly learns symbolic knowledge.\n- The framework uses an EM algorithm to iteratively update dictionaries that store hidden representations of symbolic knowledge.\n- The paper proposes two metrics, clustering information gain and heuristic shape score, to evaluate the learned representation.\n- The results show that the proposed method discovers compositional patterns and outperforms the state-of-the-art unsupervised part segmentation methods.\n\n\\textbf{Weaknesses:} \\\\\n- The paper does not provide a detailed analysis of the proposed metrics and their limitations.\n- The paper does not provide a thorough comparison with other methods, including supervised and semi-supervised methods.\n- The paper does not provide a clear explanation of the game-theoretic diffusion model and its limitations.\n- The paper does not provide a detailed analysis of the online prototype clustering algorithm and its limitations.\n\n\\textbf{Suggestions for Improvement:} \\\\\n- Provide a detailed analysis of the proposed metrics and their limitations.\n- Conduct a thorough comparison with other methods, including supervised and semi-supervised methods.\n- Provide a clear explanation of the game-theoretic diffusion model and its limitations.\n- Provide a detailed analysis of the online prototype clustering algorithm and its limitations.\n- Provide more results on the human evaluation and discuss the implications of the results.\n\n\\textbf{Recommendation:} \\\\\nBased on the review, I recommend that the authors revise the paper to address the weaknesses and improve the strengths. The authors should provide a detailed analysis of the proposed metrics and their limitations, conduct a thorough comparison with other methods, and provide a clear explanation of the game-theoretic diffusion model and its limitations. Additionally, the authors should provide more results on the human evaluation and discuss the implications of the results. Overall, the paper has the potential to make a significant contribution to the field of computer vision and cognitive science, but it requires further revisions to address the weaknesses and improve the strengths.",
        "peer_review_with_watermark": "$$$\\begin{align}\\textbf{Paper Summary:}\\ \n\\text{This paper presents a novel approach called Transitional Dictionary Learning (TDL) to learn a neural-symbolic transitional representation.}\\ \n\\text{The proposed TDL framework uses an Expectation Maximization (EM) algorithm to learn a dictionary that stores hidden representations of symbolic knowledge.}\\ \n\\text{It then uses a game-theoretic diffusion model and online prototype clustering to iteratively update the dictionary and generate a decomposition of the input.}\\ \n\\text{The framework is evaluated on three abstract compositional visual object datasets and shows significant improvements over state-of-the-art unsupervised part segmentation methods.}\\ \n\\text{Additionally, the proposed metrics, clustering information gain, and shape score are shown to be consistent with human judgments.}\\ \n\n\\textbf{Strengths:}\\ \n\\text{The paper presents a novel approach to learning a neural-symbolic transitional representation.}\\ \n\\text{The use of an EM algorithm and game-theoretic diffusion model to update the dictionary and generate a decomposition is an interesting and innovative approach.}\\ \n\\text{The evaluation on three abstract compositional visual object datasets and human assessments show the effectiveness of the proposed method.}\\ \n\\text{The proposed metrics, clustering information gain, and shape score provide a quantitative measure of the learned representation.}\\ \n\n\\textbf{Weaknesses:}\\ \n\\text{The paper may be difficult to follow due to the complexity of the proposed framework and the use of various mathematical notations.}\\ \n\\text{Some of the experimental results may be difficult to interpret, especially for readers without a deep understanding of the proposed metrics and shape score.}\\ \n\\text{The paper may not provide a clear comparison with other state-of-the-art methods, especially those that use pre-trained vision backbones.}\\ \n\\text{Some of the mathematical derivations may be missing, which can make it difficult to fully understand the proposed algorithm.}\\ \n\n\\textbf{Suggestions for Improvement:}\\ \n\\text{To improve the paper, the authors should provide a more detailed explanation of the proposed framework and the use of mathematical notations.}\\ \n\\text{The authors should provide a more detailed comparison with other state-of-the-art methods, especially those that use pre-trained vision backbones.}\\ \n\\text{The authors should provide more detailed experimental results, including more visualization and qualitative analysis.}\\ \n\\text{The authors should provide more detailed mathematical derivations to support the proposed algorithm.}\\ \n\n\\textbf{Recommendation:}\\ \n\\text{Based on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit the paper.}\\ \n\\text{With further clarification and detailed explanations, the paper has the potential to be a top-tier publication.}\\ \n\\text{However, the authors should be prepared to address the weaknesses and provide additional details to support the proposed algorithm.}\\ \n\n\\end{align}$",
        "gr_score_with": 0.7936046511627907,
        "gr_score_without": 0.7222222222222222,
        "output_without": {
            "num_tokens_scored": 270,
            "num_green_tokens": 195,
            "green_fraction": 0.7222222222222222,
            "z_score": 0.7968190728895956,
            "p_value": 0.21277805820956447
        },
        "output_with": {
            "num_tokens_scored": 344,
            "num_green_tokens": 273,
            "green_fraction": 0.7936046511627907,
            "z_score": 3.788497482946846,
            "p_value": 7.578056406256769e-05
        }
    },
    {
        "title": "ZERO-MEAN REGULARIZED SPECTRAL CONTRASTIVE LEARNING: IMPLICITLY MITIGATING WRONG CON-",
        "abstract": "Contrastive learning has emerged as a popular paradigm of self-supervised learning that learns representations by encouraging representations of positive pairs to be similar while representations of negative pairs to be far apart. The spectral contrastive loss, in synergy with the notion of positive-pair graphs, offers valuable theoretical insights into the empirical successes of contrastive learning. In this paper, we propose incorporating an additive factor into the term of spectral contrastive loss involving negative pairs. This simple modification can be equivalently viewed as introducing a regularization term that enforces the mean of representations to be zero, which thus is referred to as zero-mean regularization. It intuitively relaxes the orthogonality of representations between negative pairs and implicitly alleviates the adverse effect of wrong connections in the positive-pair graph, leading to better performance and robustness. To clarify this, we thoroughly investigate the role of zero-mean regularized spectral contrastive loss in both unsupervised and supervised scenarios with respect to theoretical analysis and quantitative evaluation. These results highlight the potential of zero-mean regularized spectral contrastive learning to be a promising approach in various tasks.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes zero-mean regularized spectral contrastive learning, which incorporates an additive factor into the spectral contrastive loss involving negative pairs. This modification relaxes the orthogonality constraint between negative pairs and alleviates the adverse effect of wrong connections in the positive-pair graph, leading to better performance and robustness. The authors investigate the role of zero-mean regularized spectral contrastive loss in both unsupervised and supervised scenarios with respect to theoretical analysis and quantitative evaluation.\n\nStrengths:\n1. The paper introduces a new modification to spectral contrastive loss, which relaxes the orthogonality constraint between negative pairs.\n2. The authors provide a theoretical analysis of the proposed method, which highlights its potential benefits in terms of performance and robustness.\n3. The paper presents experimental results on various benchmark datasets, which demonstrate the effectiveness of zero-mean regularized spectral contrastive learning.\n\nWeaknesses:\n1. The paper does not provide a clear explanation of the choice of the hyperparameter \u03c4, which is used to control the strength of regularization.\n2. The authors do not provide a detailed analysis of the limitations of the proposed method, such as the potential impact of over-regularization.\n3. The paper does not discuss the potential applications of zero-mean regularized spectral contrastive learning in real-world scenarios.\n\nSuggestions for Improvement:\n1. Provide a more detailed analysis of the choice of hyperparameter \u03c4 and its impact on the performance of the proposed method.\n2. Discuss the potential limitations of the proposed method, such as the risk of over-regularization.\n3. Explore the potential applications of zero-mean regularized spectral contrastive learning in real-world scenarios.\n\nRecommendation:\nBased on the paper's contribution to the field of contrastive learning, I recommend its acceptance for publication. However, I suggest that the authors address the limitations and provide a more detailed analysis of the proposed method to strengthen its overall quality.\n\n$$\nRecommendation: Accept with minor revisions.\n$$",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper proposes zero-mean regularized spectral contrastive learning, which incorporates an additive factor into the spectral contrastive loss involving negative pairs to relax the orthogonality constraint between negative pairs. The introduction of zero-mean regularization relaxes the constraint while explicitly mitigating the adverse effects of wrong connections in the positive-pair graph, leading to improved robustness and discriminativeness of representations. The theoretical analysis and quantitative evaluation demonstrate the potential of zero-mean regularized spectral contrastive learning in various tasks, including unsupervised domain adaptation, supervised classification, and learning with noisy labels.\n\nStrengths:\n\n1.  The paper provides a clear and well-structured introduction to the concept of spectral contrastive learning and the limitations of the existing spectral contrastive loss.\n2.  The proposal of zero-mean regularization to relax the orthogonality constraint between negative pairs is innovative and effective.\n3.  The theoretical analysis and quantitative evaluation provide strong evidence of the benefits of zero-mean regularized spectral contrastive learning in various tasks.\n4.  The experiment results demonstrate the superiority of zero-mean regularized spectral contrastive learning in enhancing contrastive learning.\n\nWeaknesses:\n\n1.  The paper assumes that the representation dimensionality d \u2265 p + r \u2212 1, which may not always be true.\n2.  The theoretical analysis assumes that the positive-pair graph has a specific structure, which may not be the case in all scenarios.\n3.  The experiment results may be biased towards the datasets used, which need to be further validated on other datasets.\n4.  The paper does not provide a clear comparison with existing state-of-the-art methods, which would provide a more comprehensive understanding of the benefits of zero-mean regularized spectral contrastive learning.\n\nSuggestions for Improvement:\n\n1.  The paper should provide a more thorough analysis of the assumptions made in the theoretical analysis.\n2.  The experiment results should be further validated on other datasets to provide a more comprehensive understanding of the benefits of zero-mean regularized spectral contrastive learning.\n3.  The paper should provide a clear comparison with existing state-of-the-art methods to provide a more comprehensive understanding of the benefits of zero-mean regularized spectral contrastive learning.\n4.  The paper should provide more details on the implementation of zero-mean regularized spectral contrastive learning, including the choice of hyperparameters and the architecture of the model.\n\nRecommendation:\n\nThe paper proposes an innovative approach to enhance spectral contrastive learning, which has the potential to improve the robustness and discriminativeness of representations in various tasks. The theoretical analysis and quantitative evaluation provide strong evidence of the benefits of zero-mean regularized spectral contrastive learning. However, further validation on other datasets and a clear comparison with existing state-of-the-art methods are necessary to provide a more comprehensive understanding of the benefits of zero-mean regularized spectral contrastive learning.",
        "gr_score_with": 0.7384105960264901,
        "gr_score_without": 0.6124031007751938,
        "output_without": {
            "num_tokens_scored": 258,
            "num_green_tokens": 158,
            "green_fraction": 0.6124031007751938,
            "z_score": -3.0703574497044035,
            "p_value": 0.998930986398015
        },
        "output_with": {
            "num_tokens_scored": 302,
            "num_green_tokens": 223,
            "green_fraction": 0.7384105960264901,
            "z_score": 1.4566153100469832,
            "p_value": 0.07261129956043448
        }
    },
    {
        "title": "AVERAGE REWARD MARKOV DECISION PROCESSES",
        "abstract": "We resolve the open question regarding the sample complexity of policy learning for maximizing the long-run average reward associated with a uniformly ergodic Markov decision process (MDP), assuming a generative model. In this context, the existing literature provides a sample complexity upper bound of \u00d5(|S||A|tmix\u03b5)* and a lower bound of \u03a9(|S||A|tmix\u03b5). In these expressions, |S| and |A| denote the cardinalities of the state and action spaces respectively, tmix serves as a uniform upper limit for the total variation mixing times, and \u03b5 signifies the error tolerance. Therefore, a notable gap of tmix still remains to be bridged. Our primary contribution is the development of an estimator for the optimal policy of average reward MDPs with a sample complexity of \u00d5(|S||A|tmix\u03b5). This marks the first algorithm and analysis to reach the literature\u2019s lower bound. Our new algorithm draws inspiration from ideas in Li et al. (2020), Jin & Sidford (2021), and Wang et al. (2023). Additionally, we conduct numerical experiments to validate our theoretical findings.",
        "peer_review_without_watermark": "$$\\boxed{\\text{Paper Summary:}$$\n\nThe paper presents a theoretical contribution to the area of reinforcement learning by providing the first provably optimal sample complexity guarantee for a tabular RL environment in which a controller wishes to maximize the long run average reward governed by a Markov decision process (MDP). The authors develop an estimator for the optimal policy of average reward MDPs with a sample complexity of $\\Theta(|S||A|tminizetmixin)$, which marks the first algorithm and analysis to reach the literature's lower bound. The authors also conduct numerical experiments to validate their theoretical findings.\n\n$$\\boxed{\\text{Strengths:}}$$\n\n1. The paper provides a significant theoretical contribution to the area of reinforcement learning by establishing a provably optimal sample complexity guarantee for a tabular RL environment.\n2. The authors develop an estimator for the optimal policy of average reward MDPs with a sample complexity of $\\Theta(|S||A|tminizetmixin)$, which marks the first algorithm and analysis to reach the literature's lower bound.\n3. The paper presents numerical experiments to validate the theoretical findings, providing empirical evidence for the proposed algorithm.\n\n$$\\boxed{\\text{Weaknesses:}}$$\n\n1. The paper assumes a strong form of MDP mixing known as uniform ergodicity, which may be conservative and not applicable to all scenarios.\n2. The analysis relies on the assumption of a finite state and action space, which may not be suitable for all applications.\n3. The paper does not provide a clear comparison with existing algorithms and methods, making it difficult to evaluate the proposed algorithm's performance.\n\n$$\\boxed{\\text{Suggestions for Improvement:}}$$\n\n1. The authors should consider relaxing the assumption of uniform ergodicity and exploring alternative mixing conditions that can be more widely applicable.\n2. The analysis should be extended to accommodate more general state and action spaces, making the algorithm more suitable for a broader range of applications.\n3. The paper should provide a clear comparison with existing algorithms and methods, highlighting the strengths and weaknesses of the proposed algorithm.\n\n$$\\boxed{\\text{Recommendation:}}$$\n\nBased on the paper's contributions, strengths, and weaknesses, I recommend that the authors revise and resubmit the paper for further review. Specifically, I suggest that they address the limitations and criticisms raised in this review and provide a more comprehensive analysis that can be applied to a wider range of applications.",
        "peer_review_with_watermark": "$$$$\nThe paper proposes an algorithm for learning an optimal policy in uniformly ergodic Markov Decision Processes (MDPs) with a sample complexity of \u0398(|S||A|tmix\u03b5), which is the first algorithm and analysis to reach the literature\u2019s lower bound. The authors also provide numerical experiments to validate their theoretical findings.\n\nStrengths:\n1. The authors provide a clear and concise introduction to the problem and their approach.\n2. The literature review is thorough and provides a good overview of the current state of the art in sample complexity of average reward RL.\n3. The authors provide a detailed analysis of the algorithm and its sample complexity.\n\nWeaknesses:\n1. The authors do not provide a clear explanation of the assumptions made in their analysis, such as the assumption of uniform ergodicity and the use of the minorization time tminorize.\n2. The authors do not provide a clear comparison of their algorithm with other existing algorithms in the literature.\n3. The numerical experiments are limited and do not provide a comprehensive evaluation of the algorithm.\n\nSuggestions for Improvement:\n1. Provide a more detailed explanation of the assumptions made in the analysis, including their implications and limitations.\n2. Provide a clear comparison of the algorithm with other existing algorithms in the literature, including their strengths and weaknesses.\n3. Include more detailed numerical experiments to evaluate the algorithm's performance in different scenarios.\n\nRecommendation:\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit their manuscript. The authors should provide a more detailed explanation of their assumptions and provide a clear comparison with existing algorithms in the literature. The numerical experiments should be more comprehensive and detailed.\n\n$$$$",
        "gr_score_with": 0.7375,
        "gr_score_without": 0.6790123456790124,
        "output_without": {
            "num_tokens_scored": 324,
            "num_green_tokens": 220,
            "green_fraction": 0.6790123456790124,
            "z_score": -0.8243786964470803,
            "p_value": 0.7951377921573426
        },
        "output_with": {
            "num_tokens_scored": 240,
            "num_green_tokens": 177,
            "green_fraction": 0.7375,
            "z_score": 1.267731382092775,
            "p_value": 0.10244694690818934
        }
    },
    {
        "title": "FANTASTIC GENERALIZATION MEASURES",
        "abstract": "We study the notion of a generalization bound being uniformly tight, meaning that the difference between the bound and the population loss is small for all learning algorithms and all population distributions. Numerous generalization bounds have been proposed in the literature as potential explanations for the ability of neural networks to generalize in the overparameterized setting. However, in their paper \u201cFantastic Generalization Measures and Where to Find Them,\u201d Jiang et al. (2020) examine more than a dozen generalization bounds, and show empirically that none of them are uniformly tight. This raises the question of whether uniformly-tight generalization bounds are at all possible in the overparameterized setting. We consider two types of generalization bounds: (1) bounds that may depend on the training set and the learned hypothesis (e.g., margin bounds). We prove mathematically that no such bound can be uniformly tight in the overparameterized setting; (2) bounds that may in addition also depend on the learning algorithm (e.g., stability bounds). For these bounds, we show a trade-off between the algorithm\u2019s performance and the bound\u2019s tightness. Namely, if the algorithm achieves good accuracy on certain distributions, then no generalization bound can be uniformly tight for it in the overparameterized setting. We explain how these formal results can, in our view, inform research on generalization bounds for neural networks, while stressing that other interpretations of these results are also possible.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary: \nThe paper examines the notion of uniformly tight generalization bounds, which imply that the difference between the bound and the population loss is small for all learning algorithms and all population distributions. The authors prove that no hypothesis class is estimable in the overparameterized setting, which implies that no generalization bound can be uniformly tight. They also show that there is a trade-off between learning performance and estimability.\n\nStrengths:\n- The paper provides a rigorous mathematical analysis of generalization bounds and their limitations in the overparameterized setting.\n- The authors introduce the concept of estimability, which is a useful framework for understanding the limitations of generalization bounds.\n- The paper highlights the importance of explicitly stating assumptions underlying generalization bounds to ensure their uniform tightness.\n\nWeaknesses:\n- The paper assumes a certain level of technical background in machine learning and learning theory, which may make it difficult for non-experts to follow.\n- The authors use a number of technical definitions and notations, which may require careful attention to detail to understand.\n- The paper focuses primarily on the theoretical implications of the results, which may not be directly applicable to practical scenarios.\n\nSuggestions for Improvement:\n- The authors could provide more context and background information on the importance of generalization bounds and their limitations in the overparameterized setting.\n- The paper could benefit from more detailed explanations of technical concepts and definitions, particularly for non-experts.\n- The authors could explore potential implications of the results for practical applications, such as neural networks and machine learning algorithms.\n\nRecommendation:\n- The paper is well-written and provides a rigorous mathematical analysis of generalization bounds.\n- The results are important and have significant implications for the field of machine learning and learning theory.\n- The authors could benefit from providing more context and background information, as well as more detailed explanations of technical concepts.\n- The paper is recommended for publication in a top-tier conference or journal in the field of machine learning and learning theory.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$\\text{Paper Summary:}$ \nThe paper studies the notion of a generalization bound being uniformly tight, which means that the difference between the bound and the population loss is small for all learning algorithms and all population distributions. The authors consider two types of generalization bounds: distribution- and algorithm-independent bounds, and distribution- and algorithm-dependent bounds. They prove that no distribution- and algorithm-independent bound can be uniformly tight in the overparameterized setting, and they show a trade-off between the performance of a learning algorithm and the estimability of a hypothesis class. \n\n$\\text{Strengths:}$ \nThe paper is well-written and provides a clear explanation of the concepts and the results. The authors provide a thorough analysis of the limitations of generalization bounds in the overparameterized setting. The paper is well-structured and easy to follow, and the definitions are clearly explained. \n\n$\\text{Weaknesses:}$ \nThe paper could benefit from more empirical evidence to support the theoretical results. The authors mention that many published generalization bounds are not tight, but they do not provide a detailed analysis of the empirical results. The paper could also benefit from more discussion on the implications of the results for the practice of deep learning. \n\n$\\text{Suggestions for Improvement:}$ \nThe paper could benefit from more empirical evidence to support the theoretical results. The authors could also explore the implications of the results for the practice of deep learning. \n\n$\\text{Recommendation:}$ \nThe paper is well-written and provides a clear explanation of the concepts and the results. The authors provide a thorough analysis of the limitations of generalization bounds in the overparameterized setting. The paper is well-structured and easy to follow. Based on the technical quality and clarity of the paper, we recommend its publication in a top-tier conference or journal in the field of machine learning. \n\n$$",
        "gr_score_with": 0.7543859649122807,
        "gr_score_without": 0.701067615658363,
        "output_without": {
            "num_tokens_scored": 281,
            "num_green_tokens": 197,
            "green_fraction": 0.701067615658363,
            "z_score": 0.03905336382737033,
            "p_value": 0.48442392142686636
        },
        "output_with": {
            "num_tokens_scored": 228,
            "num_green_tokens": 172,
            "green_fraction": 0.7543859649122807,
            "z_score": 1.7920272703498488,
            "p_value": 0.03656429890255153
        }
    },
    {
        "title": "DIFFUSIONNAG: PREDICTOR-GUIDED NEURAL ARCHI-",
        "abstract": "Existing NAS methods suffer from either an excessive amount of time for repetitive sampling and training of many task-irrelevant architectures. To tackle such limitations of existing NAS methods, we propose a paradigm shift from NAS to a novel conditional Neural Architecture Generation (NAG) framework based on diffusion models, dubbed DiffusionNAG. Specifically, we consider the neural architectures as directed graphs and propose a graph diffusion model for generating them. Moreover, with the guidance of parameterized predictors, DiffusionNAG can flexibly generate task-optimal architectures with the desired properties for diverse tasks, by sampling from a region that is more likely to satisfy the properties. This conditional NAG scheme is significantly more efficient than previous NAS schemes which sample the architectures and filter them using the property predictors. We validate the effectiveness of DiffusionNAG through extensive experiments in two predictor-based NAS scenarios: Transferable NAS and Bayesian Optimization (BO)-based NAS. DiffusionNAG achieves superior performance with speedups of up to 20\u00d7 when compared to the baselines on Transferable NAS benchmarks. Furthermore, when integrated into a BO-based algorithm, DiffusionNAG outperforms existing BO-based NAS approaches, particularly in the large MobileNetV3 search space on the ImageNet 1K dataset.",
        "peer_review_without_watermark": "$$$\\begin{align}\\textbf{Paper Summary:}~\\\\ \nThe paper proposes a novel approach called DiffusionNAG, which is a paradigm shift from existing Neural Architecture Search (NAS) methods. It introduces a conditional diffusion-based generative framework tailored for generating architectures represented as directed acyclic graphs that meet specified conditions, such as accuracy requirements. The framework leverages a meta-learned dataset-aware predictor to guide the generation process. The authors demonstrate the effectiveness of DiffusionNAG on two predictor-based NAS scenarios: Transferable NAS and BO-based NAS.\n\n\\textbf{Strengths:}~\\\\ \n1. DiffusionNAG offers several advantages compared with conventional NAS methods, including efficient and effective search, superior utilization of predictors for both NAG and evaluation purposes, and easy adaptability across diverse tasks.\n2. The proposed score network ensures the generation of valid architectures by capturing the positional information of nodes in directed acyclic graphs.\n3. The authors demonstrate the effectiveness of DiffusionNAG on extensive experiments, achieving significant acceleration and improved search performance in Transferable NAS and BO-based NAS scenarios.\n\n\\textbf{Weaknesses:}~\\\\ \n1. The paper does not provide a detailed analysis of the performance of DiffusionNAG on smaller search spaces.\n2. The authors do not discuss the potential limitations of using a meta-learned dataset-aware predictor, such as overfitting or bias towards specific datasets.\n3. The score network is not thoroughly evaluated, and its performance is not compared with other state-of-the-art methods.\n\n\\textbf{Suggestions for Improvement:}~\\\\ \n1. Perform a detailed analysis of the performance of DiffusionNAG on smaller search spaces to evaluate its scalability.\n2. Investigate the potential limitations of using a meta-learned dataset-aware predictor and propose methods to mitigate these limitations.\n3. Thoroughly evaluate the performance of the score network and compare it with other state-of-the-art methods.\n\n\\textbf{Recommendation:}~\\\\ \nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit their manuscript. The authors should address the limitations and provide a more detailed analysis of the performance of DiffusionNAG on smaller search spaces and with other state-of-the-art methods. Additionally, they should investigate the potential limitations of using a meta-learned dataset-aware predictor and propose methods to mitigate these limitations.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$Paper Summary: \nThe paper proposes a novel approach called DiffusionNAG, which is a paradigm shift from existing Neural Architecture Search (NAS) methods. DiffusionNAG utilizes a conditional generative model to generate architectures satisfying specific objectives, guided by a meta-learned dataset-aware predictor. The score network is used to ensure the generation of valid architectures. The authors demonstrate the effectiveness of DiffusionNAG on two predictor-based NAS scenarios: Transferable NAS and BO-based NAS.\n\n$$Strengths: \n1. The paper introduces a novel approach, DiffusionNAG, which can efficiently generate task-optimal architectures.\n2. The use of a meta-learned dataset-aware predictor facilitates efficient search by generating architectures that satisfy specific objectives.\n3. The score network ensures the generation of valid architectures.\n4. The authors demonstrate the effectiveness of DiffusionNAG on two predictor-based NAS scenarios.\n\n$$Weaknesses: \n1. The paper lacks a detailed analysis of the performance of DiffusionNAG on smaller search spaces.\n2. The authors do not discuss the potential limitations of DiffusionNAG, such as the need for a large amount of training data for the predictor.\n3. The score network is not thoroughly analyzed, and its performance is not compared to existing graph diffusion models.\n\n$$Suggestions for Improvement: \n1. The authors should analyze the performance of DiffusionNAG on smaller search spaces to demonstrate its effectiveness.\n2. The authors should discuss potential limitations of DiffusionNAG, such as the need for a large amount of training data for the predictor.\n3. The authors should thoroughly analyze the score network and compare its performance to existing graph diffusion models.\n\n$$Recommendation: \nBased on the strengths and weaknesses of the paper, I recommend accepting the paper for publication. However, I suggest that the authors address the weaknesses and suggestions for improvement to strengthen their paper. The authors have made a valuable contribution to the field of NAS, and their approach has the potential to improve the efficiency of NAS. With some revisions, the paper can be improved to make a stronger impact on the field.",
        "gr_score_with": 0.7915194346289752,
        "gr_score_without": 0.6962025316455697,
        "output_without": {
            "num_tokens_scored": 316,
            "num_green_tokens": 220,
            "green_fraction": 0.6962025316455697,
            "z_score": -0.1473085848420695,
            "p_value": 0.5585557716606703
        },
        "output_with": {
            "num_tokens_scored": 283,
            "num_green_tokens": 224,
            "green_fraction": 0.7915194346289752,
            "z_score": 3.3596721473342632,
            "p_value": 0.0003901750871023696
        }
    },
    {
        "title": "FUNCTIONAL INTERPOLATION FOR RELATIVE POSI-",
        "abstract": "Preventing the performance decay of Transformers on inputs longer than those used for training has been an important challenge in extending the context length of these models. Though the Transformer architecture has fundamentally no limits on the input sequence lengths it can process, the choice of position encoding used during training can limit the performance of these models on longer inputs. We propose a novel functional relative position encoding with progressive interpolation, FIRE, to improve Transformer generalization to longer contexts. We theoretically prove that this can represent some of the popular relative position encodings, such as T5\u2019s RPE, Alibi, and Kerple. We next empirically show that FIRE models have better generalization to longer contexts on both zero-shot language modeling and long text benchmarks.",
        "peer_review_without_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes a novel functional relative position encoding method, FIRE, to improve the length generalization of Transformers. FIRE uses a learnable function to map input positions to biases, and a progressive interpolation technique to ensure bounded input for the position encoding function. The authors theoretically prove that FIRE can represent popular relative position encodings and empirically show that it has strong length generalization behavior on various benchmarks.\n\nStrengths:\n1. The paper presents a novel and effective method for improving length generalization of Transformers.\n2. The authors provide a detailed theoretical analysis of the proposed method and its ability to represent popular relative position encodings.\n3. The empirical results show strong length generalization behavior on various benchmarks.\n\nWeaknesses:\n1. The paper only studies decoder models and does not analyze the role of other components of Transformer and other training components in length generalization.\n2. The authors do not provide a comprehensive comparison with all existing methods for relative position encoding.\n\nSuggestions for Improvement:\n1. The authors should extend their study to encoder models and analyze the role of other components of Transformer in length generalization.\n2. A more comprehensive comparison with existing methods for relative position encoding should be provided.\n\nRecommendation:\nThe paper presents a novel and effective method for improving length generalization of Transformers. While there are some limitations, the authors provide a detailed theoretical analysis and empirical results that demonstrate the effectiveness of FIRE. With some extensions to encoder models and other components of Transformer, the paper has the potential to make a significant contribution to the field of natural language processing.",
        "peer_review_with_watermark": "$$$\n\n\nPaper Summary:\nThe paper proposes a novel functional interpolation for relative position encoding (FIRE) to improve the generalization of Transformer models to longer contexts. FIRE uses a learnable function to map input positions to biases, and incorporates a progressive interpolation technique to ensure bounded input for the position encoding function for all input sequence lengths. The authors theoretically prove that FIRE can represent popular relative position encodings, such as T5's RPE, Alibi, and Kerple, and empirically show that FIRE models have better generalization to longer contexts on various benchmarks.\n\n\nStrengths:\n1. The paper introduces a new approach to relative position encoding, FIRE, which uses a functional interpolation technique to ensure bounded input for the position encoding function.\n2. The authors theoretically prove that FIRE can represent popular relative position encodings, providing a solid foundation for the proposed method.\n3. Empirical results show strong length generalization behavior for FIRE models on various benchmarks.\n4. The paper highlights the importance of length generalization in Transformer models and provides a detailed review of existing methods.\n\n\nWeaknesses:\n1. The paper primarily focuses on decoder-only models, leaving the analysis of the role of other components of the Transformer model, such as the encoder, and other training components, like data and optimizer, in length generalization.\n2. Some limitations are mentioned, but not fully explored, such as the lack of analysis on the effectiveness of FIRE for other natural language processing tasks beyond language modeling.\n3. While the authors mention the importance of computational efficiency, the comparison with other methods in terms of speed is limited.\n\n\nSuggestions for Improvement:\n1. Expand the analysis to include encoder-only models to better understand the role of both encoder and decoder in length generalization.\n2. Investigate the effectiveness of FIRE on other natural language processing tasks, such as question answering, text classification, and sentiment analysis.\n3. Perform a more comprehensive comparison with other methods in terms of speed to better evaluate the computational efficiency of FIRE.\n\n\nRecommendation:\nThe proposed FIRE method shows strong length generalization behavior on various benchmarks, providing a significant contribution to the field of natural language processing. While some limitations are mentioned, the authors provide a solid theoretical foundation for the proposed method, and empirical results demonstrate its effectiveness. Further exploration of the role of other components of the Transformer model, the effectiveness on other tasks, and a more comprehensive comparison with other methods will provide a more complete understanding of FIRE's capabilities.\n\n\nThe final answer is: $\\boxed{8/10}$",
        "gr_score_with": 0.7790368271954674,
        "gr_score_without": 0.6936936936936937,
        "output_without": {
            "num_tokens_scored": 222,
            "num_green_tokens": 154,
            "green_fraction": 0.6936936936936937,
            "z_score": -0.2050415617430785,
            "p_value": 0.5812301733870135
        },
        "output_with": {
            "num_tokens_scored": 353,
            "num_green_tokens": 275,
            "green_fraction": 0.7790368271954674,
            "z_score": 3.2404640164154785,
            "p_value": 0.0005966766639156643
        }
    },
    {
        "title": "BEYOND SPATIO-TEMPORAL REPRESENTATIONS: EVOLVING FOURIER TRANSFORM FOR TEMPORAL GRAPHS",
        "abstract": "We present the Evolving Graph Fourier Transform (EFT), the first invertible spectral transform that captures evolving representations on temporal graphs. We motivate our work by the inadequacy of existing methods for capturing the evolving graph spectra, which are also computationally expensive due to the temporal aspect along with the graph vertex domain. We view the problem as an optimization over the Laplacian of the continuous time dynamic graph. Additionally, we propose pseudo-spectrum relaxations that decompose the transformation process, making it highly computationally efficient. The EFT method adeptly captures the evolving graph\u2019s structural and positional properties, making it effective for downstream tasks on evolving graphs. Hence, as a reference implementation, we develop a simple neural model induced with EFT for capturing evolving graph spectra. We empirically validate our theoretical findings on a number of large-scale and standard temporal graph benchmarks and demonstrate that our model achieves state-of-the-art performance.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$\\text{Paper Summary:}$$\nThe authors propose a novel transform called Evolving Graph Fourier Transform (EFT) for temporal graphs. EFT is designed to capture evolving representations on temporal graphs and is grounded on theoretical foundations. The authors show that EFT is computationally efficient and can capture the evolving graph's structural and positional properties. They also demonstrate the effectiveness of EFT on large-scale and standard temporal graph benchmarks.\n\n$$\\text{Strengths:}$$\n1. The authors provide a comprehensive theoretical framework for EFT, which is grounded on the variational characterization of dynamic graphs.\n2. The authors demonstrate the effectiveness of EFT on large-scale and standard temporal graph benchmarks.\n3. The authors propose a novel approach to transform temporal graphs into the frequency domain.\n\n$$\\text{Weaknesses:}$$\n1. The authors do not consider generic signed and directed graphs, which is a limitation of the current work.\n2. The authors rely on pseudospectrum relaxations, which may not be the optimal solution.\n3. The authors do not provide a clear comparison with existing methods.\n\n$$\\text{Suggestions for Improvement:}$$\n1. Consider generalizing the Laplacian and the resulting transform to signed and directed graphs.\n2. Provide a clear comparison with existing methods, such as spectral GNNs and temporal graph neural networks.\n3. Investigate the optimality of pseudospectrum relaxations.\n\n$$\\text{Recommendation:}$$\nThe authors have made a significant contribution to the field of graph neural networks and temporal graphs. Their work on EFT provides a novel approach to transform temporal graphs into the frequency domain and captures evolving representations on temporal graphs. However, there are areas for improvement, such as considering generic signed and directed graphs and providing a clear comparison with existing methods. Overall, the work has the potential to impact the field of graph neural networks and temporal graphs, and the authors should continue to explore and improve their approach.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n\\text{Paper Summary:} \n\\text{ The paper proposes a novel approach, called Evolving Graph Fourier Transform (EFT), for transforming temporal graphs into their frequency domain. It aims to capture evolving spectra of temporal graphs and is grounded on theoretical foundations. The proposed method is based on pseudospectrum relaxations and is computationally efficient for real-world applications. The paper presents a detailed theoretical framework, including the variational characterization of the dynamic graph and the optimization problem for the evolving graph Fourier transform. It also discusses the properties of the proposed transform, including its ability to capture high-frequency components and its bounded error with respect to the exact solution. The paper presents experimental results demonstrating the effectiveness of EFT for various tasks, including link prediction and node classification on temporal graphs. \n\n\\text{Strengths:}\n\\text{ The paper presents a novel and theoretically grounded approach for transforming temporal graphs into their frequency domain. It provides a detailed theoretical framework and discusses the properties of the proposed transform. The experimental results demonstrate the effectiveness of EFT for various tasks. The paper is well-organized and easy to follow. \n\n\\text{Weaknesses:}\n\\text{ The paper assumes a level of background knowledge in spectral graph theory and graph neural networks, which may make it difficult for non-experts to follow. The paper does not discuss the generalization of EFT to signed and directed graphs, which is a limitation of the current approach. The paper presents a detailed theoretical framework, but the proofs and derivations may be lengthy and technical. \n\n\\text{Suggestions for Improvement:}\n\\text{ The paper could benefit from a more detailed discussion of the generalization of EFT to signed and directed graphs. The paper could also benefit from a more thorough discussion of the limitations of the current approach and potential future directions. The paper could also benefit from more detailed proofs and derivations of the theoretical framework. \n\n\\text{Recommendation:}\n\\text{ Based on the paper's technical merits and potential impact, I recommend its acceptance for publication in a top-tier conference or journal in the field of graph theory and graph neural networks. However, I would suggest that the authors address the limitations of the current approach and potential future directions in future work. \n\n}$$",
        "gr_score_with": 0.8161290322580645,
        "gr_score_without": 0.7083333333333334,
        "output_without": {
            "num_tokens_scored": 264,
            "num_green_tokens": 187,
            "green_fraction": 0.7083333333333334,
            "z_score": 0.29546842014264174,
            "p_value": 0.38381803654700014
        },
        "output_with": {
            "num_tokens_scored": 310,
            "num_green_tokens": 253,
            "green_fraction": 0.8161290322580645,
            "z_score": 4.4618195953425195,
            "p_value": 4.063331505522008e-06
        }
    },
    {
        "title": "LIPSCHITZ SINGULARITIES IN DIFFUSION MODELS",
        "abstract": "Diffusion models, which employ stochastic differential equations to sample images through integrals, have emerged as a dominant class of generative models. However, the rationality of the diffusion process itself receives limited attention, leaving the question of whether the problem is well-posed and well-conditioned. In this paper, we explore a perplexing tendency of diffusion models: they often display the infinite Lipschitz property of the network with respect to time variable near the zero point. We provide theoretical proofs to illustrate the presence of infinite Lipschitz constants and empirical results to confirm it. The Lipschitz singularities pose a threat to the stability and accuracy during both the training and inference processes of diffusion models. Therefore, the mitigation of Lipschitz singularities holds great potential for enhancing the performance of diffusion models. To address this challenge, we propose a novel approach, dubbed E-TSDM, which alleviates the Lipschitz singularities of the diffusion model near the zero point of timesteps. Remarkably, our technique yields a substantial improvement in performance. Moreover, as a byproduct of our method, we achieve a dramatic reduction in the Fr\u00e9chet Inception Distance of acceleration methods relying on network Lipschitz, including DDIM and DPM-Solver, by over 33%. Extensive experiments on diverse datasets validate our theory and method. Our work may advance the understanding of the general diffusion process, and also provide insights for the design of diffusion models.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary: \nThe paper investigates the phenomenon of infinite Lipschitz constants in diffusion models, specifically near the zero point, and proposes a novel approach called Early Timestep-Shared Diffusion Model (E-TSDM) to mitigate this issue. The authors demonstrate that E-TSDM improves the performance of diffusion models in unconditional generation, conditional generation, and fast sampling tasks.\n\nStrengths: \n1. The paper provides a thorough analysis of the infinite Lipschitz constants issue in diffusion models, which is a critical research gap in the field.\n2. The authors propose a novel approach, E-TSDM, which is effective in mitigating the Lipschitz singularities issue.\n3. The experimental results demonstrate the superiority of E-TSDM in various applications, including unconditional generation, conditional generation, and fast sampling.\n\nWeaknesses: \n1. The paper assumes that the reader is familiar with the basics of diffusion models and stochastic differential equations, which may not be the case for all readers.\n2. The mathematical derivations in the paper are not explicitly provided, which may make it difficult for readers to follow the proof.\n3. The paper does not provide a comprehensive comparison with other existing methods for mitigating Lipschitz singularities.\n\nSuggestions for Improvement: \n1. Provide a more detailed introduction to diffusion models and stochastic differential equations to help readers who are not familiar with the basics.\n2. Include explicit mathematical derivations for the theoretical proofs to make the paper more accessible to a broader audience.\n3. Conduct a more comprehensive comparison with existing methods for mitigating Lipschitz singularities to provide a more complete picture of the state-of-the-art.\n\nRecommendation: \nBased on the strengths and weaknesses of the paper, I recommend it for publication in a reputable conference or journal in the field of machine learning or computer science. The authors have made a significant contribution to the field by proposing a novel approach to mitigate the Lipschitz singularities issue in diffusion models, and the experimental results demonstrate its effectiveness. However, the paper could benefit from additional improvements to make it more accessible to a broader audience.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper presents a study on the issue of infinite Lipschitz constants in diffusion models, particularly in noise prediction and v-prediction models, which are widely adopted in image synthesis tasks. The authors demonstrate theoretically and empirically that diffusion models suffer from infinite Lipschitz constants near the zero point, which poses a threat to the stability and accuracy of the diffusion process. To address this challenge, a novel approach called Early Timestep-shared Diffusion Model (E-TSDM) is proposed, which alleviates the Lipschitz singularities by sharing timestep conditions in the interval with large Lipschitz constants. The authors evaluate E-TSDM on various datasets and demonstrate its superiority over baseline models in terms of performance and adaptability.\n\nStrengths:\n1. The paper presents a clear and concise introduction to the problem of infinite Lipschitz constants in diffusion models.\n2. The authors provide a thorough theoretical analysis of the issue, which is supported by empirical results.\n3. The proposed approach of E-TSDM is well-explained, and its effectiveness is demonstrated through extensive experiments.\n4. The paper provides a comprehensive comparison with baseline models and other potential methods to address the challenge of large Lipschitz constants.\n\nWeaknesses:\n1. The paper does not provide a detailed discussion of the limitations of the proposed approach, such as its potential to lead to decreased effectiveness in large-scale generative models.\n2. The authors assume that the reduction of Lipschitz constants to zero within each sub-interval in E-TSDM may not introduce unknown effects, which is not explicitly justified.\n3. The paper does not provide a comparison with other state-of-the-art models in image synthesis, which could provide a more comprehensive evaluation of E-TSDM.\n\nSuggestions for Improvement:\n1. The authors should provide a more detailed discussion of the limitations of E-TSDM and potential risks associated with its use in large-scale generative models.\n2. The authors should provide a more rigorous justification for the assumption that the reduction of Lipschitz constants to zero within each sub-interval in E-TSDM does not introduce unknown effects.\n3. The authors should include a comparison with other state-of-the-art models in image synthesis to provide a more comprehensive evaluation of E-TSDM.\n\nRecommendation:\nThe paper presents a significant contribution to the field of image synthesis, particularly in addressing the challenge of infinite Lipschitz constants in diffusion models. The proposed approach of E-TSDM is effective and well-explained, and its superiority over baseline models is demonstrated through extensive experiments. However, the authors should address the limitations and potential risks associated with E-TSDM to provide a more comprehensive evaluation of its effectiveness.\n\nRating: 8/10\n\n$$$",
        "gr_score_with": 0.8108108108108109,
        "gr_score_without": 0.7368421052631579,
        "output_without": {
            "num_tokens_scored": 304,
            "num_green_tokens": 224,
            "green_fraction": 0.7368421052631579,
            "z_score": 1.401753288100927,
            "p_value": 0.08049446590625703
        },
        "output_with": {
            "num_tokens_scored": 333,
            "num_green_tokens": 270,
            "green_fraction": 0.8108108108108109,
            "z_score": 4.412600420505178,
            "p_value": 5.106819746105964e-06
        }
    },
    {
        "title": "UNKNOWN DOMAIN INCONSISTENCY MINIMIZATION FOR DOMAIN GENERALIZATION",
        "abstract": "The objective of domain generalization (DG) is to enhance the transferability of the model learned from a source domain to unobserved domains. To prevent overfitting to a specific domain, Sharpness-Aware Minimization (SAM) reduces source domain\u2019s loss sharpness. Although SAM variants have delivered significant improvements in DG, we highlight that there\u2019s still potential for improvement in generalizing to unknown domains through the exploration on data space. This paper introduces an objective rooted in both parameter and data perturbed regions for domain generalization, coined Unknown Domain Inconsistency Minimization (UDIM). UDIM reduces the loss landscape inconsistency between source domain and unknown domains. As unknown domains are inaccessible, these domains are empirically crafted by perturbing instances from the source domain dataset. In particular, by aligning the loss landscape acquired in the source domain to the loss landscape of perturbed domains, we expect to achieve generalization grounded on these flat minima for the unknown domains. Theoretically, we validate that merging SAM optimization with the UDIM objective establishes an upper bound for the true objective of the DG task. In an empirical aspect, UDIM consistently outperforms SAM variants across multiple DG benchmark datasets. Notably, UDIM shows statistically significant improvements in scenarios with more restrictive domain information, underscoring UDIM\u2019s generalization capability in unseen domains. Our code is available at https://github.com/SJShin-AI/UDIM.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$\\text{Paper Summary:}$$\nThe paper proposes a novel approach to domain generalization, called Unknown Domain Inconsistency Minimization (UDIM), which minimizes the discrepancy in the loss landscape between the source domain and unobserved domains. UDIM combines sharpness-aware minimization (SAM) with data perturbation to improve generalization performance on unobserved domains. The authors provide a theoretical analysis of UDIM and demonstrate its effectiveness on multiple benchmark datasets.\n\n$$\\begin{aligned}\n$$\\text{Strengths:}$$\n- UDIM effectively minimizes the discrepancy in the loss landscape between the source domain and unobserved domains.\n- The authors provide a theoretical analysis of UDIM and demonstrate its effectiveness on multiple benchmark datasets.\n- The paper introduces a novel approach to domain generalization, which combines sharpness-aware minimization and data perturbation.\n\n$$\\begin{aligned}\n$$\\text{Weaknesses:}$$\n- The paper does not provide a clear comparison with existing state-of-the-art methods.\n- The authors assume that the perturbation of the data space is feasible, which may not be the case in all scenarios.\n- The paper does not discuss the potential risks or limitations of UDIM.\n\n$$\\begin{aligned}\n$$\\text{Suggestions for Improvement:}$$\n- The authors should provide a more detailed comparison with existing state-of-the-art methods.\n- The authors should discuss the potential risks or limitations of UDIM and provide strategies for mitigating them.\n- The authors should provide more experimental results to demonstrate the effectiveness of UDIM on different benchmark datasets.\n\n$$\\begin{aligned}\n$$\\text{Recommendation:}$$\nBased on the paper summary, strengths, weaknesses, and suggestions for improvement, I recommend that the authors revise and resubmit the paper. The authors have proposed a novel approach to domain generalization, which has the potential to improve generalization performance on unobserved domains. However, the paper needs more experimental results and a more detailed comparison with existing state-of-the-art methods to demonstrate its effectiveness. Additionally, the authors should discuss the potential risks or limitations of UDIM and provide strategies for mitigating them.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$\\text{Paper Summary:}$$\n\nThe paper proposes a novel approach to domain generalization (DG) called Unknown Domain Inconsistency Minimization (UDIM). The objective of DG is to enhance the transferability of the model learned from a source domain to unobserved domains. The authors introduce a new objective function that leverages both parameter and data perturbed regions for DG. The proposed approach minimizes the loss landscape inconsistency between the source domain and unknown domains.\n\n$$\\begin{aligned}\n$$\\text{Strengths:}$$\n\n*   The paper presents a novel approach to DG that considers both parameter and data perturbation.\n*   The authors provide a clear and concise explanation of the theoretical foundation of their approach.\n*   The experimental results show that the proposed approach consistently improves generalization performance on unobserved domains.\n\n$$\\begin{aligned}\n$$\\text{Weaknesses:}$$\n\n*   The paper assumes that the data perturbation is possible and may not be feasible in all scenarios.\n*   The authors do not provide a detailed analysis of the computational complexity of their approach.\n*   The paper relies heavily on empirical results and may not generalize well to other DG tasks.\n\n$$\\begin{aligned}\n$$\\text{Suggestions for Improvement:}$$\n\n*   The authors should provide a more detailed analysis of the theoretical foundation of their approach and its connection to established DG techniques.\n*   The paper should include a more detailed analysis of the computational complexity of the proposed approach.\n*   The authors should provide a more robust evaluation of their approach on different DG tasks and datasets.\n\n$$\\begin{aligned}\n$$\\text{Recommendation:}$$\n\n*   Based on the experimental results and the novelty of the proposed approach, I recommend accepting the paper for publication in a top-tier DG conference.\n*   However, the authors should address the weaknesses and limitations of their approach and provide a more detailed analysis of its theoretical foundation and computational complexity.",
        "gr_score_with": 0.8313253012048193,
        "gr_score_without": 0.7264957264957265,
        "output_without": {
            "num_tokens_scored": 234,
            "num_green_tokens": 170,
            "green_fraction": 0.7264957264957265,
            "z_score": 0.8844516845225558,
            "p_value": 0.18822621656754007
        },
        "output_with": {
            "num_tokens_scored": 249,
            "num_green_tokens": 207,
            "green_fraction": 0.8313253012048193,
            "z_score": 4.522081984365374,
            "p_value": 3.06171659193661e-06
        }
    },
    {
        "title": "SCALING PHYSICS-INFORMED HARD CONSTRAINTS WITH MIXTURE-OF-EXPERTS",
        "abstract": "Imposing known physical constraints, such as conservation laws, during neural network training introduces an inductive bias that can improve accuracy, reliability, convergence, and data efficiency for modeling physical dynamics. While such constraints can be softly imposed via loss function penalties, recent advancements in differentiable physics and optimization improve performance by incorporating PDE-constrained optimization as individual layers in neural networks. This enables a stricter adherence to physical constraints. However, imposing hard constraints significantly increases computational and memory costs, especially for complex dynamical systems. This is because it requires solving an optimization problem over a large number of points in a mesh, representing spatial and temporal discretizations, which greatly increases the complexity of the constraint. To address this challenge, we develop a scalable approach to enforce hard physical constraints using Mixture-of-Experts (MoE), which can be used with any neural network architecture. Our approach imposes the constraint over smaller decomposed domains, each of which is solved by an \u201cexpert\u201d through differentiable optimization. During training, each expert independently performs a localized backpropagation step by leveraging the implicit function theorem; the independence of each expert allows for parallelization across multiple GPUs. Compared to standard differentiable optimization, our scalable approach achieves greater accuracy in the neural PDE solver setting for predicting the dynamics of challenging non-linear systems. We also improve training stability and require significantly less computation time during both training and inference stages.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper presents the Physics-Informed Hard Constraint Mixture-of-Experts (PI-HC-MoE) framework, which aims to scale hard physical constraints in neural networks using a mixture-of-experts approach. The authors propose a novel method to enforce hard physical constraints using a mixture of experts, each solving a localized optimization problem, and show that this approach achieves greater accuracy and efficiency compared to standard differentiable optimization and soft penalty methods.\n\nStrengths:\n\n* The authors provide a clear and concise introduction to the problem, highlighting the importance of scaling hard physical constraints in neural networks.\n* The paper presents a well-structured and easy-to-follow approach to enforcing hard physical constraints using a mixture-of-experts framework.\n* The authors demonstrate the effectiveness of PI-HC-MoE on two challenging non-linear problems, diffusion-sorption and Navier-Stokes equations.\n* The paper provides a detailed analysis of the scalability of PI-HC-MoE compared to standard differentiable optimization.\n\nWeaknesses:\n\n* The paper may benefit from a more detailed explanation of the mixture-of-experts approach and its underlying mathematical principles.\n* The authors assume a certain level of familiarity with neural networks and physical simulations, which may make the paper less accessible to readers without a strong background in these areas.\n* The paper does not provide a comprehensive comparison with other existing methods for enforcing hard physical constraints in neural networks.\n\nSuggestions for Improvement:\n\n* Provide a more detailed explanation of the mixture-of-experts approach and its underlying mathematical principles.\n* Include a more comprehensive comparison with other existing methods for enforcing hard physical constraints in neural networks.\n* Consider adding more visualizations and illustrations to help clarify the mathematical concepts and algorithms presented in the paper.\n\nRecommendation:\n\n* The paper presents a novel and effective approach to scaling hard physical constraints in neural networks, and the authors demonstrate its effectiveness on two challenging non-linear problems.\n* With some revisions to address the weaknesses and suggestions for improvement, the paper has the potential to make a significant contribution to the field of neural networks and physics-informed simulations.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper proposes a scalable approach to enforcing hard physical constraints on neural networks using a Mixture-of-Experts (MoE) framework. The approach, called Physics-Informed Hard Constraint Mixture-of-Experts (PI-HC-MoE), decomposes the constraint into smaller domains, each solved by an \"expert\" through differentiable optimization. The MoE framework allows for parallelization across multiple GPUs and improves training stability. The paper evaluates PI-HC-MoE on two challenging non-linear problems, diffusion-sorption and turbulent Navier-Stokes, and compares its performance to standard differentiable optimization and physics-informed soft constraint methods.\n\nStrengths:\n1. Scalability: The PI-HC-MoE framework is scalable, allowing for parallelization across multiple GPUs and efficient computation of hard constraints.\n2. Training Stability: The MoE setup improves training stability by localizing the constraint and enabling faster convergence.\n3. Flexibility: The PI-HC-MoE framework can express piece-wise linear combinations, allowing for more flexibility in weighting basis functions.\n4. Generalization: The approach can be generalized to unseen timesteps and assess the quality of basis functions.\n\nWeaknesses:\n1. Complexity: The PI-HC-MoE framework may be more complex to implement and understand compared to standard differentiable optimization methods.\n2. Hyperparameter Tuning: The performance of PI-HC-MoE may be sensitive to hyperparameter tuning, such as the number of experts, basis functions, and sampling points.\n3. Computational Cost: The PI-HC-MoE framework may require significant computational resources, especially for large-scale problems.\n\nSuggestions for Improvement:\n1. Provide more detailed explanations of hyperparameter tuning and their impact on performance.\n2. Investigate ways to reduce computational cost while maintaining scalability.\n3. Consider developing more efficient algorithms for computing hard constraints, such as using sparse matrices or more advanced optimization techniques.\n\nRecommendation:\nThe PI-HC-MoE framework is a promising approach to enforcing hard physical constraints on neural networks. Its scalability, training stability, and flexibility make it an attractive option for solving challenging non-linear problems. However, further research is needed to address the complexity and hyperparameter tuning requirements of the framework. With improvements in these areas, PI-HC-MoE has the potential to become a widely adopted method in physics-informed neural networks.",
        "gr_score_with": 0.8535211267605634,
        "gr_score_without": 0.8222996515679443,
        "output_without": {
            "num_tokens_scored": 287,
            "num_green_tokens": 236,
            "green_fraction": 0.8222996515679443,
            "z_score": 4.521229168118127,
            "p_value": 3.0740792052753067e-06
        },
        "output_with": {
            "num_tokens_scored": 355,
            "num_green_tokens": 303,
            "green_fraction": 0.8535211267605634,
            "z_score": 6.31208267208923,
            "p_value": 1.3765254077588735e-10
        }
    },
    {
        "title": "GOAL-CONDITIONED REINFORCEMENT LEARNING",
        "abstract": "Offline Goal-Conditioned Reinforcement Learning (GCRL) is tasked with learning to achieve multiple goals in an environment purely from offline datasets using sparse reward functions. Offline GCRL is pivotal for developing generalist agents capable of leveraging pre-existing datasets to learn diverse and reusable skills without hand-engineering reward functions. However, contemporary approaches to GCRL based on supervised learning and contrastive learning are often suboptimal in the offline setting. An alternative perspective on GCRL optimizes for occupancy matching, but necessitates learning a discriminator, which subsequently serves as a pseudo-reward for downstream RL. Inaccuracies in the learned discriminator can cascade, negatively influencing the resulting policy. We present a novel approach to GCRL under a new lens of mixture-distribution matching, leading to our discriminator-free method: SMORe. The key insight is combining the occupancy matching perspective of GCRL with a convex dual formulation to derive a learning objective that can better leverage suboptimal offline data. SMORe learns scores or unnormalized densities representing the importance of taking an action at a state for reaching a particular goal. SMORe is principled and our extensive experiments on the fully offline GCRL benchmark composed of robot manipulation and locomotion tasks, including high-dimensional observations, show that SMORe can outperform state-of-the-art baselines by a significant margin.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper presents a novel approach to offline goal-conditioned reinforcement learning (GCRL) called SMORe, which combines the occupancy matching perspective with a convex dual formulation. The authors propose a discriminator-free method that learns unnormalized densities representing the importance of taking an action at a state for reaching a particular goal. The approach is designed to leverage suboptimal offline data and is robust to decreasing goal coverage in the offline dataset. The paper presents extensive experiments on the fully offline GCRL benchmark composed of robot manipulation and locomotion tasks, including high-dimensional observations.\n\nStrengths:\n\n* The authors present a novel approach to offline GCRL that combines occupancy matching with a convex dual formulation.\n* The approach is discriminator-free, which makes it more robust to decreasing goal coverage in the offline dataset.\n* The paper presents extensive experiments on the fully offline GCRL benchmark, which demonstrates the effectiveness of the proposed method.\n\nWeaknesses:\n\n* The paper does not provide a clear comparison to existing methods in the offline GCRL setting.\n* The authors assume that the goal-transition distribution is uniform, which may not be the case in practice.\n* The paper does not provide a detailed analysis of the convergence properties of the proposed method.\n\nSuggestions for Improvement:\n\n* The authors should provide a more detailed comparison to existing methods in the offline GCRL setting.\n* The authors should analyze the convergence properties of the proposed method and provide a theoretical guarantee of its convergence.\n* The authors should provide a more detailed analysis of the assumption that the goal-transition distribution is uniform.\n\nRecommendation:\n\n* The proposed method, SMORe, is a significant contribution to the field of offline GCRL and has the potential to be widely adopted.\n* However, the authors should address the weaknesses and suggestions for improvement mentioned above to further strengthen the paper.\n* The paper should be revised to provide a more detailed comparison to existing methods, a more detailed analysis of the convergence properties, and a more detailed analysis of the assumption that the goal-transition distribution is uniform.",
        "peer_review_with_watermark": "$$$Paper Summary:\n\nThis paper presents SMORe, a novel approach to offline goal-conditioned reinforcement learning (GCRL). SMORe formulates GCRL as an occupancy matching problem and leverages convex dual formulation to derive a learning objective that can better leverage suboptimal offline data. The method learns unnormalized scores or densities representing the importance of taking an action at a state to reach a particular goal. The authors extensively experiment with SMORe on the fully offline GCRL benchmark composed of robot manipulation and locomotion tasks, showing that SMORe outperforms state-of-the-art baselines by a significant margin.\n\nStrengths:\n\n1.  The authors provide a clear and concise introduction to the offline GCRL problem and its challenges.\n2.  The occupancy matching approach is well-explained, and the use of convex dual formulation is innovative.\n3.  The authors provide extensive experimental results, showcasing the effectiveness of SMORe on various benchmarks.\n4.  The paper discusses the limitations of existing methods, including the use of discriminators and the challenges of learning normalized densities.\n\nWeaknesses:\n\n1.  The paper could benefit from more detailed explanations of the convex dual formulation and its implications.\n2.  Some sections, such as the discussion of the limitations of existing methods, feel a bit superficial.\n3.  The paper does not provide a detailed analysis of the theoretical guarantees provided by the occupancy matching approach.\n\nSuggestions for Improvement:\n\n1.  Provide more detailed explanations of the convex dual formulation and its implications.\n2.  Conduct a more in-depth analysis of the theoretical guarantees provided by the occupancy matching approach.\n3.  Add more visualizations to the experimental results to facilitate understanding.\n\nRecommendation:\n\nI recommend accepting the paper as it is, with the above suggestions in mind. The authors have made significant contributions to the offline GCRL problem, and their approach has shown promising results in experiments. With further refinement and analysis, the paper could become an even stronger contribution to the field.\n\n$$$",
        "gr_score_with": 0.7664473684210527,
        "gr_score_without": 0.6941176470588235,
        "output_without": {
            "num_tokens_scored": 255,
            "num_green_tokens": 177,
            "green_fraction": 0.6941176470588235,
            "z_score": -0.20498001542269692,
            "p_value": 0.5812061305570141
        },
        "output_with": {
            "num_tokens_scored": 304,
            "num_green_tokens": 233,
            "green_fraction": 0.7664473684210527,
            "z_score": 2.5281621803248844,
            "p_value": 0.005733068622122777
        }
    },
    {
        "title": "VERA: VECTOR-BASED RANDOM MATRIX ADAPTATION",
        "abstract": "Low-rank adapation (LoRA) is a popular method that reduces the number of trainable parameters when finetuning large language models, but still faces acute storage challenges when scaling to even larger models or deploying numerous peruser or per-task adapted models. In this work, we present Vector-based Random Matrix Adaptation (VeRA)1, which significantly reduces the number of trainable parameters compared to LoRA, yet maintains the same performance. It achieves this by using a single pair of low-rank matrices shared across all layers and learning small scaling vectors instead. We demonstrate its effectiveness on the GLUE and E2E benchmarks, image classification tasks, and show its application in instruction-tuning of 7B and 13B language models.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces Vector-based Random Matrix Adaptation (VeRA), a novel parameter-efficient finetuning method that significantly reduces the number of trainable parameters compared to the state-of-the-art LoRA method, while maintaining comparable results. The method uses a single pair of low-rank matrices shared across all layers and learns small scaling vectors instead of LoRA's trainable matrices. VeRA is demonstrated to be effective on the GLUE and E2E benchmarks, image classification tasks, and shown to be applicable in instruction-tuning of large language models.\n\nStrengths:\n1. The proposed method is highly efficient in terms of trainable parameters, achieving significant reductions compared to LoRA and other methods.\n2. The use of shared low-rank matrices across all layers simplifies the finetuning process and reduces the number of trainable parameters.\n3. The method's ability to learn small scaling vectors allows for effective adaptation of the model to new tasks.\n4. The paper provides a comprehensive experimental evaluation of VeRA on various benchmarks and tasks, demonstrating its effectiveness.\n\nWeaknesses:\n1. The paper may benefit from a more detailed explanation of the theoretical foundations of the method, particularly in relation to the random matrix adaptation technique.\n2. Some of the experimental results, such as the performance on the MNLI task, are not reported due to time constraints, which may limit the paper's comprehensiveness.\n3. The paper does not provide a thorough analysis of the method's limitations and potential drawbacks, such as the need for careful initialization of the shared matrices and scaling vectors.\n\nSuggestions for Improvement:\n1. Provide a more detailed theoretical explanation of the method, including the underlying mathematical concepts and their implications for the finetuning process.\n2. Include a more comprehensive experimental evaluation, including results on additional benchmarks and tasks.\n3. Conduct a thorough analysis of the method's limitations and potential drawbacks, including the impact of initialization on performance.\n\nRecommendation:\nVeRA is a highly efficient finetuning method that significantly reduces the number of trainable parameters compared to LoRA and other methods. While the paper provides a comprehensive experimental evaluation, it may benefit from a more detailed theoretical explanation and a more comprehensive experimental evaluation. With some refinements, VeRA has the potential to become a leading method in the field of parameter-efficient finetuning.",
        "peer_review_with_watermark": "$$\n\\begin{align*}\n\\textbf{Paper Summary:} &\\quad \\text{The authors propose a novel finetuning method, Vector-based Random Matrix Adaptation (VeRA), which significantly reduces the number of trainable parameters compared to the state-of-the-art Low-Rank Adaptation (LoRA) method. VeRA uses a single pair of low-rank matrices shared across all layers and learning small scaling vectors instead of the traditional weight updates. The authors demonstrate the effectiveness of VeRA on the GLUE and E2E benchmarks, image classification tasks, and show its application in instruction-tuning of 7B and 13B language models.}\n\n\\textbf{Strengths:} &\\quad \n- The authors provide a thorough analysis of the current state-of-the-art finetuning methods and highlight the need for more efficient approaches.\n- The proposed VeRA method is well-structured and easy to follow.\n- The authors provide a clear and concise explanation of the mathematical formulation of VeRA.\n- The experiments demonstrate the effectiveness of VeRA in reducing the number of trainable parameters while maintaining comparable performance.\n\n\\textbf{Weaknesses:} &\\quad \n- The authors may want to provide more details about the theoretical foundations of VeRA and its connection to random matrix theory.\n- The results of the experiments may be affected by hyperparameter tuning and the choice of metrics for evaluation.\n- The authors may want to provide more insights into the impact of sharing random matrices on the performance of VeRA.\n- The application of VeRA to different architectures and domains is an area for future research.\n\n\\textbf{Suggestions for Improvement:} &\\quad \n- The authors may want to provide more details about the theoretical foundations of VeRA and its connection to random matrix theory.\n- The authors should consider including more experiments to evaluate the performance of VeRA on different benchmarks and tasks.\n- The authors may want to provide more insights into the impact of sharing random matrices on the performance of VeRA.\n- The authors should consider exploring different initialization and regularization techniques to improve the performance of VeRA.\n\n\\textbf{Recommendation:} &\\quad \nBased on the thorough analysis and clear explanation of the VeRA method, I recommend accepting the paper for publication in the conference. The authors have made a valuable contribution to the field of finetuning methods and have demonstrated the effectiveness of VeRA in reducing the number of trainable parameters while maintaining comparable performance. With some minor improvements in the theoretical foundations and experiments, the paper has the potential to make a significant impact in the field of natural language processing and machine learning.\n$$",
        "gr_score_with": 0.8255813953488372,
        "gr_score_without": 0.6996996996996997,
        "output_without": {
            "num_tokens_scored": 333,
            "num_green_tokens": 233,
            "green_fraction": 0.6996996996996997,
            "z_score": -0.011958266722235572,
            "p_value": 0.5047705444974554
        },
        "output_with": {
            "num_tokens_scored": 344,
            "num_green_tokens": 284,
            "green_fraction": 0.8255813953488372,
            "z_score": 5.082704697618128,
            "p_value": 1.8604898126539412e-07
        }
    },
    {
        "title": "SKILL MACHINES: TEMPORAL LOGIC SKILL COMPOSITION IN REINFORCEMENT LEARNING",
        "abstract": "It is desirable for an agent to be able to solve a rich variety of problems that can be specified through language in the same environment. A popular approach towards obtaining such agents is to reuse skills learned in prior tasks to generalise compositionally to new ones. However, this is a challenging problem due to the curse of dimensionality induced by the combinatorially large number of ways high-level goals can be combined both logically and temporally in language. To address this problem, we propose a framework where an agent first learns a sufficient set of skill primitives to achieve all high-level goals in its environment. The agent can then flexibly compose them both logically and temporally to provably achieve temporal logic specifications in any regular language, such as regular fragments of linear temporal logic. This provides the agent with the ability to map from complex temporal logic task specifications to near-optimal behaviours zero-shot. We demonstrate this experimentally in a tabular setting, as well as in a high-dimensional video game and continuous control environment. Finally, we also demonstrate that the performance of skill machines can be improved with regular off-policy reinforcement learning algorithms when optimal behaviours are desired.",
        "peer_review_without_watermark": "$$\\boxed{\\text{Paper Summary:}}$$\n\nThe paper proposes a framework called \"Skill Machines\" that enables agents to solve complex tasks involving temporal and spatial composition using a combination of skill primitives and skill machines. The framework is based on the idea of learning a sufficient set of skill primitives to achieve all high-level goals in an environment, and then composing them logically and temporally to solve new tasks. The authors demonstrate the effectiveness of the framework in several environments, including a high-dimensional video game and a continuous control environment. They also show that the framework can be improved with regular off-policy reinforcement learning algorithms.\n\n$$\\boxed{\\text{Strengths:}}$$\n\n1. The paper proposes a novel and effective framework for solving complex tasks involving temporal and spatial composition.\n2. The authors demonstrate the effectiveness of the framework in several environments, including high-dimensional video games and continuous control environments.\n3. The framework provides soundness guarantees, ensuring that the resulting policy adheres to the logical task specification.\n4. The authors provide a detailed analysis of the strengths and limitations of the proposed framework.\n\n$$\\boxed{\\text{Weaknesses:}}$$\n\n1. The paper assumes that the agent has access to a large amount of data, which may not be feasible in real-world scenarios.\n2. The framework may not be effective in environments with highly non-linear or non-regular dynamics.\n3. The authors do not provide a comprehensive analysis of the computational complexity of the proposed algorithm.\n4. The paper assumes that the skill primitives can be learned in a single pass, which may not be the case in practice.\n\n$$\\boxed{\\text{Suggestions for Improvement:}}$$\n\n1. Provide a more detailed analysis of the computational complexity of the proposed algorithm.\n2. Investigate the effectiveness of the framework in environments with highly non-linear or non-regular dynamics.\n3. Explore the possibility of using transfer learning or other techniques to improve the efficiency of the learning process.\n4. Provide a more comprehensive analysis of the strengths and limitations of the proposed framework.\n\n$$\\boxed{\\text{Recommendation:}}$$\n\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit their manuscript for peer review. The proposed framework shows promise in solving complex tasks involving temporal and spatial composition, and the authors provide a detailed analysis of the strengths and limitations of the framework. However, the paper could benefit from a more comprehensive analysis of the computational complexity of the proposed algorithm and a more detailed investigation of the effectiveness of the framework in environments with highly non-linear or non-regular dynamics.",
        "peer_review_with_watermark": "$$\\boxed{\\text{Paper Summary:}}$$\n\nThe paper proposes skill machines, which are finite state machines that can be learned from reward machines, allowing agents to solve complex tasks involving temporal and spatial composition. The authors demonstrate how skills can be learned and encoded in a specific form of goal-oriented value function, which, when combined with the learned skill machines, are sufficient for solving subsequent tasks without further learning. The approach guarantees that the resulting policy adheres to the logical task specification, providing assurances of safety and verifiability to the agent's decision-making. Empirical results show that the agent's performance is near-optimal, with further fine-tuning improving sample efficiency.\n\n$$\\boxed{\\text{Strengths:}}$$\n\n1. The paper presents a novel approach to temporal and spatial composition, allowing agents to solve complex tasks without further learning.\n2. The skill machine framework provides a structured way to represent logical and temporal knowledge over skills.\n3. The approach guarantees safety and verifiability, making it suitable for real-world applications.\n4. Empirical results demonstrate the effectiveness of the proposed approach.\n\n$$\\boxed{\\text{Weaknesses:}}$$\n\n1. The paper assumes deterministic environment dynamics, which may not hold in real-world scenarios.\n2. The approach requires significant expertise in temporal logic and logical composition.\n3. The empirical results may be limited to specific domains and task specifications.\n4. The paper does not provide a detailed analysis of the curse of dimensionality and its impact on the approach.\n\n$$\\boxed{\\text{Suggestions for Improvement:}}$$\n\n1. Extend the approach to handle stochastic environment dynamics.\n2. Provide more detailed explanations of temporal logic and logical composition concepts.\n3. Conduct more extensive empirical evaluations across diverse domains and task specifications.\n4. Investigate the impact of the curse of dimensionality on the approach and propose strategies to mitigate it.\n\n$$\\boxed{\\text{Recommendation:}}$$\n\nBased on the strengths and weaknesses of the paper, I recommend accepting the manuscript for publication. However, the authors should address the limitations and suggestions for improvement to further strengthen the approach.",
        "gr_score_with": 0.7864077669902912,
        "gr_score_without": 0.7022653721682848,
        "output_without": {
            "num_tokens_scored": 309,
            "num_green_tokens": 217,
            "green_fraction": 0.7022653721682848,
            "z_score": 0.08689787431778563,
            "p_value": 0.4653763445894198
        },
        "output_with": {
            "num_tokens_scored": 309,
            "num_green_tokens": 243,
            "green_fraction": 0.7864077669902912,
            "z_score": 3.3145332061211734,
            "p_value": 0.00045898138085061956
        }
    },
    {
        "title": "GNERP: GAUSSIAN-GUIDED NEURAL RECONSTRUC-",
        "abstract": "Learning surfaces from neural radiance field (NeRF) became a rising topic in Multi-View Stereo (MVS). Recent Signed Distance Function (SDF)\u2013based methods demonstrated their ability to reconstruct accurate 3D shapes of Lambertian scenes. However, their results on reflective scenes are unsatisfactory due to the entanglement of specular radiance and complicated geometry. To address the challenges, we propose a Gaussian-based representation of normals in SDF fields. Supervised by polarization priors, this representation guides the learning of geometry behind the specular reflection and captures more details than existing methods. Moreover, we propose a reweighting strategy in the optimization process to alleviate the noise issue of polarization priors. To validate the effectiveness of our design, we capture polarimetric information, and ground truth meshes in additional reflective scenes with various geometry. We also evaluated our framework on the PANDORA dataset. Comparisons prove our method outperforms existing neural 3D reconstruction methods in reflective scenes by a large margin.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$GNeRP: A Novel Gaussian-Guided Neural Reconstruction Framework for Reflective Scenes$$\n\nPaper Summary:\nThe paper proposes a novel Gaussian-based representation of normals in Signed Distance Function (SDF) fields to address the challenges of reconstructing 3D shapes of Lambertian scenes. Supervised by polarization priors, this representation guides the learning of geometry behind the specular reflection and captures more details than existing methods. The authors also introduce a reweighting strategy in the optimization process to alleviate the noise issue of polarization priors. The proposed framework, GNeRP, is evaluated on a new challenging multi-view dataset and compared with state-of-the-art methods.\n\nStrengths:\n1.  The paper presents a novel approach to reconstructing detailed geometry of reflective scenes by incorporating polarization priors and Gaussian-based representation of normals.\n2.  The proposed framework, GNeRP, is evaluated on a new challenging multi-view dataset, providing a comprehensive evaluation of the method's performance.\n3.  The authors introduce a reweighting strategy to resolve noise issues in polarization priors, improving the efficiency of polarization priors.\n\nWeaknesses:\n1.  The paper assumes that the incident light is unpolarized, which might not be true in all scenarios.\n2.  The authors do not discuss the potential limitations of the proposed framework in handling complex scenes or scenes with high-frequency specular reflection.\n3.  The paper does not provide a detailed analysis of the impact of the reweighting strategy on the reconstruction accuracy.\n\nSuggestions for Improvement:\n1.  The authors should consider incorporating more complex scenes or scenes with high-frequency specular reflection to evaluate the proposed framework's performance in these scenarios.\n2.  A more detailed analysis of the impact of the reweighting strategy on the reconstruction accuracy would be beneficial to understand its effectiveness.\n3.  The authors should discuss potential limitations of the proposed framework and how to address them in future work.\n\nRecommendation:\nBased on the strengths and weaknesses of the paper, I recommend accepting the paper for publication in a top-tier conference in computer vision or graphics. The proposed framework, GNeRP, presents a novel approach to reconstructing detailed geometry of reflective scenes, and the evaluation on a new challenging multi-view dataset provides a comprehensive evaluation of the method's performance. However, the authors should address the limitations and potential issues discussed in the review to strengthen the paper's overall quality.\n\n$$\\begin{aligned}\n\\end{aligned}$$",
        "peer_review_with_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes GNeRP, a Gaussian-guided neural reconstruction pipeline for 3D scenes, focusing on reflective objects. It leverages Gaussian-based representation of normals, guided by polarization priors, to disentangle specular reflection from geometry. The proposed method, GNeRP, overcomes the limitations of existing methods in handling reflective scenes, achieving more accurate and detailed 3D reconstructions.\n\nStrengths:\n1. Novel Gaussian-based representation of normals: This new representation captures the average orientation of normals and the changes within the neighborhood, providing more informative details about the geometry.\n2. Supervision by polarization priors: The use of polarization priors enables the disentanglement of specular reflection from geometry, allowing for more accurate 3D reconstructions.\n3. DoP reweighing strategy: The proposed reweighing strategy addresses the noise issue in polarization priors, enhancing the efficiency of the supervision.\n\nWeaknesses:\n1. Limited evaluation: The PANDORA dataset has limited reflective objects, making it less comprehensive for evaluating the performance of GNeRP.\n2. Additional noise: The introduction of the DoP reweighing strategy may introduce additional noise in the optimization process, which could negatively impact the performance.\n3. Lack of ablation study: The paper could have benefited from a more thorough ablation study, exploring the impact of different components and hyperparameters on the performance of GNeRP.\n\nSuggestions for Improvement:\n1. Use more comprehensive datasets: Incorporate more reflective objects and scenes from various datasets to evaluate the performance of GNeRP.\n2. Investigate the impact of hyperparameters: Perform a more extensive ablation study to understand the impact of different hyperparameters on the performance of GNeRP.\n3. Address the potential noise issue: Investigate methods to mitigate the potential noise introduced by the DoP reweighing strategy.\n\nRecommendation:\nGNeRP presents a significant improvement over existing methods for 3D reconstruction of reflective scenes. However, the limited evaluation and potential noise issue in the optimization process necessitate further investigation and refinement of the proposed method.",
        "gr_score_with": 0.7891373801916933,
        "gr_score_without": 0.6715542521994134,
        "output_without": {
            "num_tokens_scored": 341,
            "num_green_tokens": 229,
            "green_fraction": 0.6715542521994134,
            "z_score": -1.146264645055093,
            "p_value": 0.8741571665225498
        },
        "output_with": {
            "num_tokens_scored": 313,
            "num_green_tokens": 247,
            "green_fraction": 0.7891373801916933,
            "z_score": 3.441298832423487,
            "p_value": 0.0002894643867157986
        }
    },
    {
        "title": "CONCEPT BOTTLENECK GENERATIVE MODELS",
        "abstract": "We introduce a generative model with an intrinsically interpretable layer\u2014a concept bottleneck layer\u2014that constrains the model to encode human-understandable concepts. The concept bottleneck layer partitions the generative model into three parts: the pre-concept bottleneck portion, the CB layer, and the post-concept bottleneck portion. To train CB generative models, we complement the traditional task-based loss function for training generative models with a concept loss and an orthogonality loss. The CB layer and these loss terms are model agnostic, which we demonstrate by applying the CB layer to three different families of generative models: generative adversarial networks, variational autoencoders, and diffusion models. On multiple datasets across different types of generative models, steering a generative model, with the CB layer, outperforms all baselines\u2014in some cases, it is 10 times more effective. In addition, we show how the CB layer can be used to interpret the output of the generative model and debug the model during or post training.",
        "peer_review_without_watermark": "$$\\boxed{\\text{Paper Summary:}}\n$$ The paper introduces concept bottleneck generative models (CBGMs), which are generative models with an intrinsically interpretable layer\u2014a concept bottleneck layer\u2014that constrains the model to encode human-understandable concepts. The concept bottleneck layer partitions the generative model into three parts: the pre-concept bottleneck portion, the CB layer, and the post-concept bottleneck portion. The paper demonstrates the effectiveness of CBGMs in steering and debugging generative models.\n\n$$\\boxed{\\text{Strengths:}}\n$$ \n1. The concept bottleneck layer is a novel and effective way to introduce interpretability and controllability into generative models.\n2. The paper provides a comprehensive analysis of the strengths and limitations of CBGMs, including their ability to steer and debug generative models.\n3. The paper demonstrates the effectiveness of CBGMs on multiple datasets and generative model families, including VAEs, GANs, and diffusion models.\n4. The paper provides a clear and detailed explanation of the concept bottleneck layer and its components, making it easy to understand and implement.\n\n$$\\boxed{\\text{Weaknesses:}}\n$$ \n1. The concept bottleneck layer may not be effective for all types of generative models, and further research is needed to explore its limitations.\n2. The paper assumes that the entire training set needs to be annotated with pre-defined concepts, which may be a laborious requirement in practice.\n3. The paper has not been tested on text generation tasks, which may pose further challenges about what the nature of the concepts should be.\n\n$$\\boxed{\\text{Suggestions for Improvement:}}\n$$ \n1. Further research is needed to explore the limitations of the concept bottleneck layer and to develop more effective ways to introduce interpretability and controllability into generative models.\n2. The paper could benefit from a more detailed analysis of the concept bottleneck layer's components and their interactions.\n3. The paper could explore the use of the concept bottleneck layer on text generation tasks, which may pose further challenges about what the nature of the concepts should be.\n\n$$\\boxed{\\text{Recommendation:}}\n$$ \nBased on the strengths and weaknesses of the paper, I recommend that the authors continue to develop and refine the concept bottleneck generative models, exploring their limitations and potential applications in various domains. The paper has shown promising results and has the potential to contribute to the development of more interpretable and controllable generative models.",
        "peer_review_with_watermark": "$$$$\n\nPaper Summary:\n\nThis paper proposes concept bottleneck generative models (CBGMs), a type of generative model where a concept bottleneck layer is inserted to map input representations to human-understandable features. The concept bottleneck layer is a key component that enables steering and debugging of generative models. The proposed architecture is adaptable to three families of generative models: generative adversarial networks (GANs), variational autoencoders (VAEs), and diffusion models. The authors demonstrate the effectiveness of CBGMs in steering and debugging generative models, achieving up to 10x improvement in steerability compared to traditional approaches.\n\nStrengths:\n\n1. The proposed concept bottleneck layer is a novel and effective component that enables steering and debugging of generative models.\n2. The architecture is adaptable to three families of generative models, making it a versatile solution.\n3. The authors provide extensive experimental results demonstrating the effectiveness of CBGMs in steering and debugging generative models.\n4. The work addresses the limitations of current generative models, which are mostly inscrutable and difficult to steer.\n\nWeaknesses:\n\n1. The proposed architecture requires annotation of the entire training set with pre-defined concepts, which can be a laborious requirement in practice.\n2. The work has only been tested for image tasks, and it is unclear how well CBGMs will perform for text-based tasks.\n3. The concept bottleneck layer is susceptible to feature leakage, which can hampers steerability.\n4. The work does not address the issue of concept leakage, which is a limitation of the proposed architecture.\n\nSuggestions for Improvement:\n\n1. Develop a method to address concept leakage, which is a limitation of the proposed architecture.\n2. Provide a more detailed analysis of the concept bottleneck layer and its impact on steerability and debugging.\n3. Experiment with CBGMs for text-based tasks to evaluate their effectiveness.\n4. Develop a more efficient and scalable method for annotation of the training set.\n\nRecommendation:\n\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit their work. The proposed concept bottleneck layer is a novel and effective component that enables steering and debugging of generative models. However, addressing the limitations of the proposed architecture, such as concept leakage and annotation requirements, is crucial to making CBGMs a practical and effective solution. With revisions to address these limitations, I am confident that the paper can make a significant contribution to the field of generative modeling.",
        "gr_score_with": 0.75,
        "gr_score_without": 0.7044025157232704,
        "output_without": {
            "num_tokens_scored": 318,
            "num_green_tokens": 224,
            "green_fraction": 0.7044025157232704,
            "z_score": 0.1713187229166829,
            "p_value": 0.4319865796696948
        },
        "output_with": {
            "num_tokens_scored": 332,
            "num_green_tokens": 249,
            "green_fraction": 0.75,
            "z_score": 1.9880595947760125,
            "p_value": 0.023402549683351485
        }
    },
    {
        "title": "DiLu : A Knowledge-Driven Approach to Autonomous Driving with Large Language Models",
        "abstract": "Recent advancements in autonomous driving have relied on data-driven approaches, which are widely adopted but face challenges including dataset bias, overfitting, and uninterpretability. Drawing inspiration from the knowledge-driven nature of human driving, we explore the question of how to instill similar capabilities into autonomous driving systems and summarize a paradigm that integrates an interactive environment, a driver agent, as well as a memory component to address this question. Leveraging large language models (LLMs) with emergent abilities, we propose the DiLu framework, which combines a Reasoning and a Reflection module to enable the system to perform decision-making based on common-sense knowledge and evolve continuously. Extensive experiments prove DiLu\u2019s capability to accumulate experience and demonstrate a significant advantage in generalization ability over reinforcement learning-based methods. Moreover, DiLu is able to directly acquire experiences from real-world datasets which highlights its potential to be deployed on practical autonomous driving systems. To the best of our knowledge, we are the first to leverage knowledge-driven capability in decision-making for autonomous vehicles. Through the proposed DiLu framework, LLM is strengthened to apply knowledge and to reason causally in the autonomous driving domain. Project page: https://pjlab-adg.github.io/DiLu/",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes the DiLu framework, a knowledge-driven approach to autonomous driving that leverages large language models (LLMs) to enable decision-making based on common-sense knowledge. The framework consists of an environment, a driver agent with reasoning and reflection capabilities, and a memory component to store past experiences. The authors demonstrate the effectiveness of DiLu in accumulating experience and exhibiting strong generalization ability compared to reinforcement learning-based methods. They also show that DiLu can directly acquire experiences from real-world datasets, making it a promising approach for practical autonomous driving systems.\n\nStrengths:\n\n* The paper presents a novel knowledge-driven approach to autonomous driving that addresses the challenges of dataset bias, overfitting, and uninterpretability.\n* The DiLu framework is well-structured and easy to follow, with a clear explanation of the components and their interactions.\n* The authors provide extensive experimental results that demonstrate the effectiveness of DiLu in accumulating experience and exhibiting strong generalization ability.\n* The paper highlights the potential of leveraging LLMs to enable human-level knowledge in autonomous driving systems.\n\nWeaknesses:\n\n* The decision-making latency of the DiLu framework is significant, encompassing LLM inference and API response times, which may not be suitable for real-time applications.\n* The framework does not completely eradicate hallucinations generated by LLMs, which may lead to incorrect decisions.\n* The paper does not provide a comprehensive discussion of the limitations and challenges of the DiLu framework, such as the need for large amounts of labeled data and the potential for overfitting to the training environment.\n\nSuggestions for Improvement:\n\n* The authors should consider addressing the decision-making latency issue by exploring techniques such as LLM compression and optimization, or by using more efficient LLM architectures.\n* The framework should be designed to handle hallucinations generated by LLMs, such as by incorporating additional reasoning modules or using more robust LLMs.\n* The authors should provide a more detailed discussion of the limitations and challenges of the DiLu framework, including the need for large amounts of labeled data and the potential for overfitting to the training environment.\n\nRecommendation:\n\n* The DiLu framework is a promising approach to autonomous driving that addresses the challenges of dataset bias, overfitting, and uninterpretability. However, the significant decision-making latency and the potential for hallucinations generated by LLMs are limitations that need to be addressed. With further improvements and a more detailed discussion of the limitations and challenges, the DiLu framework has the potential to be a leading approach in the field of autonomous driving.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper proposes the DiLu framework, a knowledge-driven approach to autonomous driving that leverages large language models (LLMs) with emergent abilities. The framework consists of an environment, a driver agent with Reasoning and Reflection modules, and a Memory module to store experiences. The Reasoning module queries experiences from the Memory module, leverages LLMs to generate decisions, and employs the Reflection module to identify safe or unsafe decisions. Extensive experiments demonstrate the capability of the DiLu framework to accumulate experience, exhibit generalization ability, and outperform reinforcement learning-based methods.\n\nStrengths:\n1. The paper provides an innovative approach to autonomous driving by leveraging LLMs with emergent abilities.\n2. The framework is designed to accumulate experience, exhibit generalization ability, and improve decision-making.\n3. The experiments demonstrate the effectiveness of the DiLu framework compared to reinforcement learning-based methods.\n4. The paper discusses the limitations of the framework, including decision-making latency and hallucinations.\n\nWeaknesses:\n1. The framework experiences significant decision-making latency, which may be a critical issue in real-world autonomous driving applications.\n2. Hallucinations generated by LLMs can lead to unsafe decisions, highlighting the need for further improvement.\n3. The framework relies on the quality of the LLM, which can be affected by various factors such as dataset quality, hyperparameters, and model architecture.\n4. The Reflection module's ability to revise unsafe decisions could be improved by incorporating more advanced techniques.\n\nSuggestions for Improvement:\n1. Investigate techniques to reduce decision-making latency, such as model pruning, quantization, or optimization methods.\n2. Develop more advanced methods for revising unsafe decisions, such as incorporating external expert knowledge or using more sophisticated reflection algorithms.\n3. Explore the use of more robust LLMs, such as those trained on diverse datasets or using different architectures.\n4. Investigate the impact of the framework's design on the quality of the LLM and the overall performance of the system.\n\nRecommendation:\nThe DiLu framework is an innovative approach to autonomous driving that leverages LLMs with emergent abilities. While the framework experiences some limitations, such as decision-making latency and hallucinations, the experiments demonstrate its effectiveness compared to reinforcement learning-based methods. With further improvement in addressing these limitations, the DiLu framework has the potential to become a leading approach in the field of autonomous driving. \n\nThe authors should consider addressing the limitations of the framework, exploring more advanced techniques, and investigating the impact of the framework's design on the quality of the LLM and overall system performance. Additionally, the authors should provide more detailed explanations of the Reflection module's revision process, the use of external expert knowledge, or more sophisticated reflection algorithms.\n\nOverall, the paper presents an interesting and innovative approach to autonomous driving, and the authors have made significant contributions to the field. With further improvement, the DiLu framework has the potential to become a leading approach in the field of autonomous driving.\n\nThe authors should also consider the following:\n1. Provide more detailed explanations of the Reflection module's revision process.\n2. Investigate the use of external expert knowledge or more sophisticated reflection algorithms.\n3. Explore the impact of the framework's design on the quality of the LLM and overall system performance.\n4. Consider the use of more robust LLMs, such as those trained on diverse datasets or using different architectures.\n\nBy addressing these limitations, the authors can further improve the DiLu framework and contribute more significantly to the field of autonomous driving.\n\n$$$",
        "gr_score_with": 0.8097560975609757,
        "gr_score_without": 0.6946107784431138,
        "output_without": {
            "num_tokens_scored": 334,
            "num_green_tokens": 232,
            "green_fraction": 0.6946107784431138,
            "z_score": -0.21492633070531986,
            "p_value": 0.585087622178337
        },
        "output_with": {
            "num_tokens_scored": 410,
            "num_green_tokens": 332,
            "green_fraction": 0.8097560975609757,
            "z_score": 4.849656045851726,
            "p_value": 6.183787110321303e-07
        }
    },
    {
        "title": "GENERALIZATION: UNRAVELING LEARNING DIFFER-",
        "abstract": "This paper investigates discrepancies in how neural networks learn from different imaging domains, which are commonly overlooked when adopting computer vision techniques from the domain of natural images to other specialized domains such as medical images. Recent works have found that the generalization error of a trained network typically increases with the intrinsic dimension (ddata) of its training set. Yet, the steepness of this relationship varies significantly between medical (radiological) and natural imaging domains, with no existing theoretical explanation. We address this gap in knowledge by establishing and empirically validating a generalization scaling law with respect to ddata, and propose that the substantial scaling discrepancy between the two considered domains may be at least partially attributed to the higher intrinsic \u201clabel sharpness\u201d (KF ) of medical imaging datasets, a metric which we propose. Next, we demonstrate an additional benefit of measuring the label sharpness of a training set: it is negatively correlated with the trained model\u2019s adversarial robustness, which notably leads to models for medical images having a substantially higher vulnerability to adversarial attack. Finally, we extend our ddata formalism to the related metric of learned representation intrinsic dimension (drepr), derive a generalization scaling law with respect to drepr, and show that ddata serves as an upper bound for drepr. Our theoretical results are supported by thorough experiments with six models and eleven natural and medical imaging datasets over a range of training set sizes. Our findings offer insights into the influence of intrinsic dataset properties on generalization, representation learning, and robustness in deep neural networks.1",
        "peer_review_without_watermark": "$$\\boxed{\\text{Paper Summary:}~ The~ authors~ investigate~ discrepancies~ in~ how~ neural~ networks~ learn~ from~ different~ imaging~ domains,~ which~ are~ commonly~ overlooked~ when~ adopting~ computer~ vision~ techniques~ from~ the~ domain~ of~ natural~ images~ to~ other~ specialized~ domains~ such~ as~ medical~ images.~ They~ propose~ a~ generalization~ scaling~ law~ and~ demonstrate~ an~ additional~ benefit~ of~ measuring~ the~ label~ sharpness~ of~ a~ training~ set,~ which~ is~ negatively~ correlated~ with~ the~ trained~ model's~ adversarial~ robustness.~ The~ authors~ also~ extend~ their~ ddata~ formalism~ to~ the~ related~ metric~ of~ learned~ representation~ intrinsic~ dimension~ and~ show~ that~ ddata~ serves~ as~ an~ upper~ bound~ for~ drepr.}\n\n$$\\boxed{\\text{Strengths:}~ The~ authors~ provide~ a~ comprehensive~ analysis~ of~ the~ relationship~ between~ the~ generalization~ ability~ of~ neural~ networks~ and~ the~ intrinsic~ properties~ of~ their~ training~ sets,~ including~ dataset~ intrinsic~ dimension~ (ddata)~ and~ label~ sharpness~ (KF).~ The~ authors~ propose~ a~ novel~ measure~ of~ label~ sharpness~ and~ demonstrate~ its~ negative~ correlation~ with~ adversarial~ robustness.~ The~ authors~ also~ extend~ their~ analysis~ to~ the~ related~ metric~ of~ learned~ representation~ intrinsic~ dimension~ (drepr).}\n\n$$\\boxed{\\text{Weaknesses:}~ The~ authors~ acknowledge~ that~ the~ study~ has~ some~ limitations,~ including~ the~ difficulty~ of~ definitively~ stating~ if~ training~ set~ label~ sharpness~ (KF)~ causes~ the~ observed~ generalization~ scaling~ discrepancy~ between~ natural~ and~ medical~ image~ models.~ The~ authors~ also~ note~ that~ accounting~ for~ KF~ in~ the~ generalization~ scaling~ law~ increases~ the~ likelihood~ of~ the~ law~ given~ the~ observed~ data,~ but~ other~ potential~ factors~ unaccounted~ for~ should~ still~ be~ considered.}\n\n$$\\boxed{\\text{Suggestions~ for~ Improvement:}~ The~ authors~ could~ further~ investigate~ the~ relationship~ between~ label~ sharpness~ and~ adversarial~ robustness~ in~ other~ domains,~ such~ as~ satellite~ imaging~ or~ histopathology.~ The~ authors~ could~ also~ explore~ how~ the~ relationship~ between~ learned~ representation~ intrinsic~ dimension~ and~ generalization~ ability~ varies~ for~ networks~ trained~ on~ different~ tasks,~ including~ supervised~ (e.g.,~ segmentation,~ detection)~ and~ self-supervised~ or~ unsupervised~ learning.}\n\n$$\\boxed{\\text{Recommendation:}~ The~ authors'~ work~ provides~ a~ valuable~ contribution~ to~ the~ understanding~ of~ how~ neural~ network~ behavior~ varies~ within~ and~ between~ the~ two~ crucial~ domains~ of~ natural~ and~ medical~ images.~ The~ authors'~ proposal~ of~ a~ generalization~ scaling~ law~ and~ their~ demonstration~ of~ the~ negative~ correlation~ between~ label~ sharpness~ and~ adversarial~ robustness~ are~ particularly~ noteworthy.~ The~ authors'~ findings~ have~ the~ potential~ to~ inform~ the~ design~ of~ more~ robust~ and~ efficient~ neural~ networks~ for~ various~ applications.}$$",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$Paper Summary:\nThis paper investigates how neural networks generalize to test data and how this generalization behavior relates to the intrinsic properties of the training dataset. The authors explore two important properties of the dataset: intrinsic dimension and label sharpness. The intrinsic dimension is a measure of how complex a dataset is, while label sharpness measures how similar images can be within a class while still having different labels. The authors derive a generalization scaling law that relates these properties to generalization error, which is the difference between the predicted output and the true output. The law shows that generalization error typically increases with intrinsic dimension, but at different rates for natural and medical image datasets.\n\n$$\\text{Strengths}:$$ The authors have conducted a thorough analysis of how neural networks generalize to test data and have identified two important properties of the dataset that affect generalization behavior. The derived generalization scaling law provides a useful tool for understanding how networks generalize and how this generalization behavior can be improved.\n\n$$\\text{Weaknesses}:$$ The paper relies on some simplifying assumptions, such as the manifold hypothesis, which may not hold for all datasets. Additionally, the authors acknowledge that there could be other factors that contribute to the generalization scaling discrepancy between natural and medical image models, but these factors are not explicitly accounted for.\n\n$$\\text{Suggestions for Improvement}:$$ The authors could explore how other factors, such as model architecture and training method, affect generalization behavior. Additionally, they could investigate how their findings apply to other tasks, such as multi-class classification and semantic segmentation.\n\n$$\\text{Recommendation}:$$ This paper provides a valuable contribution to the field of deep learning and neural networks. The derived generalization scaling law provides a useful tool for understanding how networks generalize, and the analysis of label sharpness highlights an important property of datasets that can affect generalization behavior. The authors' exploration of how this behavior can be improved could lead to new insights and approaches for developing more robust and generalizable neural networks.\n\n$$\\text{Overall Rating}:$$ 4/5\n\n$$\\text{Peer Reviewer's Feedback}:$$ The authors have conducted a thorough analysis of how neural networks generalize to test data and have identified two important properties of the dataset that affect generalization behavior. The derived generalization scaling law provides a useful tool for understanding how networks generalize, and the analysis of label sharpness highlights an important property of datasets that can affect generalization behavior. However, the authors could explore how other factors, such as model architecture and training method, affect generalization behavior, and investigate how their findings apply to other tasks.",
        "gr_score_with": 0.8539682539682539,
        "gr_score_without": 0.4540682414698163,
        "output_without": {
            "num_tokens_scored": 381,
            "num_green_tokens": 173,
            "green_fraction": 0.4540682414698163,
            "z_score": -10.475323787308144,
            "p_value": 1.0
        },
        "output_with": {
            "num_tokens_scored": 315,
            "num_green_tokens": 269,
            "green_fraction": 0.8539682539682539,
            "z_score": 5.9631648346368165,
            "p_value": 1.2369931169713914e-09
        }
    },
    {
        "title": "TRANSFORMER-MODULATED DIFFUSION MODELS FOR PROBABILISTIC MULTIVARIATE TIME SERIES FORECASTING",
        "abstract": "Transformers have gained widespread usage in multivariate time series (MTS) forecasting, delivering impressive performance. Nonetheless, these existing transformer-based methods often neglect an essential aspect: the incorporation of uncertainty into the predicted series, which holds significant value in decisionmaking. In this paper, we introduce a Transformer-Modulated Diffusion Model (TMDM), uniting conditional diffusion generative process with transformers into a unified framework to enable precise distribution forecasting for MTS. TMDM harnesses the power of transformers to extract essential insights from historical time series data. This information is then utilized as prior knowledge, capturing covariate-dependence in both the forward and reverse processes within the diffusion model. Furthermore, we seamlessly integrate well-designed transformerbased forecasting methods into TMDM to enhance its overall performance. Additionally, we introduce two novel metrics for evaluating uncertainty estimation performance. Through extensive experiments on six datasets using four evaluation metrics, we establish the effectiveness of TMDM in probabilistic MTS forecasting.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$\\text{Paper Summary:}$$\nThe paper proposes a novel framework called the Transformer-Modulated Diffusion Model (TMDM) for probabilistic multivariate time series forecasting. TMDM combines the conditional diffusion generative process with well-designed transformer structures, enabling accurate distribution forecasting for time series. The authors introduce a hybrid optimization strategy that integrates the condition generative model and denoising model, allowing for efficient training and seamless compatibility with existing transformer-based forecasting models.\n\n$$\\text{Strengths:}$$\n1. The paper proposes a novel and innovative approach to probabilistic multivariate time series forecasting by merging diffusion generative process with transformer models.\n2. The authors introduce a hybrid optimization strategy that enables efficient training and seamless compatibility with existing transformer-based forecasting models.\n3. The paper presents two novel evaluation metrics, Prediction Interval Coverage Probability (PICP) and Quantile Interval Coverage Error (QICE), which provide valuable insights into assessing uncertainty estimation abilities in probabilistic multivariate time series forecasting models.\n\n$$\\text{Weaknesses:}$$\n1. The paper does not provide a clear explanation of the hyperparameter tuning process and its impact on the performance of the model.\n2. The authors do not provide a detailed analysis of the limitations and potential biases of the proposed framework, which is essential for evaluating its overall performance and generalizability.\n3. The paper does not discuss the potential applications and limitations of the proposed framework in real-world scenarios.\n\n$$\\text{Suggestions for Improvement:}$$\n1. The authors should provide a detailed analysis of the hyperparameter tuning process and its impact on the performance of the model.\n2. The authors should discuss the potential limitations and biases of the proposed framework and provide a detailed evaluation of its overall performance and generalizability.\n3. The authors should explore the potential applications and limitations of the proposed framework in real-world scenarios.\n\n$$\\text{Recommendation:}$$\nBased on the paper's contributions, strengths, and weaknesses, I recommend that the authors revise and resubmit the paper to the conference. The authors should address the weaknesses and provide a detailed analysis of the limitations and potential biases of the proposed framework. Additionally, the authors should explore the potential applications and limitations of the proposed framework in real-world scenarios. With revisions, the paper has the potential to make a significant contribution to the field of probabilistic multivariate time series forecasting.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$\\textbf{Paper Summary:}$$\nThe paper proposes a novel framework called Transformer-Modulated Diffusion Model (TMDM) for probabilistic multivariate time series forecasting. TMDM combines the conditional diffusion generative process with well-designed transformer structures to enable accurate distribution forecasting for time series. The authors introduce a hybrid optimization approach that incorporates both the condition generative model and denoising model to maximize the evidence lower bound (ELBO) of the log marginal likelihood.\n\n$$\\textbf{Strengths:}$$\n1. TMDM effectively leverages the strengths of transformers, particularly their accuracy in estimating conditional means, and extends this capability as priors across both forward and reverse processes within the diffusion model.\n2. The authors introduce a hybrid optimization approach that enhances training stability when paired with various transformers.\n3. TMDM is a versatile plug-and-play framework that effectively closes the gap between point estimates and distribution estimates.\n\n$$\\textbf{Weaknesses:}$$\n1. The authors do not address the issue of handling non-linear relationships between variables in time series data.\n2. The performance of TMDM on non-standard datasets is not evaluated.\n3. The authors do not discuss the limitations of using transformers for time series forecasting.\n\n$$\\textbf{Suggestions for Improvement:}$$\n1. To address the issue of handling non-linear relationships between variables in time series data, the authors can use techniques such as non-linear transformations or attention mechanisms in the transformer model.\n2. To evaluate the performance of TMDM on non-standard datasets, the authors can use techniques such as data augmentation or transfer learning.\n3. To discuss the limitations of using transformers for time series forecasting, the authors can compare their results with state-of-the-art methods that do not use transformers.\n\n$$\\textbf{Recommendation:}$$\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit their manuscript for peer review. The authors should address the limitations of their method and provide a more detailed discussion of its strengths and weaknesses. Additionally, they should evaluate the performance of their method on non-standard datasets and discuss its limitations.\n\n$$\\textbf{Rating:}$$\nI give this paper a rating of 7 out of 10 based on its originality, contribution, and overall quality. However, I believe that with revisions and improvements, the authors can make their manuscript more competitive and relevant to the field of time series forecasting.\n\n$$\\textbf{Final Comment:}$$\nIn conclusion, TMDM is a novel and innovative approach to probabilistic multivariate time series forecasting that leverages the strengths of transformers. However, to make it a truly competitive method, the authors need to address its limitations and provide a more detailed discussion of its strengths and weaknesses.",
        "gr_score_with": 0.7630208333333334,
        "gr_score_without": 0.6794425087108014,
        "output_without": {
            "num_tokens_scored": 287,
            "num_green_tokens": 195,
            "green_fraction": 0.6794425087108014,
            "z_score": -0.7599786920768328,
            "p_value": 0.7763663391605771
        },
        "output_with": {
            "num_tokens_scored": 384,
            "num_green_tokens": 293,
            "green_fraction": 0.7630208333333334,
            "z_score": 2.6948841892836177,
            "p_value": 0.0035206549869584167
        }
    },
    {
        "title": "ING IN WHOLE SLIDE IMAGES",
        "abstract": "The visual examination of tissue biopsy sections is fundamental for cancer diagnosis, with pathologists analyzing sections at multiple magnifications to discern tumor cells and their subtypes. However, existing attention-based multiple instance learning (MIL) models used for analyzing Whole Slide Images (WSIs) in cancer diagnostics often overlook the contextual information of tumor and neighboring tiles, leading to misclassifications. To address this, we propose the ContextAware Multiple Instance Learning (CAMIL) architecture. CAMIL incorporates neighbor-constrained attention to consider dependencies among tiles within a WSI and integrates contextual constraints as prior knowledge into the MIL model. We evaluated CAMIL on subtyping non-small cell lung cancer (TCGA-NSCLC) and detecting lymph node (CAMELYON16 and CAMELYON17) metastasis, achieving test AUCs of 97.5%, 95.9%, and 88.1%, respectively, outperforming other state-of-the-art methods. Additionally, CAMIL enhances model interpretability by identifying regions of high diagnostic value.",
        "peer_review_without_watermark": "$$$\\boxed{Peer Review}$$\n\n$\\boxed{Paper Summary:}$\n\nThe paper proposes a novel framework called Context-Aware Multiple Instance Learning (CAMIL) for whole slide imaging (WSI) classification in cancer diagnostics. CAMIL incorporates neighbor-constrained attention to consider dependencies among tiles within a WSI and integrates contextual constraints as prior knowledge into the multiple instance learning model. The proposed framework is evaluated on three histopathology datasets (CAMELYON16, CAMELYON17, and TCGA-NSCLC) and demonstrates state-of-the-art performance in terms of tile-level accuracy, area under the receiver operating characteristic curve (AUC), and F1 score.\n\n$\\boxed{Strengths:}$\n\n1.  The proposed framework effectively considers the tumor microenvironment context, which is crucial for accurate cancer diagnosis.\n2.  The neighbor-constrained attention mechanism and contextual constraints as prior knowledge enhance the model's performance.\n3.  CAMIL achieves state-of-the-art performance across multiple datasets.\n4.  The framework's interpretability is improved through the attention weights, highlighting sub-regions of high diagnostic value within the WSI.\n\n$\\boxed{Weaknesses:}$\n\n1.  The model's performance may be affected by the integration of the Nystromformer module, which introduces a trade-off between slide-level accuracy and localization performance.\n2.  The attention maps generated by CAMIL may struggle with highly localized tumors, encountering difficulties capturing intricate, short-term dependencies within the image.\n3.  The model's performance may be sensitive to the choice of hyperparameters, particularly the similarity mask used in the neighbor-constrained attention mechanism.\n\n$\\boxed{Suggestions for Improvement:}$\n\n1.  Investigate the effect of different similarity mask architectures on the model's performance.\n2.  Explore the use of additional contextual constraints, such as histopathological features or clinical data, to further enhance the model's performance.\n3.  Develop techniques to improve the model's localization performance, such as using multi-scale attention or incorporating additional image features.\n\n$\\boxed{Recommendation:}$\n\nBased on the evaluation of CAMIL on three histopathology datasets, we recommend considering this framework for WSI classification in cancer diagnostics. However, it is essential to investigate the model's performance on additional datasets and explore potential improvements to address the limitations mentioned above.",
        "peer_review_with_watermark": "$$$\\boxed{Peer Review}$$\n\n$\\boxed{Paper Summary:}$\n\nThe proposed paper introduces Context-Aware Multiple Instance Learning (CAMIL), a novel framework that leverages the dependencies among individual tiles within a Whole Slide Image (WSI) to enhance the performance of multiple instance learning (MIL) models in cancer diagnostics. The framework incorporates a neighbor-constrained attention mechanism to capture local context and contextual constraints as prior knowledge into the MIL model. The proposed approach is evaluated on three histopathology datasets and demonstrates state-of-the-art performance on tile-level classification and localization tasks.\n\n$\\boxed{Strengths:}$\n\n1. The proposed framework incorporates contextual information into the MIL model, which can lead to improved performance in cancer diagnostics.\n2. The neighbor-constrained attention mechanism can capture local context and dependencies among tiles within a WSI.\n3. The proposed approach demonstrates state-of-the-art performance on tile-level classification and localization tasks.\n4. The framework provides an interpretable model that can identify regions of high diagnostic value.\n\n$\\boxed{Weaknesses:}$\n\n1. The proposed framework may be computationally expensive due to the use of transformer layers.\n2. The neighbor-constrained attention mechanism may not be effective in capturing complex dependencies among tiles within a WSI.\n3. The framework may not generalize well to different datasets or image types.\n4. The proposed approach does not provide a clear explanation of the hyperparameter tuning process.\n\n$\\boxed{Suggestions for Improvement:}$\n\n1. The proposed framework can be improved by incorporating more sophisticated contextual information into the MIL model.\n2. The neighbor-constrained attention mechanism can be improved by using more advanced techniques to capture dependencies among tiles within a WSI.\n3. The framework can be improved by using more robust evaluation metrics to assess performance on different datasets and image types.\n4. The proposed approach can be improved by providing a clear explanation of the hyperparameter tuning process.\n\n$\\boxed{Recommendation:}$\n\nBased on the strengths and weaknesses of the proposed framework, we recommend that the authors further investigate and refine the neighbor-constrained attention mechanism to capture complex dependencies among tiles within a WSI. Additionally, the authors can explore using more robust evaluation metrics to assess performance on different datasets and image types. The proposed framework has the potential to be a state-of-the-art approach in cancer diagnostics, and with further refinement, it can provide more accurate and interpretable results.",
        "gr_score_with": 0.8040540540540541,
        "gr_score_without": 0.7272727272727273,
        "output_without": {
            "num_tokens_scored": 363,
            "num_green_tokens": 264,
            "green_fraction": 0.7272727272727273,
            "z_score": 1.1338934190276824,
            "p_value": 0.1284196289789281
        },
        "output_with": {
            "num_tokens_scored": 296,
            "num_green_tokens": 238,
            "green_fraction": 0.8040540540540541,
            "z_score": 3.9065664286251773,
            "p_value": 4.680845753144065e-05
        }
    },
    {
        "title": "COLIDE: CONCOMITANT LINEAR DAG ESTIMATION",
        "abstract": "We deal with the combinatorial problem of learning directed acyclic graph (DAG) structure from observational data adhering to a linear structural equation model (SEM). Leveraging advances in differentiable, nonconvex characterizations of acyclicity, recent efforts have advocated a continuous constrained optimization paradigm to efficiently explore the space of DAGs. Most existing methods employ lasso-type score functions to guide this search, which (i) require expensive penalty parameter retuning when the unknown SEM noise variances change across problem instances; and (ii) implicitly rely on limiting homoscedasticity assumptions. In this work, we propose a new convex score function for sparsity-aware learning of linear DAGs, which incorporates concomitant estimation of scale and thus effectively decouples the sparsity parameter from the exogenous noise levels. Regularization via a smooth, nonconvex acyclicity penalty term yields CoLiDE (Concomitant Linear DAG Estimation), a regression-based criterion amenable to efficient gradient computation and closed-form estimation of noise variances in heteroscedastic scenarios. Our algorithm outperforms state-of-the-art methods without incurring added complexity, especially when the DAGs are larger and the noise level profile is heterogeneous. We also find CoLiDE exhibits enhanced stability manifested via reduced standard deviations in several domain-specific metrics, underscoring the robustness of our novel linear DAG estimator.",
        "peer_review_without_watermark": "$$\\boxed{\\text{Paper Summary:}~\\text{The}~\\text{paper}~\\text{proposes}~\\text{CoLiDE},~\\text{a}~\\text{novel}~\\text{framework}~\\text{for}~\\text{learning}~\\text{linear}~\\text{directed}~\\text{acyclic}~\\text{graphs}~\\text{(DAGs)}~\\text{with}~\\text{exogenous}~\\text{noises}~\\text{having}~\\text{non-equal}~\\text{variances}.~\\text{The}~\\text{proposed}~\\text{approach}~\\text{is}~\\text{based}~\\text{on}~\\text{concomitant}~\\text{scale}~\\text{estimation}~\\text{techniques}~\\text{and}~\\text{combines}~\\text{convex}~\\text{score}~\\text{functions}~\\text{to}~\\text{estimate}~\\text{the}~\\text{DAG}~\\text{structure}~\\text{and}~\\text{exogenous}~\\text{noise}~\\text{variances}.}\n\n$$\\boxed{\\text{Strengths:}~\\text{The}~\\text{proposed}~\\text{approach}~\\text{is}~\\text{jointly}~\\text{convex}~\\text{in}~\\text{the}~\\text{DAG}~\\text{structure}~\\text{and}~\\text{exogenous}~\\text{noise}~\\text{variances},~\\text{and}~\\text{combines}~\\text{convex}~\\text{score}~\\text{functions}~\\text{to}~\\text{estimate}~\\text{the}~\\text{DAG}~\\text{structure}~\\text{and}~\\text{exogenous}~\\text{noise}~\\text{variances}.}\n\n$$\\boxed{\\text{Weaknesses:}~\\text{The}~\\text{paper}~\\text{does}~\\text{not}~\\text{provide}~\\text{a}~\\text{clear}~\\text{explanation}~\\text{of}~\\text{the}~\\text{choice}~\\text{of}~\\text{the}~\\text{ac}~\\text{y}~\\text{clity}~\\text{function}~\\text{Hldet}~\\text{and}~\\text{why}~\\text{it}~\\text{is}~\\text{more}~\\text{favorable}~\\text{for}~\\text{gradient}~\\text{properties}.}\n\n$$\\boxed{\\text{Suggestions}~\\text{for}~\\text{Improvement:}~\\text{The}~\\text{paper}~\\text{could}~\\text{provide}~\\text{a}~\\text{clear}~\\text{explanation}~\\text{of}~\\text{the}~\\text{choice}~\\text{of}~\\text{the}~\\text{ac}~\\text{y}~\\text{clity}~\\text{function}~\\text{Hldet}~\\text{and}~\\text{why}~\\text{it}~\\text{is}~\\text{more}~\\text{favorable}~\\text{for}~\\text{gradient}~\\text{properties}.}\n\n$$\\boxed{\\text{Recommendation:}~\\text{The}~\\text{proposed}~\\text{approach}~\\text{is}~\\text{an}~\\text{interesting}~\\text{contribution}~\\text{to}~\\text{the}~\\text{field}~\\text{of}~\\text{DAG}~\\text{learning}~\\text{and}~\\text{should}~\\text{be}~\\text{carefully}~\\text{evaluated}~\\text{for}~\\text{its}~\\text{theoretical}~\\text{and}~\\text{practical}~\\text{aspects}.}$$",
        "peer_review_with_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes CoLiDE, a novel convex score function for linear DAG estimation that incorporates concomitant estimation of scale, thereby decoupling the sparsity parameter from the exogenous noise levels. CoLiDE is designed to address the challenges of lasso-type score functions in heterogeneous exogenous noise scenarios, where the unknown SEM noise variance changes across problem instances. The authors demonstrate that CoLiDE outperforms state-of-the-art methods in various synthetic and real-world settings, including the recovery of DAG edges and weights, and provide a comprehensive experimental evaluation.\n\nStrengths: \n1. The proposed CoLiDE approach effectively addresses the challenges of heterogeneous exogenous noise in linear DAG estimation.\n2. CoLiDE incorporates concomitant estimation of scale, decoupling the sparsity parameter from the exogenous noise levels.\n3. The authors provide a comprehensive experimental evaluation, including both homoscedastic and heteroscedastic settings.\n4. CoLiDE is designed to be robust to deviations from Gaussianity and can be extended to accommodate other convex loss functions and non-linear SEMs.\n\nWeaknesses: \n1. The paper primarily focuses on linear Gaussian SEMs and does not discuss its applicability to non-linear SEMs or other types of data.\n2. Some of the experimental evaluations, such as the one on dense graphs, may be biased due to the specific characteristics of the dataset used.\n3. The authors could have explored more robustness tests, such as assessing CoLiDE's performance under different types of noise or perturbations.\n4. There is a lack of theoretical analysis on the convergence and stability of CoLiDE, which could provide further insights into its performance.\n\nSuggestions for Improvement: \n1. Extend CoLiDE to non-linear SEMs and other types of data to increase its applicability.\n2. Perform more comprehensive robustness tests, including different types of noise and perturbations.\n3. Include a theoretical analysis on convergence and stability of CoLiDE.\n4. Investigate the use of CoLiDE with other optimization methods, such as TOPO, to further enhance its performance.\n\nRecommendation: \nBased on the experimental evaluation and theoretical analysis, we recommend that CoLiDE be further explored and refined to address its limitations and expand its applicability. With its robustness to deviations from Gaussianity and ability to decouple sparsity from exogenous noise, CoLiDE holds significant promise as a novel approach to linear DAG estimation.",
        "gr_score_with": 0.8450704225352113,
        "gr_score_without": 0.8018867924528302,
        "output_without": {
            "num_tokens_scored": 212,
            "num_green_tokens": 170,
            "green_fraction": 0.8018867924528302,
            "z_score": 3.237249506382979,
            "p_value": 0.0006034392083639009
        },
        "output_with": {
            "num_tokens_scored": 355,
            "num_green_tokens": 300,
            "green_fraction": 0.8450704225352113,
            "z_score": 5.964628580047621,
            "p_value": 1.2259556351107134e-09
        }
    },
    {
        "title": "CONQUER: DIFFUSION-BASED 3D DEPTH AWARE COMPOSABLE IMAGE SYNTHESIS",
        "abstract": "Addressing the limitations of text as a source of accurate layout representation in text-conditional diffusion models, many works incorporate additional signals to condition certain attributes within a generated image. Although successful, previous works do not account for the specific localization of said attributes extended into the three dimensional plane. In this context, we present a conditional diffusion model that integrates control over three-dimensional object placement with disentangled representations of global stylistic semantics from multiple exemplar images. Specifically, we first introduce depth disentanglement training to leverage the relative depth of objects as an estimator, allowing the model to identify the absolute positions of unseen objects through the use of synthetic image triplets. We also introduce soft guidance, a method for imposing global semantics onto targeted regions without the use of any additional localization cues. Our integrated framework, COMPOSE AND CONQUER (CNC), unifies these techniques to localize multiple conditions in a disentangled manner. We demonstrate that our approach allows perception of objects at varying depths while offering a versatile framework for composing localized objects with different global semantics.",
        "peer_review_without_watermark": "$$$\\begin{align}\\textbf{Paper Summary:} &\\quad \\text{The paper presents a novel text-conditional diffusion model, called Compose and Conquer (CNC), that integrates control over three-dimensional object placement with disentangled representations of global stylistic semantics from multiple exemplar images.}\\\\ &\\quad \\text{The model uses a combination of depth disentanglement training and soft guidance to localize multiple conditions in a disentangled manner.}\\\\ &\\quad \\text{The authors demonstrate the effectiveness of their approach on various evaluation metrics, including FID, Inception Score, CLIPScore, and reconstruction metrics.}\\\\ &\\quad \\text{The authors also discuss the limitations of the current framework and leave the further decomposition of images into depth portraying primitives and the middle ground for future work.}\\end{align}\n\n$$\\textbf{Strengths:}$$\n- The paper presents a novel approach to address two main challenges in text-conditional diffusion models: three-dimensional placement of multiple objects and region-specific localization of global semantics from multiple sources.\n- The use of depth disentanglement training and soft guidance techniques is innovative and effective in localizing multiple conditions in a disentangled manner.\n- The experimental results demonstrate the effectiveness of the proposed approach on various evaluation metrics.\n\n$$\\textbf{Weaknesses:}$$\n- The paper assumes that the reader is familiar with the concept of text-conditional diffusion models and the challenges they face.\n- The explanation of the depth disentanglement training and soft guidance techniques could be more detailed and intuitive.\n- The limitations of the current framework, such as the number of available conditions and the disentangled spatial grounds, are not fully explored.\n\n$$\\textbf{Suggestions for Improvement:}$$\n- Provide a more detailed explanation of the depth disentanglement training and soft guidance techniques.\n- Explore the limitations of the current framework and propose potential solutions.\n- Consider adding more visualizations and results to support the claims made in the paper.\n\n$$\\textbf{Recommendation:}$$\n- The proposed approach is novel and effective, and the experimental results demonstrate its potential. However, the paper could benefit from a more detailed explanation of the techniques used and a more thorough exploration of the limitations of the current framework. With some revisions, the paper could be considered for publication in a top-tier conference in the field of computer vision and machine learning.",
        "peer_review_with_watermark": "$$$\\begin{gathered}\n\\text{\\em Paper Title: CONQUER: DIFFUSION-BASED 3D DEPTH AWARE COMPOSABLE IMAGE SYNTHESIS}\\\\\n\\text{\\em Paper Summary: The paper proposes a text-conditional diffusion model, COMPOSE AND CONQUER (CNC), that integrates control over three-dimensional object placement with disentangled representations of global stylistic semantics from multiple exemplar images.}\\\\\n\\text{\\em The model utilizes depth disentanglement training to leverage the relative depth of objects as an estimator, allowing the model to identify the absolute positions of unseen objects through the use of synthetic image triplets.}\\\\\n\\text{\\em The model also introduces soft guidance, a method for imposing global semantics onto targeted regions without the use of any additional localization cues.}\\\\\n\\text{\\em The proposed framework, CNC, demonstrates that the approach allows perception of objects at varying depths while offering a versatile framework for composing localized objects with different global semantics.}\\\\\n\\end{gathered}\n\n\\text{\\em Strengths:}\\\\\n- The paper proposes a novel approach to addressing the challenges of three-dimensional placement of multiple objects and region-specific localization of global semantics from multiple sources.\n- The use of depth disentanglement training and soft guidance techniques provides a disentangled representation of global stylistic semantics from multiple exemplar images.\n- The experimental results demonstrate the proficiency of the proposed approach in addressing these challenges.\n\n\\text{\\em Weaknesses:}\\\\\n- The paper assumes a specific prior knowledge of the user-preferred prior of DMs, which may not be universally applicable.\n- The proposed approach may be limited by the current framework's inability to decompose images into depth portraying primitives and the middle ground.\n- The paper may benefit from more extensive analysis of the limitations and potential biases of the proposed approach.\n\n\\text{\\em Suggestions for Improvement:}\\\\\n- The paper could benefit from more extensive analysis of the limitations and potential biases of the proposed approach.\n- The authors could explore the possibility of extending the proposed approach to handle more complex scenarios, such as scenes with multiple objects and varying depths.\n- The paper could also explore the potential applications of the proposed approach in real-world scenarios, such as image synthesis and image editing.\n\n\\text{\\em Recommendation:}\\\\\n- The paper presents a novel approach to addressing the challenges of three-dimensional placement of multiple objects and region-specific localization of global semantics from multiple sources.\n- The experimental results demonstrate the proficiency of the proposed approach in addressing these challenges.\n- However, the paper assumes a specific prior knowledge of the user-preferred prior of DMs, which may not be universally applicable, and the proposed approach may be limited by the current framework's inability to decompose images into depth portraying primitives and the middle ground.\n\n\\text{\\em Final Verdict:}\\\\\n- The paper presents a novel approach to addressing the challenges of three-dimensional placement of multiple objects and region-specific localization of global semantics from multiple sources, with promising experimental results.\n- However, the paper assumes a specific prior knowledge of the user-preferred prior of DMs, which may not be universally applicable, and the proposed approach may be limited by the current framework's inability to decompose images into depth portraying primitives and the middle ground.\n\n\\end{gathered}$$",
        "gr_score_with": 0.7988668555240793,
        "gr_score_without": 0.7064220183486238,
        "output_without": {
            "num_tokens_scored": 327,
            "num_green_tokens": 231,
            "green_fraction": 0.7064220183486238,
            "z_score": 0.2534170149896015,
            "p_value": 0.3999729903165008
        },
        "output_with": {
            "num_tokens_scored": 353,
            "num_green_tokens": 282,
            "green_fraction": 0.7988668555240793,
            "z_score": 4.053483662111118,
            "p_value": 2.5230262766394944e-05
        }
    },
    {
        "title": "BENO: BOUNDARY-EMBEDDED NEURAL OPERATORS FOR ELLIPTIC PDES",
        "abstract": "Elliptic partial differential equations (PDEs) are a major class of time-independent PDEs that play a key role in many scientific and engineering domains such as fluid dynamics, plasma physics, and solid mechanics. Recently, neural operators have emerged as a promising technique to solve elliptic PDEs more efficiently by directly mapping the input to solutions. However, existing networks typically cannot handle complex geometries and inhomogeneous boundary values present in the real world. Here we introduce Boundary-Embedded Neural Operators (BENO), a novel neural operator architecture that embeds the complex geometries and inhomogeneous boundary values into the solving of elliptic PDEs. Inspired by classical Green\u2019s function, BENO consists of two branches of Graph Neural Networks (GNNs) for interior source term and boundary values, respectively. Furthermore, a Transformer encoder maps the global boundary geometry into a latent vector which influences each message passing layer of the GNNs. We test our model extensively in elliptic PDEs with various boundary conditions. We show that all existing baseline methods fail to learn the solution operator. In contrast, our model, endowed with boundary-embedded architecture, outperforms state-of-the-art neural operators and strong baselines by an average of 60.96%. Our source code can be found https://github.com/AI4Science-WestlakeU/beno.git.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$\\text{Paper Summary:}$$\nThe paper proposes Boundary-Embedded Neural Operators (BENO), a novel neural operator architecture to solve elliptic partial differential equations (PDEs) with complex boundary conditions. BENO incorporates physics intuition through a boundary-embedded architecture, consisting of Graph Neural Networks (GNNs) and a Transformer, to model the influence of boundary conditions on the solution. The authors demonstrate the effectiveness of BENO in outperforming existing state-of-the-art methods by an average of 60.96% in solving elliptic PDE problems.\n\n$$\\text{Strengths:}$$\n1. The paper presents a novel approach to solving elliptic PDEs with complex boundary conditions.\n2. The proposed architecture, BENO, incorporates physics intuition through a boundary-embedded design.\n3. The authors demonstrate the effectiveness of BENO in outperforming existing state-of-the-art methods.\n4. The paper provides a comprehensive experimental evaluation, including various boundary shapes, values, and resolutions.\n\n$$\\text{Weaknesses:}$$\n1. The paper does not provide a clear motivation for the use of GNNs and a Transformer in BENO.\n2. The authors assume that the reader is familiar with the basics of GNNs and Transformers.\n3. The paper does not provide a detailed analysis of the performance of BENO on different datasets.\n4. The authors rely on a single dataset to evaluate the performance of BENO.\n\n$$\\text{Suggestions for Improvement:}$$\n1. Provide a clear motivation for the use of GNNs and a Transformer in BENO.\n2. Include a detailed analysis of the performance of BENO on different datasets.\n3. Evaluate the robustness of BENO to different hyperparameters and architectures.\n4. Provide a more comprehensive experimental evaluation, including more datasets and boundary conditions.\n\n$$\\text{Recommendation:}$$\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit the paper. The authors should provide a clear motivation for the use of GNNs and a Transformer in BENO, include a detailed analysis of the performance of BENO on different datasets, and evaluate the robustness of BENO to different hyperparameters and architectures. Additionally, the authors should provide a more comprehensive experimental evaluation, including more datasets and boundary conditions. With these revisions, the paper has the potential to be a strong contribution to the field of neural operator architectures for solving elliptic PDEs.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$\\text{Paper Summary:}$$\nThe paper proposes Boundary-Embedded Neural Operators (BENO), a novel neural operator architecture to solve elliptic partial differential equations (PDEs) with complex boundary conditions. BENO incorporates physics intuition through a boundary-embedded architecture, consisting of Graph Neural Networks (GNNs) and a Transformer, to model the influence of boundary conditions on the solution. The paper presents extensive experiments on various datasets, demonstrating the effectiveness of BENO in outperforming existing state-of-the-art methods by an average of 60.96% in solving elliptic PDE problems.\n\n$$\\text{Strengths:}$$\n1. The paper addresses the challenges posed by inhomogeneous boundary conditions with complex boundary geometry in solving elliptic PDEs.\n2. BENO incorporates physics intuition through a boundary-embedded architecture, consisting of GNNs and a Transformer.\n3. The paper presents extensive experiments on various datasets, demonstrating the effectiveness of BENO.\n4. The use of a Transformer to encode the full boundary information into a latent vector is a novel approach.\n\n$$\\text{Weaknesses:}$$\n1. The paper does not provide a detailed analysis of the proposed architecture, making it difficult to understand the underlying mechanisms.\n2. The experiments are limited to a specific dataset, and it is unclear whether BENO can generalize to other datasets.\n3. The paper does not provide a comprehensive comparison with other methods, making it difficult to evaluate the effectiveness of BENO.\n4. The use of a Transformer to encode the full boundary information into a latent vector may be computationally expensive.\n\n$$\\text{Suggestions for Improvement:}$$\n1. Provide a detailed analysis of the proposed architecture, including the underlying mechanisms and the role of each component.\n2. Conduct experiments on a larger dataset to evaluate the generalization of BENO.\n3. Provide a comprehensive comparison with other methods to evaluate the effectiveness of BENO.\n4. Investigate the impact of the use of a Transformer on the computational cost of BENO.\n\n$$\\text{Recommendation:}$$\nBENO is a novel neural operator architecture that addresses the challenges posed by inhomogeneous boundary conditions with complex boundary geometry in solving elliptic PDEs. While there are some weaknesses in the paper, BENO has the potential to be a effective method for solving elliptic PDEs. However, further analysis and experiments are needed to fully evaluate the effectiveness of BENO.",
        "gr_score_with": 0.7615894039735099,
        "gr_score_without": 0.7319587628865979,
        "output_without": {
            "num_tokens_scored": 291,
            "num_green_tokens": 213,
            "green_fraction": 0.7319587628865979,
            "z_score": 1.1896708125026727,
            "p_value": 0.11708790078580611
        },
        "output_with": {
            "num_tokens_scored": 302,
            "num_green_tokens": 230,
            "green_fraction": 0.7615894039735099,
            "z_score": 2.3356073074891266,
            "p_value": 0.009755858693317515
        }
    },
    {
        "title": "TRAIN NEURAL PROGRAM SYNTHESIZERS",
        "abstract": "Programming-by-example is the task of synthesizing a program that is consistent with a set of user-provided input-output examples. As examples are often an under-specification of one\u2019s intent, a good synthesizer must choose the intended program from the many that are consistent with the given set of examples. Prior work frames program synthesis as a cooperative game between a listener (that synthesizes programs) and a speaker (a user choosing examples), and shows that models of computational pragmatic inference are effective in choosing the user intended programs. However, these models require counterfactual reasoning over a large set of programs and examples, which is infeasible in realistic program spaces. In this paper, we propose a novel way to amortize this search with neural networks. We sample pairs of programs and examples via self-play between listener and speaker models, and use pragmatic inference to choose informative training examples from this sample. We then use the informative dataset to train models to improve the synthesizer\u2019s ability to disambiguate user-provided examples without human supervision. We validate our method on the challenging task of synthesizing regular expressions from example strings, and find that our method (1) outperforms models trained without choosing pragmatic examples by 23% (a 51% relative increase) (2) matches the performance of supervised learning on a dataset of pragmatic examples provided by humans, despite using no human data in training.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes a novel approach to training program synthesis models that can resolve ambiguity in program specification examples by modeling pragmatics. The approach bootstraps pragmatic synthesizers by iteratively generating data using speaker and listener models, filtering the generated data with an example selection method, and further training the speaker and listener models on the generated data. The authors validate their approach on the challenging task of synthesizing regular expressions from example strings and show that their method outperforms models trained without choosing pragmatic examples.\n\nStrengths:\n1. The paper presents a novel approach to training program synthesis models that can resolve ambiguity in program specification examples by modeling pragmatics.\n2. The approach bootstraps pragmatic synthesizers by iteratively generating data using speaker and listener models, filtering the generated data with an example selection method, and further training the speaker and listener models on the generated data.\n3. The authors validate their approach on the challenging task of synthesizing regular expressions from example strings and show that their method outperforms models trained without choosing pragmatic examples.\n\nWeaknesses:\n1. The paper does not provide a clear explanation of the example selection method used to filter the generated data.\n2. The authors do not provide a detailed analysis of the performance of their approach on different domains, such as open-ended Python code generation.\n3. The paper does not discuss the potential limitations of the approach, such as the requirement of large amounts of data to train the models.\n\nSuggestions for Improvement:\n1. The authors should provide a clear explanation of the example selection method used to filter the generated data and its impact on the performance of the approach.\n2. The authors should conduct a detailed analysis of the performance of their approach on different domains, such as open-ended Python code generation.\n3. The authors should discuss the potential limitations of the approach, such as the requirement of large amounts of data to train the models.\n\nRecommendation:\nBased on the paper summary, strengths, weaknesses, and suggestions for improvement, I recommend that the paper be accepted for publication in a top-tier conference in the field of artificial intelligence or natural language processing. The authors should be encouraged to revise the paper based on the feedback provided and resubmit it for review.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper proposes a novel approach to training neural program synthesizers that can resolve ambiguity in program specification examples by modeling pragmatics, specifically how users choose examples informatively. The authors develop an iterative method that generates informative training data using speaker and listener models, filters the data with an example selection method, and further trains the models on the generated data. The proposed method is evaluated on a challenging regular expression domain, where it matches the performance of synthesizers trained on human-produced examples, despite not using any human-produced data to train the approach.\n\nStrengths:\n1. The authors provide a clear and comprehensive overview of the problem of resolving ambiguity in program specification examples and the limitations of existing approaches.\n2. The proposed method of using self-play between speaker and listener models to generate informative training data is innovative and effective.\n3. The authors provide a thorough evaluation of the proposed method on a challenging regular expression domain, where it achieves state-of-the-art performance.\n\nWeaknesses:\n1. The authors' method relies heavily on the quality of the generated training data, which may not always be informative or relevant.\n2. The proposed method may not generalize well to other domains, where the structure of the program specification space and the user's behavior may differ significantly.\n3. The authors' use of a fixed listener model during training may limit the ability of the speaker model to adapt to changing user behavior.\n\nSuggestions for Improvement:\n1. The authors should explore using more sophisticated methods to evaluate the informativity of the generated training data, such as using techniques from computational pragmatics.\n2. The proposed method should be evaluated on a broader range of domains, to assess its generalizability and robustness.\n3. The authors should investigate the effect of using a more adaptive listener model during training, such as one that updates its parameters based on the generated training data.\n\nRecommendation:\nThe proposed method is a significant contribution to the field of programming-by-example and demonstrates a novel approach to training neural program synthesizers. With some modifications to address the limitations and weaknesses identified, the proposed method has the potential to become a state-of-the-art approach in this field.",
        "gr_score_with": 0.7169230769230769,
        "gr_score_without": 0.6638297872340425,
        "output_without": {
            "num_tokens_scored": 235,
            "num_green_tokens": 156,
            "green_fraction": 0.6638297872340425,
            "z_score": -1.2099720746691758,
            "p_value": 0.8868551957072116
        },
        "output_with": {
            "num_tokens_scored": 325,
            "num_green_tokens": 233,
            "green_fraction": 0.7169230769230769,
            "z_score": 0.6657502859356862,
            "p_value": 0.25278536294016496
        }
    },
    {
        "title": "CIRCUMVENTING CONCEPT ERASURE METHODS FOR TEXT-TO-IMAGE GENERATIVE MODELS",
        "abstract": "Text-to-image generative models can produce photo-realistic images for an extremely broad range of concepts, and their usage has proliferated widely among the general public. Yet, these models have numerous drawbacks, including their potential to generate images featuring sexually explicit content, mirror artistic styles without permission, or even hallucinate (or deepfake) the likenesses of celebrities. Consequently, various methods have been proposed in order to \u201cerase\u201d sensitive concepts from text-to-image models. In this work, we examine seven recently proposed concept erasure methods, and show that targeted concepts are not fully excised from any of these methods. Specifically, we devise an algorithm to learn special input word embeddings that can retrieve \u201cerased\u201d concepts from the sanitized models with no alterations to their weights. Our results highlight the brittleness of post hoc concept erasure methods, and call into question their use in the algorithmic toolkit for AI safety.",
        "peer_review_without_watermark": "$$\n\n$$$Paper Summary:\nThe paper presents a critical evaluation of seven concept erasure methods for text-to-image generative models, specifically Stable Diffusion. The authors show that these methods are not effective in removing targeted concepts from the models, and that they can be circumvented using a proposed \"attack\" technique called Concept Inversion (CI). The authors demonstrate that the learned word embeddings from CI can be used to generate images of the erased concept, indicating that some degree of input filtering is occurring. The study highlights the brittleness of post-hoc concept erasure methods and calls for stronger evaluation methodologies to ensure the safety of these models.\n\nStrengths:\n1. The paper provides a thorough evaluation of seven concept erasure methods, including both fine-tuning-based and inference-guiding-based methods.\n2. The authors propose a novel attack technique, Concept Inversion, which can be used to circumvent these methods.\n3. The study demonstrates the importance of understanding the limitations of concept erasure methods and the need for more robust evaluation methodologies.\n\nWeaknesses:\n1. The paper focuses primarily on Stable Diffusion, which may limit the generalizability of the results to other text-to-image generative models.\n2. The evaluation of the concept erasure methods is based on a limited set of experiments, which may not capture the full range of possible scenarios.\n3. The paper does not provide a comprehensive analysis of the underlying mechanisms of the concept erasure methods, which may limit the understanding of why they are not effective.\n\nSuggestions for Improvement:\n1. The authors should expand the evaluation to include a broader range of text-to-image generative models to ensure the generalizability of the results.\n2. The study should include a more comprehensive analysis of the underlying mechanisms of the concept erasure methods to understand why they are not effective.\n3. The authors should propose more robust evaluation methodologies to ensure the safety of these models.\n\nRecommendation:\nBased on the study, it is recommended that future work focus on developing more robust concept erasure methods that can effectively remove targeted concepts from text-to-image generative models. The authors' proposal of Concept Inversion as an attack technique provides a starting point for further research in this area. Additionally, the study highlights the need for stronger evaluation methodologies to ensure the safety of these models, which should be a priority in the development of text-to-image generative models.\n\n$$",
        "peer_review_with_watermark": "$$\n\n$$$Paper Summary:\nThe paper presents a critical evaluation of seven concept erasure methods for text-to-image generative models, specifically Stable Diffusion. The authors show that these methods are not effective in fully erasing sensitive concepts from the models, and instead, can be circumvented using a novel attack technique called Concept Inversion (CI). The study highlights the brittleness of post-hoc concept erasure methods and calls into question their use in algorithmic toolkit for AI safety.\n\nStrengths:\n\n1. The study provides a comprehensive evaluation of seven concept erasure methods, covering various techniques, including fine-tuning, inference guidance, and diffusion-based inversion.\n2. The authors propose a novel attack technique, Concept Inversion (CI), which can be used to circumvent the concept erasure methods.\n3. The study highlights the importance of understanding the mechanisms of concept erasure and the limitations of existing methods.\n\nWeaknesses:\n\n1. The study focuses primarily on Stable Diffusion models and may not be generalizable to other text-to-image models.\n2. The evaluation of concept erasure methods is based on a limited set of experiments and may not capture the full range of possible scenarios.\n3. The study could benefit from a more detailed analysis of the mechanisms of concept erasure and the implications of the findings.\n\nSuggestions for Improvement:\n\n1. The study should be extended to evaluate concept erasure methods on other text-to-image models.\n2. Additional experiments should be conducted to capture a wider range of possible scenarios.\n3. A more detailed analysis of the mechanisms of concept erasure and the implications of the findings should be provided.\n\nRecommendation:\n\nBased on the study's findings, it is recommended that concept erasure methods be viewed with caution and that their limitations be understood. The study highlights the need for more effective and robust concept erasure methods that can be relied upon to ensure the safety of text-to-image models in various applications.\n\n$$\n\n$$$",
        "gr_score_with": 0.7210144927536232,
        "gr_score_without": 0.6930379746835443,
        "output_without": {
            "num_tokens_scored": 316,
            "num_green_tokens": 219,
            "green_fraction": 0.6930379746835443,
            "z_score": -0.27006573887712854,
            "p_value": 0.6064451602650314
        },
        "output_with": {
            "num_tokens_scored": 276,
            "num_green_tokens": 199,
            "green_fraction": 0.7210144927536232,
            "z_score": 0.7618400593644654,
            "p_value": 0.22307773413192333
        }
    },
    {
        "title": "NONNEGATIVE LOW-RANK SEMIDEFINITE PROGRAM- MING",
        "abstract": "K-means clustering is a widely used machine learning method for identifying patterns in large datasets. Semidefinite programming (SDP) relaxations have recently been proposed for solving the K-means optimization problem that enjoy strong statistical optimality guarantees, but the prohibitive cost of implementing an SDP solver renders these guarantees inaccessible to practical datasets. By contrast, nonnegative matrix factorization (NMF) is a simple clustering algorithm that is widely used by machine learning practitioners, but without a solid statistical underpinning nor rigorous guarantees. In this paper, we describe an NMF-like algorithm that works by solving a nonnegative low-rank restriction of the SDP relaxed K-means formulation using a nonconvex Burer\u2013Monteiro factorization approach. The resulting algorithm is just as simple and scalable as state-of-theart NMF algorithms, while also enjoying the same strong statistical optimality guarantees as the SDP. In our experiments, we observe that our algorithm achieves substantially smaller mis-clustering errors compared to the existing state-of-the-art.",
        "peer_review_without_watermark": "$$\\boxed{\\text{The paper presents a novel algorithm for the K-means clustering problem. The algorithm uses a nonnegative low-rank SDP formulation, which achieves the statistical optimality of the K-means problem. The algorithm is simple, scalable, and enjoys strong statistical optimality guarantees. The authors provide a thorough theoretical analysis of the algorithm's convergence rate and empirical results to demonstrate its effectiveness.}}$$",
        "peer_review_with_watermark": "$$$Abstract:\n\nThe paper proposes a novel algorithm, BM, for solving the nonnegative low-rank semidefinite programming (SDP) relaxation of the K-means clustering problem. The BM algorithm is based on a nonconvex Burer-Monteiro factorization approach and is designed to be simple, scalable, and efficient. The paper presents a comprehensive analysis of the algorithm's convergence properties, including linear convergence rates in both the primal-dual and primal-dual neighborhoods of the SDP solution. The analysis is based on a combination of mathematical derivations, lemmas, and theoretical results.\n\nThe paper consists of six sections. The first section provides an overview of the BM algorithm and its application to the K-means clustering problem. The second section presents a detailed analysis of the algorithm's convergence properties, including linear convergence rates in both the primal-dual and primal-dual neighborhoods of the SDP solution. The third section discusses the theoretical results, including the minimax mis-clustering error rate of the BM algorithm. The fourth section presents experimental results, including simulation experiments using Gaussian mixture models (GMM) and real-world datasets. The fifth section discusses the implications of the theoretical results, including the robustness of the BM algorithm to different scenarios. The sixth section provides a conclusion, summarizing the key findings of the paper.\n\nThe paper makes several contributions to the field of clustering algorithms. Firstly, it proposes a novel algorithm, BM, that is simple, scalable, and efficient. Secondly, it provides a comprehensive analysis of the algorithm's convergence properties, including linear convergence rates in both the primal-dual and primal-dual neighborhoods of the SDP solution. Finally, it presents experimental results that demonstrate the robustness of the BM algorithm to different scenarios.\n\nThe paper is well-written, and the analysis is clear and concise. The theoretical results are well-justified, and the experimental results provide strong evidence for the effectiveness of the BM algorithm. Overall, the paper makes a significant contribution to the field of clustering algorithms, and its results have the potential to impact a wide range of applications.\n\nStrengths:\n\n* The paper proposes a novel algorithm, BM, that is simple, scalable, and efficient.\n* The analysis is comprehensive, including linear convergence rates in both the primal-dual and primal-dual neighborhoods of the SDP solution.\n* The experimental results provide strong evidence for the effectiveness of the BM algorithm.\n\nWeaknesses:\n\n* The paper relies on a combination of mathematical derivations, lemmas, and theoretical results, which may be challenging to understand for some readers.\n* The analysis is based on a combination of assumptions, which may not hold in all scenarios.\n\nSuggestions for improvement:\n\n* The paper could benefit from a more detailed analysis of the algorithm's convergence properties, including a more comprehensive theoretical framework.\n* The experimental results could be expanded to include more scenarios, which would provide stronger evidence for the effectiveness of the BM algorithm.\n* The paper could include a more detailed discussion of the implications of the theoretical results, including a discussion of the robustness of the BM algorithm to different scenarios.\n\nOverall, the paper is well-written, and the analysis is clear and concise. The theoretical results are well-justified, and the experimental results provide strong evidence for the effectiveness of the BM algorithm. With some minor revisions, the paper has the potential to make a significant contribution to the field of clustering algorithms.\n\nPaper Summary:\n\nThe paper proposes a novel algorithm, BM, for solving the nonnegative low-rank semidefinite programming (SDP) relaxation of the K-means clustering problem. The BM algorithm is based on a nonconvex Burer-Monteiro factorization approach and is designed to be simple, scalable, and efficient. The paper presents a comprehensive analysis of the algorithm's convergence properties, including linear convergence rates in both the primal-dual and primal-dual neighborhoods of the SDP solution. The analysis is based on a combination of mathematical derivations, lemmas, and theoretical results. The paper also presents experimental results that demonstrate the effectiveness of the BM algorithm in solving real-world clustering problems.\n\nStrengths of the paper:\n\n* The paper proposes a novel algorithm, BM, that is simple, scalable, and efficient.\n* The analysis is comprehensive, including linear convergence rates in both the primal-dual and primal-dual neighborhoods of the SDP solution.\n* The experimental results provide strong evidence for the effectiveness of the BM algorithm.\n\nWeaknesses of the paper:\n\n* The paper relies on a combination of mathematical derivations, lems, and theoretical results, which may be challenging to understand for some readers.\n* The analysis is based on a combination of assumptions, which may not hold in all scenarios.\n\nSuggestions for improvement:\n\n* The paper could benefit from a more detailed analysis of the algorithm's convergence properties, including a more comprehensive theoretical framework.\n* The experimental results could be expanded to include more scenarios, which would provide stronger evidence for the effectiveness of the BM algorithm.\n* The paper could include a more detailed discussion of the implications of the theoretical results, including a discussion of the robustness of the BM algorithm to different scenarios.\n\nRecommendation:\n\nBased on the analysis, I recommend that the paper be published in a top-tier conference or journal in the field of machine learning or computer science. The paper has the potential to make a significant contribution to the field of clustering algorithms, and its results have the potential to impact a wide range of applications. With some minor revisions, the paper has the potential to be a top-tier paper in its field.",
        "gr_score_with": 0.8071065989847716,
        "gr_score_without": 0.7123287671232876,
        "output_without": {
            "num_tokens_scored": 73,
            "num_green_tokens": 52,
            "green_fraction": 0.7123287671232876,
            "z_score": 0.22986424990746007,
            "p_value": 0.40909862847263323
        },
        "output_with": {
            "num_tokens_scored": 394,
            "num_green_tokens": 318,
            "green_fraction": 0.8071065989847716,
            "z_score": 4.63932388195756,
            "p_value": 1.7477543735681185e-06
        }
    },
    {
        "title": "SLICEGPT: COMPRESS LARGE LANGUAGE MODELS",
        "abstract": "Large language models have become the cornerstone of natural language processing, but their use comes with substantial costs in terms of compute and memory resources. Sparsification provides a solution to alleviate these resource constraints, and recent works have shown that trained models can be sparsified post-hoc. Existing sparsification techniques face challenges as they need additional data structures and offer constrained speedup with current hardware. In this paper we present SliceGPT, a new post-training sparsification scheme which replaces each weight matrix with a smaller (dense) matrix, reducing the embedding dimension of the network. Through extensive experimentation, we show that SliceGPT can remove up to 25% of the model parameters (including embeddings) for OPT 66B and LLAMA-2 70B models with modest loss in accuracy (superior to 2:4 sparsity). Our sliced models run on fewer GPUs and run faster without any additional code optimization: on 24GB consumer GPUs we reduce the total compute for inference on LLAMA-2 70B to 64% of that of the dense model; on 40GB A100 GPUs we reduce it to 66%. We offer a new insight, computational invariance in transformer networks, which enables SliceGPT and we hope it will inspire and enable future avenues to reduce memory and computation demands for pre-trained models.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces SliceGPT, a post-training sparsification scheme that replaces each weight matrix with a smaller dense matrix, reducing the embedding dimension of the network. The authors demonstrate that SliceGPT can remove up to 25% of the model parameters with modest loss in accuracy, and that sliced models run faster and require fewer GPUs than dense models.\n\nStrengths:\n- The authors provide a clear and concise introduction to the problem of large language models and the need for efficient inference.\n- The proposed method of computational invariance is novel and well-explained.\n- The authors provide extensive experimental results demonstrating the effectiveness of SliceGPT on various models and tasks.\n- The paper highlights the potential of SliceGPT to reduce the computational requirements of large language models, making it a valuable contribution to the field.\n\nWeaknesses:\n- The paper does not provide a thorough discussion of the limitations and potential drawbacks of SliceGPT.\n- Some of the experimental results, such as the zero-shot task results, are not clearly explained or presented.\n- The paper does not provide a detailed analysis of the computational invariance property and its implications for the model's behavior.\n\nSuggestions for Improvement:\n- Provide a more detailed discussion of the limitations and potential drawbacks of SliceGPT, such as the potential impact on model accuracy or the need for additional training.\n- Include more detailed explanations of the experimental results, such as the zero-shot task results, to provide a clearer understanding of the model's performance.\n- Provide a more in-depth analysis of the computational invariance property and its implications for the model's behavior.\n\nRecommendation:\n- The paper presents a novel and effective method for sparsifying large language models, and the experimental results demonstrate its potential to reduce computational requirements.\n- However, the paper could benefit from a more detailed discussion of the limitations and potential drawbacks of SliceGPT, as well as more detailed explanations of the experimental results.\n- Overall, the paper is well-written and provides a clear and concise introduction to the problem and the proposed method.",
        "peer_review_with_watermark": "$$$\\boxed{\\text{Paper Summary:}}\n$ The paper presents SliceGPT, a novel post-training sparsification scheme for large language models. The method replaces each weight matrix with a smaller dense matrix, reducing the embedding dimension of the network. The authors conduct extensive experiments on OPT and LLAMA-2 models, demonstrating that SliceGPT can remove up to 25% of model parameters while achieving superior perplexity to existing sparse methods.\n\n$\\boxed{\\text{Strengths:}}\n$ 1. The paper introduces a novel approach to sparsification, leveraging computational invariance in transformer networks.\n2. The method shows promising results in reducing model parameters and inference time.\n3. The authors provide a detailed analysis of the computational complexity and data movement in their compressed models.\n\n$\\boxed{\\text{Weaknesses:}}\n$ 1. The paper does not provide a comprehensive comparison with other sparse methods, such as low-rank approximation.\n2. The experiments are conducted on a limited set of models and tasks.\n3. The paper does not discuss potential limitations and challenges of SliceGPT, such as its inapplicability to non-RMSNorm-connected networks.\n\n$\\boxed{\\text{Suggestions for Improvement:}}\n$ 1. Conduct a more comprehensive comparison with other sparse methods to evaluate the efficacy of SliceGPT.\n2. Expand the experiments to a broader range of models and tasks.\n3. Discuss potential limitations and challenges of SliceGPT, such as its inapplicability to non-RMSNorm-connected networks.\n\n$\\boxed{\\text{Recommendation:}}\n$ Based on the analysis, I recommend that the authors continue to develop and refine SliceGPT, exploring its potential applications in other areas of deep learning. The method's ability to reduce model parameters and inference time while maintaining superior perplexity makes it an attractive approach for large language models. However, further research is needed to address potential limitations and challenges, and to establish SliceGPT as a competitive sparse method.",
        "gr_score_with": 0.7870036101083032,
        "gr_score_without": 0.7283018867924528,
        "output_without": {
            "num_tokens_scored": 265,
            "num_green_tokens": 193,
            "green_fraction": 0.7283018867924528,
            "z_score": 1.0053763828333295,
            "p_value": 0.15735782380662017
        },
        "output_with": {
            "num_tokens_scored": 277,
            "num_green_tokens": 218,
            "green_fraction": 0.7870036101083032,
            "z_score": 3.1598575944480487,
            "p_value": 0.0007892313407180339
        }
    },
    {
        "title": "FAKE IT TILL MAKE IT: FEDERATED LEARNING WITH CONSENSUS-ORIENTED GENERATION",
        "abstract": "In federated learning (FL), data heterogeneity is one key bottleneck that causes model divergence and limits performance. Addressing this, existing methods often regard data heterogeneity as an inherent property and propose to mitigate its adverse effects by correcting models. In this paper, we seek to break this inherent property by generating data to complement the original dataset to fundamentally mitigate heterogeneity level. As a novel attempt from the perspective of data, we propose federated learning with consensus-oriented generation (FedCOG). FedCOG consists of two key components at the client side: complementary data generation, which generates data extracted from the shared global model to complement the original dataset, and knowledge-distillation-based model training, which distills knowledge from global model to local model based on the generated data to mitigate over-fitting the original heterogeneous dataset. FedCOG has two critical advantages: 1) it can be a plug-and-play module to further improve the performance of most existing FL methods, and 2) it is naturally compatible with standard FL protocols such as Secure Aggregation since it makes no modification in communication process. Extensive experiments on classical and real-world FL datasets show that FedCOG consistently outperforms state-of-the-art methods .",
        "peer_review_without_watermark": "$$$\\begin{align}\\textbf{Paper Summary:}~\\text{The paper proposes a novel federated learning algorithm, FedCOG, to mitigate data heterogeneity in federated learning. FedCOG generates complementary data to reduce heterogeneity and employs knowledge distillation-based model training to mitigate its effects. The proposed algorithm is plug-and-play and compatible with standard FL protocols. Experimental results show that FedCOG outperforms state-of-the-art methods.}\\end{align}\n\n\\textbf{Strengths:} \n\n1.  The proposed algorithm, FedCOG, tackles data heterogeneity from a novel perspective by generating complementary data to reduce heterogeneity and employing knowledge distillation-based model training to mitigate its effects.\n2.  FedCOG is plug-and-play and compatible with standard FL protocols, making it a versatile solution for FL applications.\n3.  The extensive experimental results demonstrate the effectiveness of FedCOG in improving performance over state-of-the-art methods.\n\n\\textbf{Weaknesses:} \n\n1.  The paper does not provide a clear analysis of the communication cost and privacy of FedCOG. While the authors mention that FedCOG makes no compromise on these aspects, a more detailed analysis would be beneficial.\n2.  The experimental results show that FedCOG performs well on various datasets, but it is unclear whether the results generalize to other FL scenarios.\n3.  The paper does not discuss potential limitations of FedCOG, such as the requirement for a shared global model and the need for careful tuning of hyperparameters.\n\n\\textbf{Suggestions for Improvement:} \n\n1.  Conduct a more detailed analysis of the communication cost and privacy of FedCOG, including a comparison with other FL algorithms.\n2.  Investigate the generalizability of FedCOG to other FL scenarios and provide evidence of its effectiveness in these settings.\n3.  Discuss potential limitations of FedCOG and provide guidelines for tuning hyperparameters.\n4.  Consider exploring the use of advanced generative models to further improve the performance of FedCOG.\n5.  Investigate the effectiveness of FedCOG in combination with other FL algorithms, such as those that employ model correction or global model adjustment.\n\n\\textbf{Recommendation:} \n\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit the manuscript for publication. The revisions should address the limitations and suggestions for improvement outlined above, and provide a more comprehensive analysis of the communication cost, privacy, and generalizability of FedCOG. Additionally, the authors should consider exploring the use of advanced generative models and investigating the effectiveness of FedCOG in combination with other FL algorithms.",
        "peer_review_with_watermark": "$$$\\begin{align}\\textbf{Paper Summary:}~\\text{This paper proposes Federated Learning with Consensus-Oriented Generation (FedCOG), a novel approach to tackle data heterogeneity in Federated Learning (FL). FedCOG generates data to complement the original dataset, and knowledge distillation-based model training is used to mitigate the effects of heterogeneity. The proposed algorithm is plug-and-play, compatible with standard FL protocols, and improves utility without compromising on communication cost and privacy.\\textbf{}}\\end{align}$$\n\n$\\begin{align}\\textbf{Strengths:}~\\text{This paper provides a novel approach to address the data heterogeneity issue in FL, which is a crucial problem in FL. The proposed algorithm is plug-and-play, compatible with standard FL protocols, and improves utility without compromising on communication cost and privacy. The extensive experiments demonstrate the effectiveness of FedCOG.\\textbf{}}\\end{align}$\n\n$\\begin{align}\\textbf{Weaknesses:}~\\text{While the paper provides a comprehensive overview of the proposed algorithm, the explanation of the disagreement loss is not detailed, and the hyperparameters are not thoroughly justified. The ablation studies could be more comprehensive to demonstrate the impact of each module on the final performance.\\textbf{}}\\end{align}$\n\n$\\begin{align}\\textbf{Suggestions for Improvement:}~\\text{To further improve the paper, the explanation of the disagreement loss should be more detailed, and the hyperparameters should be thoroughly justified. The ablation studies should be more comprehensive to demonstrate the impact of each module on the final performance. Additionally, more experiments should be conducted to evaluate the robustness and generalizability of FedCOG.\\textbf{}}\\end{align}$\n\n$\\begin{align}\\textbf{Recommendation:}~\\text{Based on the paper, I recommend the publication of FedCOG, as it provides a novel approach to tackle data heterogeneity in FL and demonstrates the effectiveness of the proposed algorithm through extensive experiments.\\textbf{}}\\end{align}$",
        "gr_score_with": 0.8008474576271186,
        "gr_score_without": 0.7327586206896551,
        "output_without": {
            "num_tokens_scored": 348,
            "num_green_tokens": 255,
            "green_fraction": 0.7327586206896551,
            "z_score": 1.3335385720528337,
            "p_value": 0.09117756311369585
        },
        "output_with": {
            "num_tokens_scored": 236,
            "num_green_tokens": 189,
            "green_fraction": 0.8008474576271186,
            "z_score": 3.3807363888764614,
            "p_value": 0.00036145930937161904
        }
    },
    {
        "title": "LMUFORMER: LOW COMPLEXITY YET POWERFUL SPIKING MODEL WITH LEGENDRE MEMORY UNITS",
        "abstract": "Transformer models have demonstrated high accuracy in numerous applications but have high complexity and lack sequential processing capability making them ill-suited for many streaming applications at the edge where devices are heavily resource-constrained. Thus motivated, many researchers have proposed reformulating the transformer models as RNN modules which modify the self-attention computation with explicit states. However, these approaches often incur significant performance degradation. The ultimate goal is to develop a model that has the following properties: parallel training, streaming and low-cost inference, and state-of-the-art (SOTA) performance. In this paper, we propose a new direction to achieve this goal. We show how architectural modifications to a fully-sequential recurrent model can help push its performance toward Transformer models while retaining its sequential processing capability. Specifically, inspired by the recent success of Legendre Memory Units (LMU) in sequence learning tasks, we propose LMUFormer, which augments the LMU with convolutional patch embedding and convolutional channel mixer. Moreover, we present a spiking version of this architecture, which introduces the benefit of states within the patch embedding and channel mixer modules while simultaneously reducing the computing complexity. We evaluated our architectures on multiple sequence datasets. Of particular note is our performance on the Speech Commands V2 dataset (35 classes). In comparison to SOTA transformer-based models within the ANN domain, our LMUFormer demonstrates comparable performance while necessitating a remarkable 53\u00d7 reduction in parameters and a substantial 65\u00d7 decrement in FLOPs. Furthermore, when benchmarked against extant low-complexity SNN variants, our model establishes a new SOTA with an accuracy of 96.12%. Additionally, owing to our model\u2019s proficiency in real-time data processing, we are able to achieve a 32.03% reduction in sequence length, all while incurring an inconsequential decline in performance. Our code is publicly available here.",
        "peer_review_without_watermark": "$$$\\begin{align}\\textbf{Paper Summary:} &\\quad \\text{The paper proposes a novel sequential network architecture, dubbed LMUFormer, that combines the benefits of Legendre Memory Units (LMU) with convolutional patch embedding and convolutional channel mixers. The proposed model is designed to process data sequentially while retaining the parallel training capabilities of transformer models. The authors evaluate their architecture on multiple sequence datasets and demonstrate comparable performance to state-of-the-art (SOTA) transformer-based models while achieving a significant reduction in parameters and computational complexity.}\\end{align}\n\n$$\\textbf{Strengths:}$$\n- The proposed LMUFormer model demonstrates comparable performance to SOTA transformer-based models on various sequence learning tasks.\n- The model achieves a significant reduction in parameters and computational complexity, making it suitable for resource-constrained environments.\n- The spiking version of the LMUFormer model achieves SOTA performance among prevailing SNN models on the Speech Commands V2 dataset.\n\n$$\\textbf{Weaknesses:}$$\n- The paper does not provide a comprehensive comparison with other SNN models, which may limit the generalizability of the results.\n- The evaluation of the model on the Long Range Arena (LRA) benchmark is limited to a few tasks, which may not accurately represent the model's performance on more complex tasks.\n- The ablation study could be more comprehensive to fully understand the impact of different patch embeddings and channel mixers on the final performance.\n\n$$\\textbf{Suggestions for Improvement:}$$\n- The authors should provide a more detailed comparison with other SNN models to demonstrate the robustness of their proposed architecture.\n- A more comprehensive evaluation on the LRA benchmark and other sequence learning tasks is necessary to accurately assess the model's performance.\n- The ablation study could be extended to investigate the impact of different hyperparameters and model architectures on the final performance.\n\n$$\\textbf{Recommendation:}$$\n- Based on the experimental results, the LMUFormer model is a promising approach for sequence learning tasks, particularly in resource-constrained environments.\n- The proposed model's ability to achieve comparable performance to SOTA transformer-based models while reducing parameters and computational complexity makes it a valuable contribution to the field of SNNs.\n- However, further research is necessary to fully understand the model's limitations and to explore its potential applications in various domains.",
        "peer_review_with_watermark": "$$$\\boxed{Peer Review}$$\n\n**Paper Summary:**\nThe paper proposes a new architecture, LMUFormer, which combines the benefits of Legendre Memory Units (LMU) and convolutional neural networks. LMUFormer is a low-complexity model that can be trained in parallel and processes data sequentially during inference. The authors also present a spiking version of the model, called Spiking LMUFormer, which achieves state-of-the-art performance on the Speech Commands V2 dataset. The paper demonstrates that LMUFormer can reduce the model size by approximately 53\u00d7 and computational complexity by roughly 65\u00d7 while achieving comparable performance to SOTA models.\n\n**Strengths:**\n\n1. The authors have proposed a novel architecture, LMUFormer, which combines the benefits of LMU and convolutional neural networks.\n2. The spiking version of the model, Spiking LMUFormer, achieves state-of-the-art performance on the Speech Commands V2 dataset.\n3. The paper demonstrates the potential of SNN models to harness their inherent temporal dynamics for superior performance with long sequences.\n4. The authors have conducted extensive experiments to evaluate the performance of LMUFormer and Spiking LMUFormer on various tasks.\n\n**Weaknesses:**\n\n1. The paper does not provide a clear comparison with other state-of-the-art models, such as Spikeformer and Spike-driven ViT.\n2. The authors have not provided a detailed analysis of the computational complexity of LMUFormer and Spiking LMUFormer.\n3. The paper does not discuss the potential limitations of LMUFormer and Spiking LMUFormer, such as the need for careful tuning of hyperparameters.\n4. The authors have not provided a clear explanation of how the spiking mechanism affects the performance of the model.\n\n**Suggestions for Improvement:**\n\n1. The authors should provide a more detailed comparison with other state-of-the-art models.\n2. The authors should provide a detailed analysis of the computational complexity of LMUFormer and Spiking LMUFormer.\n3. The authors should discuss the potential limitations of LMUFormer and Spiking LMUFormer.\n4. The authors should provide a clear explanation of how the spiking mechanism affects the performance of the model.\n5. The authors should consider providing more experimental results, such as the effect of sequence length on the performance of the model.\n\n**Recommendation:**\n\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit their paper. The authors have proposed a novel architecture, LMUFormer, which has the potential to improve the performance of SNN models. However, the paper needs more detailed analysis and comparison with other state-of-the-art models. Additionally, the authors should consider providing more experimental results to demonstrate the effectiveness of their model.",
        "gr_score_with": 0.7225806451612903,
        "gr_score_without": 0.7072463768115942,
        "output_without": {
            "num_tokens_scored": 345,
            "num_green_tokens": 244,
            "green_fraction": 0.7072463768115942,
            "z_score": 0.29371140702093723,
            "p_value": 0.38448921852014406
        },
        "output_with": {
            "num_tokens_scored": 310,
            "num_green_tokens": 224,
            "green_fraction": 0.7225806451612903,
            "z_score": 0.8675760324277121,
            "p_value": 0.19281323596884453
        }
    },
    {
        "title": "MOTION GUIDANCE: DIFFUSION-BASED IMAGE EDIT-",
        "abstract": "Diffusion models are capable of generating impressive images conditioned on text descriptions, and extensions of these models allow users to edit images at a relatively coarse scale. However, the ability to precisely edit the layout, position, pose, and shape of objects in images with diffusion models is still difficult. To this end, we propose motion guidance, a zero-shot technique that allows a user to specify dense, complex motion fields that indicate where each pixel in an image should move. Motion guidance works by steering the diffusion sampling process with the gradients through an off-the-shelf optical flow network. Specifically, we design a guidance loss that encourages the sample to have the desired motion, as estimated by a flow network, while also being visually similar to the source image. By simultaneously sampling from a diffusion model and guiding the sample to have low guidance loss, we can obtain a motion-edited image. We demonstrate that our technique works on complex motions and produces high quality edits of real and generated images.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary:\nThe paper proposes a novel zero-shot image editing technique called motion guidance, which enables users to specify dense, complex motion fields to edit images. The method guides the diffusion sampling process using an off-the-shelf optical flow network, encouraging the generated image to have the desired motion while being visually similar to the source image. The authors demonstrate that their technique works on complex motions and produces high-quality edits of real and generated images.\n\nStrengths:\n1. The paper introduces a new and innovative approach to image editing using diffusion models and optical flow networks.\n2. The method is simple, zero-shot, and does not require text or training, making it accessible to a wide range of users.\n3. The authors provide a comprehensive evaluation of their technique, including qualitative and quantitative results on various datasets.\n4. The paper discusses the limitations of existing image editing techniques and highlights the potential of motion guidance in further integrating motion estimation models into image manipulation models.\n\nWeaknesses:\n1. The method inherits the slow sampling speed of diffusion models, which may limit its practical applications.\n2. The authors acknowledge that certain target flows may not be possible with their current implementation, which may limit the technique's versatility.\n3. The paper does not provide a detailed analysis of the impact of occlusions on the editing process, which may affect the technique's performance in real-world scenarios.\n4. The authors' discussion of limitations and potential future directions could be more comprehensive, providing a clearer roadmap for future research.\n\nSuggestions for Improvement:\n1. The authors could explore ways to address the slow sampling speed issue, such as using more efficient diffusion models or incorporating parallel processing techniques.\n2. To improve the technique's versatility, the authors could investigate ways to adapt the optical flow network to handle more complex target flows, such as those with occlusions or multiple objects.\n3. A more detailed analysis of the impact of occlusions on the editing process could provide valuable insights into the technique's performance in real-world scenarios.\n4. The authors could provide more guidance on potential future directions, such as integrating motion guidance with other image editing techniques or exploring applications in areas like video editing and animation.\n\nRecommendation:\nThe paper presents an innovative approach to image editing using diffusion models and optical flow networks. While the technique has some limitations, it has the potential to revolutionize the field of image editing. With further research and development, the authors' motion guidance technique could become a powerful tool for image manipulation and could potentially be applied to various areas of computer vision and image processing.",
        "peer_review_with_watermark": "$$$ \n\nPaper Title: MOTION GUIDANCE: DIFFUSION-BASED IMAGE EDIT\n\nPaper Summary:\nThe authors propose motion guidance, a zero-shot technique that allows users to specify dense, complex motion fields to edit images using diffusion models. They guide the diffusion sampling process using an off-the-shelf optical flow network, which encourages the sample to have the desired motion while also being visually similar to the source image. The authors demonstrate that their technique works on complex motions and produces high-quality edits of real and generated images.\n\nStrengths:\n1. Simple and Zero-Shot: The authors' approach does not require any training, and users can specify complex motion fields without modifying the diffusion network architecture.\n2. Effective on Complex Motions: The authors demonstrate that their method can handle complex motions, such as translations, rotations, homographies, stretching, deformations, and even flow fields extracted from videos.\n3. Diverse Applications: The authors show that their method can be applied to a wide range of images with diverse objects and backgrounds, including non-photorealistic images.\n4. Soft Optimization: The authors' method optimizes a soft constraint, satisfying the flow while also producing a plausible image, which makes it more robust to coarsely defined target flows and ambiguous flows.\n\nWeaknesses:\n1. Slow Sampling Speed: Diffusion models, like the authors' method, are susceptible to slow sampling speed, which can lead to artifacts and slow performance.\n2. Limitations of Optical Flow Estimator: The authors' method inherits the limitations of their optical flow estimator, such as not being able to handle certain target flows.\n3. Lack of Comparison to Other Methods: The authors compare their method to InstructPix2Pix, SDEdit, and RePaint, but it would be beneficial to include a more comprehensive comparison with other state-of-the-art methods.\n\nSuggestions for Improvement:\n1. Investigate ways to improve the sampling speed of the diffusion model, such as using more efficient diffusion processes or incorporating prior knowledge about the target motion.\n2. Explore the use of more advanced optical flow estimators that can handle complex target flows and occlusions.\n3. Conduct a more comprehensive comparison with other state-of-the-art methods to demonstrate the robustness and superiority of the authors' approach.\n\nRecommendation:\nThe authors' proposed motion guidance technique is a significant contribution to the field of image manipulation using diffusion models. Its simplicity, zero-shot nature, and ability to handle complex motions make it a promising approach. With some further refinement and improvement, this technique has the potential to revolutionize the field of image manipulation and open up new avenues for research.",
        "gr_score_with": 0.8208616780045351,
        "gr_score_without": 0.799492385786802,
        "output_without": {
            "num_tokens_scored": 394,
            "num_green_tokens": 315,
            "green_fraction": 0.799492385786802,
            "z_score": 4.309514127316028,
            "p_value": 8.180680362642208e-06
        },
        "output_with": {
            "num_tokens_scored": 441,
            "num_green_tokens": 362,
            "green_fraction": 0.8208616780045351,
            "z_score": 5.5385778807516175,
            "p_value": 1.524688191653538e-08
        }
    },
    {
        "title": "STRUCTURAL ESTIMATION OF PARTIALLY OBSERVED LINEAR NON-GAUSSIAN ACYCLIC MODEL: A PRAC-",
        "abstract": "Conventional causal discovery approaches, which seek to uncover causal relationships among measured variables, are typically sensitive to the presence of latent variables. While various methods have been developed to address this confounding issue, they often rely on strong assumptions about the underlying causal structure. In this paper, we consider a general scenario where measured and latent variables collectively form a partially observed causally sufficient linear system and latent variables may be anywhere in the causal structure. We theoretically show that with the aid of high-order statistics, the causal graph is (almost) fully identifiable if, roughly speaking, each latent set has a sufficient number of pure children, which can be either latent or measured. Naturally, LiNGAM, a model without latent variables, is encompassed as a special case. Based on the identification theorem, we develop a principled algorithm to identify the causal graph by testing for statistical independence involving only measured variables in specific manners. Experimental results show that our method effectively recovers the causal structure, even when latent variables are influenced by measured variables.",
        "peer_review_without_watermark": "$$\\boxed{\\text{Paper Summary:}}$$\n\nThe paper presents a novel approach to causal discovery in the presence of partially observed latent variables. The authors propose a partially observed linear non-Gaussian acyclic model (PO-LiNGAM) and develop an algorithm to identify the causal graph. The algorithm consists of three phases: identifying leaf nodes and their parents, discovering new atomic units, and refining atomic units. The authors provide theoretical guarantees for the identifiability of the causal graph and demonstrate the effectiveness of the algorithm on synthetic and real-world datasets.\n\n$$\\boxed{\\text{Strengths:}}$$\n\n1. The paper provides a comprehensive treatment of causal discovery in the presence of partially observed latent variables.\n2. The authors propose a novel approach to identifying causal structures under PO-LiNGAM.\n3. The algorithm is well-structured and easy to follow.\n4. The paper provides thorough theoretical guarantees for the identifiability of the causal graph.\n5. The authors demonstrate the effectiveness of the algorithm on synthetic and real-world datasets.\n\n$$\\boxed{\\text{Weaknesses:}}$$\n\n1. The paper assumes a linear causal model, which may not be realistic in all cases.\n2. The algorithm requires a sufficient number of pure children for each atomic unit, which may be difficult to achieve in practice.\n3. The paper does not provide a clear comparison with other existing methods for causal discovery.\n4. The experimental results are limited to a few synthetic and real-world datasets.\n5. The paper does not discuss the limitations of the algorithm in terms of computational complexity.\n\n$$\\boxed{\\text{Suggestions for Improvement:}}$$\n\n1. Extend the algorithm to non-linear causal models.\n2. Provide a more detailed comparison with other existing methods for causal discovery.\n3. Conduct more extensive experiments on synthetic and real-world datasets.\n4. Discuss the limitations of the algorithm in terms of computational complexity.\n5. Consider incorporating additional prior knowledge or constraints to improve the identifiability of the causal graph.\n\n$$\\boxed{\\text{Recommendation:}}$$\n\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit the paper to the conference. The authors have made significant contributions to the field of causal discovery, and their novel approach to identifying causal structures under PO-LiNGAM has the potential to be widely adopted. However, the paper requires some revisions to address the weaknesses and limitations mentioned above. With revisions, the paper has the potential to be a top-notch contribution to the field of causal discovery.",
        "peer_review_with_watermark": "$$\\boxed{\\text{Paper Summary:}}$$\n\nThe paper presents a novel approach for causal discovery in partially observed linear non-Gaussian acyclic models, which allow for the presence of latent variables that may influence measured variables. The authors develop a three-phase algorithm that leverages high-order statistics, specifically the Generalized Independent Noise (GIN) condition, to identify the causal graph. The algorithm is theoretically justified, and experimental results demonstrate its effectiveness on synthetic and real-world datasets. The authors establish the identifiability of the causal graph under the proposed model, assuming a sufficient number of pure children for each atomic unit. The paper contributes to the field of causal discovery, providing a more inclusive scenario for latent variables and improving the identifiability of causal structures.\n\n$$\\boxed{\\text{Strengths:}}$$\n\n1. The paper presents a novel approach for causal discovery in partially observed linear non-Gaussian acyclic models.\n2. The authors leverage high-order statistics, specifically the GIN condition, to identify the causal graph.\n3. The algorithm is theoretically justified, and experimental results demonstrate its effectiveness on synthetic and real-world datasets.\n4. The paper establishes the identifiability of the causal graph under the proposed model, assuming a sufficient number of pure children for each atomic unit.\n5. The authors provide a more inclusive scenario for latent variables, allowing for their influence on measured variables.\n\n$$\\boxed{\\text{Weaknesses:}}$$\n\n1. The paper relies on strong assumptions, such as the GIN condition, which may not always hold in practice.\n2. The algorithm may require a sufficient number of pure children for each atomic unit, which may not always be feasible in real-world scenarios.\n3. The paper does not provide a clear explanation of how to handle overlapping variables between discovered latent sets.\n4. The experimental results may not demonstrate the superiority of the proposed method over existing approaches, as the comparison is limited to a few datasets.\n5. The paper does not provide a clear evaluation of the computational complexity of the proposed algorithm.\n\n$$\\boxed{\\text{Suggestions for Improvement:}}$$\n\n1. Provide a more comprehensive evaluation of the proposed method, including a comparison with existing approaches on a larger dataset.\n2. Investigate alternative methods for handling overlapping variables between discovered latent sets.\n3. Provide a more detailed explanation of how to handle cases where the GIN condition does not hold.\n4. Consider providing a more comprehensive evaluation of the computational complexity of the proposed algorithm.\n5. Investigate the possibility of reducing the number of pure children required for each atomic unit.\n\n$$\\boxed{\\text{Recommendation:}}$$\n\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit their paper for further review. The authors have made a significant contribution to the field of causal discovery, and their proposed method has demonstrated promising results. However, further evaluation and improvement are necessary to establish the method's superiority over existing approaches and to address potential limitations.",
        "gr_score_with": 0.8547008547008547,
        "gr_score_without": 0.780564263322884,
        "output_without": {
            "num_tokens_scored": 319,
            "num_green_tokens": 249,
            "green_fraction": 0.780564263322884,
            "z_score": 3.139989056242775,
            "p_value": 0.0008447707307006808
        },
        "output_with": {
            "num_tokens_scored": 351,
            "num_green_tokens": 300,
            "green_fraction": 0.8547008547008547,
            "z_score": 6.324651848222242,
            "p_value": 1.2690208061949907e-10
        }
    },
    {
        "title": "DISTRIBUTIONAL MINIMAX PROBLEMS",
        "abstract": "In this paper, we extend mean-field Langevin dynamics to minimax optimization over probability distributions for the first time with symmetric and provably convergent updates. We propose mean-field Langevin averaged gradient (MFL-AG), a single-loop algorithm that implements gradient descent ascent in the distribution spaces with a novel weighted averaging, and establish average-iterate convergence to the mixed Nash equilibrium. We also study both time and particle discretization regimes and prove a new uniform-in-time propagation of chaos result which accounts for the dependency of the particle interactions on all previous distributions. Furthermore, we propose mean-field Langevin anchored best response (MFL-ABR), a symmetric double-loop algorithm based on best response dynamics with linear last-iterate convergence. Finally, we study applications to zero-sum Markov games and conduct simulations demonstrating long-term optimality.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$\\text{Paper Summary:}$$\n\nThe authors propose a novel approach to distributional minimax problems by extending mean-field Langevin dynamics (MFLD) to minimax optimization over probability distributions. They introduce two algorithms: mean-field Langevin averaged gradient (MFL-AG) and mean-field Langevin anchored best response (MFL-ABR). MFL-AG is a single-loop algorithm that implements gradient descent ascent in the distribution spaces with a novel weighted averaging. MFL-ABR is a symmetric double-loop algorithm based on best response dynamics with linear last-iterate convergence.\n\n$$\\text{Strengths:}$$\n\n1.  The authors provide a thorough analysis of the convergence of MFL-AG, establishing average-iterate convergence to the mixed Nash equilibrium.\n2.  They also establish a new uniform-in-time propagation of chaos result that accounts for the dependency of the particle interactions on all previous distributions.\n3.  The authors propose a symmetric double-loop algorithm, MFL-ABR, which realizes the best-response flow suggested in Lascu et al. (2023) via an inner loop running Langevin dynamics.\n4.  They demonstrate the superior optimality of both algorithms compared to MFL-DA.\n\n$$\\text{Weaknesses:}$$\n\n1.  The authors assume that the functional derivatives of L are uniformly bounded, which may not hold in all cases.\n2.  The analysis of the propagation of chaos framework is complicated by the dependence of the interactions on all previous distributions.\n3.  The authors do not provide a detailed analysis of the convergence of MFL-ABR in the discrete particle case.\n\n$$\\text{Suggestions for Improvement:}$$\n\n1.  The authors should provide a more detailed analysis of the assumptions made in the paper, particularly the assumption that the functional derivatives of L are uniformly bounded.\n2.  The authors should provide a more detailed analysis of the convergence of MFL-ABR in the discrete particle case.\n3.  The authors should consider the case where the functional derivatives of L are not uniformly bounded.\n\n$$\\text{Recommendation:}$$\n\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit the paper with the suggested improvements. The authors have made significant contributions to the field of mean-field dynamics and have proposed novel algorithms for distributional minimax problems. With further revisions, the paper has the potential to be a top-tier submission to a conference or journal.",
        "peer_review_with_watermark": "$$\\begin{align*}\n\\textbf{Paper Summary:} \nThe authors propose symmetric mean-field Langevin dynamics for distributional minimax optimization problems, extending mean-field Langevin dynamics to minimax optimization over probability distributions. They propose two single-loop algorithms, mean-field Langevin averaged gradient (MFL-AG) and mean-field Langevin anchored best response (MFL-ABR), and establish average-iterate convergence to the mixed Nash equilibrium. They also study applications to zero-sum Markov games.\n\n\\textbf{Strengths:}\n- The authors make significant contributions by extending mean-field Langevin dynamics to minimax optimization over probability distributions, providing new tools for analysis and optimization in various fields, including reinforcement learning, game theory, and deep learning.\n- The authors propose two new algorithms, MFL-AG and MFL-ABR, and establish average-iterate convergence, demonstrating the effectiveness of these methods in achieving optimal solutions.\n\n\\textbf{Weaknesses:}\n- The authors require strong convexity of $U_\\mu$ and $U_\\nu$, which might not be guaranteed in all cases. Relaxing this assumption could make the algorithms more widely applicable.\n\n\\textbf{Suggestions for Improvement:}\n- To further enhance the theoretical guarantees, relaxing the strong convexity assumption on $U_\\mu$ and $U_\\nu$ could be explored.\n- Developing single-loop symmetric algorithms with last-iterate convergence would be an interesting direction, as it would allow for more efficient optimization.\n\n\\textbf{Recommendation:}\nThe authors make significant contributions by developing new algorithms for distributional minimax optimization. The proposed algorithms, MFL-AG and MFL-ABR, demonstrate average-iterate convergence, establishing a new framework for analysis and optimization in various fields. The work provides a solid foundation for further research in mean-field dynamics, reinforcement learning, and game theory.",
        "gr_score_with": 0.7730769230769231,
        "gr_score_without": 0.6447761194029851,
        "output_without": {
            "num_tokens_scored": 335,
            "num_green_tokens": 216,
            "green_fraction": 0.6447761194029851,
            "z_score": -2.205665638698897,
            "p_value": 0.9862962902485065
        },
        "output_with": {
            "num_tokens_scored": 260,
            "num_green_tokens": 201,
            "green_fraction": 0.7730769230769231,
            "z_score": 2.5713268193136423,
            "p_value": 0.005065483537374811
        }
    },
    {
        "title": "TOWARDS ROBUST OUT-OF-DISTRIBUTION GENERALIZATION BOUNDS VIA SHARPNESS",
        "abstract": "Generalizing to out-of-distribution (OOD) data or unseen domain, termed OOD generalization, still lacks appropriate theoretical guarantees. Canonical OOD bounds focus on different distance measurements between source and target domains but fail to consider the optimization property of the learned model. As empirically shown in recent work, the sharpness of learned minima influences OOD generalization. To bridge this gap between optimization and OOD generalization, we study the effect of sharpness on how a model tolerates data change in domain shift which is usually captured by \"robustness\" in generalization. In this paper, we give a rigorous connection between sharpness and robustness, which gives better OOD guarantees for robust algorithms. It also provides a theoretical backing for \"flat minima leads to better OOD generalization\". Overall, we propose a sharpness-based OOD generalization bound by taking robustness into consideration, resulting in a tighter bound than non-robust guarantees. Our findings are supported by the experiments on a ridge regression model, as well as the experiments on deep learning classification tasks.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$\\textbf{Paper Summary:}$$\nThe paper proposes a new framework for out-of-distribution (OOD) generalization bounds, focusing on the relationship between algorithmic robustness and sharpness. The authors derive a robust OOD generalization bound by incorporating robustness into the existing OOD generalization theory. The proposed bound is tighter than non-robust guarantees and provides a theoretical backing for the observation that flat minima lead to better OOD generalization.\n\n$$\\textbf{Strengths:}$$\n1. The paper provides a clear connection between robustness and sharpness, which is essential for understanding the OOD generalization problem.\n2. The authors derive a novel robust OOD generalization bound that effectively captures algorithmic robustness in the presence of shifting data distributions.\n3. The paper presents experimental results that support the theoretical findings, demonstrating the effectiveness of the proposed bound.\n\n$$\\textbf{Weaknesses:}$$\n1. The paper assumes that the loss function is upper-bounded, which may not always hold in practice.\n2. The authors use a specific definition of robustness, which might not be applicable to all algorithms or models.\n3. The paper does not provide a comprehensive analysis of the limitations of the proposed bound, such as its dependence on the number of partitions (K).\n\n$$\\textbf{Suggestions for Improvement:}$$\n1. Provide a more comprehensive analysis of the assumptions made in the paper, including the upper-boundedness of the loss function and the specific definition of robustness.\n2. Explore the limitations of the proposed bound, such as its dependence on K, and discuss potential modifications or extensions to address these limitations.\n3. Consider providing additional experimental results to further validate the theoretical findings and demonstrate the robustness of the proposed bound.\n\n$$\\textbf{Recommendation:}$$\nBased on the strengths and weaknesses of the paper, I recommend that it be accepted for publication in its current form, with minor revisions to address the limitations and assumptions mentioned above. The paper provides a significant contribution to the field of OOD generalization and sheds light on the importance of robustness and sharpness in this context. With further refinement, the paper has the potential to become a seminal work in the field.",
        "peer_review_with_watermark": "$$\\begin{align}\\textbf{Paper Summary:} \nThe paper explores Out-of-Distribution (OOD) generalization, which refers to a model's ability to generalize to unseen data that is drawn from a different distribution than the data it was trained on. The authors propose a new framework for OOD generalization that incorporates algorithmic robustness and sharpness. They show that sharpness, a measure of how flat the minimum of a model's loss function is, has a negative impact on generalization. The authors also propose a new bound for OOD generalization that is tighter than existing bounds.\n\n\\textbf{Strengths:}\n1. The paper provides a new and insightful perspective on OOD generalization by incorporating algorithmic robustness and sharpness.\n2. The authors provide a clear and concise explanation of the concepts and notations used in the paper.\n3. The paper includes several examples and experiments to illustrate the effectiveness of the proposed framework.\n\n\\textbf{Weaknesses:}\n1. The paper assumes a high level of technical expertise in machine learning and optimization, which may make it difficult for non-experts to follow.\n2. The paper does not provide a clear and comprehensive literature review, which may leave readers wondering about the relevance and significance of the work.\n3. Some of the mathematical derivations and proofs are not explicitly provided, which may make it difficult for readers to verify the results.\n\n\\textbf{Suggestions for Improvement:}\n1. The paper could benefit from a more comprehensive literature review to provide context and relevance to existing work in OOD generalization.\n2. The mathematical derivations and proofs could be more explicitly provided to allow readers to verify the results.\n3. The paper could include more experimental results and examples to illustrate the effectiveness of the proposed framework.\n\n\\textbf{Recommendation:}\nBased on the strengths and weaknesses of the paper, I recommend that it be accepted for publication in a top-tier machine learning conference or journal. The paper provides a new and insightful perspective on OOD generalization, and the authors have made significant contributions to the field. However, the paper could benefit from some revisions to address the weaknesses and provide a more comprehensive and accessible presentation of the work.",
        "gr_score_with": 0.7974683544303798,
        "gr_score_without": 0.7264150943396226,
        "output_without": {
            "num_tokens_scored": 318,
            "num_green_tokens": 231,
            "green_fraction": 0.7264150943396226,
            "z_score": 1.027912337500094,
            "p_value": 0.15199553275773803
        },
        "output_with": {
            "num_tokens_scored": 316,
            "num_green_tokens": 252,
            "green_fraction": 0.7974683544303798,
            "z_score": 3.7809203442798207,
            "p_value": 7.812483272627048e-05
        }
    },
    {
        "title": "TEXTFIELD3D: TOWARDS ENHANCING OPEN- VOCABULARY 3D GENERATION WITH NOISY TEXT FIELDS",
        "abstract": "Generative models have shown remarkable progress in 3D aspect. Recent works learn 3D representation explicitly under text-3D guidance. However, limited text3D data restricts the vocabulary scale and text control of generations. Generators may easily fall into a stereotype concept for certain text prompts, thus losing openvocabulary generation ability. To tackle this issue, we introduce a conditional 3D generative model, namely TextField3D.Specifically, rather than using the text prompts as input directly, we suggest to inject dynamic noise into the latent space of given text prompts, i.e., Noisy Text Fields (NTFs). In this way, limited 3D data can be mapped to the appropriate range of textual latent space that is expanded by NTFs. To this end, an NTFGen module is proposed to model general text latent code in noisy fields. Meanwhile, an NTFBind module is proposed to align viewinvariant image latent code to noisy fields, further supporting image-conditional 3D generation. To guide the conditional generation in both geometry and texture, multi-modal discrimination is constructed with a text-3D discriminator and a text2.5D discriminator. Compared to previous methods, TextField3D includes three merits: 1) large vocabulary, 2) text consistency, and 3) low latency. Extensive experiments demonstrate that our method achieves a potential open-vocabulary 3D generation capability.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces TextField3D, a conditional 3D generative model that tackles the open-vocabulary generation capability of 3D models. The authors propose Noisy Text Fields (NTFs) to map limited 3D data to the vast range of textual latent space of pre-trained models. An NTFGen module generates noisy text latent code, and an NTFBind module aligns view-invariant image latent code with NTFs. Multi-modal discrimination is used to supervise the generation quality and text consistency.\n\nStrengths:\n1. The authors address the open-vocabulary generation capability of 3D models by introducing NTFs, which can expand the range of textual latent space.\n2. The proposed NTFGen and NTFBind modules are effective in generating open-vocabulary 3D objects with complicated text prompts.\n3. The multi-modal discrimination framework is well-designed, which guides the generation process and ensures text consistency.\n\nWeaknesses:\n1. The authors rely on a limited dataset (Objaverse) and a small number of training examples, which may not fully capture the complexity of the 3D data.\n2. The evaluation metrics (FID and CLIP-score) may not fully capture the open-vocabulary capability of the model.\n3. The authors do not discuss the potential risks of generating malicious content.\n\nSuggestions for Improvement:\n1. Use a larger and more diverse dataset to train the model.\n2. Introduce additional evaluation metrics to capture the open-vocabulary capability of the model.\n3. Discuss the potential risks of generating malicious content and propose strategies to mitigate them.\n\nRecommendation:\nTextField3D is a promising approach to enhancing open-vocabulary capability in 3D generative models. However, further improvements are needed to address the limitations of the current model. The authors should consider using a larger and more diverse dataset, introducing additional evaluation metrics, and discussing the potential risks of generating malicious content.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper introduces TextField3D, a conditional 3D generative model that enhances open-vocabulary 3D generation capability with noisy text fields (NTFs). It addresses the issue of limited 3D data by mapping limited 3D data to dynamic textual latent space using NTFs. An NTFGen module is proposed to model general text latent code in noisy fields, and an NTFBind module is further proposed to align view-invariant image latent code to noisy fields.\n\nStrengths:\n\n*   TextField3D introduces a novel approach to enhance open-vocabulary 3D generation capability with noisy text fields.\n*   The use of NTFs can map limited 3D data to dynamic textual latent space, expanding the vocabulary of 3D generations.\n*   The NTFGen module can model general text latent code in noisy fields, ensuring text consistency in generated 3D objects.\n*   The NTFBind module can align view-invariant image latent code to noisy fields, ensuring generation consistency across different views.\n\nWeaknesses:\n\n*   The paper may be difficult to understand due to its technical complexity, especially for those without a strong background in 3D generative models and text embeddings.\n*   The evaluation of TextField3D's performance is mostly based on quantitative metrics, which may not capture the full range of its capabilities.\n*   The paper does not discuss potential applications or real-world scenarios where TextField3D can be used.\n\nSuggestions for Improvement:\n\n*   Provide a clear explanation of the technical concepts used in the paper, especially those related to 3D generative models, text embeddings, and noisy text fields.\n*   Offer a more comprehensive evaluation of TextField3D's performance, including qualitative analysis and discussion of its strengths and limitations.\n*   Discuss potential applications or real-world scenarios where TextField3D can be used, such as in video games, virtual reality, or robotic simulation.\n\nRecommendation:\n\n*   The paper is well-written, but its technical complexity may make it challenging for some readers to understand.\n*   With additional explanations, a more comprehensive evaluation, and discussion of potential applications, TextField3D has the potential to make a significant contribution to the field of 3D generative models.\n*   It is recommended to revise the paper to make its content more accessible to a wider range of readers.\n\n$$$",
        "gr_score_with": 0.7721518987341772,
        "gr_score_without": 0.652014652014652,
        "output_without": {
            "num_tokens_scored": 273,
            "num_green_tokens": 178,
            "green_fraction": 0.652014652014652,
            "z_score": -1.730136326321547,
            "p_value": 0.9581970393383313
        },
        "output_with": {
            "num_tokens_scored": 316,
            "num_green_tokens": 244,
            "green_fraction": 0.7721518987341772,
            "z_score": 2.7988631119993483,
            "p_value": 0.0025641436487879197
        }
    },
    {
        "title": "COMPLEX PRIORS AND FLEXIBLE INFERENCE IN RECURRENT CIRCUITS WITH DENDRITIC NONLINEARITIES",
        "abstract": "Despite many successful examples in which probabilistic inference can account for perception, we have little understanding of how the brain represents and uses structured priors that capture the complexity of natural input statistics. Here we construct a recurrent circuit model that can implicitly represent priors over latent variables, and combine them with sensory and contextual sources of information to encode task-specific posteriors. Inspired by the recent success of diffusion models as means of learning and using priors over images, our model uses dendritic nonlinearities optimized for denoising, and stochastic somatic integration with the degree of noise modulated by an oscillating global signal. Combining these elements into a recurrent network yields a dynamical system that samples from the prior at a rate prescribed by the period of the global oscillator. Additional inputs reflecting sensory or top-down contextual information alter these dynamics to generate samples from the corresponding posterior, with different input gating patterns selecting different inference tasks. We demonstrate that this architecture can sample from low dimensional nonlinear manifolds and multimodal posteriors. Overall, the model provides a new framework for circuit-level representation of probabilistic information, in a format that facilitates flexible inference.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper presents a recurrent circuit model that can implicitly represent complex priors and combine them with sensory and contextual information to encode task-specific posteriors. The model uses dendritic nonlinearities optimized for denoising and stochastic somatic integration with the degree of noise modulated by an oscillating global signal. The authors demonstrate that this architecture can sample from low-dimensional nonlinear manifolds and multimodal posteriors.\n\nStrengths:\n\n1. The paper provides a novel approach to representing complex priors in recurrent neural circuits.\n2. The use of dendritic nonlinearities and stochastic somatic integration is biologically plausible and could potentially be used to model neural activity in the brain.\n3. The authors demonstrate the ability of the model to sample from complex distributions, including low-dimensional nonlinear manifolds and multimodal posteriors.\n\nWeaknesses:\n\n1. The model is still relatively simple and lacks a clear understanding of how the different components interact with each other.\n2. The authors rely heavily on simulations and do not provide enough empirical evidence to support their claims.\n3. The model's ability to generalize to new tasks and distributions is not well understood.\n\nSuggestions for Improvement:\n\n1. The authors should provide more detailed explanations of how the different components of the model interact with each other.\n2. The authors should provide more empirical evidence to support their claims, such as experimental results or more extensive simulations.\n3. The authors should investigate the model's ability to generalize to new tasks and distributions.\n\nRecommendation:\n\nBased on the paper's strengths and weaknesses, I would recommend that the authors revise and resubmit the paper. The authors have made a significant contribution to the field of neural circuit modeling, and with further development and refinement, their model could have a major impact on our understanding of how the brain represents and uses complex priors. However, the paper's limitations need to be addressed, and the authors should provide more detailed explanations of their model's components and their interactions. Additionally, the authors should provide more empirical evidence to support their claims and investigate the model's ability to generalize to new tasks and distributions.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe authors propose a recurrent circuit model that can implicitly represent complex priors and combine them with other sources of information to encode task-specific posteriors. The model uses dendritic nonlinearities, stochastic somatic integration, and a global oscillation to sample from the prior at a rate prescribed by the period of the oscillation. The authors demonstrate that the model can sample from low-dimensional nonlinear manifolds and multimodal posteriors. They also propose a modular approach to flexible inference, where the prior-encoding circuit can be reused to do flexible inference by altering the flow-fields of the prior.\n\nStrengths:\n\n* The authors provide a novel approach to representing complex priors and combining them with other sources of information to encode task-specific posteriors.\n* The model uses biologically-motivated nonlinearities and stochastic integration, which makes it more plausible to be implemented in the brain.\n* The authors demonstrate the ability of the model to sample from complex distributions and multimodal posteriors.\n\nWeaknesses:\n\n* The authors do not provide a clear explanation of how the prior is represented in the recurrent circuit, which makes it difficult to understand the underlying mechanism.\n* The model assumes that the prior is represented by the nonlinear reverse operator, which is not explicitly defined.\n* The authors do not provide a clear comparison with other models, which makes it difficult to evaluate the effectiveness of the proposed approach.\n* The simulations are limited to 2D manifolds, which may not be sufficient to demonstrate the ability of the model to sample from complex distributions.\n\nSuggestions for Improvement:\n\n* Provide a clear explanation of how the prior is represented in the recurrent circuit.\n* Define the nonlinear reverse operator explicitly.\n* Compare the proposed approach with other models to evaluate its effectiveness.\n* Increase the dimensionality of the manifolds to demonstrate the ability of the model to sample from complex distributions.\n\nRecommendation:\n\n* The proposed approach is novel and biologically-motivated, but it requires further development to demonstrate its effectiveness and generalizability.\n* The authors should provide more detailed explanations of the underlying mechanism and compare the proposed approach with other models to evaluate its effectiveness.\n* The simulations should be increased in dimensionality to demonstrate the ability of the model to sample from complex distributions.\n* The authors should also investigate the neural signatures of the proposed approach and provide experimental validation to support the claims.",
        "gr_score_with": 0.7959183673469388,
        "gr_score_without": 0.7171717171717171,
        "output_without": {
            "num_tokens_scored": 297,
            "num_green_tokens": 213,
            "green_fraction": 0.7171717171717171,
            "z_score": 0.6457765999379512,
            "p_value": 0.2592120222309279
        },
        "output_with": {
            "num_tokens_scored": 294,
            "num_green_tokens": 234,
            "green_fraction": 0.7959183673469388,
            "z_score": 3.588936677109701,
            "p_value": 0.00016601473526777386
        }
    },
    {
        "title": "A LIE GROUP APPROACH TO RIEMANNIAN BATCH NORMALIZATION",
        "abstract": "Manifold-valued measurements exist in numerous applications within computer vision and machine learning. Recent studies have extended Deep Neural Networks (DNNs) to manifolds, and concomitantly, normalization techniques have also been adapted to several manifolds, referred to as Riemannian normalization. Nonetheless, most of the existing Riemannian normalization methods have been derived in an ad hoc manner and only apply to specific manifolds. This paper establishes a unified framework for Riemannian Batch Normalization (RBN) techniques on Lie groups. Our framework offers the theoretical guarantee of controlling both the Riemannian mean and variance. Empirically, we focus on Symmetric Positive Definite (SPD) manifolds, which possess three distinct types of Lie group structures. Using the deformation concept, we generalize the existing Lie groups on SPD manifolds into three families of parameterized Lie groups. Specific normalization layers induced by these Lie groups are then proposed for SPD neural networks. We demonstrate the effectiveness of our approach through three sets of experiments: radar recognition, human action recognition, and electroencephalography (EEG) classification. The code is available at https://github.com/GitZH-Chen/LieBN.git.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary: \nThis paper proposes a novel framework called LieBN, enabling batch normalization over Lie groups. The authors establish a unified framework for Riemannian Batch Normalization (RBN) techniques on Lie groups. They generalize the existing Lie groups on SPD manifolds and showcase their framework on the parameterized Lie groups of SPD manifolds.\n\nStrengths:\n- The paper provides a theoretical guarantee of controlling both the Riemannian mean and variance.\n- The authors demonstrate the effectiveness of their approach through extensive experiments on various datasets.\n- The framework is general and can be applied to other Lie groups in the future.\n\nWeaknesses:\n- The paper lacks a clear comparison with existing state-of-the-art methods.\n- Some of the experimental results are not reported in detail, making it difficult to fully understand the performance of the proposed method.\n- The discussion on the choice of metrics, deformation, and training efficiency is not thorough.\n\nSuggestions for Improvement:\n- The authors should provide a more detailed comparison with existing state-of-the-art methods.\n- They should report more experimental results, including the standard deviation of the performance metrics.\n- The discussion on the choice of metrics, deformation, and training efficiency should be more thorough.\n\nRecommendation:\nThe proposed LieBN framework is a significant contribution to the field of machine learning, and it has the potential to improve the performance of various models. However, further work is needed to fully explore the capabilities of the framework and to address the limitations mentioned above.\n\n$$\\begin{aligned}\n$$Author's Response:\nThank you for your detailed review. We appreciate your comments and suggestions. We agree that a more detailed comparison with existing state-of-the-art methods is needed, and we plan to include this in our future work. We also acknowledge that more experimental results are needed, and we will provide more detailed results in our future publications. We appreciate your feedback on the discussion on the choice of metrics, deformation, and training efficiency, and we will make sure to provide more thorough explanations in our future work.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThis paper proposes a novel framework called LieBN, which enables batch normalization over Lie groups. The proposed framework generalizes existing Riemannian normalization methods to Lie groups, providing a unified approach to normalization on various manifolds. The authors demonstrate the effectiveness of their approach on several datasets, including radar recognition, human action recognition, and EEG classification.\n\nStrengths:\n\n* The paper provides a comprehensive review of existing Riemannian normalization methods and highlights the need for a unified framework that can handle various Lie groups.\n* The proposed LieBN framework is flexible and can be applied to different types of Lie groups, making it a generalizable approach.\n* The authors provide a detailed analysis of the advantages of their approach, including improved performance on several datasets and reduced training time.\n\nWeaknesses:\n\n* The paper assumes a good understanding of Riemannian geometry and Lie groups, which may be a barrier to entry for readers without a strong background in these areas.\n* The authors rely heavily on existing literature and do not provide a comprehensive derivation of their framework from first principles.\n* The evaluation of the proposed approach is mostly based on empirical results, which may not be sufficient to establish its theoretical guarantees.\n\nSuggestions for Improvement:\n\n* The paper could benefit from a more detailed theoretical analysis of the proposed framework, including a proof of its effectiveness and a discussion of its limitations.\n* The authors could provide a more comprehensive evaluation of their approach, including a comparison with other state-of-the-art methods and a discussion of its robustness to different types of noise and outliers.\n* The paper could be improved by providing more details on the implementation of the proposed framework, including the choice of hyperparameters and the training procedures used to evaluate its performance.\n\nRecommendation:\n\n* The proposed LieBN framework is a valuable contribution to the field of Riemannian normalization and provides a unified approach to normalization on various manifolds.\n* The authors demonstrate the effectiveness of their approach on several datasets and provide a detailed analysis of its advantages.\n* However, the paper could benefit from a more comprehensive theoretical analysis and a more detailed evaluation of its performance to establish its robustness and generalizability.\n\n$$$",
        "gr_score_with": 0.722972972972973,
        "gr_score_without": 0.6578073089700996,
        "output_without": {
            "num_tokens_scored": 301,
            "num_green_tokens": 198,
            "green_fraction": 0.6578073089700996,
            "z_score": -1.5973895014764874,
            "p_value": 0.9449105443983945
        },
        "output_with": {
            "num_tokens_scored": 296,
            "num_green_tokens": 214,
            "green_fraction": 0.722972972972973,
            "z_score": 0.8624886920341311,
            "p_value": 0.19420932653750722
        }
    },
    {
        "title": "MAGNITUDE INVARIANT PARAMETRIZATIONS IMPROVE HYPERNETWORK LEARNING",
        "abstract": "Hypernetworks, neural networks that predict the parameters of another neural network, are powerful models that have been successfully used in diverse applications from image generation to multi-task learning. Unfortunately, existing hypernetworks are often challenging to train. Training typically converges far more slowly than for non-hypernetwork models, and the rate of convergence can be very sensitive to hyperparameter choices. In this work, we identify a fundamental and previously unidentified problem that contributes to the challenge of training hypernetworks: a magnitude proportionality between the inputs and outputs of the hypernetwork. We demonstrate both analytically and empirically that this can lead to unstable optimization, thereby slowing down convergence, and sometimes even preventing any learning. We present a simple solution to this problem using a revised hypernetwork formulation that we call Magnitude Invariant Parametrizations (MIP). We demonstrate the proposed solution on several hypernetwork tasks, where it consistently stabilizes training and achieves faster convergence. Furthermore, we perform a comprehensive ablation study including choices of activation function, normalization strategies, input dimensionality, and hypernetwork architecture; and find that MIP improves training in all scenarios. We also provide easy-to-use code that can turn existing networks into MIP-based hypernetworks.",
        "peer_review_without_watermark": "$$$\\begin{align}\\textbf{Paper Summary:}~\\\\ \nThe paper proposes a new hypernetwork formulation called Magnitude Invariant Parametrizations (MIP) to improve the stability and convergence of hypernetworks. The authors identify a previously unstudied problem in hypernetwork training, where the magnitude proportionality between the inputs and outputs of the hypernetwork causes unstable optimization. They demonstrate that MIP effectively eliminates this dependency, leading to faster convergence and more stable training. The authors evaluate their proposed solution on several hypernetwork tasks, including Bayesian neural networks, hypermorph, and scale-space hypernetworks, and show consistent improvements in model convergence and accuracy.\\\\\n\\textbf{Strengths:}~\\\\ \n1. The paper identifies a previously unstudied problem in hypernetwork training, which is a significant contribution to the field.\n2. The proposed MIP formulation is simple and effective in eliminating the magnitude proportionality issue.\n3. The authors provide extensive experimental results to demonstrate the effectiveness of MIP on various hypernetwork tasks.\n4. The paper discusses the limitations of existing hypernetwork formulations and highlights the need for a more stable and efficient approach.\n5. The authors provide a PyTorch library, HyperLight, to facilitate the development of hypernetwork models.\n\n\\textbf{Weaknesses:}~\\\\ \n1. The paper assumes that the hypernetwork architecture is a series of fully connected layers, which may not be the case in all applications.\n2. The authors focus on fully connected layers, but do not discuss the impact of other layer types, such as convolutional or recurrent layers.\n3. The paper uses a limited number of optimizers and hyperparameters, which may not be representative of all possible scenarios.\n4. The authors do not discuss the impact of MIP on hypernetworks with different activation functions or normalization strategies.\n5. The paper does not provide a comprehensive analysis of the theoretical foundations of MIP.\n\n\\textbf{Suggestions for Improvement:}~\\\\ \n1. The authors should consider a more general hypernetwork architecture that can handle different layer types.\n2. The authors should evaluate MIP on a wider range of optimizers and hyperparameters to ensure its robustness.\n3. The authors should discuss the impact of MIP on hypernetworks with different activation functions and normalization strategies.\n4. The authors should provide a more comprehensive analysis of the theoretical foundations of MIP.\n5. The authors should consider the application of MIP to other areas of machine learning, such as transfer learning and meta-learning.\n\n\\textbf{Recommendation:}~\\\\ \nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit their manuscript. The authors have made a significant contribution to the field of hypernetworks by identifying a previously unstudied problem and proposing a simple and effective solution. However, the paper could benefit from a more comprehensive analysis of the theoretical foundations of MIP and a broader evaluation of its effectiveness on different hypernetwork architectures and optimizers.",
        "peer_review_with_watermark": "$$$$\n\nPaper Summary:\nThe paper presents a new approach to address the training instability problem in hypernetworks, which are neural networks that predict the parameters of another neural network. The authors identify a previously unidentified problem in hypernetwork training, where the magnitude proportionality between the inputs and outputs of the hypernetwork leads to unstable optimization and slow convergence. To address this problem, the authors propose a revised hypernetwork formulation called Magnitude Invariant Parametrizations (MIP), which effectively eliminates the influence of the scale of hypernetwork inputs on the scale of predicted parameters. The authors demonstrate the effectiveness of MIP on several hypernetwork tasks, including Bayesian neural networks, hypermorphic networks, and scale-space hypernetworks.\n\nStrengths:\n\n* The paper identifies a previously unidentified problem in hypernetwork training and proposes a new approach to address it.\n* The authors provide a thorough analysis of the problem and demonstrate the effectiveness of MIP on several hypernetwork tasks.\n* The paper presents a clear and concise introduction to hypernetworks and their applications.\n* The authors provide a detailed experimental setup and evaluation of MIP on several hypernetwork tasks.\n\nWeaknesses:\n\n* The paper does not provide a detailed comparison with existing hypernetwork formulations and normalization strategies.\n* The authors' claim that MIP never reduces model performance is not supported by the paper's results, which show that MIP consistently outperforms the default hypernetwork formulation.\n* The paper's discussion of limitations is brief and does not provide a clear roadmap for future work.\n\nSuggestions for Improvement:\n\n* The authors should provide a more detailed comparison with existing hypernetwork formulations and normalization strategies to demonstrate the superiority of MIP.\n* The authors should provide more evidence to support their claim that MIP never reduces model performance.\n* The authors should provide a more detailed discussion of limitations and future work.\n\nRecommendation:\nOverall, the paper presents a new approach to address the training instability problem in hypernetworks and demonstrates its effectiveness on several hypernetwork tasks. However, the authors should address the weaknesses mentioned above to strengthen the paper's presentation.\n\n$$$$\n\nPaper: MAGNITUDE INVARIANT PARAMETRIZATIONS IMPROVE HYPERNETWORK LEARNING\n\nRecommendation: ACCEPT WITH REVISIONS",
        "gr_score_with": 0.7653061224489796,
        "gr_score_without": 0.6905940594059405,
        "output_without": {
            "num_tokens_scored": 404,
            "num_green_tokens": 279,
            "green_fraction": 0.6905940594059405,
            "z_score": -0.412556341072545,
            "p_value": 0.6600341530480639
        },
        "output_with": {
            "num_tokens_scored": 294,
            "num_green_tokens": 225,
            "green_fraction": 0.7653061224489796,
            "z_score": 2.4435313546278823,
            "p_value": 0.00727215285904838
        }
    },
    {
        "title": "OUT-OF-DOMAIN KNOWLEDGE DISTILLATION",
        "abstract": "Due to privacy or patent concerns, a growing number of large models are released without granting access to their training data, making transferring their knowledge inefficient and problematic. In response, Data-Free Knowledge Distillation (DFKD) methods have emerged as direct solutions. However, simply adopting models derived from DFKD for real-world applications suffers significant performance degradation, due to the discrepancy between teachers\u2019 training data and real-world scenarios (student domain). The degradation stems from the portions of teachers\u2019 knowledge that are not applicable to the student domain. They are specific to the teacher domain and would undermine students\u2019 performance. Hence, selectively transferring teachers\u2019 appropriate knowledge becomes the primary challenge in DFKD. In this work, we propose a simple but effective method AuG-KD. It utilizes an uncertainty-guided and sample-specific anchor to align student-domain data with the teacher domain and leverages a generative method to progressively trade off the learning process between OOD knowledge distillation and domain-specific information learning via mixup learning. Extensive experiments in 3 datasets and 8 settings demonstrate the stability and superiority of our approach. Code available at https://github.com/IshiKura-a/AuG-KD",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes a novel method called AuG-KD (Anchor-Based Mixup Generative Knowledge Distillation) for addressing the Out-of-Domain Knowledge Distillation (OOD-KD) problem. OOD-KD occurs when a teacher model is trained on a different domain than the student model, resulting in poor performance. The proposed method uses a data-driven anchor to align student-domain data with the teacher domain and leverages a generative method to progressively evolve the learning process from OOD knowledge distillation to domain-specific information learning.\n\nStrengths:\n- The proposed method addresses the OOD-KD problem, which is a significant challenge in knowledge distillation.\n- The use of a data-driven anchor to align student-domain data with the teacher domain is innovative and effective.\n- The generative method used to progressively evolve the learning process is well-designed and effective.\n- The extensive experiments conducted demonstrate the stability and superiority of the proposed method.\n\nWeaknesses:\n- The paper does not provide a clear explanation of the assumptions made about the data and the teacher model.\n- The evaluation of the proposed method is limited to three datasets, which may not be representative of the broader scope of the OOD-KD problem.\n- The paper does not discuss the potential limitations and challenges of the proposed method.\n\nSuggestions for Improvement:\n- Provide a clear explanation of the assumptions made about the data and the teacher model.\n- Conduct experiments on a wider range of datasets to demonstrate the generalizability of the proposed method.\n- Discuss the potential limitations and challenges of the proposed method, such as the requirement for large amounts of data to train the generator.\n\nRecommendation:\n- The proposed method AuG-KD is effective in addressing the OOD-KD problem and has the potential to improve the performance of student models in real-world applications.\n- However, further research is needed to address the limitations and challenges of the proposed method, such as the requirement for large amounts of data to train the generator.\n- The proposed method can be improved by incorporating additional techniques, such as domain adaptation and transfer learning, to further enhance its performance and generalizability.\n\n$$$",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$The paper proposes a method for Out-of-Domain Knowledge Distillation (AuG-KD) to address the problem of transferring knowledge from a teacher model to a student model in a real-world scenario where the teacher model is not available. The method is based on an uncertainty-guided and sample-specific anchor to align student-domain data with the teacher domain and leverages a generative method to progressively trade off the learning process between OOD knowledge distillation and domain-specific information learning.\n\nThe strengths of the paper include:\n- The problem of Out-of-Domain Knowledge Distillation is a critical issue in many real-world applications, and the paper provides a practical solution to this problem.\n- The proposed method, AuG-KD, is simple and effective, and its stability and superiority are demonstrated through extensive experiments.\n- The paper provides a comprehensive analysis of the problem and its related concepts, including knowledge distillation, data-free knowledge distillation, and domain shift.\n\nHowever, there are several weaknesses in the paper:\n- The paper lacks a clear definition of the problem and its boundaries, which makes it difficult to evaluate the effectiveness of the proposed method.\n- The experiments are limited to a small number of datasets and settings, and more comprehensive experiments are needed to evaluate the generalizability of the proposed method.\n- The paper does not provide a clear comparison with state-of-the-art methods, and a more thorough analysis of the strengths and weaknesses of the proposed method compared to existing methods is needed.\n- The paper could benefit from more detailed analysis of the results and a more thorough discussion of the implications of the findings.\n\n$$\nRecommendation: \nThe paper proposes a practical solution to the problem of Out-of-Domain Knowledge Distillation, and its simplicity and effectiveness are demonstrated through extensive experiments. However, a more thorough analysis of the results and a more comprehensive comparison with state-of-the-art methods are needed to fully evaluate the effectiveness of the proposed method. The paper is recommended for its contribution to the field of knowledge distillation and its potential applications in real-world scenarios.",
        "gr_score_with": 0.7972508591065293,
        "gr_score_without": 0.6840277777777778,
        "output_without": {
            "num_tokens_scored": 288,
            "num_green_tokens": 197,
            "green_fraction": 0.6840277777777778,
            "z_score": -0.591496174854685,
            "p_value": 0.7229059913202668
        },
        "output_with": {
            "num_tokens_scored": 291,
            "num_green_tokens": 232,
            "green_fraction": 0.7972508591065293,
            "z_score": 3.620181074604904,
            "p_value": 0.00014719845957336745
        }
    },
    {
        "title": "TOOLLLM: FACILITATING LARGE LANGUAGE MODELS TO MASTER 16000+ REAL-WORLD APIS",
        "abstract": "Despite the advancements of open-source large language models (LLMs), e.g., LLaMA, they remain significantly limited in tool-use capabilities, i.e., using external tools (APIs) to fulfill human instructions. The reason is that current instruction tuning largely focuses on basic language tasks but ignores the tool-use domain. This is in contrast to the excellent tool-use capabilities of state-of-the-art (SOTA) closed-source LLMs, e.g., ChatGPT. To bridge this gap, we introduce ToolLLM, a general tool-use framework encompassing data construction, model training, and evaluation. We first present ToolBench, an instruction-tuning dataset for tool use, which is constructed automatically using ChatGPT. Specifically, the construction can be divided into three stages: (i) API collection: we collect 16, 464 real-world RESTful APIs spanning 49 categories from RapidAPI Hub; (ii) instruction generation: we prompt ChatGPT to generate diverse instructions involving these APIs, covering both single-tool and multi-tool scenarios; (iii) solution path annotation: we use ChatGPT to search for a valid solution path (chain of API calls) for each instruction. To enhance the reasoning capabilities of LLMs, we develop a novel depth-first search-based decision tree algorithm. It enables LLMs to evaluate multiple reasoning traces and expand the search space. Moreover, to evaluate the tool-use capabilities of LLMs, we develop an automatic evaluator: ToolEval. Based on ToolBench, we fine-tune LLaMA to obtain an LLM ToolLLaMA, and equip it with a neural API retriever to recommend appropriate APIs for each instruction. Experiments show that ToolLLaMA demonstrates a remarkable ability to execute complex instructions and generalize to unseen APIs, and exhibits comparable performance to ChatGPT. Our ToolLLaMA also demonstrates strong zero-shot generalization ability in an out-of-distribution tool-use dataset: APIBench. The codes, trained models, and demo are publicly available at https://github.com/OpenBMB/ToolBench.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary:\nThe paper proposes a framework called ToolLLM, which enables large language models (LLMs) to master 16,000+ real-world APIs. The framework consists of three main components: data construction, model training, and evaluation. The data construction process involves collecting APIs, generating instructions, and annotating solution paths. The model training process fine-tunes an LLM on the constructed data. The evaluation process uses an automatic evaluator to assess the tool-use capabilities of the model. The paper presents experimental results showing that ToolLLM outperforms other models in various tasks, including single-tool and multi-tool instructions.\n\nStrengths:\n1. The paper provides a comprehensive framework for tool use in LLMs, covering data construction, model training, and evaluation.\n2. The proposed depth-first search-based decision tree algorithm (DFSDT) is effective in enhancing the planning and reasoning ability of LLMs.\n3. The automatic evaluator ToolEval provides a robust and scalable assessment for machine tool use.\n4. The paper demonstrates the generalization ability of ToolLLM to out-of-distribution domains.\n\nWeaknesses:\n1. The paper does not provide a detailed analysis of the limitations of the proposed framework.\n2. The experimental results show that the proposed framework outperforms other models, but it does not provide a clear comparison with the state-of-the-art models.\n3. The paper does not discuss the potential risks and challenges associated with the proposed framework.\n\nSuggestions for Improvement:\n1. The paper should provide a more detailed analysis of the limitations of the proposed framework and discuss potential risks and challenges.\n2. The experimental results should be compared with the state-of-the-art models to provide a clear evaluation of the proposed framework.\n3. The paper should discuss the potential applications of the proposed framework in real-world scenarios.\n\nRecommendation:\nThe paper provides a comprehensive framework for tool use in LLMs, which demonstrates the generalization ability of the model to out-of-distribution domains. However, the paper should provide a more detailed analysis of the limitations of the proposed framework and discuss potential risks and challenges. Additionally, the experimental results should be compared with the state-of-the-art models to provide a clear evaluation of the proposed framework.",
        "peer_review_with_watermark": "$$$$\n\nPaper Summary:\n\nThe paper introduces ToolLLM, a framework designed to facilitate large language models (LLMs) to master 16,000+ real-world APIs, enabling them to perform complex tasks and interact with external tools effectively. ToolLLM is built on top of the ToolBench dataset, which is constructed automatically using ChatGPT to generate instructions, APIs, and solution paths for various tasks. The framework consists of three components: data construction, model training, and evaluation. ToolLLaMA, a fine-tuned version of the LLaMA model, demonstrates remarkable generalization ability to unseen APIs and performs comparably to the \"teacher model\" ChatGPT.\n\nStrengths:\n\n1. The paper addresses a critical gap in the field of LLMs by providing a framework for tool use and mastering real-world APIs.\n2. ToolBench, the proposed dataset, is a significant contribution to the field, covering a wide range of APIs and practical use cases.\n3. The proposed decision tree-based algorithm, Depth First Search-based Decision Tree (DFSDT), effectively expands the search space and improves the planning and reasoning ability of LLMs.\n4. The automatic evaluator ToolEval provides a robust and reliable assessment for machine tool use.\n5. The framework's generalization ability to out-of-distribution domains is a significant strength.\n\nWeaknesses:\n\n1. The paper does not provide a comprehensive analysis of the limitations and challenges of the proposed framework.\n2. The use of ChatGPT for data construction and model training might limit the applicability of the framework to other models.\n3. The paper does not provide a detailed comparison with other state-of-the-art frameworks and models.\n4. The proposed neural API retriever might require further fine-tuning and optimization for optimal performance.\n5. The paper's focus on ToolLLM and ToolBench might overlook other important aspects of LLMs and tool use.\n\nSuggestions for Improvement:\n\n1. Conduct a more comprehensive analysis of the limitations and challenges of the proposed framework.\n2. Provide a more detailed comparison with other state-of-the-art frameworks and models.\n3. Investigate the applicability of the framework to other models and datasets.\n4. Optimize the proposed neural API retriever for better performance.\n5. Consider adding more robust evaluation metrics and methods to assess the framework's generalization ability.\n\nRecommendation:\n\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit the paper for peer review. The authors should address the limitations and challenges of the proposed framework, provide a more detailed comparison with other state-of-the-art frameworks and models, and optimize the proposed neural API retriever for better performance. Additionally, they should consider adding more robust evaluation metrics and methods to assess the framework's generalization ability.",
        "gr_score_with": 0.7678571428571429,
        "gr_score_without": 0.6549295774647887,
        "output_without": {
            "num_tokens_scored": 284,
            "num_green_tokens": 186,
            "green_fraction": 0.6549295774647887,
            "z_score": -1.6574527335797438,
            "p_value": 0.9512860112593808
        },
        "output_with": {
            "num_tokens_scored": 392,
            "num_green_tokens": 301,
            "green_fraction": 0.7678571428571429,
            "z_score": 2.9317636492797483,
            "p_value": 0.0016852157236988462
        }
    },
    {
        "title": "WHAT\u2019S IN MY BIG DATA?",
        "abstract": "Large text corpora are the backbone of language models. However, we have a limited understanding of the content of these corpora, including general statistics, quality, social factors, and inclusion of evaluation data (contamination). In this work, we propose WHAT\u2019S IN MY BIG DATA? (WIMBD), a platform and a set of sixteen analyses that allow us to reveal and compare the contents of large text corpora. WIMBD builds on two basic capabilities\u2014count and search\u2014at scale, which allows us to analyze more than 35 terabytes on a standard compute node. We apply WIMBD to ten different corpora used to train popular language models, including C4, The Pile, and RedPajama. Our analysis uncovers several surprising and previously undocumented findings about these corpora, including the high prevalence of duplicate, synthetic, and low-quality content, personally identifiable information, toxic language, and benchmark contamination. For instance, we find that about 50% of the documents in RedPajama and LAION-2B-en are duplicates. In addition, several datasets used for benchmarking models trained on such corpora are contaminated with respect to important benchmarks, including the Winograd Schema Challenge and parts of GLUE and SuperGLUE. We open-source WIMBD\u2019s code and artifacts to provide a standard set of evaluations for new text-based corpora and to encourage more analyses and transparency around them.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes WHAT'S IN MY BIG DATA? (WIMBD), a platform and set of sixteen analyses for processing and analyzing large text corpora. The authors use WIMBD to analyze ten different corpora used to train popular language models, including C4, The Pile, and RedPajama. The analysis uncovers several surprising and previously undocumented findings about these corpora, including the high prevalence of duplicate, synthetic, and low-quality content, personally identifiable information, toxic language, and benchmark contamination.\n\nStrengths:\n1. The authors provide a comprehensive analysis of large text corpora, highlighting the importance of data understanding in machine learning research.\n2. The proposed WIMBD platform and set of analyses provide a standardized framework for evaluating large text corpora.\n3. The authors demonstrate the effectiveness of WIMBD in uncovering hidden patterns and anomalies in large text corpora.\n\nWeaknesses:\n1. The authors rely heavily on existing datasets and corpora, which may limit the generalizability of their findings.\n2. The analysis is focused on a specific set of corpora, which may not be representative of the broader landscape of large text corpora.\n3. The authors do not provide a clear explanation of the limitations and potential biases of their analysis.\n\nSuggestions for Improvement:\n1. The authors should consider incorporating more diverse datasets and corpora to increase the generalizability of their findings.\n2. The authors should provide a more detailed explanation of the limitations and potential biases of their analysis.\n3. The authors should consider exploring the use of more advanced techniques, such as transfer learning and ensemble methods, to improve the accuracy and robustness of their analysis.\n\nRecommendation:\nThe paper provides a valuable contribution to the field of natural language processing and machine learning research. The proposed WIMBD platform and set of analyses provide a standardized framework for evaluating large text corpora, and the authors' findings highlight the importance of data understanding in machine learning research. However, the authors should consider addressing the limitations and potential biases of their analysis, and incorporating more diverse datasets and corpora to increase the generalizability of their findings.\n\n$$$Paper Quality:\nThe paper is well-written and clearly organized, with a clear and concise introduction, methodology, and results section. The authors provide a thorough analysis of the corpora and identify several surprising and previously undocumented findings. However, the paper could benefit from a more detailed explanation of the limitations and potential biases of the analysis, and the incorporation of more diverse datasets and corpora to increase the generalizability of the findings.\n\n$$$Overall Impact:\nThe paper has the potential to significantly impact the field of natural language processing and machine learning research. The proposed WIMBD platform and set of analyses provide a standardized framework for evaluating large text corpora, and the authors' findings highlight the importance of data understanding in machine learning research. However, the authors should consider addressing the limitations and potential biases of their analysis, and incorporating more diverse datasets and corpora to increase the generalizability of their findings.",
        "peer_review_with_watermark": "$$\\boxed{\\text{Peer Review}}$$\n\n$$\\text{Paper Title: WHAT'S IN MY BIG DATA?}\\$$\n\n$$\\text{Abstract:}\\$$\n\nThis paper proposes a platform and set of analyses for revealing and comparing the contents of large text corpora. The authors use their platform, WIMBD, to analyze ten different corpora used to train popular language models, including C4, The Pile, and RedPajama. Their analysis uncovers surprising findings about the high prevalence of duplicate, synthetic, and low-quality content, personally identifiable information, toxic language, and benchmark contamination. The authors also provide a set of analyses for understanding the content of large text corpora and offer their platform as a tool for further analysis and transparency.\n\n$$\\text{Strengths:}\\$$\n\n1. The authors provide a comprehensive analysis of ten different corpora used to train popular language models.\n2. The analysis uncovers surprising findings about the high prevalence of duplicate, synthetic, and low-quality content, personally identifiable information, toxic language, and benchmark contamination.\n3. The authors provide a set of analyses for understanding the content of large text corpora, including data statistics, data quality, community- and society-relevant measurements, and cross-data analysis.\n4. The authors offer their platform, WIMBD, as a tool for further analysis and transparency.\n\n$$\\text{Weaknesses:}\\$$\n\n1. The analysis may be limited by the size and complexity of the corpora used.\n2. The authors may have had biases in their analysis or interpretation of the results.\n3. The platform, WIMBD, may not be suitable for all types of corpora or analysis.\n4. The authors may not have considered all possible limitations and sources of error in their analysis.\n\n$$\\text{Suggestions for Improvement:}\\$$\n\n1. Consider using a more diverse set of corpora to increase the generalizability of the results.\n2. Provide more detailed explanations of the analysis and interpretation of the results.\n3. Consider using more advanced techniques, such as clustering or dimensionality reduction, to better understand the content of the corpora.\n4. Provide more detailed instructions and examples for using the platform, WIMBD.\n\n$$\\text{Recommendation:}\\$$\n\nBased on the strengths and weaknesses of the paper, I recommend that the authors continue to develop and refine their platform, WIMBD, and use it to further analyze and understand the contents of large text corpora. I also suggest that they consider the limitations and sources of error in their analysis and provide more detailed explanations and instructions for using their platform. With further development and refinement, WIMBD has the potential to become a powerful tool for understanding the contents of large text corpora and improving the quality and transparency of language models.",
        "gr_score_with": 0.8466076696165191,
        "gr_score_without": 0.7663551401869159,
        "output_without": {
            "num_tokens_scored": 321,
            "num_green_tokens": 246,
            "green_fraction": 0.7663551401869159,
            "z_score": 2.594283538108638,
            "p_value": 0.004739414013892477
        },
        "output_with": {
            "num_tokens_scored": 339,
            "num_green_tokens": 287,
            "green_fraction": 0.8466076696165191,
            "z_score": 5.890428547729745,
            "p_value": 1.9259769720896666e-09
        }
    },
    {
        "title": "UNLEASHING LARGE-SCALE VIDEO GENERATIVE PRE-TRAINING FOR VISUAL ROBOT MANIPULATION",
        "abstract": "Generative pre-trained models have demonstrated remarkable effectiveness in language and vision domains by learning useful representations. In this paper, we extend the scope of this effectiveness by showing that visual robot manipulation can significantly benefit from large-scale video generative pre-training. We introduce GR-1, a GPT-style model designed for multi-task language-conditioned visual robot manipulation. GR-1 takes as inputs a language instruction, a sequence of observation images, and a sequence of robot states. It predicts robot actions as well as future images in an end-to-end manner. Thanks to a flexible design, GR-1 can be seamlessly finetuned on robot data after pre-trained on a large-scale video dataset. We perform extensive experiments on the challenging CALVIN benchmark and a real robot. On CALVIN benchmark, our method outperforms state-of-the-art baseline methods and improves the success rate from 88.9% to 94.9%. In the setting of zero-shot unseen scene generalization, GR-1 improves the success rate from 53.3% to 85.4%. In real robot experiments, GR-1 also outperforms baseline methods and shows strong potentials in generalization to unseen scenes and objects. We provide inaugural evidence that a unified GPT-style transformer, augmented with large-scale video generative pre-training, exhibits remarkable generalization to multi-task visual robot manipulation. Project page: https://GR1-Manipulation.github.io",
        "peer_review_without_watermark": "$$\n\n$$$Paper Summary:\nThe paper proposes a novel approach to visual robot manipulation learning by leveraging large-scale video generative pre-training. The proposed method, GR-1, is a GPT-style transformer that takes as inputs a language instruction, a sequence of observation images, and robot states and outputs actions and future images in an end-to-end manner. The model is pre-trained on language-conditioned video prediction with a large-scale video dataset and then finetuned on robot data to predict actions and future images.\n\nStrengths:\n1. The proposed method leverages large-scale video generative pre-training, which can learn general patterns from large datasets and enable the model to easily generalize to related tasks.\n2. The use of a GPT-style transformer allows the model to take different modalities as inputs and outputs future images and actions in an end-to-end manner.\n3. The model is flexible and can be seamlessly finetuned on robot data after pre-training on a large-scale video dataset.\n\nWeaknesses:\n1. The paper does not provide a detailed analysis of the pre-training process, which may affect the quality of the pre-trained model.\n2. The evaluation of the model on the CALVIN benchmark and real robot experiments is limited, and more extensive evaluation is needed to fully assess the performance of the proposed method.\n3. The paper does not provide a clear comparison with other state-of-the-art methods in visual robot manipulation learning.\n\nSuggestions for Improvement:\n1. Provide a detailed analysis of the pre-training process, including the choice of hyperparameters, batch size, and learning rate, to ensure that the pre-trained model is of high quality.\n2. Evaluate the model on more extensive datasets and benchmarks to fully assess its performance and generalization capability.\n3. Compare the proposed method with other state-of-the-art methods in visual robot manipulation learning to provide a clear understanding of its strengths and weaknesses.\n\nRecommendation:\nThe proposed method, GR-1, shows promising results in visual robot manipulation learning by leveraging large-scale video generative pre-training. However, more extensive evaluation and comparison with other state-of-the-art methods are needed to fully assess its performance and generalization capability. With further improvements and evaluations, GR-1 has the potential to become a leading method in visual robot manipulation learning.\n\n$$",
        "peer_review_with_watermark": "$$\n\n$$$Paper Summary:\nThe paper proposes a novel approach to large-scale video generative pre-training for visual robot manipulation. The authors introduce GR-1, a GPT-style transformer model that leverages language-conditioned video prediction to enhance learning of multi-task visual robot manipulation. The model is first pre-trained on a large-scale video dataset and then finetuned on robot data. The authors perform extensive experiments on the CALVIN benchmark and a real robot, demonstrating the effectiveness of GR-1 in improving state-of-the-art methods in multi-task learning, zero-shot unseen scene generalization, small dataset, and zero-shot unseen language generalization.\n\nStrengths:\n1. The authors provide a clear and concise overview of the problem and propose a novel approach to large-scale video generative pre-training.\n2. The GR-1 model is well-designed, and the authors provide a clear explanation of its architecture and training procedure.\n3. The authors perform extensive experiments to evaluate the performance of GR-1, which demonstrates its effectiveness in various scenarios.\n4. The paper includes a thorough analysis of the results, which highlights the strengths and limitations of GR-1.\n\nWeaknesses:\n1. The paper assumes that the reader has prior knowledge of generative pre-trained models and transformers, which may make it difficult for non-experts to follow.\n2. The authors do not provide a detailed analysis of the limitations and potential biases of GR-1, which may limit its generalizability to other tasks and scenarios.\n3. The paper does not provide a clear explanation of how GR-1 is compared to other state-of-the-art methods, which may make it difficult to evaluate its performance relative to other models.\n4. The authors do not provide a detailed discussion of the potential applications and future work, which may limit the impact and potential of GR-1.\n\nSuggestions for Improvement:\n1. The authors should provide a more detailed analysis of the limitations and potential biases of GR-1, which may limit its generalizability to other tasks and scenarios.\n2. The authors should provide a clear explanation of how GR-1 is compared to other state-of-the-art methods, which may make it easier to evaluate its performance relative to other models.\n3. The authors should provide a more detailed discussion of the potential applications and future work, which may limit the impact and potential of GR-1.\n4. The authors should consider providing additional experiments and results to further evaluate the performance of GR-1 in different scenarios.\n\nRecommendation:\nThe authors have made a significant contribution to the field of visual robot manipulation, and GR-1 has shown promising results in various scenarios. However, to further establish its effectiveness and generalizability, the authors should address the limitations and potential biases of GR-1, provide a clear comparison to other state-of-the-art methods, and discuss its potential applications and future work.\n\n$$",
        "gr_score_with": 0.7881619937694704,
        "gr_score_without": 0.707641196013289,
        "output_without": {
            "num_tokens_scored": 301,
            "num_green_tokens": 213,
            "green_fraction": 0.707641196013289,
            "z_score": 0.2892910120784207,
            "p_value": 0.38617934487079497
        },
        "output_with": {
            "num_tokens_scored": 321,
            "num_green_tokens": 253,
            "green_fraction": 0.7881619937694704,
            "z_score": 3.4468649825574857,
            "p_value": 0.00028356596794126626
        }
    },
    {
        "title": "CADE AND CONTINUOUS SCENE RECONSTRUCTION FROM FOVEATED VISUAL SAMPLING",
        "abstract": "High accuracy, low latency and high energy efficiency represent a set of conflicting goals when searching for system solutions for image classification and detection. While high-quality images naturally result in more precise detection and classification, they also result in a heavier computational workload for imaging and processing, reduced camera frame rates, and increased data communication between the camera and processor. Taking inspiration from the foveal-peripheral sampling mechanism, and saccade mechanism of the human visual system and the filling-in phenomena of brain, we have developed an active scene reconstruction architecture based on multiple foveal views. This model stitches together information from a sequence of foveal-peripheral views, which are sampled from multiple glances. Assisted by a reinforcement learning-based saccade mechanism, our model reduces the required input pixels by over 90% per frame while maintaining the same level of performance in image recognition as with the original images. We evaluated the effectiveness of our model using the GTSRB dataset and the ImageNet dataset. Using an equal number of input pixels, our model demonstrates a 5% higher image recognition accuracy compared to state-of-theart foveal-peripheral based vision systems. Furthermore, we demonstrate that our foveal sampling/saccadic scene reconstruction model exhibits significantly lower complexity and higher data efficiency during the training phase compared to existing approaches. Code is available at Github.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes a novel framework for image classification and object detection using foveal-peripheral vision and saccade control. The proposed system employs a foveal-peripheral sampling mechanism, which reduces the amount of input data required for image processing. The system also incorporates a scene reconstruction module, which stitches together information from multiple foveal-peripheral views to generate a reconstructed image. The saccade controller is trained using reinforcement learning to optimize the sampling strategy and improve the classification accuracy.\n\nStrengths:\n\n1. The proposed system demonstrates high data efficiency during the training phase, requiring only a small portion of the training data to achieve similar performance to state-of-the-art foveal-peripheral based vision systems.\n2. The system achieves a 5% higher image recognition accuracy compared to state-of-the-art foveal-peripheral based vision systems, while reducing the required input pixels by over 90% per frame.\n3. The saccade model is highly transferable and works effectively on scenes that differ from the training classes.\n\nWeaknesses:\n\n1. The paper does not provide a clear explanation of the foveal-peripheral sampling strategy and how it is optimized using reinforcement learning.\n2. The evaluation of the system's performance is limited to two datasets (GTSRB and ImageNet) and does not provide a comprehensive analysis of its performance on other datasets.\n3. The paper does not discuss the potential limitations and challenges of the proposed system, such as the impact of varying lighting conditions, occlusions, and other real-world factors on the system's performance.\n\nSuggestions for Improvement:\n\n1. Provide a more detailed explanation of the foveal-peripheral sampling strategy and how it is optimized using reinforcement learning.\n2. Evaluate the system's performance on a larger and more diverse set of datasets to demonstrate its robustness and generalizability.\n3. Discuss the potential limitations and challenges of the proposed system and provide strategies for addressing them.\n\nRecommendation:\n\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit the paper for peer review. The authors should provide a more detailed explanation of the foveal-peripheral sampling strategy and how it is optimized using reinforcement learning, evaluate the system's performance on a larger and more diverse set of datasets, and discuss the potential limitations and challenges of the proposed system. With these revisions, the paper has the potential to make a significant contribution to the field of computer vision and image processing.",
        "peer_review_with_watermark": "$$$Paper Summary:\n\nThe paper proposes a novel framework for image sensing and processing that leverages the foveal-peripheral vision mechanism and saccadic eye movements to achieve high accuracy, low latency, and high energy efficiency. The framework consists of a predictive reconstruction module, an evaluation module, and a policy module, which work together to merge multiple foveal-peripheral views controlled by saccades into a reconstructed image. The predictive reconstruction module uses a self-supervised learning approach to minimize a hybrid loss function that combines mean squared error and structural similarity index. The policy module is implemented as an advantage actor-critic (A2C) model that selects the next foveal center location based on the reconstructed image and the evaluation module's reward signal.\n\nThe experimental results show that the proposed framework achieves a top-1 accuracy of 92.1% on the GTSRB dataset and 77.2% on the ImageNet dataset, with a significant improvement in terms of top-1 accuracy compared to state-of-the-art foveal-peripheral based vision systems.\n\nStrengths:\n\n* The proposed framework leverages the foveal-peripheral vision mechanism and saccadic eye movements to achieve high accuracy, low latency, and high energy efficiency.\n* The use of self-supervised learning for the predictive reconstruction module enables the framework to learn from unlabeled data.\n* The advantage actor-critic (A2C) model used for the policy module provides a robust and efficient way to select the next foveal center location.\n\nWeaknesses:\n\n* The framework requires a significant number of training data to achieve good performance, which may be a limitation for real-world applications.\n* The use of a hybrid loss function for the predictive reconstruction module may not be optimal, and other loss functions may be more effective.\n* The framework may not work well for images with complex scenes or high levels of occlusion, which may require more advanced image processing techniques.\n\nSuggestions for Improvement:\n\n* Use a larger number of training data to improve the robustness and generalizability of the framework.\n* Explore other loss functions for the predictive reconstruction module, such as mean absolute error or peak signal-to-noise ratio.\n* Develop more advanced image processing techniques to handle complex scenes or high levels of occlusion.\n* Investigate the use of transfer learning or domain adaptation to improve the framework's performance on different datasets or tasks.\n\nRecommendation:\n\nThe proposed framework is a significant contribution to the field of image sensing and processing, and it has the potential to improve the performance and energy efficiency of real-world systems. However, there are some limitations and potential areas for improvement that should be addressed in future work. With some modifications and refinements, the framework could be a valuable tool for a wide range of applications, from surveillance and security to healthcare and autonomous driving.\n\n$$$",
        "gr_score_with": 0.7793764988009593,
        "gr_score_without": 0.7189349112426036,
        "output_without": {
            "num_tokens_scored": 338,
            "num_green_tokens": 243,
            "green_fraction": 0.7189349112426036,
            "z_score": 0.7596472613518377,
            "p_value": 0.223732730416147
        },
        "output_with": {
            "num_tokens_scored": 417,
            "num_green_tokens": 325,
            "green_fraction": 0.7793764988009593,
            "z_score": 3.537124276066885,
            "p_value": 0.00020225463892183739
        }
    },
    {
        "title": "SMOOTH ECE: PRINCIPLED RELIABILITY DIAGRAMS",
        "abstract": "Calibration measures and reliability diagrams are two fundamental tools for measuring and interpreting the calibration of probabilistic predictors. Calibration measures quantify the degree of miscalibration, and reliability diagrams visualize the structure of this miscalibration. However, the most common constructions of reliability diagrams and calibration measures \u2014 binning and ECE \u2014 both suffer from well-known flaws (e.g. discontinuity). We show that a simple modification fixes both constructions: first smooth the observations using an RBF kernel, then compute the Expected Calibration Error (ECE) of this smoothed function. We prove that with a careful choice of bandwidth, this method yields a calibration measure that is well-behaved in the sense of B\u0142asiok, Gopalan, Hu, and Nakkiran (2023) \u2014 a consistent calibration measure. We call this measure the SmoothECE. Moreover, the reliability diagram obtained from this smoothed function visually encodes the SmoothECE, just as binned reliability diagrams encode the BinnedECE. We also develop a Python package with simple, hyperparameter-free methods for measuring and plotting calibration: https://anonymous.4open. science/r/smoothece-anon/.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes a new calibration measure called SmoothECE (Smooth Expected Calibration Error) and a method to construct principled reliability diagrams that visually encode this measure. The SmoothECE is a consistent calibration measure in the sense of B\u0142asiok et al. (2023), which means it is a polynomial upper and lower bound of the true calibration distance. The SmoothECE is defined as the expected calibration error of a smoothed version of the original distribution, where the smoothing is done using a reflected Gaussian kernel. The authors also provide a method to choose the scale of the smoothing, which is done using a binary search algorithm. The SmoothECE is compared to the classical Binned ECE and the authors show that it is more robust and can handle discontinuities in the calibration function.\n\nStrengths:\n\n* The paper provides a new calibration measure that is consistent in the sense of B\u0142asiok et al. (2023).\n* The method to construct reliability diagrams is principled and visually encodes the SmoothECE.\n* The authors provide a Python package to efficiently implement the suggested method.\n* The paper includes several experiments to demonstrate the effectiveness of the SmoothECE.\n\nWeaknesses:\n\n* The paper assumes that the predictor is a binary classifier, but the method can be generalized to multi-class classifiers.\n* The authors do not provide a clear explanation of why the reflected Gaussian kernel is used instead of a standard Gaussian kernel.\n* The paper does not discuss the potential biases of the SmoothECE, such as the bias introduced by the reflected Gaussian kernel.\n* The authors do not provide a clear comparison of the SmoothECE with other calibration measures, such as the Binned ECE.\n\nSuggestions for Improvement:\n\n* Provide a clear explanation of why the reflected Gaussian kernel is used instead of a standard Gaussian kernel.\n* Discuss the potential biases of the SmoothECE and provide a way to mitigate them.\n* Compare the SmoothECE with other calibration measures, such as the Binned ECE, to demonstrate its effectiveness.\n* Provide a more detailed explanation of how the binary search algorithm works and why it is necessary.\n\nRecommendation:\n\n* The paper is well-written and provides a clear and concise overview of the SmoothECE and its method.\n* The authors have provided a Python package to efficiently implement the suggested method, which is a significant advantage.\n* However, the paper could benefit from a more detailed explanation of the potential biases of the SmoothECE and a comparison with other calibration measures.\n* Overall, I recommend that the authors revise the paper to address these suggestions and provide a more comprehensive comparison of the SmoothECE with other calibration measures.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$\\text{\\underline{Paper Summary:}}$$\nThis paper proposes a new calibration measure, SmoothECE, which is a consistent calibration measure in the sense of B\u0142asiok et al. (2023). The SmoothECE is a smoothed version of the Expected Calibration Error (ECE) and is obtained by using a kernel density estimation of the predictions and the outcomes. The paper also proposes a principled way of choosing the bandwidth for the kernel density estimation, which is crucial for the theoretical guarantees of the SmoothECE.\n\n$$\\begin{aligned}\n$$\\text{\\underline{Strengths:}}$$\n* The paper presents a new and well-behaved calibration measure that is consistent in the sense of B\u0142asiok et al. (2023).\n* The SmoothECE is a smoothed version of the ECE and is obtained by using a kernel density estimation of the predictions and the outcomes.\n* The paper proposes a principled way of choosing the bandwidth for the kernel density estimation, which is crucial for the theoretical guarantees of the SmoothECE.\n* The SmoothECE can be visually represented in a reliability diagram, which is a useful tool for understanding and assessing calibration properties of a given predictor.\n\n$$\\begin{aligned}\n$$\\text{\\underline{Weaknesses:}}$$\n* The paper assumes that the predictor is a binary predictor, which may not be the case in all situations.\n* The SmoothECE is a smoothed version of the ECE, which may not be as simple to compute as the ECE.\n* The paper does not provide a detailed analysis of the computational complexity of the SmoothECE.\n\n$$\\begin{aligned}\n$$\\text{\\underline{Suggestions for Improvement:}}$$\n* The paper could benefit from a more detailed analysis of the assumptions made by the SmoothECE, such as the assumption that the predictor is a binary predictor.\n* The paper could also benefit from a more detailed analysis of the computational complexity of the SmoothECE, which could help to improve its efficiency and scalability.\n* The paper could also benefit from a more detailed comparison with existing calibration measures, which could help to establish the SmoothECE as a more robust and widely applicable calibration measure.\n\n$$\\begin{aligned}\n$$\\text{\\underline{Recommendation:}}$$\n* The SmoothECE is a well-behaved and consistent calibration measure that can be used to assess the reliability of probabilistic predictors.\n* The SmoothECE can be visually represented in a reliability diagram, which is a useful tool for understanding and assessing calibration properties of a given predictor.\n* The paper proposes a principled way of choosing the bandwidth for the kernel density estimation, which is crucial for the theoretical guarantees of the SmoothECE.\n\n$$\\begin{aligned}\n$$\\text{\\underline{Rating:}}$$\n* The paper is well-written and clearly presents the main contributions and results of the work.\n* The paper is well-organized and easy to follow, with a clear and logical structure.\n* The paper is well-referenced and provides a thorough literature review of existing work in the field of calibration measures.\n\n$$\\begin{aligned}\n$$\\text{\\underline{Final Review:}}$$\nOverall, the paper presents a new and well-behaved calibration measure, the SmoothECE, which is consistent in the sense of B\u0142asiok et al. (2023). The SmoothECE can be visually represented in a reliability diagram, which is a useful tool for understanding and assessing calibration properties of a given predictor. The paper also proposes a principled way of choosing the bandwidth for the kernel density estimation, which is crucial for the theoretical guarantees of the SmoothECE. The SmoothECE is a smoothed version of the ECE and is obtained by using a kernel density estimation of the predictions and the outcomes. The paper is well-written and clearly presents the main contributions and results of the work, and the paper is well-organized and easy to follow, with a clear and logical structure.",
        "gr_score_with": 0.7967213114754098,
        "gr_score_without": 0.6822429906542056,
        "output_without": {
            "num_tokens_scored": 321,
            "num_green_tokens": 219,
            "green_fraction": 0.6822429906542056,
            "z_score": -0.6942448904797747,
            "p_value": 0.7562356774885235
        },
        "output_with": {
            "num_tokens_scored": 305,
            "num_green_tokens": 243,
            "green_fraction": 0.7967213114754098,
            "z_score": 3.6860604137651642,
            "p_value": 0.00011387615365818683
        }
    },
    {
        "title": "LEARNING MULTI-FACETED PROTOTYPICAL USER INTERESTS",
        "abstract": "We seek to uncover the latent interest units from behavioral data to better learn user preferences under the VAE framework. Existing practices tend to ignore the multiple facets of item characteristics, which may not capture it at appropriate granularity. Moreover, current studies equate the granularity of item space to that of user interests, which we postulate is not ideal as user interests would likely map to a small subset of item space. In addition, the compositionality of user interests has received inadequate attention, preventing the modeling of interactions between explanatory factors driving a user\u2019s decision. To resolve this, we propose to align user interests with multi-faceted item characteristics. First, we involve prototype-based representation learning to discover item characteristics along multiple facets. Second, we compose user interests from uncovered item characteristics via binding mechanism, separating the granularity of user preferences from that of item space. Third, we design a dedicated bi-directional binding block, aiding the derivation of compositional user interests. On real-world datasets, the experimental results demonstrate the strong performance of our proposed method compared to a series of baselines.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes a novel approach to disentangled representation learning for recommendation systems, called FACETVAE. FACETVAE addresses the shortcomings of existing VAE-based models by disentangling item space under multiple facets, binding compositional user interests from low-level ones, and effectively binding user interests via a bi-directional binding block. The proposed method is evaluated on three real-world datasets, and the experimental results demonstrate its strong performance compared to state-of-the-art baselines.\n\nStrengths:\n1. FACETVAE addresses the limitations of existing VAE-based models by disentangling item space under multiple facets, which improves the modeling of user interests.\n2. The proposed method effectively binds compositional user interests from low-level ones discovered from item space, which enhances the interpretability of user preferences.\n3. The bi-directional binding block is a novel component that enables the competition between low-level interests to attend to high-level counterparts, which improves the diversity of user interests.\n\nWeaknesses:\n1. The computational cost of FACETVAE is higher than that of some baselines, which may be a limitation in practice.\n2. The evaluation of FACETVAE on some datasets may be biased due to the limited number of prototypes used to group items.\n\nSuggestions for Improvement:\n1. To improve the efficiency of multi-faceted item grouping, the authors could explore more efficient algorithms or techniques for grouping items under multiple facets.\n2. To discover the number of facets and the number of clusters per facet in a data-driven manner, the authors could develop more sophisticated methods for facet discovery and clustering.\n\nRecommendation:\nI recommend accepting the paper for publication in its current form. The proposed method, FACETVAE, has the potential to improve the performance of recommendation systems, and its contributions to the field of disentangled representation learning are significant. With some minor revisions to address the limitations mentioned above, the paper can provide valuable insights and inspiration for future research in the field.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper proposes a novel framework for learning multi-faceted prototypical user interests using Variational AutoEncoder (VAE). The authors introduce FACETVAE, which stands for FACETed Variational AutoEncoder, to disentangle the multiple facets of item space and model user preferences at a finer granularity. The framework consists of three main innovations: 1) disentangling item space under multiple facets, 2) binding compositional user interests from low-level ones discovered from item space, and 3) effectively binding user interests via bi-directional binding block.\n\nStrengths:\n1. The paper addresses the limitations of existing VAE-based disentangled recommendation models by disentangling item space and modeling user preferences at a finer granularity.\n2. The bi-directional binding block is a novel mechanism that effectively binds user interests and enables compositionality of user preferences.\n3. The framework is efficient and scalable, with a linear time complexity for multi-faceted item grouping.\n\nWeaknesses:\n1. The paper assumes a uniform distribution of facets underlying item space, which may not always hold in reality.\n2. The authors rely heavily on the performance of the bi-directional binding block, which may not generalize well to different datasets or scenarios.\n3. The framework does not provide a clear mechanism for selecting the number of facets or clusters per facet, which may require additional tuning or experimentation.\n\nSuggestions for Improvement:\n1. Develop a more robust method for selecting the number of facets or clusters per facet, such as using clustering algorithms or dimensionality reduction techniques.\n2. Investigate the generalizability of the bi-directional binding block across different datasets and scenarios.\n3. Provide more theoretical analysis and mathematical proofs to support the efficacy of the bi-directional binding block and the overall framework.\n\nRecommendation:\nThe paper proposes a novel and innovative framework for learning multi-faceted prototypical user interests using VAE. The authors have made significant contributions to the field of recommendation systems, and the framework has the potential to improve the accuracy and interpretability of user preferences. However, further research is needed to address the limitations and weaknesses of the framework, and to provide a more robust and generalizable solution for real-world applications.\n\nRating: 8/10\n\n$$$",
        "gr_score_with": 0.7507507507507507,
        "gr_score_without": 0.6789297658862876,
        "output_without": {
            "num_tokens_scored": 299,
            "num_green_tokens": 203,
            "green_fraction": 0.6789297658862876,
            "z_score": -0.7950515853775576,
            "p_value": 0.7867082521722298
        },
        "output_with": {
            "num_tokens_scored": 333,
            "num_green_tokens": 250,
            "green_fraction": 0.7507507507507507,
            "z_score": 2.020947076057927,
            "p_value": 0.021642621977662545
        }
    },
    {
        "title": "MAKING PRE-TRAINED LANGUAGE MODELS GREAT",
        "abstract": "The transferability of deep neural networks (DNNs) has made significant progress in image and language processing. However, due to the heterogeneity among tables, such DNN bonus is still far from being well exploited on tabular data prediction (e.g., regression or classification tasks). Condensing knowledge from diverse domains, language models (LMs) possess the capability to comprehend feature names from various tables, potentially serving as versatile learners in transferring knowledge across distinct tables and diverse prediction tasks, but their discrete text representation space is inherently incompatible with numerical feature values in tables. In this paper, we present TP-BERTa, a specifically pre-trained LM for tabular data prediction. Concretely, a novel relative magnitude tokenization converts scalar numerical feature values to finely discrete, high-dimensional tokens, and an intra-feature attention approach integrates feature values with the corresponding feature names. Comprehensive experiments demonstrate that our pre-trained TP-BERTa leads the performance among tabular DNNs and is competitive with Gradient Boosted Decision Tree models in typical tabular data regime.",
        "peer_review_without_watermark": "$$\\boxed{\\text{Paper Summary:}}$$\n\nThe paper presents TP-BERTa, a pre-trained language model specifically designed for tabular data prediction tasks. The model utilizes a novel relative magnitude tokenization approach to represent numerical values and an intra-feature attention module to integrate feature names and values. The authors demonstrate the effectiveness of TP-BERTa on various tabular datasets, outperforming classical and advanced deep neural networks, and achieving competitive performances with Gradient Boosted Decision Trees (GBDTs) in typical tabular data regimes.\n\n$$\\boxed{\\text{Strengths:}}$$\n\n1.  The paper introduces a novel approach to handling numerical features in tables, which is essential for tabular data prediction tasks.\n2.  The relative magnitude tokenization approach and intra-feature attention module are effective in integrating feature names and values, enabling the model to capture semantic relationships between them.\n3.  The authors provide extensive experimental results, demonstrating the superiority of TP-BERTa over various non-LM DNNs and competitive performances with GBDTs.\n4.  The paper highlights the potential of pre-trained language models in handling tabular data, which can be beneficial for cross-table learning and knowledge transfer.\n\n$$\\boxed{\\text{Weaknesses:}}$$\n\n1.  The paper may benefit from a more detailed discussion on the limitations of the proposed approach, such as the potential for overfitting or the need for more extensive pre-training data.\n2.  The authors may consider exploring other numerical encoding strategies or comparison techniques to further evaluate the effectiveness of TP-BERTa.\n3.  The paper's focus on tabular data prediction tasks may limit its applicability to other domains or tasks, which could be explored in future studies.\n4.  The authors may consider providing more insights into the importance of feature type distributions and the potential impact of different magnitude token numbers on the model's performance.\n\n$$\\boxed{\\text{Suggestions for Improvement:}}$$\n\n1.  Conduct more extensive ablation studies to evaluate the importance of different components, such as the relative magnitude tokenization approach, intra-feature attention module, or magnitude-aware triplet loss function.\n2.  Explore other numerical encoding strategies or comparison techniques to further evaluate the effectiveness of TP-BERTa and identify potential limitations or weaknesses.\n3.  Investigate the applicability of TP-BERTa to other domains or tasks, such as text classification, sentiment analysis, or natural language generation.\n4.  Provide more insights into the importance of feature type distributions and the potential impact of different magnitude token numbers on the model's performance.\n\n$$\\boxed{\\text{Recommendation:}}$$\n\nBased on the provided review, I recommend accepting the paper for publication in a top-tier conference or journal. The authors have made significant contributions to the field of tabular data prediction, and TP-BERTa demonstrates unprecedented progress over various non-LM DNNs. While there are some areas for improvement, the paper's strengths outweigh its weaknesses, and the authors have provided a solid foundation for future research and development.",
        "peer_review_with_watermark": "$$\\boxed{\\text{Paper Summary:}}$$\n\nThe paper presents a novel approach, called TP-BERTa, for tabular data prediction using pre-trained language models (LMs). TP-BERTa is specifically designed to handle numerical features in tables by employing a novel relative magnitude tokenization approach and an intra-feature attention module. The paper proposes a pre-trained LM for tabular prediction based on RoBERTa and presents a comparative analysis with other state-of-the-art tabular prediction models. Experimental results show that the pre-trained TP-BERTa outperforms other tabular DNNs and is competitive with GBDTs in the typical tabular data regime.\n\n$$\\boxed{\\text{Strengths:}}$$\n\n1.  The paper presents a novel approach for handling numerical features in tables using a novel relative magnitude tokenization approach and an intra-feature attention module.\n2.  The paper demonstrates the effectiveness of the proposed approach through extensive experimental results.\n3.  The paper provides a comparative analysis with other state-of-the-art tabular prediction models.\n4.  The paper discusses the potential of pre-trained LMs in handling tabular data prediction tasks.\n\n$$\\boxed{\\text{Weaknesses:}}$$\n\n1.  The paper may benefit from a more detailed discussion on the theoretical foundation of the relative magnitude tokenization approach.\n2.  The paper may benefit from a more extensive analysis of the impact of the intra-feature attention module on the performance of the proposed approach.\n3.  The paper may benefit from a more detailed discussion on the potential limitations of the proposed approach, such as the requirement for extensive pre-training data.\n4.  The paper may benefit from a more extensive comparison with other tabular prediction models, including those that use different numerical encoding strategies.\n\n$$\\boxed{\\text{Suggestions for Improvement:}}$$\n\n1.  Conduct a more extensive analysis of the theoretical foundation of the relative magnitude tokenization approach.\n2.  Evaluate the impact of the intra-feature attention module on the performance of the proposed approach through a more extensive set of experiments.\n3.  Discuss the potential limitations of the proposed approach in more detail, including the requirement for extensive pre-training data.\n4.  Conduct a more extensive comparison with other tabular prediction models, including those that use different numerical encoding strategies.\n\n$$\\boxed{\\text{Recommendation:}}$$\n\nBased on the experimental results and the analysis presented in the paper, I recommend the use of the proposed approach, TP-BERTa, for tabular data prediction tasks. However, I also recommend that the authors consider the potential limitations of the approach and conduct further research to address these limitations. Additionally, I recommend that the authors consider a more extensive comparison with other tabular prediction models to ensure that the proposed approach is indeed the best approach for handling numerical features in tables.",
        "gr_score_with": 0.8309859154929577,
        "gr_score_without": 0.743142144638404,
        "output_without": {
            "num_tokens_scored": 401,
            "num_green_tokens": 298,
            "green_fraction": 0.743142144638404,
            "z_score": 1.8852296844333114,
            "p_value": 0.029699417376803035
        },
        "output_with": {
            "num_tokens_scored": 284,
            "num_green_tokens": 236,
            "green_fraction": 0.8309859154929577,
            "z_score": 4.8169720069661395,
            "p_value": 7.287656339980927e-07
        }
    },
    {
        "title": "LOCAL COMPOSITE SADDLE POINT OPTIMIZATION",
        "abstract": "Distributed optimization (DO) approaches for saddle point problems (SPP) have recently gained in popularity due to the critical role they play in machine learning (ML). Existing works mostly target smooth unconstrained objectives in Euclidean space, whereas ML problems often involve constraints or non-smooth regularization, which results in a need for composite optimization. Moreover, although non-smooth regularization often serves to induce structure (e.g., sparsity), standard aggregation schemes in distributed optimization break this structure. Addressing these issues, we propose Federated Dual Extrapolation (FeDualEx), an extra-step primal-dual algorithm with local updates, which is the first of its kind to encompass both saddle point optimization and composite objectives under the distributed paradigm. Using a generalized notion of Bregman divergence, we analyze its convergence and communication complexity in the homogeneous setting. Furthermore, the empirical evaluation demonstrates the effectiveness of FeDualEx for inducing structure in these challenging settings.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes Federated Dual Extrapolation (FeDualEx), a distributed optimization algorithm for composite saddle point problems (SPP) that can handle both smooth and non-smooth regularization terms. The algorithm is designed to induce structure in the aggregated solution and is evaluated on various composite SPP problems. The authors provide a convergence analysis of FeDualEx and show that it achieves a rate of O(1/R^2) in the homogeneous setting and O(1/T) in the sequential setting.\n\nStrengths:\n- FeDualEx is the first distributed optimization algorithm for composite SPP that can handle both smooth and non-smooth regularization terms.\n- The algorithm is designed to induce structure in the aggregated solution and is evaluated on various composite SPP problems.\n- The authors provide a convergence analysis of FeDualEx and show that it achieves a rate of O(1/R^2) in the homogeneous setting and O(1/T) in the sequential setting.\n\nWeaknesses:\n- The analysis of FeDualEx assumes that the clients are homogeneous, which may not be the case in practice.\n- The algorithm relies on the assumption that the regularization terms are smooth, which may not be the case in practice.\n- The analysis of FeDualEx does not provide a clear bound on the communication complexity of the algorithm.\n\nSuggestions for Improvement:\n- The authors should provide a more detailed analysis of the homogeneous setting and show that the assumptions made are indeed valid in practice.\n- The authors should consider the case where the regularization terms are non-smooth and provide a bound on the communication complexity of the algorithm.\n- The authors should also consider the case where the clients are heterogeneous and provide a bound on the convergence rate of the algorithm.\n\nRecommendation:\n- The paper is well-written and provides a clear overview of the algorithm and its convergence analysis.\n- The authors have made a significant contribution to the field of distributed optimization by proposing FeDualEx, which is the first distributed optimization algorithm for composite SPP that can handle both smooth and non-smooth regularization terms.\n- However, the analysis of FeDualEx assumes that the clients are homogeneous, which may not be the case in practice. The authors should provide a more detailed analysis of the homogeneous setting and show that the assumptions made are indeed valid in practice.\n\n$$$",
        "peer_review_with_watermark": "$$$\\begin{align*}\n\\textbf{Paper Summary:} \nThe paper proposes Federated Dual Extrapolation (FeDualEx), an algorithm for distributed optimization of composite saddle point problems. The authors address the challenges of composite optimization in the distributed paradigm by developing an algorithm that can induce structure in the aggregated solution. The authors analyze the convergence rate of FeDualEx in the homogeneous setting, showing that it is the first algorithm to achieve this in the composite saddle point optimization setting.\n\n\\textbf{Strengths:} \nThe paper presents an original contribution to the field of distributed optimization by addressing the challenges of composite optimization in the distributed paradigm. The authors provide a thorough analysis of the algorithm's convergence rate, which is the first of its kind in the composite saddle point optimization setting. The paper also presents experimental evaluations that demonstrate the effectiveness of FeDualEx in inducing structures in the aggregated solution.\n\n\\textbf{Weaknesses:} \nThe paper assumes that the optimization domain is compact with respect to the Bregman divergence, which may not hold in all cases. The authors also assume that the gradient operator is \u03b2-Lipschitz, which may not hold in all cases. The paper also requires additional assumptions, such as unbiased estimates and bounded variance of the gradient.\n\n\\textbf{Suggestions for Improvement:} \nThe authors should consider addressing the assumptions mentioned above to make the paper more applicable to a wider range of problems. Additionally, the authors could consider exploring the heterogeneous federated setting of composite saddle point optimization, which would be a challenging direction for future work.\n\n\\textbf{Recommendation:} \nBased on the thorough analysis of the algorithm's convergence rate and the experimental evaluations, I recommend that the paper be published in its current form. The authors have made a significant contribution to the field of distributed optimization by addressing the challenges of composite optimization in the distributed paradigm.\n\n$$\\$",
        "gr_score_with": 0.8587786259541985,
        "gr_score_without": 0.7318181818181818,
        "output_without": {
            "num_tokens_scored": 220,
            "num_green_tokens": 161,
            "green_fraction": 0.7318181818181818,
            "z_score": 1.0298573010888743,
            "p_value": 0.15153849864831276
        },
        "output_with": {
            "num_tokens_scored": 262,
            "num_green_tokens": 225,
            "green_fraction": 0.8587786259541985,
            "z_score": 5.608323253239932,
            "p_value": 1.0214809354906576e-08
        }
    },
    {
        "title": "FINE-TUNED LANGUAGE MODELS GENERATE STABLE INORGANIC MATERIALS",
        "abstract": "We propose fine-tuning large language models for generation of stable materials. While unorthodox, fine-tuning large language models on text-encoded atomistic data is simple to implement yet reliable, with around 90% of sampled structures obeying physical constraints on atom positions and charges. Using energy above hull calculations from both learned ML potentials and gold-standard DFT calculations, we show that our strongest model (fine-tuned LLaMA-2 70B) can generate materials predicted to be metastable at about twice the rate (49% vs 28%) of CDVAE, a competing diffusion model. Because of text prompting\u2019s inherent flexibility, our models can simultaneously be used for unconditional generation of stable material, infilling of partial structures and text-conditional generation. Finally, we show that language models\u2019 ability to capture key symmetries of crystal structures improves with model scale, suggesting that the biases of pretrained LLMs are surprisingly well-suited for atomistic data.",
        "peer_review_without_watermark": "$$\n\nThe paper proposes a novel approach to generating stable inorganic materials using fine-tuned large language models (LLMs). The authors fine-tune LLaMA-2 models on text-encoded atomistic data and show that the strongest model can generate materials predicted to be metastable at a higher rate than a competing diffusion model.\n\nStrengths:\n1. The authors demonstrate the effectiveness of fine-tuning LLMs on atomistic data, which is a novel approach to materials generation.\n2. The paper highlights the ability of LLMs to capture key symmetries of crystal structures, which is essential for generating stable materials.\n3. The authors propose a new metric, IPT, to assess the invariance of language models to continuous group transformations, which is a useful contribution to the field.\n\nWeaknesses:\n1. The paper relies heavily on the fine-tuning approach, which may not be generalizable to other materials generation tasks.\n2. The authors do not provide a thorough comparison with other state-of-the-art methods, such as CDVAE, which may limit the applicability of their approach.\n3. The paper does not discuss the potential risks and challenges associated with using LLMs for materials generation, such as the potential for hallucinations or the lack of interpretability.\n\nSuggestions for Improvement:\n1. The authors should provide a more comprehensive comparison with other state-of-the-art methods to demonstrate the superiority of their approach.\n2. The paper should discuss the potential risks and challenges associated with using LLMs for materials generation and provide strategies for mitigating these risks.\n3. The authors should explore the use of other metrics to evaluate the performance of their approach, such as the structural and compositional validity metrics.\n\nRecommendation:\nI recommend that the authors revise their paper to address the weaknesses and suggestions for improvement outlined above. The authors should provide a more comprehensive comparison with other state-of-the-art methods, discuss the potential risks and challenges associated with using LLMs for materials generation, and explore the use of other metrics to evaluate the performance of their approach. With these revisions, the paper has the potential to make a significant contribution to the field of materials generation using LLMs.\n\n$$",
        "peer_review_with_watermark": "$$$\\boxed{\\text{Paper Summary:}}$\n\nThe paper proposes fine-tuning large language models (LLMs) for generation of stable materials. The authors demonstrate that their method can generate materials predicted to be metastable at a higher rate than a competing diffusion model. The fine-tuning approach is simple to implement yet reliable, with around 90% of sampled structures obeying physical constraints. The authors also show that their method can generate materials predicted to be stable at about twice the rate of the competing model.\n\n$\\boxed{\\text{Strengths:}}$\n\n1. The authors have successfully demonstrated the use of LLMs for generation of stable materials.\n2. The fine-tuning approach is simple to implement and reliable.\n3. The authors have shown that their method can generate materials predicted to be metastable at a higher rate than a competing diffusion model.\n4. The authors have also demonstrated that their method can generate materials predicted to be stable at about twice the rate of the competing model.\n\n$\\boxed{\\text{Weaknesses:}}$\n\n1. The paper assumes that the reader is familiar with the basics of materials science and LLMs.\n2. The paper does not provide a comprehensive literature review on the topic of materials generation using LLMs.\n3. The authors do not discuss the potential limitations of their method, such as the need for large amounts of training data.\n4. The paper does not provide a detailed explanation of the fine-tuning approach used in the paper.\n\n$\\boxed{\\text{Suggestions for Improvement:}}$\n\n1. The authors should provide a comprehensive literature review on the topic of materials generation using LLMs.\n2. The authors should discuss the potential limitations of their method, such as the need for large amounts of training data.\n3. The authors should provide a detailed explanation of the fine-tuning approach used in the paper.\n4. The authors should consider using more advanced evaluation metrics for their method.\n\n$\\boxed{\\text{Recommendation:}}$\n\nBased on the paper summary, strengths, weaknesses, and suggestions for improvement, I recommend that the authors revise and resubmit their paper. The authors have made a significant contribution to the field of materials generation using LLMs, and their paper has the potential to be a leading publication in the field. However, the authors need to address the weaknesses and suggestions for improvement to make their paper more comprehensive and robust.",
        "gr_score_with": 0.8143939393939394,
        "gr_score_without": 0.7859531772575251,
        "output_without": {
            "num_tokens_scored": 299,
            "num_green_tokens": 235,
            "green_fraction": 0.7859531772575251,
            "z_score": 3.2433056736830634,
            "p_value": 0.0005907568873964019
        },
        "output_with": {
            "num_tokens_scored": 264,
            "num_green_tokens": 215,
            "green_fraction": 0.8143939393939394,
            "z_score": 4.055975585594417,
            "p_value": 2.4962737302453746e-05
        }
    },
    {
        "title": "BADEXPERT: EXTRACTING BACKDOOR FUNCTIONAL- ITY FOR ACCURATE BACKDOOR INPUT DETECTION",
        "abstract": "In this paper, we present a novel defense against backdoor attacks on deep neural networks (DNNs), wherein adversaries covertly implant malicious behaviors (backdoors) into DNNs. Our defense falls within the category of post-development defenses that operate independently of how the model was generated. Our proposed defense is built upon an intriguing concept: given a backdoored model, we reverse engineer it to directly extract its backdoor functionality to a backdoor expert model. To accomplish this, we finetune the backdoored model over a small set of intentionally mislabeled clean samples, such that it unlearns the normal functionality while still preserving the backdoor functionality, and thus resulting in a model (dubbed a backdoor expert model) that can only recognize backdoor inputs. Based on the extracted backdoor expert model, we show the feasibility of devising robust backdoor input detectors that filter out the backdoor inputs during model inference. Further augmented by an ensemble strategy with a finetuned auxiliary model, our defense, BaDExpert (Backdoor Input Detection with Backdoor Expert), effectively mitigates 17 SOTA backdoor attacks while minimally impacting clean utility. The effectiveness of BaDExpert has been verified on multiple datasets (CIFAR10, GTSRB, and ImageNet) across multiple model architectures (ResNet, VGG, MobileNetV2, and Vision Transformer). Our code is integrated into our research toolbox: https://github.com/vtu81/backdoor-toolbox. Untrusted Source Incorrect Labels Small Reserved Clean Set Recognize Forgot Clean Task Backdoor Task Backdoored Model M Backdoor Expert B Finetuning Figure 1: Extracting backdoor functionality via finetuning on a mislabeled small clean set. The backdoored modelM can correctly recognize both benign and poisoned samples whereas our backdoor expert model B can only recognize backdoor samples.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$\\textbf{Paper Summary:}$$\nThe paper proposes a novel defense strategy, BaDExpert, against backdoor attacks on deep neural networks (DNNs). The defense operates independently of the model development and relies on post-development defenses. BaDExpert directly extracts the backdoor functionality from a compromised model and uses it to devise a backdoor input detector. The proposed approach is evaluated on multiple datasets and model architectures, achieving state-of-the-art results.\n\n$$\\textbf{Strengths:}$$\n1. The proposed approach directly extracts the backdoor functionality from a compromised model, providing a unique perspective on post-development defenses.\n2. BaDExpert achieves state-of-the-art results on multiple datasets and model architectures.\n3. The approach is flexible and can be applied to various types of backdoor attacks.\n4. The proposed method is robust against adaptive attacks.\n\n$$\\textbf{Weaknesses:}$$\n1. The paper relies on the assumption that the backdoor model can be finetuned on a set of mislabeled clean samples to extract the backdoor functionality. This assumption may not hold in all cases.\n2. The proposed approach may not be effective against all types of backdoor attacks, such as those using global transformations as triggers.\n3. The paper does not provide a comprehensive analysis of the theoretical foundations of the proposed approach.\n4. The evaluation of BaDExpert is limited to a few datasets and model architectures, and further evaluation on more diverse datasets and models is necessary.\n\n$$\\textbf{Suggestions for Improvement:}$$\n1. Provide a more comprehensive analysis of the theoretical foundations of the proposed approach.\n2. Evaluate BaDExpert on more diverse datasets and model architectures.\n3. Investigate the robustness of BaDExpert against different types of backdoor attacks, including those using global transformations as triggers.\n4. Consider adding additional defense mechanisms to enhance the robustness of BaDExpert.\n\n$$\\textbf{Recommendation:}$$\nBaDExpert is a promising defense strategy against backdoor attacks on DNNs. However, further evaluation and analysis are necessary to fully understand its strengths and weaknesses. Based on the current results, I recommend that BaDExpert be considered as a potential defense mechanism for protecting against backdoor attacks on DNNs.",
        "peer_review_with_watermark": "$$\n\n$$Paper Summary:$$\n\nThe paper proposes a novel defense strategy against backdoor attacks on deep neural networks (DNNs), which are attacks that embed hidden behaviors (backdoors) into DNNs. The defense strategy, dubbed BaDExpert, directly extracts the backdoor functionality from a compromised model and uses it to devise an accurate and resilient detector for backdoor inputs during inference-time. The authors evaluate BaDExpert on multiple datasets and model architectures and show that it is effective against various attacks.\n\n$$Strengths:$$\n\n1. The paper introduces a novel defense strategy against backdoor attacks, which is a significant contribution to the field.\n2. The authors provide a clear and concise explanation of the BaDExpert defense strategy and its components.\n3. The paper evaluates BaDExpert on multiple datasets and model architectures, which demonstrates its effectiveness and generalizability.\n4. The authors provide an adaptive study against BaDExpert, which shows its resilience against diverse adaptive attacks.\n\n$$Weaknesses:$$\n\n1. The paper does not provide a thorough analysis of the backdoor attacks, which may limit its effectiveness in real-world scenarios.\n2. The authors rely heavily on empirical evaluations, which may not provide a comprehensive understanding of the defense strategy's performance.\n3. The paper does not provide a detailed analysis of the trade-offs between different components of the BaDExpert defense strategy, which may be important for practical deployment.\n4. The authors do not provide a clear evaluation of the computational resources required for BaDExpert, which may be an important consideration for deployment.\n\n$$Suggestions for Improvement:$$\n\n1. Provide a more comprehensive analysis of the backdoor attacks, including their motivations, techniques, and limitations.\n2. Include more detailed evaluations of the defense strategy's performance, including its accuracy, precision, recall, and F1-score.\n3. Analyze the trade-offs between different components of the BaDExpert defense strategy, including the impact of the learning rate, the number of clean samples, and the threshold for backdoor input detection.\n4. Provide a clear evaluation of the computational resources required for BaDExpert, including its memory and computational requirements.\n\n$$Recommendation:$$\n\nBased on the evaluation, I recommend that the BaDExpert defense strategy be considered for deployment in real-world scenarios, but with the caveat that it should be carefully evaluated and refined to address the limitations and weaknesses identified in the paper. Additionally, the authors should consider providing more comprehensive and detailed evaluations of the defense strategy's performance to support its adoption.\n\n$$\n\n$$",
        "gr_score_with": 0.8096676737160121,
        "gr_score_without": 0.7190635451505016,
        "output_without": {
            "num_tokens_scored": 299,
            "num_green_tokens": 215,
            "green_fraction": 0.7190635451505016,
            "z_score": 0.7193323867701753,
            "p_value": 0.23596807274237502
        },
        "output_with": {
            "num_tokens_scored": 331,
            "num_green_tokens": 268,
            "green_fraction": 0.8096676737160121,
            "z_score": 4.353945422526475,
            "p_value": 6.6854504233024814e-06
        }
    },
    {
        "title": "LLMS MEET VLMS: BOOST OPEN VOCABULARY OB-",
        "abstract": "Inspired by the outstanding zero-shot capability of vision language models (VLMs) in image classification tasks, open-vocabulary object detection has attracted increasing interest by distilling the broad VLM knowledge into detector training. However, most existing open-vocabulary detectors learn by aligning region embeddings with categorical labels (e.g., bicycle) only, disregarding the capability of VLMs on aligning visual embeddings with fine-grained text description of object parts (e.g., pedals and bells). This paper presents DVDet, a Descriptor-Enhanced Open Vocabulary Detector that introduces conditional context prompts and hierarchical textual descriptors that enable precise region-text alignment as well as open-vocabulary detection training in general. Specifically, the conditional context prompt transforms regional embeddings into image-like representations that can be directly integrated into general open vocabulary detection training. In addition, we introduce large language models as an interactive and implicit knowledge repository which enables iterative mining and refining visually oriented textual descriptors for precise region-text alignment. Extensive experiments over multiple large-scale benchmarks show that DVDet outperforms the state-of-the-art consistently by large margins.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces DVDet, an open-vocabulary object detection approach that leverages the zero-shot capabilities of vision language models (VLMs) to enhance detection performance. DVDet consists of two key designs: Conditional Context regional Prompt (CCP) and a hierarchical descriptor generation mechanism that iteratively interacts with large language models (LLMs) to mine and refine fine-grained descriptors. The authors evaluate DVDet on two large-scale benchmarks, COCO and LVIS, and demonstrate significant improvements over state-of-the-art methods.\n\nStrengths:\n1. The paper presents a novel approach to open-vocabulary object detection that leverages the strengths of VLMs and LLMs.\n2. The Conditional Context regional Prompt (CCP) design is innovative and effective in transforming region embeddings into image-like representations.\n3. The hierarchical descriptor generation mechanism is well-designed and allows for iterative interaction with LLMs to refine fine-grained descriptors.\n4. The authors provide extensive experimental results to demonstrate the effectiveness of DVDet on two large-scale benchmarks.\n\nWeaknesses:\n1. The paper may benefit from a more detailed explanation of the LLMs-assisted descriptor generation mechanism, particularly for readers who are not familiar with LLMs.\n2. Some of the experimental results, such as the performance on the PASCAL VOC benchmark, are not provided in sufficient detail.\n3. The paper does not discuss potential limitations or challenges of the proposed approach, such as the need for large amounts of data to train LLMs.\n\nSuggestions for Improvement:\n1. Provide a more detailed explanation of the LLMs-assisted descriptor generation mechanism, including the role of the hierarchical update mechanism and the semantic selection strategy.\n2. Include more experimental results, such as performance on the PASCAL VOC benchmark, to demonstrate the generalization of DVDet to other datasets.\n3. Discuss potential limitations or challenges of the proposed approach, such as the need for large amounts of data to train LLMs.\n4. Consider providing a comparison with other state-of-the-art methods to demonstrate the superiority of DVDet.\n\nRecommendation:\nBased on the strengths and weaknesses of the paper, I recommend that it be accepted for publication in a top-tier conference or journal in computer vision or machine learning. The innovative approach presented in the paper has the potential to significantly improve open-vocabulary object detection, and the extensive experimental results demonstrate its effectiveness. However, the paper may benefit from additional explanations and experimental results to fully justify its contributions.",
        "peer_review_with_watermark": "$$$ Paper Summary:\nThe paper proposes a novel open-vocabulary object detection approach called Descriptor-Enhanced Open Vocabulary Detection (DVDet). The method leverages the zero-shot capabilities of vision language models (VLMs) to enhance open vocabulary detection. The proposed approach consists of two key designs: a Conditional Context Regional Prompt (CCP) that transforms regional embeddings into image-like representations and a hierarchical descriptor generation mechanism that iteratively interacts with large language models (LLMs) to refine fine-grained descriptors. The experimental results demonstrate that DVDet improves the performance of existing open vocabulary detectors consistently across multiple large-scale benchmarks.\n\nStrengths:\n1. The paper proposes a novel and effective approach to open vocabulary object detection that leverages the strengths of VLMs.\n2. The use of Conditional Context Regional Prompt (CCP) to transform regional embeddings into image-like representations is a significant innovation.\n3. The hierarchical descriptor generation mechanism that interacts with LLMs to refine fine-grained descriptors is a valuable contribution.\n4. The experimental results demonstrate the effectiveness of the proposed approach across multiple large-scale benchmarks.\n\nWeaknesses:\n1. The paper assumes that the VLMs have been trained on a large-scale dataset and may not generalize well to new environments or tasks.\n2. The use of LLMs as an interactive knowledge repository may require significant computational resources and may not be feasible for real-time applications.\n3. The paper does not provide a comprehensive analysis of the trade-offs between the different design choices and the potential limitations of the proposed approach.\n\nSuggestions for Improvement:\n1. The paper could benefit from a more comprehensive analysis of the trade-offs between the different design choices and the potential limitations of the proposed approach.\n2. The use of LLMs as an interactive knowledge repository could be explored further to reduce the computational requirements and improve the generalization of the proposed approach.\n3. The paper could include more experimental results on different benchmarks and environments to demonstrate the robustness and generalizability of the proposed approach.\n\nRecommendation:\nBased on the strengths and weaknesses of the paper, I recommend that it be accepted for publication in a top-tier conference or journal in computer vision or machine learning. The proposed approach has the potential to make a significant impact on the field of open vocabulary object detection, and the experimental results demonstrate its effectiveness across multiple large-scale benchmarks. However, the paper could benefit from a more comprehensive analysis of the trade-offs and potential limitations of the proposed approach.",
        "gr_score_with": 0.7492447129909365,
        "gr_score_without": 0.6666666666666666,
        "output_without": {
            "num_tokens_scored": 345,
            "num_green_tokens": 230,
            "green_fraction": 0.6666666666666666,
            "z_score": -1.3510724722962926,
            "p_value": 0.9116638907462282
        },
        "output_with": {
            "num_tokens_scored": 331,
            "num_green_tokens": 248,
            "green_fraction": 0.7492447129909365,
            "z_score": 1.9550774211344784,
            "p_value": 0.02528696641519336
        }
    },
    {
        "title": "SHARING RATIO DECOMPOSITION",
        "abstract": "The truthfulness of existing explanation methods in authentically elucidating the underlying model\u2019s decision-making process has been questioned. Existing methods have deviated from faithfully representing the model, thus susceptible to adversarial attacks. To address this, we propose a novel eXplainable AI (XAI) method called SRD (Sharing Ratio Decomposition), which sincerely reflects the model\u2019s inference process, resulting in significantly enhanced robustness in our explanations. Different from the conventional emphasis on the neuronal level, we adopt a vector perspective to consider the intricate nonlinear interactions between filters. We also introduce an interesting observation termed Activation-PatternOnly Prediction (APOP), letting us emphasize the importance of inactive neurons and redefine relevance encapsulating all relevant information including both active and inactive neurons. Our method, SRD, allows for the recursive decomposition of a Pointwise Feature Vector (PFV), providing a high-resolution Effective Receptive Field (ERF) at any layer.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$\\text{Paper Summary:}$$\nThe paper proposes a novel eXplainable AI (XAI) method called Sharing Ratio Decomposition (SRD), which aims to faithfully represent the decision-making process of complex deep learning models. The proposed method analyzes the model using Pointwise Feature Vectors (PFVs) and decomposes relevance with sharing ratios. It reflects the model's inference process and relies exclusively on model-generated data, resulting in robust and trustworthy explanations.\n\n$$\\text{Strengths:}$$\n1. The proposed method reflects the model's inference process faithfully, relying exclusively on model-generated data.\n2. The adoption of a vector perspective accounts for nonlinear interactions between filters, departing from conventional neuron-level analyses.\n3. The identification of Activation-Pattern-Only Prediction (APOP) highlights the influence of inactive neurons in model behavior, which has been overlooked so far by conventional approaches.\n4. The method outperforms other saliency map methods across various metrics, including effectiveness, sophistication, and resilience.\n\n$$\\text{Weaknesses:}$$\n1. The paper lacks a clear explanation of the sharing ratio calculation, and its derivation is mentioned in the appendix.\n2. The method's performance is evaluated on a limited number of datasets and models, which may not be representative of the broader XAI community.\n3. The paper does not discuss potential limitations or challenges of the proposed method, such as the computational complexity of the recursive decomposition.\n\n$$\\text{Suggestions for Improvement:}$$\n1. Provide a clear and concise explanation of the sharing ratio calculation and its derivation.\n2. Evaluate the proposed method on a larger and more diverse range of datasets and models.\n3. Discuss potential limitations and challenges of the proposed method, such as computational complexity.\n4. Consider incorporating additional evaluation metrics that assess the interpretability and transparency of the model's decision-making process.\n\n$$\\text{Recommendation:}$$\nBased on the strengths and weaknesses of the proposed method, we recommend further development and evaluation of Sharing Ratio Decomposition (SRD) to explore its potential as a robust and trustworthy XAI method. Specifically, we suggest:\n\n1. Investigating the application of SRD to a broader range of deep learning models and datasets.\n2. Developing more efficient algorithms for the recursive decomposition of PFVs.\n3. Evaluating the interpretability and transparency of the model's decision-making process using additional metrics.\n4. Conducting a more comprehensive comparison with other XAI methods to assess SRD's performance and limitations.",
        "peer_review_with_watermark": "$$\\boxed{\\text{Paper Summary:} \\quad \\text{This paper proposes a novel method called Sharing Ratio Decomposition (SRD) for explaining the decision-making process of complex deep learning models. SRD decomposes the pointwise feature vector into shares of preactivation neurons occupying the same spatial location of a layer and uses sharing ratios to reflect the nonlinear interactions between filters. The method provides high-resolution effective receptive fields at any layer and maintains its explanatory power even in the face of perturbations. Experimental results on various models and metrics demonstrate the superiority of SRD over other saliency map methods.}\n\n$$\\boxed{\\text{Strengths:} \\quad \\text{1. SRD provides high-resolution effective receptive fields at any layer, offering a comprehensive exploration of local to global explanations.} \\quad \\text{2. The method maintains its explanatory power even in the face of perturbations, demonstrating its robustness.} \\quad \\text{3. SRD reflects the nonlinear interactions between filters, departing from conventional neuron-level analyses.} \\quad \\text{4. The identification of Activation-Pattern-Only Prediction (APOP) highlights the influence of inactive neurons in model behavior.}\n\n$$\\boxed{\\text{Weaknesses:} \\quad \\text{1. SRD requires prior knowledge of sharing ratios, which can be challenging to derive.} \\quad \\text{2. The method may be computationally expensive due to the recursive decomposition of pointwise feature vectors.} \\quad \\text{3. SRD may not be applicable to models with non-linear activation functions.} \\quad \\text{4. The paper could benefit from more comprehensive analysis of adversarial attacks on SRD.}\n\n$$\\boxed{\\text{Suggestions for Improvement:} \\quad \\text{1. Develop an efficient algorithm for computing sharing ratios, which could be used to speed up the computation of SRD.} \\quad \\text{2. Investigate the applicability of SRD to models with non-linear activation functions.} \\quad \\text{3. Conduct a more comprehensive analysis of adversarial attacks on SRD, including the evaluation of its robustness against targeted attacks.} \\quad \\text{4. Explore the use of SRD for explaining decision-making processes in other types of machine learning models.}\n\n$$\\boxed{\\text{Recommendation:} \\quad \\text{This paper proposes a novel method for explaining the decision-making process of complex deep learning models, which provides high-resolution effective receptive fields at any layer and maintains its explanatory power even in the face of perturbations. The experimental results demonstrate the superiority of SRD over other saliency map methods. However, the method requires prior knowledge of sharing ratios, which can be challenging to derive. Therefore, I recommend that the authors develop an efficient algorithm for computing sharing ratios and conduct a more comprehensive analysis of adversarial attacks on SRD.}$$",
        "gr_score_with": 0.7975077881619937,
        "gr_score_without": 0.7328042328042328,
        "output_without": {
            "num_tokens_scored": 378,
            "num_green_tokens": 277,
            "green_fraction": 0.7328042328042328,
            "z_score": 1.3917657280497164,
            "p_value": 0.08199667564188196
        },
        "output_with": {
            "num_tokens_scored": 321,
            "num_green_tokens": 256,
            "green_fraction": 0.7975077881619937,
            "z_score": 3.812257030178421,
            "p_value": 6.885178438298975e-05
        }
    },
    {
        "title": "PARETO DEEP LONG-TAILED RECOGNITION: A CONFLICT-AVERSE SOLUTION",
        "abstract": "Deep long-tailed recognition (DLTR) has attracted much attention due to its close touch with realistic scenarios. Recent advances have focused on re-balancing across various aspects, e.g., sampling strategy, loss re-weighting, logit adjustment, and input/parameter perturbation, etc. However, few studies have considered dynamic re-balancing to address intrinsic optimization conflicts, which are identified as prevalent and critical issues in this study. In this paper, we empirically establish the severity of the optimization conflict issue in the DLTR scenario, which leads to a degradation of representation learning. This observation serves as the motivation for pursuing Pareto optimal solutions. Unfortunately, a straightforward integration of multi-objective optimization (MOO) with DLTR methods is infeasible due to the disparity between multi-task learning (MTL) and DLTR. Therefore, we propose effective alternatives by decoupling MOO-based MTL from a temporal perspective rather than a structural one. Furthermore, we enhance the integration of MOO and DLTR by investigating the generalization and convergence problems. Specifically, we propose optimizing the variability collapse loss, guided by the derived MOObased DLTR generalization bound, to improve generalization. Additionally, we anticipate worst-case optimization to ensure convergence. Building upon the proposed MOO framework, we introduce a novel method called Pareto deep LOngTailed recognition (PLOT). Extensive evaluations demonstrate that our method not only generally improves mainstream pipelines, but also achieves an augmented version to realize state-of-the-art performance across multiple benchmarks. Code is available at https://github.com/zzpustc/PLOT.",
        "peer_review_without_watermark": "$$$\\begin{align}\\textbf{Paper Summary:}~\\text{The paper proposes a novel approach to address the optimization conflict issue in deep long-tailed recognition (DLTR) by integrating multi-objective optimization (MOO) with DLTR. The authors introduce a new method called Pareto deep long-tailed recognition (PLOT) and demonstrate its effectiveness in improving the performance of mainstream DLTR methods across multiple benchmarks. The proposed approach is based on decoupling MOO-based multi-task learning (MTL) from a structural to a temporal perspective, allowing for the application of MOO algorithms in DLTR without model architecture modifications. The authors also propose two theoretical motivated operations, variability collapse loss and anticipating worst-case optimization, to ensure the generalization and convergence of MOO-based DLTR.}\n\n\\textbf{Strengths:}~1) The paper identifies the optimization conflict issue in DLTR and proposes a novel approach to address it. 2) The authors provide a clear and detailed explanation of the proposed method, including the decoupling of MOO-based MTL from a structural to a temporal perspective. 3) The experimental results demonstrate the effectiveness of PLOT in improving the performance of mainstream DLTR methods across multiple benchmarks.\n\n\\textbf{Weaknesses:}~1) The paper assumes that the MOO algorithms used are stable and convergent, which may not always be the case. 2) The authors do not provide a comprehensive comparison with other state-of-the-art DLTR methods, which may limit the robustness of the proposed approach. 3) The paper focuses on the optimization conflict issue in DLTR and does not discuss other potential challenges, such as class imbalance and data noise.\n\n\\textbf{Suggestions for Improvement:}~1) The authors should provide a more comprehensive analysis of the stability and convergence of the proposed MOO algorithms. 2) The paper should include a more detailed comparison with other state-of-the-art DLTR methods to demonstrate the robustness of the proposed approach. 3) The authors should discuss other potential challenges in DLTR, such as class imbalance and data noise, and propose strategies to address them.\n\n\\textbf{Recommendation:}~Based on the strengths and weaknesses of the paper, I recommend that it be accepted for publication in a top-tier conference in machine learning. However, the authors should address the weaknesses and suggestions for improvement to strengthen the paper and make it more competitive.",
        "peer_review_with_watermark": "$$$$\n\nPaper Summary:\nThe paper proposes a novel approach to deep long-tailed recognition (DLTR) by addressing the optimization conflict issue in DLTR methods. The authors empirically establish the severity of the optimization conflict issue in DLTR and propose a novel method called Pareto deep long-tailed recognition (PLOT). PLOT integrates multi-objective optimization (MOO) with DLTR to mitigate optimization conflicts, improve generalization, and enhance performance.\n\nStrengths:\n1. The paper provides a thorough analysis of optimization conflicts in DLTR methods, highlighting the need for addressing this issue.\n2. The authors propose a novel approach to MOO-based DLTR, which integrates MOO with DLTR to mitigate optimization conflicts.\n3. The paper presents extensive evaluations on various benchmarks, demonstrating the effectiveness of PLOT.\n4. The authors provide a clear explanation of the optimization conflicts, MOO, and DLTR, making the paper accessible to researchers in the field.\n\nWeaknesses:\n1. The paper's analysis of optimization conflicts is limited to DLTR methods, and it is unclear whether the results generalize to other machine learning problems.\n2. The authors rely heavily on the choice of MOO algorithms, specifically MGDA, EPO, and CAGrad, without providing a comprehensive evaluation of their performance.\n3. The paper's evaluation of PLOT is extensive, but it is unclear whether the results are representative of the entire DLTR community.\n4. The authors' approach to addressing optimization conflicts is novel, but it is unclear whether it is the most effective solution.\n\nSuggestions for Improvement:\n1. The authors should provide a more comprehensive analysis of optimization conflicts in DLTR methods, including other approaches and techniques.\n2. The authors should evaluate the performance of PLOT on a wider range of DLTR benchmarks, including those with varying levels of imbalance.\n3. The authors should provide a more detailed explanation of the optimization conflicts, MOO, and DLTR, including theoretical foundations and mathematical derivations.\n4. The authors should explore other approaches to addressing optimization conflicts, such as using other MOO algorithms or incorporating additional regularization techniques.\n\nRecommendation:\nBased on the paper's strengths and weaknesses, I recommend that the authors revise and resubmit the paper with the suggested improvements. The paper has the potential to make a significant contribution to the DLTR community, but it requires further development to fully realize its potential.\n\n$$$$",
        "gr_score_with": 0.8287461773700305,
        "gr_score_without": 0.7365269461077845,
        "output_without": {
            "num_tokens_scored": 334,
            "num_green_tokens": 246,
            "green_fraction": 0.7365269461077845,
            "z_score": 1.4567229081138504,
            "p_value": 0.07259644180913188
        },
        "output_with": {
            "num_tokens_scored": 327,
            "num_green_tokens": 271,
            "green_fraction": 0.8287461773700305,
            "z_score": 5.080407776696244,
            "p_value": 1.883127705459895e-07
        }
    },
    {
        "title": "RAIN: YOUR LANGUAGE MODELS CAN ALIGN THEMSELVES",
        "abstract": "Large language models (LLMs) often demonstrate inconsistencies with human preferences. Previous research typically gathered human preference data and then aligned the pre-trained models using reinforcement learning or instruction tuning, a.k.a. the finetuning step. In contrast, aligning frozen LLMs without requiring alignment data is more appealing. This work explores the potential of the latter setting. We discover that by integrating self-evaluation and rewind mechanisms, unaligned LLMs can directly produce responses consistent with human preferences via self-boosting. We introduce a novel inference method, Rewindable Auto-regressive INference (RAIN), that allows pre-trained LLMs to evaluate their own generation and use the evaluation results to guide rewind and generation for AI safety. Notably, RAIN operates without the need of extra data for model alignment and abstains from any training, gradient computation, or parameter updates. Experimental results evaluated by GPT-4 and humans demonstrate the effectiveness of RAIN: on the HH dataset, RAIN improves the harmlessness rate of LLaMA 30B from 82% of vanilla inference to 97%, while maintaining the helpfulness rate. On the TruthfulQA dataset, RAIN improves the truthfulness of the already-well-aligned LLaMA-2-chat 13B model by 5%. The code is available at https://github.com/SafeAILab/RAIN.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces a novel inference method called Rewindable Auto-regressive INference (RAIN) that enables frozen large language models (LLMs) to align themselves without finetuning or requiring additional data. RAIN integrates self-evaluation and rewind mechanisms to guide the generation process, allowing LLMs to produce responses consistent with human preferences. The authors evaluate RAIN on various datasets, including the Anthropic's Helpful and Harmless (HH) dataset and the TruthfulQA dataset, and demonstrate its effectiveness in improving the harmlessness rate and truthfulness of LLMs.\n\nStrengths:\n1. RAIN is a novel and effective approach to aligning frozen LLMs without requiring additional data or finetuning.\n2. The method is based on self-evaluation and rewind mechanisms, which are intuitive and well-suited for LLMs.\n3. RAIN is flexible and can be employed as a plug-in during the inference phase, allowing it to be easily integrated with existing LLMs.\n4. The authors provide a detailed explanation of the RAIN method and its components, making it accessible to readers with varying backgrounds.\n\nWeaknesses:\n1. The paper assumes that the self-evaluation mechanism is accurate, which may not always be the case. There is a risk of biased or inaccurate evaluations, which could negatively impact the performance of RAIN.\n2. The RAIN method may not be effective for all types of LLMs or datasets. Further evaluation is needed to determine its applicability and limitations.\n3. The authors do not provide a clear comparison with existing alignment methods, such as RLHF and RLAIF, which may provide a more comprehensive understanding of the strengths and weaknesses of RAIN.\n\nSuggestions for Improvement:\n1. The authors should provide a more detailed analysis of the self-evaluation mechanism, including its limitations and potential biases.\n2. Further evaluation is needed to determine the applicability and limitations of RAIN for different types of LLMs and datasets.\n3. A comparison with existing alignment methods, such as RLHF and RLAIF, should be included to provide a more comprehensive understanding of the strengths and weaknesses of RAIN.\n\nRecommendation:\nThe paper presents a novel and effective approach to aligning frozen LLMs without requiring additional data or finetuning. While there are some limitations and potential biases in the self-evaluation mechanism, RAIN shows promise as a plug-in approach for improving the safety and truthfulness of LLMs. With further evaluation and analysis, RAIN has the potential to become a widely adopted and effective method for aligning LLMs.",
        "peer_review_with_watermark": "$$$ Paper Summary:\nThe paper proposes a novel method called Rewindable Auto-regressive INference (RAIN) for aligning frozen large language models (LLMs) without requiring finetuning or labeled data. RAIN integrates self-evaluation and rewind mechanisms into the generation phase of LLMs, enabling them to produce responses consistent with human preferences. The authors demonstrate the effectiveness of RAIN using various experiments and compare it with other alignment methods. \n\nStrengths:\n1. RAIN is a novel approach that integrates self-evaluation and rewind mechanisms into LLM generation.\n2. It does not require finetuning or labeled data, making it a promising method for aligning frozen LLMs.\n3. RAIN can be employed as a plug-in, making it easy to integrate with existing auto-regressive language models.\n4. Experimental results demonstrate the effectiveness of RAIN in improving alignment and safety of LLMs.\n\nWeaknesses:\n1. RAIN may not perform well for small-scale models or models with limited capacity.\n2. The method may not be suitable for all language generation tasks or domains.\n3. RAIN requires computational resources and may have a higher time overhead compared to vanilla auto-regressive inference.\n4. The accuracy of self-evaluation may have errors, which can impact the performance of RAIN.\n\nSuggestions for Improvement:\n1. Investigate RAIN's performance on small-scale models and models with limited capacity.\n2. Evaluate RAIN's effectiveness for various language generation tasks and domains.\n3. Optimize RAIN's computational resources and time overhead.\n4. Improve the accuracy of self-evaluation by using more sophisticated evaluation metrics or techniques.\n\nRecommendation:\nThe paper presents a novel and promising approach for aligning frozen LLMs using RAIN. While there are some limitations and areas for improvement, RAIN demonstrates its effectiveness in improving alignment and safety of LLMs. Further research is needed to address these limitations and optimize RAIN for various use cases. I recommend accepting the paper for publication in its current state.",
        "gr_score_with": 0.8266666666666667,
        "gr_score_without": 0.7202216066481995,
        "output_without": {
            "num_tokens_scored": 361,
            "num_green_tokens": 260,
            "green_fraction": 0.7202216066481995,
            "z_score": 0.8384161045909193,
            "p_value": 0.20089852386888463
        },
        "output_with": {
            "num_tokens_scored": 300,
            "num_green_tokens": 248,
            "green_fraction": 0.8266666666666667,
            "z_score": 4.787549991450211,
            "p_value": 8.441484546088017e-07
        }
    },
    {
        "title": "GRAPH NEURAL NETWORKS",
        "abstract": "Fairness-aware graph neural networks (GNNs) have gained a surge of attention as they can reduce the bias of predictions on any demographic group (e.g., female) in graph-based applications. Although these methods greatly improve the algorithmic fairness of GNNs, the fairness can be easily corrupted by carefully designed adversarial attacks. In this paper, we investigate the problem of adversarial attacks on fairness of GNNs and propose G-FairAttack, a general framework for attacking various types of fairness-aware GNNs in terms of fairness with an unnoticeable effect on prediction utility. In addition, we propose a fast computation technique to reduce the time complexity of G-FairAttack. The experimental study demonstrates that G-FairAttack successfully corrupts the fairness of different types of GNNs while keeping the attack unnoticeable. Our study on fairness attacks sheds light on potential vulnerabilities in fairness-aware GNNs and guides further research on the robustness of GNNs in terms of fairness.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary: \nThe paper proposes a novel fairness attack method on Graph Neural Networks (GNNs) named GFairAttack, which consists of two parts: a carefully designed surrogate loss function and an optimization method. The proposed surrogate loss function is designed to represent all types of fairness loss terms, and the optimization method uses a non-gradient attack algorithm to solve the constrained optimization problem. The paper also proposes a fast computation technique to reduce the time complexity of GFairAttack.\n\nStrengths:\n- The paper proposes a novel fairness attack method on GNNs, which is the first to consider the unnoticeable requirement for fairness attacks.\n- The proposed surrogate loss function is designed to represent all types of fairness loss terms, making it a versatile and effective attack method.\n- The paper provides a fast computation technique to reduce the time complexity of GFairAttack, making it more efficient and practical for real-world applications.\n\nWeaknesses:\n- The paper does not provide a comprehensive analysis of the potential vulnerabilities in fairness-aware GNNs, which is an important aspect of fairness attacks.\n- The proposed optimization method uses a non-gradient attack algorithm, which may not be effective for all types of fairness-aware GNNs.\n- The paper does not provide a detailed analysis of the impact of the parameter 'a' on the time cost and test results for victim models, which is an important aspect of the fast computation technique.\n\nSuggestions for Improvement:\n- The paper should provide a more comprehensive analysis of the potential vulnerabilities in fairness-aware GNNs, including a discussion of the limitations and challenges of fairness attacks.\n- The proposed optimization method should be further analyzed to determine its effectiveness for different types of fairness-aware GNNs.\n- The paper should provide a more detailed analysis of the impact of the parameter 'a' on the time cost and test results for victim models, including a discussion of the tradeoff between effectiveness and efficiency.\n\nRecommendation:\n- The paper makes a significant contribution to the field of fairness attacks on GNNs, and the proposed GFairAttack method is a novel and effective attack method.\n- The paper provides a fast computation technique to reduce the time complexity of GFairAttack, making it more efficient and practical for real-world applications.\n- However, the paper has some limitations and weaknesses that need to be addressed, including a lack of comprehensive analysis of potential vulnerabilities and limitations of the proposed optimization method.\n- The paper should be further improved to address these limitations and weaknesses, and to provide a more comprehensive analysis of the potential vulnerabilities in fairness-aware GNNs.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$Paper Summary: \nThe paper proposes the first unnoticeable fairness attack framework, G-FairAttack, to attack fairness-aware graph neural networks (GNNs). The attack framework is designed to target the fairness of GNNs while keeping the attack unnoticeable to the model owner. The proposed attack framework consists of two parts: a surrogate loss function and an optimization method. The surrogate loss function is designed to represent the unknown victim loss function, and the optimization method is used to find the optimal poisoned graph structure. The paper also proposes a fast computation approach to reduce the time complexity of the attack.\n\nStrengths: \n- The paper proposes a novel and effective attack framework, G-FairAttack, to attack fairness-aware GNNs.\n- The attack framework is designed to target the fairness of GNNs while keeping the attack unnoticeable to the model owner.\n- The paper also proposes a fast computation approach to reduce the time complexity of the attack.\n\nWeaknesses: \n- The paper does not provide a detailed analysis of the vulnerability of fairness-aware GNNs to attacks.\n- The proposed attack framework is limited to fairness evasion attacks and does not consider fairness poisoning attacks.\n- The paper does not provide a thorough evaluation of the attack framework's performance on different types of GNNs.\n\nSuggestions for Improvement: \n- The paper should provide a detailed analysis of the vulnerability of fairness-aware GNNs to attacks.\n- The proposed attack framework should be extended to consider fairness poisoning attacks.\n- The paper should provide a thorough evaluation of the attack framework's performance on different types of GNNs.\n\nRecommendation: \n- The paper proposes a novel and effective attack framework, G-FairAttack, to attack fairness-aware GNNs.\n- The attack framework is designed to target the fairness of GNNs while keeping the attack unnoticeable to the model owner.\n- However, the paper should provide a detailed analysis of the vulnerability of fairness-aware GNNs to attacks and extend the attack framework to consider fairness poisoning attacks.\n- The paper should also provide a thorough evaluation of the attack framework's performance on different types of GNNs.\n\n$$\\begin{aligned}\n$$Note: The review is based on the provided paper and is written in the standard conference peer-review format.",
        "gr_score_with": 0.8516746411483254,
        "gr_score_without": 0.7185185185185186,
        "output_without": {
            "num_tokens_scored": 270,
            "num_green_tokens": 194,
            "green_fraction": 0.7185185185185186,
            "z_score": 0.664015894074663,
            "p_value": 0.25334006922310737
        },
        "output_with": {
            "num_tokens_scored": 209,
            "num_green_tokens": 178,
            "green_fraction": 0.8516746411483254,
            "z_score": 4.784939729133243,
            "p_value": 8.551932469317794e-07
        }
    },
    {
        "title": "AN EFFICIENT MEMBERSHIP INFERENCE ATTACK FOR THE DIFFUSION MODEL BY PROXIMAL INITIALIZATION",
        "abstract": "Recently, diffusion models have achieved remarkable success in generating tasks, including image and audio generation. However, like other generative models, diffusion models are prone to privacy issues. In this paper, we propose an efficient query-based membership inference attack (MIA), namely Proximal Initialization Attack (PIA), which utilizes groundtruth trajectory obtained by \u03b5 initialized in t = 0 and predicted point to infer memberships. Experimental results indicate that the proposed method can achieve competitive performance with only two queries that achieve at least 6\u00d7 efficiency than the previous SOTA baseline on both discrete-time and continuous-time diffusion models. Moreover, previous works on the privacy of diffusion models have focused on vision tasks without considering audio tasks. Therefore, we also explore the robustness of diffusion models to MIA in the text-tospeech (TTS) task, which is an audio generation task. To the best of our knowledge, this work is the first to study the robustness of diffusion models to MIA in the TTS task. Experimental results indicate that models with mel-spectrogram (image-like) output are vulnerable to MIA, while models with audio output are relatively robust to MIA. Code is available at https://github.com/kong13661/PIA.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes a novel membership inference attack (MIA) method for diffusion models, called Proximal Initialization Attack (PIA). The method leverages the groundtruth trajectory of a diffusion model to infer the membership of a sample. Experimental results demonstrate the effectiveness of PIA on various diffusion models, including continuous-time and discrete-time models. The paper also explores the robustness of diffusion models to MIA in the text-to-speech (TTS) task and finds that models with audio output are more robust to MIA.\n\nStrengths:\n1. The paper proposes a novel MIA method for diffusion models, which is an active area of research.\n2. The experimental results demonstrate the effectiveness of PIA on various diffusion models.\n3. The paper explores the robustness of diffusion models to MIA in the TTS task, which is a new aspect of research.\n\nWeaknesses:\n1. The paper does not provide a clear theoretical foundation for the proposed MIA method.\n2. The experimental results are limited to a few diffusion models and TTS datasets.\n3. The paper does not discuss the potential limitations and challenges of the proposed MIA method.\n\nSuggestions for Improvement:\n1. Provide a clear theoretical foundation for the proposed MIA method, including the underlying mathematical framework and the assumptions made.\n2. Conduct experiments on a larger set of diffusion models and TTS datasets to demonstrate the generalizability of PIA.\n3. Discuss the potential limitations and challenges of the proposed MIA method, including the impact of model complexity, dataset size, and query budget.\n\nRecommendation:\nBased on the paper's contributions and experimental results, I recommend accepting the paper for publication in its current form. However, I suggest that the authors address the limitations and challenges mentioned above to strengthen the paper's overall quality and impact.\n\n $$$",
        "peer_review_with_watermark": "$$\n$$ $$$$\n\nPaper Summary:\nThe paper proposes a novel membership inference attack (MIA) method for diffusion models, called Proximal Initialization Attack (PIA). PIA is a query-based attack that uses the groundtruth trajectory obtained by initializing the diffusion process with a small noise and predicting the next point. The attack is designed to be efficient and can achieve competitive performance with only two queries. The authors evaluate the attack on three image datasets and three audio datasets and show that PIA can achieve higher True Positive Rate (TPR) at 1% False Positive Rate (FPR) compared to previous methods.\n\nStrengths:\n1. The authors propose a novel and efficient MIA method for diffusion models.\n2. The attack is designed to be query-based, making it suitable for models that are difficult to query.\n3. The authors evaluate the attack on both image and audio datasets.\n4. The results show that PIA can achieve higher TPR at 1% FPR compared to previous methods.\n\nWeaknesses:\n1. The attack relies on the availability of the groundtruth trajectory, which may not be feasible in all cases.\n2. The attack may not be effective for models that have a large amount of noise in their training data.\n3. The authors do not provide a comprehensive evaluation of the attack's performance on different models and datasets.\n4. The paper does not provide a detailed explanation of the attack's mechanism and how it works.\n\nSuggestions for Improvement:\n1. Provide a more detailed explanation of the attack's mechanism and how it works.\n2. Evaluate the attack's performance on a more comprehensive set of models and datasets.\n3. Provide a more detailed analysis of the attack's limitations and potential biases.\n4. Consider providing a more detailed explanation of how the attack can be improved and extended to other types of models.\n\nRecommendation:\nThe paper proposes a novel and efficient MIA method for diffusion models. While the attack has some limitations, it is a significant contribution to the field of MIA and diffusion models. The authors should consider providing a more detailed explanation of the attack's mechanism and how it works, as well as evaluating the attack's performance on a more comprehensive set of models and datasets.\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$$\n\n$$ $$$\n\n$$ $$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$\n$$",
        "gr_score_with": 0.7710437710437711,
        "gr_score_without": 0.7315175097276264,
        "output_without": {
            "num_tokens_scored": 257,
            "num_green_tokens": 188,
            "green_fraction": 0.7315175097276264,
            "z_score": 1.1025766981069645,
            "p_value": 0.1351055170440349
        },
        "output_with": {
            "num_tokens_scored": 297,
            "num_green_tokens": 229,
            "green_fraction": 0.7710437710437711,
            "z_score": 2.6717424036648483,
            "p_value": 0.003772927486665982
        }
    },
    {
        "title": "INTRA-CLASS INCOHERENCE",
        "abstract": "The current face recognition (FR) algorithms has achieved a high level of accuracy, making further improvements increasingly challenging. While existing FR algorithms primarily focus on optimizing margins and loss functions, limited attention has been given to exploring the feature representation space. Therefore, this paper endeavors to improve FR performance in the view of feature representation space. Firstly, we consider two FR models that exhibit distinct performance discrepancies, where one model exhibits superior recognition accuracy compared to the other. We implement orthogonal decomposition on the features from the superior model along those from the inferior model and obtain two sub-features. Surprisingly, we find the sub-feature orthogonal to the inferior still possesses a certain level of face distinguishability. We adjust the modulus of the sub-features and recombine them through vector addition. Experiments demonstrate this recombination is likely to contribute to an improved facial feature representation, even better than features from the original superior model. Motivated by this discovery, we further consider how to improve FR accuracy when there is only one FR model available. Inspired by knowledge distillation, we incorporate the intraclass incoherence constraint (IIC) to solve the problem. Experiments on various FR benchmarks show the existing state-of-the-art method with IIC can be further improved, highlighting its potential to further enhance FR performance.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary:\nThe paper proposes a novel approach to improve face recognition performance by introducing intra-class incoherence constraint (IIC) into the face recognition framework. The authors analyze the feature representation space of two face recognition models and discover that the superior model contains innovations that are orthogonal to the inferior model. They propose a method to incorporate these innovations into the feature representation space, which leads to improved face recognition performance. The authors also explore the application of IIC to existing face recognition algorithms and demonstrate its potential to further enhance face recognition accuracy.\n\nStrengths:\n1. The paper provides a thorough analysis of the feature representation space of face recognition models and introduces a novel approach to improve face recognition performance.\n2. The authors demonstrate the effectiveness of IIC in improving face recognition accuracy on various benchmarks.\n3. The paper explores the application of IIC to existing face recognition algorithms and highlights its potential to further enhance face recognition accuracy.\n\nWeaknesses:\n1. The paper relies heavily on the assumption that the superior model contains innovations that are orthogonal to the inferior model, which may not always be the case.\n2. The authors do not provide a comprehensive evaluation of the IIC approach on different face recognition datasets and algorithms.\n3. The paper does not discuss the potential limitations and challenges of the IIC approach.\n\nSuggestions for Improvement:\n1. The authors should provide a more comprehensive evaluation of the IIC approach on different face recognition datasets and algorithms.\n2. The authors should discuss the potential limitations and challenges of the IIC approach, such as the need for careful tuning of hyperparameters and the potential impact on model generalizability.\n3. The authors should explore the application of IIC to other computer vision tasks and datasets.\n\nRecommendation:\nThe paper proposes a novel approach to improve face recognition performance by introducing intra-class incoherence constraint (IIC) into the face recognition framework. While the paper demonstrates the effectiveness of IIC on various benchmarks, it is essential to provide a more comprehensive evaluation of the approach and discuss its potential limitations and challenges. With further development and evaluation, the IIC approach has the potential to contribute to the field of face recognition and computer vision.\n\n$$\\begin{aligned}\n$$",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$Paper Summary:\nThe paper proposes a novel approach to improve face recognition performance by introducing intra-class incoherence constraint (IIC) into the face recognition framework. The authors analyze the feature representation space of two face recognition models and find that the superior model contains innovations that are orthogonal to the inferior model. They propose a method to incorporate these innovations into the inferior model to improve its performance. The authors evaluate their approach on several face recognition benchmarks and show that it outperforms the existing state-of-the-art methods.\n\nStrengths:\n1. The paper provides a thorough analysis of the feature representation space of face recognition models and identifies the benefits of incorporating innovations into the inferior model.\n2. The authors propose a novel approach to improve face recognition performance by introducing IIC, which is a unique and innovative idea.\n3. The paper evaluates the proposed approach on several face recognition benchmarks and shows that it outperforms the existing state-of-the-art methods.\n\nWeaknesses:\n1. The paper does not provide a clear motivation for why IIC is beneficial for face recognition. The authors assume that IIC is beneficial, but they do not provide a rigorous proof.\n2. The paper does not discuss the limitations of the proposed approach. For example, the authors do not discuss the effect of IIC on the training time or the computational cost of the proposed approach.\n3. The paper does not provide a comparison of the proposed approach with other state-of-the-art methods. While the authors evaluate their approach on several benchmarks, they do not provide a comparison with other methods that use different approaches to improve face recognition performance.\n\nSuggestions for Improvement:\n1. The authors should provide a clear motivation for why IIC is beneficial for face recognition. They should provide a rigorous proof that IIC improves face recognition performance.\n2. The authors should discuss the limitations of the proposed approach. They should evaluate the effect of IIC on the training time, computational cost, and other factors that may impact the performance of the proposed approach.\n3. The authors should provide a comparison of the proposed approach with other state-of-the-art methods. They should evaluate their approach on several benchmarks and compare it with other methods that use different approaches to improve face recognition performance.\n\nRecommendation:\nI recommend that the authors revise their paper to address the weaknesses and improve the strengths of the paper. The authors should provide a clear motivation for why IIC is beneficial for face recognition, discuss the limitations of the proposed approach, and provide a comparison with other state-of-the-art methods. With these revisions, the paper has the potential to be a significant contribution to the field of face recognition.\n\n$$\\begin{aligned}",
        "gr_score_with": 0.8515901060070671,
        "gr_score_without": 0.8260869565217391,
        "output_without": {
            "num_tokens_scored": 253,
            "num_green_tokens": 209,
            "green_fraction": 0.8260869565217391,
            "z_score": 4.376437947661414,
            "p_value": 6.03172567259083e-06
        },
        "output_with": {
            "num_tokens_scored": 283,
            "num_green_tokens": 241,
            "green_fraction": 0.8515901060070671,
            "z_score": 5.564862359870266,
            "p_value": 1.3117970505921916e-08
        }
    },
    {
        "title": "POLYNORMER: POLYNOMIAL-EXPRESSIVE GRAPH TRANSFORMER IN LINEAR TIME",
        "abstract": "Graph transformers (GTs) have emerged as a promising architecture that is theoretically more expressive than message-passing graph neural networks (GNNs). However, typical GT models have at least quadratic complexity and thus cannot scale to large graphs. While there are several linear GTs recently proposed, they still lag behind GNN counterparts on several popular graph datasets, which poses a critical concern on their practical expressivity. To balance the trade-off between expressivity and scalability of GTs, we propose Polynormer, a polynomialexpressive GT model with linear complexity. Polynormer is built upon a novel base model that learns a high-degree polynomial on input features. To enable the base model permutation equivariant, we integrate it with graph topology and node features separately, resulting in local and global equivariant attention models. Consequently, Polynormer adopts a linear local-to-global attention scheme to learn high-degree equivariant polynomials whose coefficients are controlled by attention scores. Polynormer has been evaluated on 13 homophilic and heterophilic datasets, including large graphs with millions of nodes. Our extensive experiment results show that Polynormer outperforms state-of-the-art GNN and GT baselines on most datasets, even without the use of nonlinear activation functions. Source code of Polynormer is freely available at: github.com/cornell-zhang/Polynormer.",
        "peer_review_without_watermark": "$$$\\boxed{\\text{Paper Summary:}}$\n\nThe paper proposes Polynormer, a linear graph transformer that is polynomial-expressive and scalable to large graphs. It builds upon a base model that learns a high-degree polynomial on input features and integrates graph topology and node features separately to derive local and global equivariant attention models. The proposed architecture adopts a local-to-global attention scheme to learn high-degree equivariant polynomials whose coefficients are controlled by attention scores. Polynormer has been evaluated on 13 homophilic and heterophilic datasets and outperforms state-of-the-art GNN and GT baselines on most datasets, even without the use of nonlinear activation functions.\n\n$\\boxed{\\text{Strengths:}}$\n\n1. The paper introduces a novel approach to balance the expressivity and scalability of graph transformers.\n2. The proposed Polynormer architecture is polynomial-expressive and can learn high-degree equivariant polynomials with linear complexity.\n3. The paper provides extensive experimental results on various graph datasets and demonstrates the efficacy of Polynormer.\n\n$\\boxed{\\text{Weaknesses:}}$\n\n1. The paper may benefit from more detailed analysis of the computational complexity of the proposed architecture.\n2. The evaluation of Polynormer on large graphs relies on random partitioning, which may not accurately represent the full-batch training scenario.\n3. The paper may provide more insights on the interpretability of the attention scores and their role in learning critical global structural information.\n\n$\\boxed{\\text{Suggestions for Improvement:}}$\n\n1. Provide a more detailed analysis of the computational complexity of the proposed architecture and discuss potential optimization techniques to improve scalability.\n2. Evaluate Polynormer on larger graphs using full-batch training or other methods to ensure robustness.\n3. Provide more insights on the interpretability of the attention scores and their role in learning critical global structural information.\n\n$\\boxed{\\text{Recommendation:}}$\n\nBased on the experimental results and the proposed architecture, I recommend accepting the paper for publication. However, I suggest that the authors address the potential weaknesses and provide additional insights to further strengthen the paper.",
        "peer_review_with_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes Polynormer, a polynomial-expressive graph transformer model that can expressively represent a high-degree polynomial in linear time. Polynormer is built upon a base model that learns a high-degree polynomial on input features, and it adopts a local-to-global attention scheme to learn high-degree equivariant polynomials whose coefficients are controlled by attention scores. The model is evaluated on 13 homophilic and heterophilic datasets, and the results show that Polynormer outperforms state-of-the-art GNN and GT baselines on most datasets, even without the use of nonlinear activation functions.\n\nStrengths:\n- The paper introduces a new concept of polynomial-expressiveness in graph transformers, which is theoretically more expressive than message-passing graph neural networks (GNNs).\n- The proposed Polynormer model is capable of learning high-degree polynomials in linear time, making it scalable to large graphs.\n- The paper evaluates Polynormer on a wide range of graph datasets and achieves state-of-the-art results.\n\nWeaknesses:\n- The paper relies heavily on the proposed base model, and it is unclear how the base model is trained and optimized.\n- The paper does not provide a comprehensive analysis of the polynomial expressivity of Polynormer, and it is unclear how the model captures global and high-order feature interactions.\n- The paper does not provide a clear comparison of Polynormer with other graph models, and it is unclear how the model compares to other state-of-the-art models in terms of performance and scalability.\n\nSuggestions for Improvement:\n- Provide a more comprehensive analysis of the polynomial expressivity of Polynormer, including a detailed explanation of how the model captures global and high-order feature interactions.\n- Provide a clear comparison of Polynormer with other graph models, including a discussion of the performance and scalability of the model in comparison to other state-of-the-art models.\n- Provide a more detailed explanation of how the base model is trained and optimized, including the optimization algorithm and the training procedure.\n\nRecommendation:\n- The paper introduces a new and interesting concept of polynomial-expressiveness in graph transformers, and the proposed Polynormer model is capable of learning high-degree polynomials in linear time, making it scalable to large graphs.\n- However, the paper relies heavily on the proposed base model, and a more comprehensive analysis of the polynomial expressivity of Polynormer is needed to fully understand the capabilities of the model.\n- Overall, the paper is well-written and provides a clear overview of the proposed model and its evaluation on various graph datasets. However, further analysis and comparison with other graph models are needed to fully understand the strengths and limitations of Polynormer.}$",
        "gr_score_with": 0.7963525835866262,
        "gr_score_without": 0.7114754098360656,
        "output_without": {
            "num_tokens_scored": 305,
            "num_green_tokens": 217,
            "green_fraction": 0.7114754098360656,
            "z_score": 0.4373292016331551,
            "p_value": 0.33093631028177595
        },
        "output_with": {
            "num_tokens_scored": 329,
            "num_green_tokens": 262,
            "green_fraction": 0.7963525835866262,
            "z_score": 3.8137451282583807,
            "p_value": 6.84383149839e-05
        }
    },
    {
        "title": "COT3DREF: CHAIN-OF-THOUGHTS DATA-EFFICIENT 3D VISUAL GROUNDING",
        "abstract": "3D visual grounding is the ability to localize objects in 3D scenes conditioned by utterances. Most existing methods devote the referring head to localize the referred object directly, causing failure in complex scenarios. In addition, it does not illustrate how and why the network reaches the final decision. In this paper, we address this question \u201cCan we design an interpretable 3D visual grounding framework that has the potential to mimic the human perception system?\u201d. To this end, we formulate the 3D visual grounding problem as a sequence-to-sequence (Seq2Seq) task by first predicting a chain of anchors and then the final target. Interpretability not only improves the overall performance but also helps us identify failure cases. Following the chain of thoughts approach enables us to decompose the referring task into interpretable intermediate steps, boosting the performance and making our framework extremely data-efficient. Moreover, our proposed framework can be easily integrated into any existing architecture. We validate our approach through comprehensive experiments on the Nr3D, Sr3D, and Scanrefer benchmarks and show consistent performance gains compared to existing methods without requiring manually annotated data. Furthermore, our proposed framework, dubbed CoT3DRef, is significantly data-efficient, whereas on the Sr3D dataset, when trained only on 10% of the data, we match the SOTA performance that trained on the entire data. The code is available at https://cot3dref.github.io/.",
        "peer_review_without_watermark": "$$$${Paper Title: COT3DREF: CHAIN-OF-THOUGHTS DATA-EFFICIENT 3D VISUAL GROUNDING}\n\nThe paper proposes a novel framework for 3D visual grounding, termed CoT3DRef, which addresses the limitations of existing methods in terms of interpretability and data efficiency. The authors formulate the 3D visual grounding problem as a sequence-to-sequence task and introduce a Chain-of-Thoughts (CoT) approach to decompose the referring task into multiple interpretable steps. The proposed framework achieves state-of-the-art results on three challenging benchmarks, Nr3D, Sr3D, and ScanRefer, without requiring any manual annotations.\n\n**Strengths:**\n\n1. The paper provides a clear and concise overview of the 3D visual grounding problem and the limitations of existing methods.\n2. The CoT approach is well-explained, and the authors provide a detailed description of the proposed framework.\n3. The authors conduct extensive experiments to evaluate the performance of CoT3DRef on three challenging benchmarks.\n4. The paper discusses the limitations of the proposed framework, including the accuracy gap between automatically collected pseudo-labels and ground-truth data.\n\n**Weaknesses:**\n\n1. The paper does not provide a thorough analysis of the strengths and weaknesses of existing methods.\n2. The authors rely heavily on pseudo-labels, which can lead to performance degradation on certain benchmarks.\n3. The paper does not provide a detailed discussion of the limitations of the anchor localization block in the pseudo module.\n4. The authors do not provide a comprehensive evaluation of the proposed framework on other 3D scene datasets.\n\n**Suggestions for Improvement:**\n\n1. Provide a more detailed analysis of the strengths and weaknesses of existing methods.\n2. Explore alternative approaches to anchor localization, such as using human-annotated data or more advanced machine learning algorithms.\n3. Discuss the limitations of the pseudo module in more detail and provide suggestions for improvement.\n4. Evaluate the proposed framework on other 3D scene datasets to demonstrate its generalizability.\n\n**Recommendation:**\n\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit the paper for publication. The authors have made significant contributions to the field of 3D visual grounding, and their proposed framework has the potential to improve the interpretability and data efficiency of existing methods. However, the authors need to address the limitations of their framework and provide a more comprehensive evaluation of its performance on other benchmarks and datasets.\n\n$$${Paper Summary:}\n\nThe paper proposes a novel framework for 3D visual grounding, termed CoT3DRef, which addresses the limitations of existing methods in terms of interpretability and data efficiency. The authors formulate the 3D visual grounding problem as a sequence-to-sequence task and introduce a Chain-of-Thoughts (CoT) approach to decompose the referring task into multiple interpretable steps. The proposed framework achieves state-of-the-art results on three challenging benchmarks, Nr3D, Sr3D, and ScanRefer, without requiring any manual annotations.\n\n**Strengths:**\n\n* Clear and concise overview of the 3D visual grounding problem\n* Well-explained CoT approach\n* State-of-the-art results on three challenging benchmarks\n* Data-efficient framework without manual annotations\n\n**Weaknesses:**\n\n* Rely heavily on pseudo-labels\n* Limited evaluation on other 3D scene datasets\n* Lack of detailed analysis of existing methods\n* Limited discussion of limitations of the anchor localization block\n\n**Suggestions for Improvement:**\n\n* Provide a more detailed analysis of existing methods\n* Explore alternative approaches to anchor localization\n* Discuss limitations of the pseudo module in more detail\n* Evaluate framework on other 3D scene datasets\n\n**Recommendation:**\n\nRevise and resubmit the paper for publication. The authors have made significant contributions to the field of 3D visual grounding, and their proposed framework has the potential to improve the interpretability and data efficiency of existing methods. However, the authors need to address the limitations of their framework and provide a more comprehensive evaluation of its performance on other benchmarks and datasets.",
        "peer_review_with_watermark": "$$$${Paper: COT3DREF: CHAIN-OF-THOUGHTS DATA-EFFICIENT 3D VISUAL GROUNDING\n\nPaper Summary:\nThe authors propose a novel framework for 3D visual grounding called CoT3DRef. The framework formulates the problem as a sequence-to-sequence task, where the input is a natural language description and the output is a chain of anchor objects and the final target object. The authors use a Chain-of-Thoughts (CoT) approach to decompose the referring task into multiple interpretable steps. The framework achieves state-of-the-art results on three challenging benchmarks (Nr3D, Sr3D, and ScanRefer) without requiring any additional manual annotations.\n\nStrengths:\n\n1. The authors address the limitations of existing methods by proposing a new framework that incorporates a Chain-of-Thoughts approach.\n2. The framework is data-efficient and can be easily integrated into other architectures.\n3. The authors use a combination of rule-based methods, syntactic parsing, and in-context learning to collect pseudo-labels for the anchor objects.\n\nWeaknesses:\n\n1. The accuracy of the pseudo-labels plays a vital role in the overall performance, and the authors acknowledge a significant accuracy gap between automatically collected pseudo-labels and ground-truth data.\n2. The anchor localization block in the pseudo module is tailored on the ScanNet dataset and will thus need some adaptations to be usable on other 3D scene datasets.\n3. The Pathway module does not handle the multi-path scenario, where multiple paths are valid.\n\nSuggestions for Improvement:\n\n1. Enhance the performance of the pseudo-label module by collecting high-quality labels or using more accurate methods for label generation.\n2. Adapt the anchor localization block to other 3D scene datasets.\n3. Improve the Pathway module to handle the multi-path scenario.\n\nRecommendation:\n\nThe proposed framework, CoT3DRef, is a significant contribution to the field of 3D visual grounding. The authors' use of a Chain-of-Thoughts approach and data-efficient methods makes the framework attractive for practical applications. However, further improvement is needed to address the limitations mentioned above.\n\nRating: 8/10\n\nTime: O(1)\n\nSpace: O(n)\n\nNote: The rating is based on the overall quality of the paper, the significance of the contribution, and the potential impact on the field. The time and space complexity are not directly relevant to the rating but are provided for completeness.\n\nPlease let me know if you want me to make any changes or if you'd like me to review another paper.",
        "gr_score_with": 0.7180094786729858,
        "gr_score_without": 0.726161369193154,
        "output_without": {
            "num_tokens_scored": 409,
            "num_green_tokens": 297,
            "green_fraction": 0.726161369193154,
            "z_score": 1.1545492840781977,
            "p_value": 0.12413752268056771
        },
        "output_with": {
            "num_tokens_scored": 422,
            "num_green_tokens": 303,
            "green_fraction": 0.7180094786729858,
            "z_score": 0.8073237325370688,
            "p_value": 0.2097399971761204
        }
    },
    {
        "title": "ADVERSARIAL CAUSAL BAYESIAN OPTIMIZATION",
        "abstract": "In Causal Bayesian Optimization (CBO), an agent intervenes on a structural causal model with known graph but unknown mechanisms to maximize a downstream reward variable. In this paper, we consider the generalization where other agents or external events also intervene on the system, which is key for enabling adaptiveness to non-stationarities such as weather changes, market forces, or adversaries. We formalize this generalization of CBO as Adversarial Causal Bayesian Optimization (ACBO) and introduce the first algorithm for ACBO with bounded regret: Causal Bayesian Optimization with Multiplicative Weights (CBO-MW). Our approach combines a classical online learning strategy with causal modeling of the rewards. To achieve this, it computes optimistic counterfactual reward estimates by propagating uncertainty through the causal graph. We derive regret bounds for CBO-MW that naturally depend on graph-related quantities. We further propose a scalable implementation for the case of combinatorial interventions and submodular rewards. Empirically, CBO-MW outperforms non-causal and non-adversarial Bayesian optimization methods on synthetic environments and environments based on real-word data. Our experiments include a realistic demonstration of how CBO-MW can be used to learn users\u2019 demand patterns in a shared mobility system and reposition vehicles in strategic areas.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$\\textbf{Paper Summary:}$$\nThe paper introduces Adversarial Causal Bayesian Optimization (ACBO), a generalization of Causal Bayesian Optimization (CBO) that incorporates external events and adversaries. The authors propose a novel algorithm, CBO-MW, that combines classical online learning with causal modeling of rewards. The algorithm is shown to have bounded regret and is scalable for combinatorial interventions and submodular rewards. The authors also propose a distributed version of the algorithm, D-CBO-MW, that can scale to large action spaces.\n\n$$\\textbf{Strengths:}$$\n1. The paper introduces a novel and important generalization of CBO that incorporates external events and adversaries.\n2. The authors propose a novel algorithm, CBO-MW, that combines classical online learning with causal modeling of rewards.\n3. The algorithm is shown to have bounded regret and is scalable for combinatorial interventions and submodular rewards.\n4. The authors also propose a distributed version of the algorithm, D-CBO-MW, that can scale to large action spaces.\n\n$$\\textbf{Weaknesses:}$$\n1. The paper assumes a strong regularity assumption on the functions fi, which may not hold in practice.\n2. The authors do not provide a clear analysis of the computational complexity of the algorithm.\n3. The paper does not provide a clear comparison of the performance of CBO-MW and D-CBO-MW on different synthetic function network tasks.\n\n$$\\textbf{Suggestions for Improvement:}$$\n1. Provide a more detailed analysis of the computational complexity of the algorithm.\n2. Provide a clear comparison of the performance of CBO-MW and D-CBO-MW on different synthetic function network tasks.\n3. Consider relaxing the strong regularity assumption on the functions fi.\n\n$$\\textbf{Recommendation:}$$\nI recommend that the authors revise the paper to address the weaknesses and suggestions for improvement. The paper has the potential to be a significant contribution to the field of causal Bayesian optimization, and with revisions, it can provide a more comprehensive analysis of the algorithm and its performance.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$\\textbf{Paper Summary:}$$\nThe paper introduces Adversarial Causal Bayesian Optimization (ACBO), a generalization of Causal Bayesian Optimization (CBO) to account for external events and other agents' interventions. ACBO is formalized as a novel algorithm called Causal Bayesian Optimization with Multiplicative Weights (CBO-MW) that combines classical online learning with causal modeling of rewards. CBO-MW is shown to achieve bounded regret and is proposed to be scalable to combinatorial interventions and submodular rewards. The authors empirically demonstrate the superiority of CBO-MW over non-causal and non-adversarial methods on synthetic and real-world data.\n\n$$\\textbf{Strengths:}$$\n- The authors provide a comprehensive analysis of the limitations of existing CBO methods and propose a novel approach to adapt to non-stationarity and multi-agent environments.\n- The use of calibrated models and causal UCB oracle enables efficient exploration-exploitation trade-off in ACBO.\n- The authors provide a detailed analysis of the theoretical performance of CBO-MW and propose a distributed version of the algorithm (D-CBO-MW) for large-scale problems.\n\n$$\\textbf{Weaknesses:}$$\n- The paper assumes a soft intervention model where interventions affect outputs additively, which might not be suitable for all problems.\n- The authors do not discuss potential limitations of using calibrated models and causal UCB oracle in practice.\n- Some sections (e.g., Appendix A.2) seem to be tangential to the main paper and might be removed for a streamlined version.\n\n$$\\textbf{Suggestions for Improvement:}$$\n- Consider discussing potential limitations and generalization of CBO-MW to other problem settings.\n- Clarify the assumptions made about the reward structure and how they might impact the performance of ACBO.\n- Consider adding a discussion on potential applications of ACBO beyond shared mobility systems.\n\n$$\\textbf{Recommendation:}$$\nThe paper presents a novel and comprehensive approach to causal Bayesian optimization in non-stationary and multi-agent environments. While there are some limitations and potential areas for improvement, the authors' work is of significant interest to researchers and practitioners in automated machine learning and decision-making under uncertainty. With some revisions to address the mentioned points, this paper can be considered for publication in a top-tier conference or journal.",
        "gr_score_with": 0.8315789473684211,
        "gr_score_without": 0.7330508474576272,
        "output_without": {
            "num_tokens_scored": 236,
            "num_green_tokens": 173,
            "green_fraction": 0.7330508474576272,
            "z_score": 1.107972429967917,
            "p_value": 0.13393686141912547
        },
        "output_with": {
            "num_tokens_scored": 380,
            "num_green_tokens": 316,
            "green_fraction": 0.8315789473684211,
            "z_score": 5.597170785495562,
            "p_value": 1.0893902643394166e-08
        }
    },
    {
        "title": "MAMMOTH: BUILDING MATH GENERALIST MODELS THROUGH HYBRID INSTRUCTION TUNING",
        "abstract": "We introduce MAmmoTH, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving. The MAmmoTH models are trained on MathInstruct, our meticulously curated instruction tuning dataset. MathInstruct is compiled from 13 math datasets with intermediate rationales, six of which have rationales newly curated by us. It presents a unique hybrid of chain-of-thought (CoT) and program-of-thought (PoT) rationales, and also ensures extensive coverage of diverse fields in math. The hybrid of CoT and PoT not only unleashes the potential of tool use but also allows different thought processes for different math problems. As a result, the MAmmoTH series substantially outperform existing open-source models on nine mathematical reasoning datasets across all scales with an average accuracy gain between 16% and 32%. Remarkably, our MAmmoTH-7B model reaches 33% on MATH (a competition-level dataset), which exceeds the best open-source 7B model (WizardMath) by 23%, and the MAmmoTH-34B model achieves 44% accuracy on MATH, even surpassing GPT4\u2019s CoT result. Our work underscores the importance of diverse problem coverage and the use of hybrid rationales in developing superior math generalist models.",
        "peer_review_without_watermark": "$$$ \n\nPaper Summary:\nThe paper introduces MAmmoTH, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving. The models are trained on MathInstruct, a meticulously curated instruction tuning dataset. The authors demonstrate that the MAmmoTH models substantially outperform existing open-source models on nine mathematical reasoning datasets across all scales, achieving average accuracy gains of 16% to 32%. The MAmmoTH-7B model even surpasses the best open-source 7B model, WizardMath, by 23%, and the MAmmoTH-34B model achieves 44% accuracy on MATH, exceeding GPT4's CoT result.\n\nStrengths:\n1. The authors have introduced a novel math instruction tuning approach, combining chain-of-thought (CoT) and program-of-thought (PoT) rationales, which significantly enhances the models' general math problem-solving capabilities.\n2. The use of a hybrid instruction tuning dataset, MathInstruct, provides diverse problem coverage and ensures extensive coverage of different math fields and complexity levels.\n3. The authors demonstrate the effectiveness of the proposed approach through extensive experiments and comparisons with existing open-source models.\n\nWeaknesses:\n1. The paper could benefit from a more detailed explanation of the hybrid instruction tuning approach and how it overcomes the limitations of existing CoT and PoT approaches.\n2. The authors rely heavily on the performance of the MAmmoTH models on specific datasets, which may not generalize to other math problem-solving tasks.\n3. The paper does not provide a comprehensive evaluation of the models' performance on more complex or abstract math problems.\n\nSuggestions for Improvement:\n1. The authors could provide more details on the architecture of the MAmmoTH models and how they integrate the CoT and PoT rationales.\n2. The evaluation of the models' performance on more complex or abstract math problems would provide a more comprehensive understanding of their general math problem-solving capabilities.\n3. The authors could explore the potential applications of the MAmmoTH models in other domains, such as science, technology, engineering, and mathematics (STEM) education.\n\nRecommendation:\nThe proposed approach and the introduction of the MAmmoTH models are significant contributions to the field of large language models. The authors' ability to combine CoT and PoT rationales and demonstrate the effectiveness of the approach through extensive experiments is commendable. However, the paper could benefit from more detailed explanations and a more comprehensive evaluation of the models' performance. With further refinement and exploration of the models' capabilities, the MAmmoTH models have the potential to become a valuable tool for math education and problem-solving. \n\nRating: 8/10\n\nRevision Comments:\n1. Please provide more details on the architecture of the MAmmoTH models.\n2. Explore the potential applications of the MAmmoTH models in other domains, such as STEM education.\n3. Provide a more comprehensive evaluation of the models' performance on more complex or abstract math problems.",
        "peer_review_with_watermark": "$$$Paper Summary:\n\nThe paper introduces MAmmoTH, a series of open-source large language models tailored for general math problem-solving. The MAmmoTH models are trained on MathInstruct, a meticulously curated instruction tuning dataset. The study demonstrates that the MAmmoTH series substantially outperform existing open-source models on nine mathematical reasoning datasets across all scales, with an average accuracy gain between 16% and 32%. The authors also highlight the importance of diverse problem coverage and the use of hybrid rationales in developing superior math generalist models.\n\nStrengths:\n\n* The study presents a novel approach to instruction tuning for LLMs, combining the strengths of chain-of-thought (CoT) and program-of-thought (PoT) rationales.\n* The use of a hybrid instruction tuning dataset, MathInstruct, provides a unique blend of broad coverage of different math fields and complexity levels, as well as hybrid CoT & PoT rationales.\n* The study demonstrates the potential of MAmmoTH models as math generalists, outperforming existing open-source models on a wide range of datasets.\n* The authors provide a comprehensive evaluation framework, including ablation studies and case studies, to demonstrate the effectiveness of the proposed approach.\n\nWeaknesses:\n\n* The study relies heavily on the quality of the MathInstruct dataset, which may not be generalizable to all math problem types.\n* The authors do not provide a detailed analysis of the limitations of the MAmmoTH models, such as their ability to handle very complex or abstract mathematical problems.\n* The study focuses primarily on the performance of MAmmoTH models on in-domain datasets, with limited exploration of their performance on out-of-domain datasets.\n* The authors do not provide a detailed explanation of the impact of the hybrid decoding strategy on the performance of MAmmoTH models.\n\nSuggestions for Improvement:\n\n* The study could benefit from a more detailed analysis of the limitations of the MAmmoTH models, including their ability to handle very complex or abstract mathematical problems.\n* The authors could explore the performance of MAmmoTH models on out-of-domain datasets, which could provide a more comprehensive understanding of their generalizability.\n* The study could include a more detailed evaluation of the impact of the hybrid decoding strategy on the performance of MAmmoTH models.\n* The authors could consider exploring the application of MAmmoTH models in other domains, such as science or engineering, to demonstrate their generalizability.\n\nRecommendation:\n\n* The study presents a novel approach to instruction tuning for LLMs, combining the strengths of CoT and PoT rationales, and demonstrates the potential of MAmmoTH models as math generalists.\n* However, the study has some limitations, including a reliance on the quality of the MathInstruct dataset and a limited exploration of the performance of MAmmoTH models on out-of-domain datasets.\n* The authors should consider addressing these limitations in future work, such as exploring the performance of MAmmoTH models on a wider range of datasets and analyzing their limitations in handling complex or abstract mathematical problems.",
        "gr_score_with": 0.7637362637362637,
        "gr_score_without": 0.6913265306122449,
        "output_without": {
            "num_tokens_scored": 392,
            "num_green_tokens": 271,
            "green_fraction": 0.6913265306122449,
            "z_score": -0.3747367070507921,
            "p_value": 0.646071855015945
        },
        "output_with": {
            "num_tokens_scored": 364,
            "num_green_tokens": 278,
            "green_fraction": 0.7637362637362637,
            "z_score": 2.6535522630557313,
            "p_value": 0.003982471752814647
        }
    },
    {
        "title": "LEFTOVER-LUNCH: ADVANTAGE-BASED OFFLINE REINFORCEMENT LEARNING FOR LANGUAGE MODELS",
        "abstract": "Reinforcement Learning with Human Feedback (RLHF) is the most prominent method for Language Model (LM) alignment. However, RLHF is an unstable and data-hungry process that continually requires new high-quality LM-generated data for finetuning. We introduce Advantage-Leftover Lunch RL (A-LOL), a new class of offline policy gradient algorithms that enable RL training on any pre-existing data. By assuming the entire LM output sequence as a single action, A-LOL allows incorporating sequence-level classifiers or human-designed scoring functions as rewards. Subsequently, by using LM\u2019s value estimate, A-LOL only trains on positive advantage (leftover) data points, making it resilient to noise. Overall, A-LOL is an easy-to-implement, sample-efficient, and stable LM training recipe. We demonstrate the effectiveness of A-LOL and its variants with a set of four different language generation tasks. We compare against both online RL (PPO) and recent preference-based (DPO, PRO) and reward-based (GOLD) offline RL baselines. On the commonly-used RLHF benchmark, Helpful and Harmless Assistant (HHA), LMs trained with A-LOL methods achieve the highest diversity while also being rated more safe and helpful than the baselines according to humans. Additionally, in the remaining three tasks, A-LOL could optimize multiple distinct reward functions even when using noisy or suboptimal training data.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary:\nThe paper proposes a novel class of offline policy gradient algorithms called Advantage-Leftover Lunch RL (A-LOL) for language model (LM) training. A-LOL is designed to be easy to implement, sample-efficient, and stable, and it can be used with any pre-existing data. The algorithm assumes the entire LM output sequence as a single action and incorporates sequence-level classifiers or human-designed scoring functions as rewards. A-LOL only trains on positive advantage (leftover) data points, making it resilient to noise. The authors demonstrate the effectiveness of A-LOL and its variants on four different language generation tasks and compare them with other offline RL methods.\n\n$$Strengths:\n1. A-LOL is designed to be easy to implement and sample-efficient.\n2. The algorithm is stable and resilient to noise.\n3. A-LOL can be used with any pre-existing data.\n4. The authors demonstrate the effectiveness of A-LOL and its variants on four different language generation tasks.\n\n$$Weaknesses:\n1. The paper does not provide a clear explanation of the importance weight and its role in the algorithm.\n2. The authors do not discuss the potential risks of using A-LOL, such as mode collapse or overfitting.\n3. The paper does not provide a comprehensive comparison of A-LOL with other offline RL methods.\n\n$$Suggestions for Improvement:\n1. Provide a clear explanation of the importance weight and its role in the algorithm.\n2. Discuss the potential risks of using A-LOL and provide suggestions for mitigating them.\n3. Conduct a more comprehensive comparison of A-LOL with other offline RL methods.\n4. Provide more details on the experimental setup and results.\n\n$$Recommendation:\nBased on the paper, I recommend that the authors continue to develop and refine A-LOL, addressing the weaknesses and suggestions for improvement mentioned above. Additionally, I recommend that the authors consider publishing the code and data used in the experiments to facilitate further research and development.",
        "peer_review_with_watermark": "$$\\begin{gathered}\n\\textbf{Paper Summary:} \nThe authors propose a new class of offline policy gradient algorithms called Advantage-Leftover Lunch RL (A-LOL) that enable reinforcement learning (RL) training on any pre-existing data. The algorithm assumes the entire output sequence of a language model as a single action and incorporates sequence-level classifiers or human-designed scoring functions as rewards. This approach allows A-LOL to discard unfavorable data points and improve stability and sample efficiency. The authors demonstrate the effectiveness of A-LOL and its variants on four different language generation tasks and compare them with other offline RL baselines.\n\n\\textbf{Strengths:} \n1. The authors propose a new and effective approach to offline RL training on pre-existing data.\n2. The algorithm is easy to implement and requires minimal modifications to existing language models.\n3. The authors demonstrate the robustness of A-LOL to noisy and suboptimal training data.\n4. The variants of A-LOL (with sequence-level importance weight and KL penalty) show improved performance on certain tasks.\n\n\\textbf{Weaknesses:} \n1. The authors do not compare their method with online RL methods (e.g., PPO), which may be more suitable for certain tasks.\n2. The paper assumes that the reference policy is a good initial policy, which may not always be the case.\n3. The authors do not discuss the limitations of their method on tasks with multiple rewards or unidimensional preferences.\n4. The paper lacks a thorough analysis of the theoretical properties of the proposed algorithm.\n\n\\textbf{Suggestions for Improvement:} \n1. Compare the proposed method with online RL methods (e.g., PPO) on tasks that require exploration.\n2. Discuss the limitations of the method on tasks with multiple rewards or unidimensional preferences.\n3. Provide a more detailed analysis of the theoretical properties of the proposed algorithm.\n4. Experiment with different variants of the algorithm and discuss their strengths and weaknesses.\n5. Consider implementing a more robust method for handling noisy and suboptimal training data.\n\n\\textbf{Recommendation:} \nThe proposed method of Advantage-Leftover Lunch RL (A-LOL) is a promising approach to offline RL training on pre-existing data. While it has several strengths, it also has limitations that need to be addressed. I recommend that the authors continue to explore and improve their method, considering the suggestions for improvement provided above. The results of the paper demonstrate the effectiveness of A-LOL on certain tasks, and with further development, it may become a competitive method for offline RL tasks.",
        "gr_score_with": 0.8278688524590164,
        "gr_score_without": 0.7272727272727273,
        "output_without": {
            "num_tokens_scored": 275,
            "num_green_tokens": 200,
            "green_fraction": 0.7272727272727273,
            "z_score": 0.9869275424396534,
            "p_value": 0.1618390804535082
        },
        "output_with": {
            "num_tokens_scored": 366,
            "num_green_tokens": 303,
            "green_fraction": 0.8278688524590164,
            "z_score": 5.338210104467409,
            "p_value": 4.69343224757394e-08
        }
    },
    {
        "title": "SWE-BENCH: CAN LANGUAGE MODELS RESOLVE REAL-WORLD GITHUB ISSUES?",
        "abstract": "Language models have outpaced our ability to evaluate them effectively, but for their future development it is essential to study the frontier of their capabilities. We find real-world software engineering to be a rich, sustainable, and challenging testbed for evaluating the next generation of language models. To this end, we introduce SWE-bench, an evaluation framework consisting of 2,294 software engineering problems drawn from real GitHub issues and corresponding pull requests across 12 popular Python repositories. Given a codebase along with a description of an issue to be resolved, a language model is tasked with editing the codebase to address the issue. Resolving issues in SWE-bench frequently requires understanding and coordinating changes across multiple functions, classes, and even files simultaneously, calling for models to interact with execution environments, process extremely long contexts and perform complex reasoning that goes far beyond traditional code generation tasks. Our evaluations show that both state-ofthe-art proprietary models and our fine-tuned model SWE-Llama can resolve only the simplest issues. The best-performing model, Claude 2, is able to solve a mere 1.96% of the issues. Advances on SWE-bench represent steps towards LMs that are more practical, intelligent, and autonomous.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces SWE-bench, a benchmark for evaluating the capabilities of language models (LMs) in resolving real-world GitHub issues. The benchmark consists of 2,294 software engineering problems drawn from real GitHub issues and corresponding pull requests across 12 popular Python repositories. The goal of SWE-bench is to provide a realistic and challenging testbed for evaluating the next generation of LMs.\n\nThe authors evaluate multiple state-of-the-art LMs on SWE-bench and find that they fail to solve all except the simplest issues. The best-performing model, Claude 2, is able to solve only 1.96% of the issues. The authors also release two fine-tuned models, SWE-Llama 7b and 13b, based on the CodeLlama model.\n\nThe paper discusses the construction of SWE-bench, including the construction of task instances, the filtering of candidate task instances, and the evaluation of model performance. The authors also discuss the challenges faced by LMs in resolving real-world GitHub issues, including the need to understand and coordinate changes across multiple functions, classes, and files simultaneously.\n\nThe paper concludes that SWE-bench represents a significant step towards LMs that are more practical, intelligent, and autonomous.\n\n$$Strengths:\n\n1. SWE-bench provides a realistic and challenging testbed for evaluating the capabilities of LMs in resolving real-world GitHub issues.\n2. The benchmark consists of 2,294 software engineering problems drawn from real GitHub issues and corresponding pull requests across 12 popular Python repositories.\n3. The authors evaluate multiple state-of-the-art LMs on SWE-bench and provide a comprehensive analysis of their performance.\n4. The paper discusses the challenges faced by LMs in resolving real-world GitHub issues and provides a detailed analysis of the results.\n\n$$Weaknesses:\n\n1. The benchmark may be biased towards simpler issues, as the authors find that LMs fail to solve all except the simplest issues.\n2. The authors may have missed some potential issues with the benchmark, such as the need for more diverse and representative task instances.\n3. The paper may not provide enough context for readers who are not familiar with the specifics of GitHub and software engineering.\n\n$$Suggestions for Improvement:\n\n1. Consider adding more diverse and representative task instances to the benchmark to reduce the bias towards simpler issues.\n2. Provide more context for readers who are not familiar with the specifics of GitHub and software engineering.\n3. Consider using more advanced evaluation metrics that take into account the complexity and nuance of the issues being addressed.\n\n$$Recommendation:\n\nBased on the paper, I recommend that the authors continue to develop and refine SWE-bench, with a focus on adding more diverse and representative task instances and providing more context for readers who are not familiar with the specifics of GitHub and software engineering. I also recommend that the authors consider using more advanced evaluation metrics that take into account the complexity and nuance of the issues being addressed. With further development and refinement, SWE-bench has the potential to become a leading benchmark for evaluating the capabilities of LMs in resolving real-world GitHub issues.",
        "peer_review_with_watermark": "$$$ paper summary:\n\nThe paper introduces SWE-bench, an evaluation framework for language models to resolve real-world GitHub issues. The framework consists of 2,294 software engineering problems drawn from real GitHub issues and corresponding pull requests across 12 popular Python repositories. The authors evaluate multiple state-of-the-art proprietary models and their fine-tuned model SWE-Llama on SWE-bench and find that they struggle to resolve issues, with the best-performing model, Claude 2, able to solve only 1.96% of the issues. The authors also fine-tune their model SWE-Llama and demonstrate its capabilities on SWE-bench. The paper concludes that SWE-bench provides a realistic and challenging testbed for evaluating language models and their capabilities in software engineering tasks.\n\n$$$strengths:\n\n1. The paper introduces a realistic and challenging evaluation framework for language models, SWE-bench.\n2. The authors demonstrate the capabilities of their fine-tuned model SWE-Llama on SWE-bench.\n3. The paper highlights the difficulties faced by language models in software engineering tasks and the need for more realistic and challenging benchmarks.\n4. The authors provide detailed explanations of their methodology and results, making the paper easy to follow and understand.\n\n$$$weaknesses:\n\n1. The paper does not provide a comprehensive analysis of the strengths and weaknesses of the models evaluated on SWE-bench.\n2. The authors do not discuss the potential biases of the SWE-bench dataset and how they may affect the results.\n3. The paper does not provide a detailed comparison of the performance of different models on SWE-bench.\n4. The authors do not discuss the potential applications and implications of their results beyond the scope of language model evaluation.\n\n$$$suggestions for improvement:\n\n1. The authors should provide a more comprehensive analysis of the strengths and weaknesses of the models evaluated on SWE-bench.\n2. The authors should discuss the potential biases of the SWE-bench dataset and how they may affect the results.\n3. The authors should provide a detailed comparison of the performance of different models on SWE-bench.\n4. The authors should discuss the potential applications and implications of their results beyond the scope of language model evaluation.\n5. The authors should provide more detailed explanations of their methodology and results to make the paper easier to follow and understand.\n6. The authors should consider including more diverse and realistic GitHub issues and pull requests to make SWE-bench more challenging and relevant to real-world software engineering tasks.\n\n$$$recommendation:\n\nBased on the paper's content and analysis, I recommend that the authors revise and resubmit their paper to address the weaknesses and suggestions for improvement. The paper provides a realistic and challenging evaluation framework for language models and demonstrates the capabilities of their fine-tuned model SWE-Llama on SWE-bench. With further analysis and discussion of the potential biases of the dataset and the implications of their results, the paper has the potential to contribute meaningfully to the field of language model evaluation and software engineering.",
        "gr_score_with": 0.7395209580838323,
        "gr_score_without": 0.6424731182795699,
        "output_without": {
            "num_tokens_scored": 372,
            "num_green_tokens": 239,
            "green_fraction": 0.6424731182795699,
            "z_score": -2.4212110987775963,
            "p_value": 0.9922655543187735
        },
        "output_with": {
            "num_tokens_scored": 334,
            "num_green_tokens": 247,
            "green_fraction": 0.7395209580838323,
            "z_score": 1.5761264251723626,
            "p_value": 0.057498335104983984
        }
    },
    {
        "title": "SEER: LANGUAGE INSTRUCTED VIDEO PREDICTION WITH LATENT DIFFUSION MODELS",
        "abstract": "Imagining the future trajectory is the key for robots to make sound planning and successfully reach their goals. Therefore, text-conditioned video prediction (TVP) is an essential task to facilitate general robot policy learning. To tackle this task and empower robots with the ability to foresee the future, we propose a sample and computation-efficient model, named Seer, by inflating the pretrained text-toimage (T2I) stable diffusion models along the temporal axis. We enhance the U-Net and language conditioning model by incorporating computation-efficient spatial-temporal attention. Furthermore, we introduce a novel Frame Sequential Text Decomposer module that dissects a sentence\u2019s global instruction into temporally aligned sub-instructions, ensuring precise integration into each frame of generation. Our framework allows us to effectively leverage the extensive prior knowledge embedded in pretrained T2I models across the frames. With the adaptable-designed architecture, Seer makes it possible to generate high-fidelity, coherent, and instruction-aligned video frames by fine-tuning a few layers on a small amount of data. The experimental results on Something Something V2 (SSv2), Bridgedata and EpicKitchens-100 datasets demonstrate our superior video prediction performance with around 480-GPU hours versus CogVideo with over 12,480-GPU hours: achieving the 31% FVD improvement compared to the current SOTA model on SSv2 and 83.7% average preference in the human evaluation. Our project is available at https://seervideodiffusion.github.io/",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary:\nThe paper proposes a novel approach to text-conditioned video prediction (TVP) using latent diffusion models. The proposed method, named Seer, leverages the prior knowledge of pre-trained text-to-image (T2I) models to generate high-quality videos by fine-tuning a few layers on a small amount of data. Seer incorporates a Frame Sequential Text Decomposer module to decompose the language instruction into fine-grained sub-instructions, ensuring precise integration into each frame of generation.\n\nStrengths:\n1. The proposed method, Seer, is sample and computation-efficient, reducing the data and computation costs compared to other TVP methods.\n2. The use of Frame Sequential Text Decomposer module enables precise integration of language instructions into each frame of generation.\n3. The experiments demonstrate superior performance of Seer over other recent models in terms of Frechet Video Distance (FVD) and Kernel Video Distance (KVD) metrics.\n\nWeaknesses:\n1. The paper does not provide a clear comparison of the proposed method with other state-of-the-art TVP methods, which may limit the generalizability of the results.\n2. The experiments are conducted on a limited number of datasets, which may not be representative of the broader TVP task.\n3. The paper does not provide a detailed analysis of the impact of the Frame Sequential Text Decomposer module on the video generation process.\n\nSuggestions for Improvement:\n1. The authors should provide a more detailed comparison of Seer with other state-of-the-art TVP methods to demonstrate its superiority.\n2. The experiments should be conducted on a larger and more diverse set of datasets to improve the generalizability of the results.\n3. A more detailed analysis of the impact of the Frame Sequential Text Decomposer module on the video generation process would provide insights into its effectiveness.\n\nRecommendation:\nThe proposed method, Seer, is a significant contribution to the TVP task, offering a sample and computation-efficient approach to generating high-quality videos. However, the authors should address the limitations mentioned above to further strengthen the paper. With some revisions, the paper has the potential to be a top-notch submission to the conference.",
        "peer_review_with_watermark": "$$$Paper Summary:\n\nThe paper introduces Seer, a sample and computation-efficient model for text-conditioned video prediction (TVP) that leverages pretrained text-to-image stable diffusion models. The proposed method, Seer, utilizes a novel Frame Sequential Text Decomposer to decompose global language instructions into fine-grained sub-instructions, which are then used to guide video generation. The experiments demonstrate that Seer achieves state-of-the-art performance on three datasets, SSv2, Bridgedata, and Epic100, outperforming existing baselines.\n\nStrengths:\n\n1.  Seer's architecture is well-designed, leveraging pretrained text-to-image stable diffusion models and a novel Frame Sequential Text Decomposer to achieve efficient and high-quality video generation.\n2.  The method effectively handles temporal dynamics and achieves precise text-video alignment in video manipulation.\n3.  The experiments demonstrate that Seer outperforms existing baselines, showcasing its superiority in terms of Fre\u0301chet Video Distance (FVD) and Kernel Video Distance (KVD) metrics.\n\nWeaknesses:\n\n1.  The paper could benefit from a more detailed explanation of the Frame Sequential Text Decomposer, including its mathematical formulation and optimization procedure.\n2.  The authors could provide more insight into the impact of sub-instruction guidance on frame generation and unveil the implicit semantic information contained within a single sub-instruction.\n3.  The evaluation of Seer's generalizability on an unseen dataset, EGO4D, is limited to a single experiment, and more comprehensive evaluation is needed to assess its robustness.\n\nSuggestions for Improvement:\n\n1.  To further improve Seer's performance, consider incorporating additional guidance mechanisms, such as visual-linguistic alignment or scene understanding, to improve text-video alignment.\n2.  The authors could explore different optimization procedures for the Frame Sequential Text Decomposer, such as gradient-based or gradient-free methods, to improve convergence and efficiency.\n3.  To assess Seer's robustness, conduct more comprehensive evaluation on unseen datasets, including EGO4D, and compare it to other state-of-the-art methods.\n\nRecommendation:\n\nBased on the experimental results and the well-designed architecture of Seer, I recommend that it be accepted for publication in a reputable conference or journal. The paper's contributions to efficient and high-quality TVP and its superiority over existing baselines make it a valuable addition to the research community.",
        "gr_score_with": 0.8636363636363636,
        "gr_score_without": 0.7602523659305994,
        "output_without": {
            "num_tokens_scored": 317,
            "num_green_tokens": 241,
            "green_fraction": 0.7602523659305994,
            "z_score": 2.340960516412472,
            "p_value": 0.009617100551091624
        },
        "output_with": {
            "num_tokens_scored": 374,
            "num_green_tokens": 323,
            "green_fraction": 0.8636363636363636,
            "z_score": 6.905672428396213,
            "p_value": 2.4983087994214738e-12
        }
    },
    {
        "title": "CONVOLUTION MEETS LORA: PARAMETER EFFI-",
        "abstract": "The Segment Anything Model (SAM) stands as a foundational framework for image segmentation. While it exhibits remarkable zero-shot generalization in typical scenarios, its advantage diminishes when applied to specialized domains like medical imagery and remote sensing. To address this limitation, this paper introduces Conv-LoRA, a simple yet effective parameter-efficient fine-tuning approach. By integrating ultra-lightweight convolutional parameters into Low-Rank Adaptation (LoRA), Conv-LoRA can inject image-related inductive biases into the plain ViT encoder, further reinforcing SAM\u2019s local prior assumption. Notably, Conv-LoRA not only preserves SAM\u2019s extensive segmentation knowledge but also revives its capacity of learning high-level image semantics, which is constrained by SAM\u2019s foreground-background segmentation pretraining. Comprehensive experimentation across diverse benchmarks spanning multiple domains underscores ConvLoRA\u2019s superiority in adapting SAM to real-world semantic segmentation tasks.1",
        "peer_review_without_watermark": "$$$ \n\nPaper Summary:\nThe paper proposes Conv-LoRA, a parameter-efficient fine-tuning approach for adapting the Segment Anything Model (SAM) to real-world semantic segmentation tasks. SAM is a foundation model for image segmentation that exhibits remarkable zero-shot generalization in typical scenarios but fails to generalize well to specialized domains like medical imagery and remote sensing. Conv-LoRA integrates ultra-lightweight convolutional parameters into Low-Rank Adaptation (LoRA) to inject image-related inductive biases into the plain ViT encoder, further reinforcing SAM's local prior assumption. The approach is simple, generic, and obtains promising results across multiple domains.\n\nStrengths:\n\n1. The proposed approach, Conv-LoRA, is simple and generic, making it a promising method for adapting SAM to various downstream segmentation applications.\n2. Conv-LoRA leverages the strengths of LoRA, a popular parameter-efficient fine-tuning approach, to inject image-related local prior knowledge into the ViT encoder.\n3. The approach is effective in boosting the segmentation performance, especially in domains where SAM's pretraining is limited.\n4. The authors provide extensive experimentation across diverse benchmarks, showcasing the robustness and effectiveness of Conv-LoRA.\n\nWeaknesses:\n\n1. The paper does not provide a comprehensive analysis of the limitations of SAM's pretraining in specialized domains, which might limit its generalization to these domains.\n2. The authors rely on existing work on LoRA and MoE, which might not be entirely novel or groundbreaking in the field.\n3. The approach might not be suitable for all segmentation tasks, especially those requiring high-level semantic information or complex object relationships.\n4. The authors do not provide a detailed analysis of the computational and memory overhead of Conv-LoRA, which might be a concern for large-scale deployments.\n\nSuggestions for Improvement:\n\n1. The authors should provide a more detailed analysis of the limitations of SAM's pretraining in specialized domains and discuss potential ways to address these limitations.\n2. The approach could be further improved by incorporating additional techniques, such as multi-scale attention or spatial attention, to better capture high-level semantic information.\n3. The authors should provide a more comprehensive analysis of the computational and memory overhead of Conv-LoRA, including comparisons with state-of-the-art methods.\n4. The approach could be more robustly evaluated on a wider range of benchmarks, including those with varying levels of complexity and domain specificity.\n\nRecommendation:\n\nBased on the strengths and weaknesses of the paper, I recommend that Conv-LoRA be considered as a promising approach for adapting SAM to real-world semantic segmentation tasks. However, further improvements are needed to address the limitations and weaknesses identified in the paper. Specifically, the authors should provide a more detailed analysis of SAM's pretraining limitations, incorporate additional techniques to improve the approach, and provide a more comprehensive evaluation of Conv-LoRA's computational and memory overhead. With these improvements, Conv-LoRA has the potential to become a leading method for adapting SAM to various downstream segmentation applications. \n\n$$",
        "peer_review_with_watermark": "$$$$\n\nPaper Summary:\nThis paper proposes Conv-LoRA, a novel parameter-efficient fine-tuning (PEFT) approach for applying the Segment Anything Model (SAM) to downstream semantic segmentation applications. Conv-LoRA incorporates ultra-lightweight convolutional parameters into the Low-Rank Adaptation (LoRA) framework, allowing SAM to learn image-related inductive biases. The proposed method is simple, generic, and achieves promising results across multiple domains, including natural images, agriculture, remote sensing, and healthcare.\n\nStrengths:\n\n* Conv-LoRA is a novel PEFT approach that addresses the limitations of SAM in handling specialized domains.\n* The method is simple and generic, making it suitable for a wide range of applications.\n* Conv-LoRA achieves promising results across multiple domains, demonstrating its effectiveness in adapting SAM to real-world semantic segmentation tasks.\n* The paper provides a comprehensive analysis of the strengths and weaknesses of SAM, highlighting its limitations in learning high-level semantic information.\n\nWeaknesses:\n\n* The paper does not provide a rigorous comparison with other PEFT methods, making it difficult to evaluate the effectiveness of Conv-LoRA in isolation.\n* The experimental results are limited to a few datasets, and the paper does not provide a comprehensive evaluation of Conv-LoRA's performance on other datasets.\n* The paper does not discuss the potential limitations of Conv-LoRA in handling very large or complex datasets.\n* The paper could benefit from a more detailed analysis of the role of LoRA in Conv-LoRA, as it is not clear how the low-rank adaptation matrices contribute to the overall performance of the method.\n\nSuggestions for Improvement:\n\n* Conduct a more comprehensive evaluation of Conv-LoRA's performance on a wide range of datasets, including those with varying levels of complexity and size.\n* Compare Conv-LoRA with other PEFT methods, such as VPT, LST, and SSF, to evaluate its effectiveness in isolation.\n* Provide a more detailed analysis of the role of LoRA in Conv-LoRA, including its impact on the model's capacity to learn high-level semantic information.\n* Discuss the potential limitations of Conv-LoRA in handling very large or complex datasets, and provide guidance on how to address these challenges.\n\nRecommendation:\n\n* Conv-LoRA is a promising PEFT approach for adapting SAM to downstream semantic segmentation applications, particularly in handling specialized domains.\n* However, further evaluation and comparison with other PEFT methods are necessary to fully understand the effectiveness of Conv-LoRA.\n* The paper provides a solid foundation for future research, and the authors should consider exploring the limitations of Conv-LoRA and developing strategies to address these challenges.",
        "gr_score_with": 0.8757225433526011,
        "gr_score_without": 0.7620192307692307,
        "output_without": {
            "num_tokens_scored": 416,
            "num_green_tokens": 317,
            "green_fraction": 0.7620192307692307,
            "z_score": 2.7603451766953895,
            "p_value": 0.0028870159404885748
        },
        "output_with": {
            "num_tokens_scored": 346,
            "num_green_tokens": 303,
            "green_fraction": 0.8757225433526011,
            "z_score": 7.132731606520595,
            "p_value": 4.919815529688576e-13
        }
    },
    {
        "title": "FORMER FOR PHOTOREALISTIC TEXT-TO-IMAGE SYNTHESIS",
        "abstract": "The most advanced text-to-image (T2I) models require significant training costs (e.g., millions of GPU hours), seriously hindering the fundamental innovation for the AIGC community while increasing CO2 emissions. This paper introduces PIXART-\u03b1, a Transformer-based T2I diffusion model whose image generation quality is competitive with state-of-the-art image generators (e.g., Imagen, SDXL, and even Midjourney), reaching near-commercial application standards. Additionally, it supports high-resolution image synthesis up to 1024 \u00d7 1024 resolution with low training cost, as shown in Figure 1 and 2. To achieve this goal, three core designs are proposed: (1) Training strategy decomposition: We devise three distinct training steps that respectively optimize pixel dependency, textimage alignment, and image aesthetic quality; (2) Efficient T2I Transformer: We incorporate cross-attention modules into Diffusion Transformer (DiT) to inject text conditions and streamline the computation-intensive class-condition branch; (3) High-informative data: We emphasize the significance of concept density in text-image pairs and leverage a large Vision-Language model to auto-label dense pseudo-captions to assist text-image alignment learning. As a result, PIXART-\u03b1\u2019s training speed markedly surpasses existing large-scale T2I models, e.g., PIXART\u03b1 only takes 12% of Stable Diffusion v1.5\u2019s training time (\u223c753 vs. \u223c6,250 A100 GPU days), saving nearly $300,000 ($28,400 vs. $320,000) and reducing 90% CO2 emissions. Moreover, compared with a larger SOTA model, RAPHAEL, our training cost is merely 1%. Extensive experiments demonstrate that PIXART-\u03b1 excels in image quality, artistry, and semantic control. We hope PIXART-\u03b1 will provide new insights to the AIGC community and startups to accelerate building their own high-quality yet low-cost generative models from scratch.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces PIXART-\u03b1, a Transformer-based text-to-image (T2I) diffusion model that achieves competitive image generation quality with significant reductions in training costs and CO2 emissions. The model employs three core designs: training strategy decomposition, efficient T2I Transformer, and high-informative data. PIXART-\u03b1 demonstrates near-commercial application standards in image generation quality, with improved performance in alignment, semantic control, and human preference. The model's training speed is significantly faster than existing large-scale T2I models, resulting in substantial cost savings and reduced environmental impact.\n\nStrengths:\n\n* The paper presents a novel approach to T2I diffusion models, achieving competitive image generation quality with significant reductions in training costs and CO2 emissions.\n* The three core designs of the model are well-explained and contribute to its success.\n* The paper provides extensive experiments and comparisons with state-of-the-art models, demonstrating the effectiveness of PIXART-\u03b1.\n* The use of high-informative data and auto-labeling pipeline is a significant improvement over existing datasets.\n\nWeaknesses:\n\n* The paper does not provide a comprehensive comparison with all state-of-the-art models, which may limit the generalizability of the results.\n* The evaluation metrics used, such as FID and human preference, may not fully capture the complexities of image generation quality.\n* The paper does not provide a detailed analysis of the limitations and potential biases of the proposed model.\n* The use of pre-trained weights and reparameterization technique may introduce additional complexity and potential issues.\n\nSuggestions for Improvement:\n\n* Conduct a more comprehensive comparison with all state-of-the-art models to demonstrate the robustness and generalizability of PIXART-\u03b1.\n* Consider using additional evaluation metrics that capture more aspects of image generation quality, such as diversity, coherence, and creativity.\n* Provide a detailed analysis of the limitations and potential biases of the proposed model, including discussions on potential issues with pre-trained weights and reparameterization technique.\n* Consider exploring the use of additional techniques, such as adversarial training or data augmentation, to further improve the performance and robustness of PIXART-\u03b1.\n\nRecommendation:\n\n* Based on the strengths and weaknesses of the paper, I recommend that it be accepted for publication in a top-tier conference in computer vision or machine learning. The paper presents a novel and effective approach to T2I diffusion models, and the authors have demonstrated a thorough understanding of the technical aspects of the model. However, I suggest that the authors address the limitations and potential biases of the proposed model, as well as conduct a more comprehensive comparison with all state-of-the-art models, to further strengthen the paper.",
        "peer_review_with_watermark": "$$\n\nPaper Summary:\nThe paper presents PIXART-\u03b1, a novel text-to-image (T2I) diffusion model that significantly reduces computational demands while maintaining competitive image generation quality. The authors propose three core designs: (1) training strategy decomposition, (2) efficient T2I Transformer, and (3) high-informative data, which contribute to the success of PIXART-\u03b1. The model achieves near-commercial application standards in image generation quality, and its training speed surpasses existing large-scale T2I models, saving nearly $300,000 and reducing 90% CO2 emissions.\n\nStrengths:\n\n1. The authors provide a thorough analysis of the challenges faced by existing T2I models, including high training costs and CO2 emissions, and propose a novel solution to address these challenges.\n2. The three core designs, including training strategy decomposition, efficient T2I Transformer, and high-informative data, demonstrate the effectiveness of the proposed approach.\n3. The authors provide extensive experiments, including comparisons with state-of-the-art models, user studies, and ablation studies, which demonstrate the robustness and efficiency of PIXART-\u03b1.\n\nWeaknesses:\n\n1. The paper assumes that the reader is familiar with the basics of T2I models and diffusion probabilistic models, which may limit the accessibility of the paper for non-experts.\n2. The authors do not provide a comprehensive discussion of the limitations and potential biases of the proposed approach, which may be important considerations for future work.\n3. The paper relies heavily on existing datasets and benchmarks, which may not be representative of the full range of possible scenarios and applications.\n\nSuggestions for Improvement:\n\n1. The authors should provide more detailed explanations of the assumptions and limitations underlying the proposed approach, as well as potential biases and sources of error.\n2. The authors should provide more comprehensive discussions of the potential applications and limitations of the proposed approach, as well as potential future work and extensions.\n3. The authors should provide more detailed evaluations of the robustness and generalizability of the proposed approach, including comparisons with other models and datasets.\n\nRecommendation:\n\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit the paper with the above suggestions incorporated. The authors have made significant contributions to the field of T2I models, and their work has the potential to inspire further innovation and advancements in this field.\n\n$$",
        "gr_score_with": 0.7217391304347827,
        "gr_score_without": 0.6684931506849315,
        "output_without": {
            "num_tokens_scored": 365,
            "num_green_tokens": 244,
            "green_fraction": 0.6684931506849315,
            "z_score": -1.3135353369968605,
            "p_value": 0.9054986891655039
        },
        "output_with": {
            "num_tokens_scored": 345,
            "num_green_tokens": 249,
            "green_fraction": 0.7217391304347827,
            "z_score": 0.881134221062805,
            "p_value": 0.18912258848975239
        }
    },
    {
        "title": "ON DIFFERENTIALLY PRIVATE FEDERATED LINEAR CONTEXTUAL BANDITS",
        "abstract": "We consider cross-silo federated linear contextual bandit (LCB) problem under differential privacy, where multiple silos interact with their respective local users and communicate via a central server to realize collaboration without sacrificing each user\u2019s privacy. We identify three issues in the state-of-the-art (Dubey & Pentland, 2020): (i) failure of claimed privacy protection, (ii) incorrect regret bound due to noise miscalculation and (iii) ungrounded communication cost. To resolve these issues, we take a two-step approach. First, we design an algorithmic framework consisting of a generic federated LCB algorithm and flexible privacy protocols. Then, leveraging the proposed framework, we study federated LCBs under two different privacy constraints. We first establish privacy and regret guarantees under silo-level local differential privacy, which fix the issues present in state-of-the-art algorithm. To further improve the regret performance, we next consider shuffle model of differential privacy, under which we show that our algorithm can achieve nearly \u201coptimal\u201d regret without a trusted server. We accomplish this via two different schemes \u2013 one relies on a new result on privacy amplification via shuffling for DP mechanisms and another one leverages the integration of a shuffle protocol for vector sum into the tree-based mechanism, both of which might be of independent interest. Finally, we support our theoretical results with numerical evaluations over contextual bandit instances generated from both synthetic and real-life data.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary:\nThe paper proposes a novel approach to private federated linear contextual bandits (LCBs), which addresses the limitations of existing algorithms in achieving differential privacy and regret guarantees. The authors introduce a two-step framework, first designing a generic federated LCB algorithm and flexible privacy protocols, and then proving regret guarantees under two different privacy constraints: silo-level LDP and SDP. The proposed algorithm achieves nearly optimal regret without a trusted server, and the authors demonstrate its efficacy through numerical evaluations on synthetic and real-life data.\n\nStrengths:\n- The paper addresses the limitations of existing algorithms in achieving differential privacy and regret guarantees.\n- The authors introduce a two-step framework that combines algorithmic and analytical approaches.\n- The proposed algorithm achieves nearly optimal regret without a trusted server.\n\nWeaknesses:\n- The paper assumes that the central server is not trusted, which may not be the case in real-world scenarios.\n- The authors do not provide a clear explanation of the assumptions made in the paper.\n- The numerical evaluations are limited to synthetic data, and it would be beneficial to evaluate the algorithm on real-life data as well.\n\nSuggestions for Improvement:\n- Provide a clear explanation of the assumptions made in the paper.\n- Evaluate the algorithm on real-life data to demonstrate its efficacy.\n- Consider the case where the central server is trusted, and propose a modified algorithm that addresses this scenario.\n\nRecommendation:\n- The paper presents a novel approach to private federated LCBs, and the authors make significant contributions to the field.\n- However, the paper assumes that the central server is not trusted, which may not be the case in real-world scenarios.\n- With some modifications, the paper can be improved to address these limitations and provide a more comprehensive analysis of the proposed algorithm.\n\n$$\\begin{aligned}\n$$Paper Summary:\nThe paper proposes a novel approach to private federated linear contextual bandits (LCBs), which addresses the limitations of existing algorithms in achieving differential privacy and regret guarantees. The authors introduce a two-step framework, first designing a generic federated LCB algorithm and flexible privacy protocols, and then proving regret guarantees under two different privacy constraints: silo-level LDP and SDP. The proposed algorithm achieves nearly optimal regret without a trusted server, and the authors demonstrate its efficacy through numerical evaluations on synthetic and real-life data.\n\nStrengths:\n- The paper addresses the limitations of existing algorithms in achieving differential privacy and regret guarantees.\n- The authors introduce a two-step framework that combines algorithmic and analytical approaches.\n- The proposed algorithm achieves nearly optimal regret without a trusted server.\n\nWeaknesses:\n- The paper relies heavily on the shuffling mechanism to amplify privacy, which may not be effective in all scenarios.\n- The authors do not provide a clear explanation of the assumptions made in the paper.\n\nSuggestions for Improvement:\n- Provide a clear explanation of the assumptions made in the paper.\n- Consider alternative mechanisms to amplify privacy, such as noise injection or differential privacy mechanisms.\n- Evaluate the algorithm on real-life data to demonstrate its efficacy.\n\nRecommendation:\n- The paper presents a novel approach to private federated LCBs, and the authors make significant contributions to the field.\n- However, the paper relies heavily on the shuffling mechanism, which may not be effective in all scenarios.\n- With some modifications, the paper can be improved to address these limitations and provide a more comprehensive analysis of the proposed algorithm.\n\n$$\\begin{aligned}\n$$Paper Summary:\nThe paper proposes a novel approach to private federated linear contextual bandits (LCBs), which addresses the limitations of existing algorithms in achieving differential privacy and regret guarantees. The authors introduce a two-step framework, first designing a generic federated LCB algorithm and flexible privacy protocols, and then proving regret guarantees under two different privacy constraints: silo-level LDP and SDP. The proposed algorithm achieves nearly optimal regret without a trusted server, and the authors demonstrate its efficacy through numerical evaluations on synthetic and real-life data.\n\nStrengths:\n- The paper introduces a novel approach to private federated LCBs that addresses the limitations of existing algorithms.\n- The authors provide a clear and comprehensive analysis of the proposed algorithm.\n- The numerical evaluations demonstrate the efficacy of the proposed algorithm.\n\nWeaknesses:\n- The paper assumes that the central server is not trusted, which may not be the case in real-world scenarios.\n- The authors do not provide a clear explanation of the assumptions made in the paper.\n\nSuggestions for Improvement:\n- Provide a clear explanation of the assumptions made in the paper.\n- Evaluate the algorithm on real-life data to demonstrate its efficacy.\n- Consider the case where the central server is trusted, and propose a modified algorithm that addresses this scenario.\n\nRecommendation:\n- The paper presents a novel approach to private federated LCBs, and the authors make significant contributions to the field.\n- However, the paper assumes that the central server is not trusted, which may not be the case in real-world scenarios.\n- With some modifications, the paper can be improved to address these limitations and provide a more comprehensive analysis of the proposed algorithm.",
        "peer_review_with_watermark": "$$$Abstract:\n\nThe paper presents the work \"Differentially Private Federated Linear Contextual Bandits\", which considers the cross-silo federated linear contextual bandit problem under differential privacy. The authors propose an algorithmic framework consisting of a generic federated linear contextual bandit algorithm and flexible privacy protocols, which provides both silo-level local differential privacy (LDP) and shuffle differential privacy (SDP) guarantees. The authors also provide theoretical results, including regret bounds and communication cost analyses. The results show that the proposed algorithm can achieve nearly optimal regret without a trusted server, while ensuring correct privacy guarantees.\n\nPaper Summary:\n\nThe paper discusses the cross-silo federated linear contextual bandit problem, where multiple silos interact with their respective local users and communicate via a central server to realize collaboration without sacrificing each user's privacy. The authors identify three issues in the state-of-the-art algorithm (Dubey & Pentland, 2020): (1) failure of claimed privacy protection, (2) incorrect regret bound due to noise miscalculation, and (3) ungrounded communication cost. To resolve these issues, the authors propose a two-step approach: (1) designing an algorithmic framework consisting of a generic federated linear contextual bandit algorithm and flexible privacy protocols, and (2) proving regret guarantees under silo-level LDP and shuffle SDP.\n\nStrengths:\n\n* The paper presents a comprehensive analysis of the cross-silo federated linear contextual bandit problem under differential privacy.\n* The authors propose an algorithmic framework that provides both silo-level local differential privacy (LDP) and shuffle differential privacy (SDP) guarantees.\n* The theoretical results, including regret bounds and communication cost analyses, show that the proposed algorithm can achieve nearly optimal regret without a trusted server, while ensuring correct privacy guarantees.\n\nWeaknesses:\n\n* The paper assumes that the central server is trustworthy, which may not be the case in real-world scenarios.\n* The communication cost analysis is limited to the case where the adaptive communication schedule is used, which may not be the case in all scenarios.\n* The theoretical results may not be directly applicable to all practical scenarios, such as when the number of agents is large or the data is high-dimensional.\n\nSuggestions for Improvement:\n\n* Consider adding more details on the assumptions made by the algorithm, such as the assumption that the central server is trustworthy.\n* Provide more comprehensive communication cost analyses, including the case where the data-adaptive schedule is used.\n* Consider adding more theoretical results, such as regret bounds and communication cost analyses, for larger numbers of agents or higher-dimensional data.\n\nRecommendation:\n\nThe paper presents an important contribution to the field of differentially private federated learning, which is a growing area of research. The proposed algorithmic framework provides both silo-level local differential privacy (LDP) and shuffle differential privacy (SDP) guarantees, which is a significant achievement. The theoretical results, including regret bounds and communication cost analyses, show that the proposed algorithm can achieve nearly optimal regret without a trusted server, while ensuring correct privacy guarantees. However, there are some limitations to the paper, such as the assumption that the central server is trustworthy and the limited communication cost analysis. To further improve the paper, the authors should consider adding more details on the assumptions made by the algorithm, providing more comprehensive communication cost analyses, and adding more theoretical results.\n\n$$$Theoretical Results:\n\nThe paper presents several theoretical results, including:\n\n* Theorem 5.1 (Performance under silo-level LDP): The authors show that the proposed algorithm satisfies (\u03b5, \u03b4)-silo-level LDP, with a regret bound of O ( dMB log T+d \u221a MT log(MT/\u03b1) ) +O\u0303 (\u221a T (Md)3/4 log1/4(1/\u03b4)\u221a \u03b5 log1/4 ( T/B\u03b1 ) ).\n* Theorem 5.3 (Performance under SDP via amplification): The authors show that the proposed algorithm satisfies (\u03b5, \u03b4)-SDP, with a regret bound of O ( dMB log T+d \u221a MT log(MT/\u03b1) ) +O\u0303 ( d3/4 \u221a MT log3/4(M\u03ba/\u03b4)\u221a \u03b5 log1/4 ( T/B\u03b1 ) ).\n* Theorem 5.5 (Performance under SDP via vector sum): The authors show that the proposed algorithm satisfies (\u03b5, \u03b4)-SDP, with a regret bound of O ( dMB log T+d \u221a MT log(MT/\u03b1) ) +O\u0303 ( d3/4 \u221a MT log3/4(\u03bad2/\u03b4)\u221a \u03b5 log1/4 ( T/B\u03b1 ) ).\n\nOverall, the theoretical results show that the proposed algorithm can achieve nearly optimal regret without a trusted server, while ensuring correct privacy guarantees.\n\n$$Communication Cost:\n\nThe paper presents several results on the communication cost of the proposed algorithm, including:\n\n* Theorem 4.2 (Communication cost under silo-level LDP): The authors show that the communication cost is O ( \u221a MT ) under (\u03b5, \u03b4)-silo-level LDP.\n* Theorem 5.3 (Communication cost under SDP via amplification): The authors show that the communication cost is O ( \u221a MT ) under (\u03b5, \u03b4)-SDP via amplification.\n* Theorem 5.5 (Communication cost under SDP via vector sum): The authors show that the communication cost is O ( \u221a MT ) under (\u03b5, \u03b4)-SDP via vector sum.\n\nOverall, the results show that the communication cost of the proposed algorithm is relatively low, with an upper bound of O ( \u221a MT ) under both silo-level LDP and SDP.\n\n$$Empirical Results:\n\nThe paper presents several empirical results, including:\n\n* Simulation results: The authors simulate several scenarios, including synthetic bandits and real-data bandits, to evaluate the performance of the proposed algorithm.\n* Results show that the proposed algorithm can achieve nearly optimal regret, while ensuring correct privacy guarantees.\n\nOverall, the empirical results support the theoretical results, showing that the proposed algorithm can achieve nearly optimal regret without a trusted server, while ensuring correct privacy guarantees.\n\n$$Conclusion:\n\nThe paper presents an important contribution to the field of differentially private federated learning, which is a growing area of research. The proposed algorithmic framework provides both silo-level local differential privacy (LDP) and shuffle differential privacy (SDP) guarantees, which is a significant achievement. The theoretical results, including regret bounds and communication cost analyses, show that the proposed algorithm can achieve nearly optimal regret without a trusted server, while ensuring correct privacy guarantees. The empirical results support the theoretical results, showing that the proposed algorithm can achieve nearly optimal regret, while ensuring correct privacy guarantees.",
        "gr_score_with": 0.787719298245614,
        "gr_score_without": 0.6770833333333334,
        "output_without": {
            "num_tokens_scored": 288,
            "num_green_tokens": 195,
            "green_fraction": 0.6770833333333334,
            "z_score": -0.8486684247915048,
            "p_value": 0.8019670896455309
        },
        "output_with": {
            "num_tokens_scored": 570,
            "num_green_tokens": 449,
            "green_fraction": 0.787719298245614,
            "z_score": 4.570070809225681,
            "p_value": 2.4377972558651604e-06
        }
    },
    {
        "title": "ZERO BUBBLE (ALMOST) PIPELINE PARALLELISM",
        "abstract": "Pipeline parallelism is one of the key components for large-scale distributed training, yet its efficiency suffers from pipeline bubbles which were deemed inevitable. In this work, we introduce a scheduling strategy that, to our knowledge, is the first to successfully achieve zero pipeline bubbles under synchronous training semantics. The key idea behind this improvement is to split the backward computation into two parts, one that computes gradient for the input and another that computes for the parameters. Based on this idea, we handcraft novel pipeline schedules that significantly outperform the baseline methods. We further develop an algorithm that automatically finds an optimal schedule based on specific model configuration and memory limit. Additionally, to truly achieve zero bubble, we introduce a novel technique to bypass synchronizations during the optimizer step. Experimental evaluations show that our method outperforms the 1F1B schedule up to 15% in throughput under a similar memory limit. This number can be further pushed to 30% when the memory constraint is relaxed. We believe our results mark a major step forward in harnessing the true potential of pipeline parallelism. The source code based on Megatron-LM is publicly avaiable at https: //github.com/sail-sg/zero-bubble-pipeline-parallelism.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces a novel strategy to improve the efficiency of pipeline parallelism by splitting the activation gradient and parameter gradient in backward computation. The authors propose two handcrafted schedules (ZB-H1 and ZB-H2) and an automatic scheduling algorithm that can minimize the pipeline bubble rate under different memory budgets. The schedules produced by the automatic algorithm consistently outperform 1F1B and achieve close to zero bubble rate.\n\nStrengths:\n1. The paper presents a novel approach to improving pipeline parallelism efficiency by splitting the activation gradient and parameter gradient in backward computation.\n2. The authors propose two handcrafted schedules (ZB-H1 and ZB-H2) and an automatic scheduling algorithm that can minimize the pipeline bubble rate under different memory budgets.\n3. The paper presents extensive empirical evaluations of the proposed schedules against 1F1B and other baseline methods.\n\nWeaknesses:\n1. The paper assumes that the execution times of forward, backward, and weight computations are identical, which may not be realistic in all cases.\n2. The paper does not provide a comprehensive analysis of the communication overhead and its impact on the pipeline bubble rate.\n3. The automatic scheduling algorithm may not be able to find the optimal schedule for all possible memory budgets and pipeline configurations.\n\nSuggestions for Improvement:\n1. The authors should provide a more detailed analysis of the communication overhead and its impact on the pipeline bubble rate.\n2. The paper should provide a more comprehensive evaluation of the automatic scheduling algorithm's performance under different memory budgets and pipeline configurations.\n3. The authors should consider including a more detailed analysis of the out-of-memory issues that may arise when using zero bubble schedules.\n\nRecommendation:\nThe paper presents a novel approach to improving pipeline parallelism efficiency and achieves promising results in its empirical evaluations. However, the authors should address the limitations of their assumptions and provide a more comprehensive analysis of the communication overhead and the automatic scheduling algorithm's performance. With these improvements, the paper can contribute significantly to the field of distributed deep learning.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper presents a novel scheduling strategy to improve the efficiency of pipeline parallelism in distributed training. The proposed strategy, Zero Bubble (Almost) Pipeline Parallelism, splits the backward computation into two parts, one for gradient computation with respect to input and another for parameter gradient. This allows for strategic placement of parameter updates to fill pipeline bubbles, resulting in a significant reduction in pipeline bubbles. The authors also introduce an automatic pipeline scheduling algorithm that adapts to realistic scenarios by using more accurate estimates of execution times. Experimental evaluations demonstrate the effectiveness of the proposed strategy, outperforming baseline methods in terms of throughput and achieving close to zero bubble rates.\n\nStrengths:\n- The paper presents a novel scheduling strategy to reduce pipeline bubbles in distributed training.\n- The proposed strategy is implemented using an automatic pipeline scheduling algorithm that adapts to realistic scenarios.\n- Experimental evaluations demonstrate the effectiveness of the proposed strategy in achieving high throughput and reducing pipeline bubbles.\n\nWeaknesses:\n- The paper assumes a specific architecture (Megatron-LM) and may not be applicable to other architectures.\n- The proposed strategy may not be suitable for models with large memory requirements.\n- The experimental evaluations may not cover all possible scenarios, and the results may not generalize to other environments.\n\nSuggestions for Improvement:\n- The paper should consider other architectures and evaluate the proposed strategy's applicability to these architectures.\n- The authors should investigate the effects of different memory constraints on the proposed strategy's performance.\n- The experimental evaluations should include a more comprehensive set of scenarios to ensure the proposed strategy's generalizability.\n\nRecommendation:\n- The proposed strategy, Zero Bubble (Almost) Pipeline Parallelism, shows promise in reducing pipeline bubbles in distributed training. With some modifications to address the limitations mentioned above, this strategy has the potential to achieve significant improvements in throughput and scalability for large-scale distributed training.",
        "gr_score_with": 0.7226277372262774,
        "gr_score_without": 0.62,
        "output_without": {
            "num_tokens_scored": 250,
            "num_green_tokens": 155,
            "green_fraction": 0.62,
            "z_score": -2.7602622373694166,
            "p_value": 0.9971122509553474
        },
        "output_with": {
            "num_tokens_scored": 274,
            "num_green_tokens": 198,
            "green_fraction": 0.7226277372262774,
            "z_score": 0.8173475416390696,
            "p_value": 0.20686492257369105
        }
    },
    {
        "title": "TRANSFORMER-VQ: LINEAR-TIME TRANSFORMERS",
        "abstract": "We introduce Transformer-VQ, a decoder-only transformer computing softmaxbased dense self-attention in linear time. Transformer-VQ\u2019s efficient attention is enabled by vector-quantized keys and a novel caching mechanism. In our large-scale experiments, Transformer-VQ is shown highly competitive in quality, obtaining 0.99 bpb on Enwik8, 26.6 ppl on PG-19, and 3.16 bpb on ImageNet64. In addition, the optimized implementation of Transformer-VQ is over 3x faster than a comparable quadratic-time transformer at sequence length 8k, is over 12x faster at 32k, and can scale to 131k with similar throughput. Code available: https://github.com/transformer-vq/transformer_vq k1 k2 k3 k4 k5 7\u2192 VQ \u2248 k\u03021 k\u03022 k\u03023 k\u03024 k\u03025 Figure 1: Schematic of the VQ-Attention approximation. The colorful and blank boxes depict the keys and attention weights, respectively. The keys on the right have been vector-quantized. Since the green keys k2, k5 map to the same code, they have the same attention weights in this attention head.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary: \nThe paper introduces Transformer-VQ, a decoder-only transformer that computes softmax-based dense self-attention in linear time. It achieves this by using vector-quantized keys and a novel caching mechanism. The model is compared with several state-of-the-art models on various tasks, including Enwik8, PG-19, and ImageNet64.\n\n$$Strengths: \n1. The paper introduces a novel method for computing dense self-attention in linear time, which can potentially lead to significant improvements in efficiency and scalability.\n2. The model is compared with several state-of-the-art models on various tasks, providing a comprehensive evaluation of its performance.\n3. The paper provides a detailed mathematical description of the attention mechanism, making it easier for researchers to reproduce and build upon the results.\n\n$$Weaknesses: \n1. The paper does not provide a detailed analysis of the model's strengths and weaknesses compared to other models in the literature.\n2. Some of the mathematical derivations and proofs are not provided, making it difficult for readers to verify the results.\n3. The paper does not provide a comprehensive discussion of the potential limitations and challenges of the proposed method.\n\n$$Suggestions for Improvement: \n1. Provide a more detailed analysis of the model's strengths and weaknesses compared to other models in the literature.\n2. Include all mathematical derivations and proofs to make the paper more transparent and reproducible.\n3. Discuss the potential limitations and challenges of the proposed method in more detail.\n\n$$Recommendation: \nThe paper introduces a novel method for computing dense self-attention in linear time, which has the potential to significantly improve efficiency and scalability. However, the paper could benefit from a more detailed analysis of the model's strengths and weaknesses, as well as a more comprehensive discussion of the potential limitations and challenges of the proposed method. With these improvements, the paper could be considered for publication in a top-tier conference or journal.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper introduces Transformer-VQ, a decoder-only transformer that can compute softmax-based dense self-attention in linear time. The model uses vector-quantized keys, localized positional biases, and a compressive cache that can be attended to efficiently while yielding the same results as uncompressed attention over the same keys.\n\nStrengths:\n- The paper presents a new and efficient attention mechanism that can be applied to decoder-only transformers.\n- The use of vector-quantized keys and a compressive cache allows for linear-time attention, which is a significant improvement over previous methods.\n- The model is simple to implement and can be sampled from easily.\n\nWeaknesses:\n- The paper may not be suitable for very long sequences due to the limited capacity of the cache.\n- The model may not perform well on tasks that require a lot of contextual information, as it relies on a compressive cache.\n\nSuggestions for Improvement:\n- The authors could explore ways to improve the capacity of the cache, such as using a more efficient caching mechanism or increasing the cache size.\n- The authors could also experiment with different vector-quantization schemes to see if they can improve the performance of the model on certain tasks.\n\nRecommendation:\n- The authors have made a significant contribution to the field of natural language processing with the introduction of Transformer-VQ, a decoder-only transformer that can compute softmax-based dense self-attention in linear time.\n- The model has shown strong results on several benchmarks, including Enwik8, PG-19, and ImageNet64.\n- However, further research is needed to explore the limitations of the model and to see if it can be applied to more complex tasks.\n\n$$$",
        "gr_score_with": 0.72265625,
        "gr_score_without": 0.66015625,
        "output_without": {
            "num_tokens_scored": 256,
            "num_green_tokens": 169,
            "green_fraction": 0.66015625,
            "z_score": -1.3911390502544498,
            "p_value": 0.9179083673605561
        },
        "output_with": {
            "num_tokens_scored": 256,
            "num_green_tokens": 185,
            "green_fraction": 0.72265625,
            "z_score": 0.7910398521054739,
            "p_value": 0.21446036815711006
        }
    },
    {
        "title": "IN-CONTEXT LEARNING LEARNS LABEL RELATION-",
        "abstract": "The predictions of Large Language Models (LLMs) on downstream tasks often improve significantly when including examples of the input\u2013label relationship in the context. However, there is currently no consensus about how this in-context learning (ICL) ability of LLMs works. For example, while Xie et al. (2022) liken ICL to a general-purpose learning algorithm, Min et al. (2022b) argue ICL does not even learn label relationships from in-context examples. In this paper, we provide novel insights into how ICL leverages label information, revealing both capabilities and limitations. To ensure we obtain a comprehensive picture of ICL behavior, we study probabilistic aspects of ICL predictions and thoroughly examine the dynamics of ICL as more examples are provided. Our experiments show that ICL predictions almost always depend on in-context labels and that ICL can learn truly novel tasks in-context. However, we also find that ICL struggles to fully overcome prediction preferences acquired from pre-training data and, further, that ICL does not consider all in-context information equally.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper investigates the mechanisms of in-context learning (ICL) in Large Language Models (LLMs). ICL is a technique that improves LLM predictions by providing examples of the input\u2013label relationship. However, there is currently no consensus about how ICL works. The authors study the probabilistic aspects of ICL predictions and examine the dynamics of ICL as more examples are provided. They find that ICL predictions almost always depend on in-context labels and that ICL can learn truly novel tasks in-context. However, they also find that ICL struggles to fully overcome prediction preferences acquired from pre-training data and does not consider all in-context information equally.\n\nStrengths:\n- The authors provide a thorough analysis of ICL behavior using a range of experiments and metrics.\n- They address the limitations of previous studies and provide a more comprehensive understanding of ICL.\n- The paper highlights the importance of considering probabilistic aspects of ICL predictions.\n\nWeaknesses:\n- The paper relies heavily on experiments with specific LLMs and tasks, which may not be generalizable to other settings.\n- Some of the results, such as the finding that ICL does not treat all information provided in-context equally, may be surprising and require further investigation.\n- The paper does not provide a clear theoretical framework for understanding ICL behavior, which may limit its applicability to other areas of natural language processing.\n\nSuggestions for Improvement:\n- The authors could provide more theoretical insights into ICL behavior, such as exploring the role of label relationships in ICL or developing a more formal framework for understanding ICL dynamics.\n- To improve generalizability, the authors could conduct experiments with a broader range of LLMs and tasks.\n- The paper could benefit from a more detailed discussion of the implications of the findings for alignment and other applications of ICL.\n\nRecommendation:\n- The paper contributes significantly to our understanding of ICL behavior and provides important insights into the mechanisms of ICL.\n- However, the results should be interpreted with caution, and further investigation is needed to confirm the findings and explore their implications.\n- The paper's results have the potential to inform the development of more effective ICL methods and to improve the safety and reliability of LLMs in various applications.",
        "peer_review_with_watermark": "$$\n\n$$Paper Summary:$$\nThe paper investigates the in-context learning (ICL) ability of large language models (LLMs) and aims to provide novel insights into how ICL leverages label information. The authors formulate a set of questions that encode their beliefs about how an idealized conventional learning algorithm should incorporate label information. They then study ICL behavior in relation to these questions, focusing on whether ICL takes the input-label relationship of in-context examples into account when predicting for test queries, whether ICL is powerful enough to overcome prediction preferences originating from pre-training, and whether ICL treats all in-context information equally.\n\n$$Strengths:$$\n1. The paper provides a thorough analysis of ICL behavior and highlights the importance of label information in ICL predictions.\n2. The authors formulate a set of null hypotheses that are tested empirically, providing a systematic approach to understanding ICL.\n3. The paper considers multiple aspects of ICL, including the effect of label randomization, the ability of ICL to learn novel label relationships, and the treatment of different sources of in-context information.\n4. The authors provide a comprehensive experimental setup, including a range of LLMs and tasks, and evaluate ICL predictions using multiple metrics.\n\n$$Weaknesses:$$\n1. The paper may be too long and dense for readers who are not familiar with the ICL and LLM communities.\n2. Some of the results may be difficult to interpret, particularly for readers who are not familiar with probabilistic metrics and ICL training dynamics.\n3. The paper does not provide a detailed comparison with existing ICL studies, which may limit the impact of the results.\n4. The authors may have overemphasized the importance of label information in ICL, which may not be the case for all tasks or LLMs.\n\n$$Suggestions for Improvement:$$\n1. Provide a detailed comparison with existing ICL studies to situate the results in the broader context.\n2. Use more intuitive and accessible notation and terminology, particularly for readers who are not familiar with ICL and LLM communities.\n3. Provide a more detailed explanation of the probabilistic metrics used in the paper, particularly for readers who are not familiar with these concepts.\n4. Consider providing a more detailed analysis of the limitations of ICL, including the impact of label randomization and the treatment of different sources of in-context information.\n\n$$Recommendation:$$\nThe paper makes significant contributions to the understanding of ICL and provides novel insights into the role of label information in ICL predictions. However, the paper may benefit from a more detailed comparison with existing ICL studies and a more accessible notation and terminology. With some revisions, the paper has the potential to be a leading work in the ICL and LLM communities.",
        "gr_score_with": 0.8125,
        "gr_score_without": 0.729106628242075,
        "output_without": {
            "num_tokens_scored": 347,
            "num_green_tokens": 253,
            "green_fraction": 0.729106628242075,
            "z_score": 1.1831695632715462,
            "p_value": 0.11837097650517586
        },
        "output_with": {
            "num_tokens_scored": 368,
            "num_green_tokens": 299,
            "green_fraction": 0.8125,
            "z_score": 4.709413066250556,
            "p_value": 1.2421557270488195e-06
        }
    },
    {
        "title": "THE EFFECTIVENESS OF RANDOM FORGETTING FOR ROBUST GENERALIZATION",
        "abstract": "Deep neural networks are susceptible to adversarial attacks, which can compromise their performance and accuracy. Adversarial Training (AT) has emerged as a popular approach for protecting neural networks against such attacks. However, a key challenge of AT is robust overfitting, where the network\u2019s robust performance on test data deteriorates with further training, thus hindering generalization. Motivated by the concept of active forgetting in the brain, we introduce a novel learning paradigm called \u201cForget to Mitigate Overfitting (FOMO)\". FOMO alternates between the forgetting phase, which randomly forgets a subset of weights and regulates the model\u2019s information through weight reinitialization, and the relearning phase, which emphasizes learning generalizable features. Our experiments on benchmark datasets and adversarial attacks show that FOMO alleviates robust overfitting by significantly reducing the gap between the best and last robust test accuracy while improving the state-of-the-art robustness. Furthermore, FOMO provides a better trade-off between standard and robust accuracy, outperforming baseline adversarial methods. Finally, our framework is robust to AutoAttacks and increases generalization in many real-world scenarios.1",
        "peer_review_without_watermark": "$$\\boxed{\\text{Paper Summary:}}$$\n\nThe paper proposes a novel learning paradigm called \"Forget to Mitigate Overfitting\" (FOMO) to address the problem of robust overfitting in adversarial training (AT). FOMO alternates between the forgetting phase, which randomly forgets a subset of weights and regulates the model's information through weight reinitialization, and the relearning phase, which emphasizes learning generalizable features. The paper presents experimental results on benchmark datasets and adversarial attacks, showing that FOMO alleviates robust overfitting and achieves significant results across multiple architectures and datasets.\n\n$$\\boxed{\\text{Strengths:}}$$\n\n1. The paper provides a clear motivation for the problem of robust overfitting in AT and presents a novel solution to address this issue.\n2. The proposed FOMO paradigm is well-structured and easy to understand.\n3. The paper presents extensive experimental results on benchmark datasets and adversarial attacks, demonstrating the effectiveness of FOMO.\n4. The authors provide a thorough analysis of the ablation study, showing the importance of each component of the FOMO paradigm.\n5. The paper discusses the biological underpinnings of robust generalization and provides a theoretical framework for understanding the effectiveness of FOMO.\n\n$$\\boxed{\\text{Weaknesses:}}$$\n\n1. The paper assumes a certain level of prior knowledge about adversarial training and robust generalization, which may not be familiar to all readers.\n2. The experimental results, while extensive, may not be conclusive for all architectures and datasets.\n3. The paper does not provide a detailed analysis of the potential limitations of FOMO, such as its applicability to complex models or its robustness to different types of attacks.\n4. Some of the technical details, such as the implementation of the FOMO paradigm, are not explicitly provided in the paper.\n5. The paper does not discuss potential future work or directions for improving the FOMO paradigm.\n\n$$\\boxed{\\text{Suggestions for Improvement:}}$$\n\n1. Provide a more detailed analysis of the potential limitations of FOMO and discuss potential future work.\n2. Include more technical details about the implementation of the FOMO paradigm.\n3. Discuss the applicability of FOMO to complex models and its robustness to different types of attacks.\n4. Provide more experimental results, including comparisons with other state-of-the-art methods.\n5. Consider including a theoretical analysis of the FOMO paradigm to provide a deeper understanding of its effectiveness.\n\n$$\\boxed{\\text{Recommendation:}}$$\n\nBased on the paper's strengths and weaknesses, I recommend that the authors revise and resubmit their paper for publication. The authors have proposed a novel solution to the problem of robust overfitting in AT, and their experimental results demonstrate its effectiveness. However, the paper could benefit from a more detailed analysis of the potential limitations and future directions of the FOMO paradigm. With revisions, the paper has the potential to be a top-tier conference submission.",
        "peer_review_with_watermark": "$$$ \n\nPaper Summary: \nThe paper proposes a novel adversarial training paradigm called Forget to Mitigate Overfitting (FOMO) to improve the performance and generalization of deep neural networks. FOMO alternates between the forgetting phase, which randomly forgets a subset of weights and regulates the model's information through weight reinitialization, and the relearning phase, which emphasizes learning generalizable features. The authors demonstrate the effectiveness of FOMO on various benchmarks and adversarial attacks, showing that it alleviates robust overfitting and achieves significant results across multiple architectures and datasets.\n\nStrengths: \n1. The paper presents a well-structured and coherent approach to addressing robust overfitting in adversarial training.\n2. The authors provide a clear and concise explanation of the concept of active forgetting and its relation to human brain function.\n3. The proposed method, FOMO, is effective in improving both standard and robust performance and generalization across a wide range of architectures, datasets, and perturbation types.\n4. The authors provide a comprehensive analysis of the results, including ablation studies and comparisons with baseline methods.\n\nWeaknesses: \n1. The paper may benefit from more detailed explanations of the theoretical underpinnings of FOMO, particularly in relation to the concept of active forgetting.\n2. Some of the notation and definitions may be unfamiliar to non-experts, which could make the paper more difficult to understand.\n3. The authors may want to consider providing more detailed comparisons with other existing methods for addressing robust overfitting in adversarial training.\n\nSuggestions for Improvement: \n1. Provide more detailed explanations of the theoretical underpinnings of FOMO, particularly in relation to the concept of active forgetting.\n2. Consider providing more detailed comparisons with other existing methods for addressing robust overfitting in adversarial training.\n3. Clarify any unfamiliar notation or definitions to make the paper more accessible to a wider audience.\n\nRecommendation: \nBased on the paper's strengths and weaknesses, I recommend that it be accepted for publication in its current form. However, the authors may want to consider addressing the suggestions for improvement to further strengthen the paper.",
        "gr_score_with": 0.8354430379746836,
        "gr_score_without": 0.7964824120603015,
        "output_without": {
            "num_tokens_scored": 398,
            "num_green_tokens": 317,
            "green_fraction": 0.7964824120603015,
            "z_score": 4.200297394865309,
            "p_value": 1.3328230593512514e-05
        },
        "output_with": {
            "num_tokens_scored": 316,
            "num_green_tokens": 264,
            "green_fraction": 0.8354430379746836,
            "z_score": 5.25400619270053,
            "p_value": 7.441293649191687e-08
        }
    },
    {
        "title": "ENERGY-GUIDED ENTROPIC NEURAL OPTIMAL TRANSPORT",
        "abstract": "Energy-based models (EBMs) are known in the Machine Learning community for decades. Since the seminal works devoted to EBMs dating back to the noughties, there have been a lot of efficient methods which solve the generative modelling problem by means of energy potentials (unnormalized likelihood functions). In contrast, the realm of Optimal Transport (OT) and, in particular, neural OT solvers is much less explored and limited by few recent works (excluding WGAN-based approaches which utilize OT as a loss function and do not model OT maps themselves). In our work, we bridge the gap between EBMs and Entropy-regularized OT. We present a novel methodology which allows utilizing the recent developments and technical improvements of the former in order to enrich the latter. From the theoretical perspective, we prove generalization bounds for our technique. In practice, we validate its applicability in toy 2D and image domains. To showcase the scalability, we empower our method with a pre-trained StyleGAN and apply it to high-res AFHQ 512 \u00d7 512 unpaired I2I translation. For simplicity, we choose simple shortand long-run EBMs as a backbone of our Energy-guided Entropic OT approach, leaving the application of more sophisticated EBMs for future research. Our code is available at: https: //github.com/PetrMokrov/Energy-guided-Entropic-OT Figure 1: AFHQ 512\u00d7 512 Cat\u2192Dog unpaired translation by our Energy-guided EOT solver applied in the latent space of StyleGAN2-ADA. Our approach does not need data2latent encoding. Left: source samples; right: translated samples.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$\\text{Paper Summary:}$$\nThe authors propose a novel methodology to bridge the gap between Energy-based Models (EBMs) and Entropy-regularized Optimal Transport (EOT). The proposed approach utilizes the recent developments and technical improvements of EBMs to enrich EOT. The authors prove generalization bounds for their technique and validate its applicability in toy 2D and image domains.\n\n$$\\text{Strengths:}$$\n1. The authors propose a novel approach to bridge the gap between EBMs and EOT.\n2. The authors prove generalization bounds for their technique.\n3. The authors validate the applicability of their approach in toy 2D and image domains.\n\n$$\\text{Weaknesses:}$$\n1. The authors' approach may be computationally expensive due to the use of MCMC methods.\n2. The authors' approach may not be suitable for all types of data, particularly those with high-dimensional spaces.\n3. The authors' approach may not be as efficient as other existing methods for EOT.\n\n$$\\text{Suggestions for Improvement:}$$\n1. The authors should consider using more efficient MCMC methods to reduce computational cost.\n2. The authors should explore the use of more efficient optimization algorithms to improve the efficiency of their approach.\n3. The authors should consider using more robust methods to handle high-dimensional spaces.\n\n$$\\text{Recommendation:}$$\nThe proposed approach is a valuable contribution to the field of EOT and EBMs. However, further research is needed to improve the efficiency and robustness of the approach. The authors should consider addressing the weaknesses and suggestions for improvement mentioned above to make their approach more suitable for practical applications.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n&\\text{Paper Summary: The paper proposes a novel energy-based approach to solving the Entropic Optimal Transport (EOT) problem, which is a fundamental problem in the field of optimal transport. The authors present a novel methodology that bridges the gap between energy-based models and EOT, and demonstrate its effectiveness in solving EOT problems. The approach is based on using energy-based models to implicitly recover EOT plans, and the authors provide theoretical bounds and empirical results to support the effectiveness of the approach.}\n\n\\end{aligned}$$\n\n$$\\begin{aligned}&\\text{Strengths: The paper presents a novel and effective approach to solving the EOT problem, and provides theoretical bounds and empirical results to support its effectiveness. The authors also demonstrate the applicability of the approach to a variety of problems, including unpaired image-to-image translation and high-dimensional I2I translation.}\n\n\\end{aligned}$$\n\n$$\\begin{aligned}&\\text{Weaknesses: The paper relies on the use of MCMC methods for training and inference, which can be time-consuming and may not always converge to the desired distribution. The approach also requires the use of a pre-trained StyleGAN, which may limit its applicability to other problems.}\n\n\\end{aligned}$$\n\n$$\\begin{aligned}&\\text{Suggestions for Improvement: The paper could benefit from a more detailed discussion of the limitations of the approach, including the use of MCMC methods and the reliance on pre-trained models. The authors could also explore the use of other optimization regimes, such as short-run training, to improve the effectiveness of the approach.}\n\n\\end{aligned}$$\n\n$$\\begin{aligned}&\\text{Recommendation: The paper presents a novel and effective approach to solving the EOT problem, and its results are promising. However, the approach has some limitations, and further research is needed to fully explore its potential.}\n\n\\end{aligned}$$",
        "gr_score_with": 0.842911877394636,
        "gr_score_without": 0.7682403433476395,
        "output_without": {
            "num_tokens_scored": 233,
            "num_green_tokens": 179,
            "green_fraction": 0.7682403433476395,
            "z_score": 2.2730527608183966,
            "p_value": 0.0115115003325653
        },
        "output_with": {
            "num_tokens_scored": 261,
            "num_green_tokens": 220,
            "green_fraction": 0.842911877394636,
            "z_score": 5.038240918841154,
            "p_value": 2.3491491585743628e-07
        }
    },
    {
        "title": "SEMIREWARD: A GENERAL REWARD MODEL FOR SEMI-SUPERVISED LEARNING",
        "abstract": "Semi-supervised learning (SSL) has witnessed great progress with various improvements in the self-training framework with pseudo labeling. The main challenge is how to distinguish high-quality pseudo labels against the confirmation bias. However, existing pseudo-label selection strategies are limited to pre-defined schemes or complex hand-crafted policies specially designed for classification, failing to achieve high-quality labels, fast convergence, and task versatility simultaneously. To these ends, we propose a Semi-supervised Reward framework (SemiReward) that predicts reward scores to evaluate and filter out high-quality pseudo labels, which is pluggable to mainstream SSL methods in wide task types and scenarios. To mitigate confirmation bias, SemiReward is trained online in two stages with a generator model and subsampling strategy. With classification and regression tasks on 13 standard SSL benchmarks across three modalities, extensive experiments verify that SemiReward achieves significant performance gains and faster convergence speeds upon Pseudo Label, FlexMatch, and Free/SoftMatch. Code and models are available at https://github.com/Westl ake-AI/SemiReward. ESC-50 250 ESC-50 500 FSDnoisy-18k 1773 UrtraSound-8k 400 Yelp Review 250",
        "peer_review_without_watermark": "$$\\boxed{\\text{Paper Summary:}  \nThe paper proposes a Semi-supervised Reward framework (SemiReward) that predicts reward scores to evaluate and filter out high-quality pseudo labels in semi-supervised learning (SSL). The rewarder network is designed to model correlations and predict credible reward scores, which is trained online in a two-stage pipeline assisted by a generator network to avoid confirmation bias. The proposed approach is general, pluggable, and can be used with various SSL methods in wide task types and scenarios. Experimental results demonstrate consistent performance gains and convergence speedup when applying SemiReward to popular SSL algorithms.}\n\n$$\\boxed{\\text{Strengths:}  \n1. The proposed approach is general and pluggable, making it suitable for various SSL methods and task types.\n2. The use of a two-stage training pipeline and a generator network helps to avoid confirmation bias and improves the quality of pseudo labels.\n3. The rewarder network is designed to model correlations and predict credible reward scores, making it a reliable indicator for high-quality labels.\n4. The approach has been extensively evaluated on diverse classification and regression datasets, demonstrating consistent performance gains and convergence speedup.}\n\n$$\\boxed{\\text{Weaknesses:}  \n1. The defined reward scores and rewarder only support sample-level labels, which may not be suitable for fine-grained labels in some scenarios.\n2. The approach requires repeating the teacher model and the rewarder several times to get reliable pseudo labels, which may lead to extra computational costs and performance decreasing at the end of training.\n3. The approach may not be suitable for imbalanced regression datasets, as it may not be able to select high-quality pseudo labels effectively.}\n\n$$\\boxed{\\text{Suggestions for Improvement:}  \n1. Design a more efficient sampling and selection pipeline for SSL training to reduce computational costs.\n2. Explore the use of fine-grained labels in the rewarder network to improve its performance on tasks requiring token-level rewarding.\n3. Investigate the use of adaptive data augmentations to further enhance SSL performance.}\n\n$$\\boxed{\\text{Recommendation:}  \nBased on the experimental results and the proposed approach, I recommend that the authors continue to improve and refine the SemiReward framework. The approach has shown promising results and has the potential to become a new paradigm for measuring pseudo-label quality in SSL scenarios. However, further research is needed to address the limitations and weaknesses identified in the paper.}$",
        "peer_review_with_watermark": "$$\\boxed{\\text{Paper Summary:} \nThe paper proposes a Semi-supervised Reward framework (SemiReward) that predicts reward scores to evaluate and filter out high-quality pseudo labels in semi-supervised learning (SSL). The rewarder network is trained online in a two-stage pipeline to avoid confirmation bias. Extensive experiments on diverse classification and regression datasets demonstrate consistent performance gains and convergence speedup when applying SemiReward to popular SSL algorithms.\n\nStrengths:\n1. The proposed SemiReward framework can be used to select high-quality pseudo labels in SSL scenarios.\n2. The two-stage training pipeline and generator network are designed to avoid confirmation bias.\n3. The paper provides a general and pluggable framework for SSL scenarios.\n4. The experiments demonstrate consistent performance gains and convergence speedup.\n\nWeaknesses:\n1. The defined reward scores and rewarder only support sample-level labels.\n2. The paper requires repeating the teacher model and the rewarder several times to get reliable pseudo labels, leading to extra computational costs.\n3. The semi-supervised reward modeling may not be directly applicable to reinforcement learning (RL) scenarios.\n\nSuggestions for Improvement:\n1. Design a more efficient sampling and selection pipeline for SSL training.\n2. Explore pre-training a general rewarder with large-scale pre-trained backbones on open-source datasets.\n3. Extend SemiReward with adaptive data augmentations to further enhance SSL performance.\n4. Investigate combining SSL with reward modeling for RL training.\n\nRecommendation:\nThe paper proposes a valuable contribution to the semi-supervised learning community by introducing a general and pluggable framework for selecting high-quality pseudo labels. The proposed SemiReward framework demonstrates consistent performance gains and convergence speedup in SSL scenarios. However, further research is needed to address the limitations and improve the applicability of SemiReward in RL scenarios.",
        "gr_score_with": 0.8,
        "gr_score_without": 0.7457627118644068,
        "output_without": {
            "num_tokens_scored": 354,
            "num_green_tokens": 264,
            "green_fraction": 0.7457627118644068,
            "z_score": 1.8789003017258985,
            "p_value": 0.030129053825494592
        },
        "output_with": {
            "num_tokens_scored": 280,
            "num_green_tokens": 224,
            "green_fraction": 0.8,
            "z_score": 3.651483716701107,
            "p_value": 0.00013036481642765842
        }
    },
    {
        "title": "META-LEARNING PRIORS USING UNROLLED PROXIMAL NETWORKS",
        "abstract": "Relying on prior knowledge accumulated from related tasks, meta-learning offers a powerful approach to learning a novel task from limited training data. Recent approaches parameterize the prior with a family of probability density functions or recurrent neural networks, whose parameters can be optimized by utilizing validation data from the observed tasks. While these approaches have appealing empirical performance, the expressiveness of their prior is relatively low, which limits the generalization and interpretation of meta-learning. Aiming at expressive yet meaningful priors, this contribution puts forth a novel prior representation model that leverages the notion of algorithm unrolling. The key idea is to unroll the proximal gradient descent steps, where learnable piecewise linear functions are developed to approximate the desired proximal operators within tight theoretical error bounds established for both smooth and non-smooth proximal functions. The resultant multi-block neural network not only broadens the scope of learnable priors, but also enhances interpretability from an optimization viewpoint. Numerical tests conducted on few-shot learning datasets demonstrate markedly improved performance with flexible, visualizable, and understandable priors.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes a novel meta-learning approach termed MetaProxNet, which leverages algorithm unrolling to learn flexible and generalized priors. The proposed method uses piecewise linear functions (PLFs) to approximate proximal operators, allowing for more expressive priors and improved interpretability. The authors demonstrate the effectiveness of MetaProxNet through numerical tests on few-shot learning datasets, outperforming state-of-the-art meta-learning methods.\n\nStrengths:\n1. The authors provide a clear and concise introduction to the problem of meta-learning and the limitations of existing approaches.\n2. The proposed method of using algorithm unrolling to learn priors is innovative and well-motivated.\n3. The use of PLFs to approximate proximal operators is a novel and effective approach.\n4. The authors provide a thorough theoretical analysis of the error bounds for the PLF-based proximal operator.\n\nWeaknesses:\n1. The paper assumes a high level of background knowledge in meta-learning and optimization, which may make it difficult for non-experts to follow.\n2. The authors may benefit from providing more detailed explanations of certain technical concepts, such as the definition of proximal operators and the properties of piecewise linear functions.\n3. The numerical tests may be limited by the choice of datasets and hyperparameters, which could impact the generalizability of the results.\n4. The authors may want to consider providing more discussion on the potential applications and limitations of MetaProxNet in real-world scenarios.\n\nSuggestions for Improvement:\n1. Provide more detailed explanations of technical concepts and provide references to relevant literature for non-experts.\n2. Consider including more diverse and challenging datasets in the numerical tests to demonstrate the robustness of MetaProxNet.\n3. Investigate the potential applications and limitations of MetaProxNet in real-world scenarios, such as image and speech recognition.\n4. Consider implementing MetaProxNet with more complicated backbones and DC modules to further demonstrate its effectiveness.\n\nRecommendation:\nBased on the paper's technical quality and innovation, I recommend accepting the paper for publication. However, the authors should be aware of the potential limitations and suggest avenues for future research to further develop and apply MetaProxNet.",
        "peer_review_with_watermark": "$$$Paper Summary:\n\nThe paper introduces a novel meta-learning approach termed MetaProxNet, which leverages algorithm unrolling to learn flexible and generalized priors. The proposed approach uses a multi-block neural network, where each block is responsible for approximating a proximal operator using learnable piecewise linear functions (PLFs). The learned priors are obtained by unrolling the proximal gradient descent (PGD) algorithm, which allows for the approximation of any smooth or continuous proximal operator.\n\nThe paper presents a theoretical analysis of the error bounds between the learned PLFs and the optimal proximal operator. The results show that the error bounds decrease as the number of PLFs increases, indicating that the learned priors can approximate any smooth or continuous proximal operator with high accuracy.\n\nNumerical tests are conducted on several meta-learning benchmark datasets, which demonstrate the superiority of MetaProxNet relative to state-of-the-art meta-learning methods.\n\nStrengths:\n\n1. The paper introduces a novel approach to meta-learning, which leverages algorithm unrolling to learn flexible and generalized priors.\n2. The theoretical analysis of the error bounds provides a rigorous understanding of the approximation capabilities of the learned priors.\n3. The numerical tests demonstrate the superiority of MetaProxNet relative to state-of-the-art meta-learning methods.\n\nWeaknesses:\n\n1. The paper assumes that the task-invariant common prior knowledge can be acquired as an inductive bias, which may not be true in all cases.\n2. The paper does not provide a comprehensive analysis of the convergence guarantees for MetaProxNet.\n3. The paper assumes that the proximal operator can be approximated using PLFs, which may not be true in all cases.\n\nSuggestions for Improvement:\n\n1. Provide a more comprehensive analysis of the convergence guarantees for MetaProxNet.\n2. Conduct a more extensive set of numerical tests to further evaluate the performance of MetaProxNet.\n3. Provide a more detailed analysis of the assumptions made by the paper, including the assumption that the task-invariant common prior knowledge can be acquired as an inductive bias.\n\nRecommendation:\n\nI recommend that the paper be accepted for publication in a top-tier conference or journal in the field of machine learning or optimization. The paper's novel approach to meta-learning and its theoretical analysis of the error bounds make it a valuable contribution to the field.\n\n$$$\n\nNote: The review is based on the provided paper text and may not be a comprehensive review of the paper's content or methodology. The reviewer's opinions and suggestions are subjective and may not reflect the opinions of other reviewers or experts in the field.",
        "gr_score_with": 0.7748538011695907,
        "gr_score_without": 0.6328358208955224,
        "output_without": {
            "num_tokens_scored": 335,
            "num_green_tokens": 212,
            "green_fraction": 0.6328358208955224,
            "z_score": -2.682566317336497,
            "p_value": 0.9963470167608612
        },
        "output_with": {
            "num_tokens_scored": 342,
            "num_green_tokens": 265,
            "green_fraction": 0.7748538011695907,
            "z_score": 3.0207672550604343,
            "p_value": 0.001260675438187559
        }
    },
    {
        "title": "PLUG-AND-PLAY: AN EFFICIENT POST-TRAINING PRUNING METHOD FOR LARGE LANGUAGE MODELS",
        "abstract": "With the rapid growth of large language models (LLMs), there is increasing demand for memory and computation for LLMs. Recent efforts on post-training pruning of LLMs aim to reduce the model size and computation, yet the performance is still sub-optimal. In this paper, we present a plug-and-play solution for post-training pruning of LLMs. The proposed solution has two innovative components: 1) Relative Importance and Activations (RIA), a new pruning metric that jointly considers the weight and activations efficiently on LLMs; and 2) Channel Permutation, a new approach to maximally preserve important weights under N:M sparsity. The proposed two components can be readily combined to further enhance the N:M structured pruned LLMs. Our empirical experiments show that RIA alone can already surpass all existing post-training pruning methods on prevalent LLMs, e.g., LLaMA ranging from 7B to 65B. Furthermore, N:M structured pruning with channel permutation can even outperform the original LLaMA2 70B on zero-shot tasks, together with practical speed-up on specific hardware.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes a plug-and-play post-training pruning method for large language models (LLMs) called Relative Importance and Activations (RIA). The proposed method consists of two key components: RIA, a new pruning metric that jointly considers the weight and activations efficiently, and Channel Permutation, a new approach to maximally preserve important weights under N:M sparsity. The authors evaluate their method on three popular LLMs and show that RIA outperforms existing SOTA one-shot pruning techniques SparseGPT and Wanda, and achieves a significant performance boost with the incorporation of Channel Permutation.\n\nStrengths:\n1. The proposed RIA metric is novel and efficient, jointly considering the weight and activations to prune the LLMs.\n2. Channel Permutation is a new approach to maximally preserve important weights under N:M sparsity, which is effective in reducing the performance drop.\n3. The authors provide extensive experiments on prominent LLMs and show that their method outperforms existing SOTA one-shot pruning techniques.\n4. The proposed method is hardware-friendly, ensuring enhanced inference acceleration.\n\nWeaknesses:\n1. The paper does not provide a clear explanation of the channel permutation approach, and the Hungarian algorithm is not thoroughly explained.\n2. The authors do not provide a comprehensive analysis of the time complexity of the proposed method.\n3. The paper does not discuss the potential limitations and challenges of the proposed method.\n\nSuggestions for Improvement:\n1. Provide a clear explanation of the Channel Permutation approach and the Hungarian algorithm used to solve the linear sum assignment problem.\n2. Conduct a thorough analysis of the time complexity of the proposed method to ensure that it is efficient and scalable.\n3. Discuss the potential limitations and challenges of the proposed method, such as the requirement for calibration data and the potential impact on model performance.\n\nRecommendation:\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit the paper for peer review. The authors should address the weaknesses and provide a clear explanation of the Channel Permutation approach and the Hungarian algorithm used to solve the linear sum assignment problem. Additionally, they should conduct a thorough analysis of the time complexity of the proposed method and discuss the potential limitations and challenges of the proposed method.",
        "peer_review_with_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes a plug-and-play post-training pruning method for large language models (LLMs). The proposed solution has two key components: Relative Importance and Activations (RIA), a new pruning metric that jointly considers the weight and activations efficiently on LLMs; and Channel Permutation, a new approach to maximally preserve important weights under N:M sparsity.\n\nStrengths:\n1. The proposed solution has been shown to consistently outperform existing SOTA one-shot pruning techniques SparseGPT and Wanda across various model sizes.\n2. Channel Permutation successfully reduces the performance drop when adapting the model to N:M constraint by reframing the input channel permutation problem as a combinatorial optimization task.\n3. The method is hardware-friendly, ensuring enhanced inference acceleration.\n\nWeaknesses:\n1. The paper does not provide a thorough analysis of the time complexity of the proposed methods.\n2. The results of the experiments are mostly based on the HuggingFace Transformers library and may not generalize well to other datasets or environments.\n\nSuggestions for Improvement:\n1. The authors should provide a more detailed analysis of the time complexity of the proposed methods and their implications on real-world deployment.\n2. The authors should investigate the generalizability of their results across different datasets and environments.\n3. The authors should provide a more thorough comparison with existing methods in terms of their theoretical foundations and practical implications.\n\nRecommendation:\nBased on the provided results and analysis, I recommend accepting the paper for publication in its current form. However, I would like to suggest that the authors address the mentioned weaknesses and provide a more comprehensive analysis in their final manuscript.\n\n$$\\boxed{Rating:}$$\n4/5",
        "gr_score_with": 0.7457627118644068,
        "gr_score_without": 0.6254071661237784,
        "output_without": {
            "num_tokens_scored": 307,
            "num_green_tokens": 192,
            "green_fraction": 0.6254071661237784,
            "z_score": -2.8520467969892285,
            "p_value": 0.9978280647436621
        },
        "output_with": {
            "num_tokens_scored": 295,
            "num_green_tokens": 220,
            "green_fraction": 0.7457627118644068,
            "z_score": 1.7151934642642273,
            "p_value": 0.043154881376387996
        }
    },
    {
        "title": "DIFFTACTILE: A PHYSICS-BASED DIFFERENTIABLE TACTILE SIMULATOR FOR CONTACT-RICH ROBOTIC MANIPULATION",
        "abstract": "We introduce DIFFTACTILE, a physics-based differentiable tactile simulation system designed to enhance robotic manipulation with dense and physically accurate tactile feedback. In contrast to prior tactile simulators which primarily focus on manipulating rigid bodies and often rely on simplified approximations to model stress and deformations of materials in contact, DIFFTACTILE emphasizes physics-based contact modeling with high fidelity, supporting simulations of diverse contact modes and interactions with objects possessing a wide range of material properties. Our system incorporates several key components, including a Finite Element Method (FEM)-based soft body model for simulating the sensing elastomer, a multi-material simulator for modeling diverse object types (such as elastic, elastoplastic, cables) under manipulation, a penalty-based contact model for handling contact dynamics. The differentiable nature of our system facilitates gradient-based optimization for both 1) refining physical properties in simulation using real-world data, hence narrowing the sim-to-real gap and 2) efficient learning of tactile-assisted grasping and contact-rich manipulation skills. Additionally, we introduce a method to infer the optical response of our tactile sensor to contact using an efficient pixel-based neural module. We anticipate that DIFFTACTILE will serve as a useful platform for studying contact-rich manipulations, leveraging the benefits of dense tactile feedback and differentiable physics. Code and supplementary materials are available at the project website1.",
        "peer_review_without_watermark": "$$$\\begin{align}\\textbf{Paper Summary:} &\\quad \\text{The paper introduces DIFFTACTILE, a physics-based differentiable tactile simulator for contact-rich robotic manipulation. DIFFTACTILE models the sensing elastomer, multi-material objects, and penalty-based contacts. The system is differentiable, allowing for efficient gradient-based policy learning and system identification to close the sim-to-real gap. The authors evaluate the simulator on various tasks, including grasping, surface following, cable straightening, case opening, and object reposing.}\\\\\n\\textbf{Strengths:} &\\quad \\text{The paper makes significant contributions to the field of tactile simulation, providing a comprehensive and accurate model for contact-rich robotic manipulation. The differentiability of the system is a key feature, enabling efficient skill learning and system identification. The authors demonstrate the versatility of the simulator on various tasks, showcasing its potential for advancing skill learning in contact-rich robotic manipulation.}\\\\\n\\textbf{Weaknesses:} &\\quad \\text{One of the main limitations of the paper is the lack of comparison with other state-of-the-art tactile simulators. Additionally, the authors could have provided more detailed explanations of the penalty-based contact model and its parameters. Furthermore, the paper could benefit from more comprehensive evaluation metrics and more detailed results for certain tasks.}\\\\\n\\textbf{Suggestions for Improvement:} &\\quad \\text{To improve the paper, the authors could provide a more detailed comparison with other state-of-the-art tactile simulators, including their strengths and limitations. They could also provide more detailed explanations of the penalty-based contact model and its parameters, as well as its tuning process. Additionally, they could consider using more comprehensive evaluation metrics, such as robustness and generalizability metrics, to evaluate the performance of the simulator.}\\\\\n\\textbf{Recommendation:} &\\quad \\text{Based on the paper's contributions and potential, I recommend its publication in a top-tier conference or journal. However, I suggest that the authors address the limitations and weaknesses mentioned above to improve the paper's overall quality and impact.}\\\\\n\\textbf{Additional Comments:} &\\quad \\text{The paper provides a comprehensive and accurate model for contact-rich robotic manipulation. The differentiability of the system is a key feature, enabling efficient skill learning and system identification. The authors demonstrate the versatility of the simulator on various tasks, showcasing its potential for advancing skill learning in contact-rich robotic manipulation. However, the paper could benefit from more detailed explanations of the penalty-based contact model and its parameters, as well as more comprehensive evaluation metrics and results.}\\\\\n\\end{align}$$",
        "peer_review_with_watermark": "$$$\\begin{align}\\text{Paper Summary:}~\\\\\n\\text{This paper introduces DIFFTACTILE, a physics-based differentiable tactile simulator for contact-rich robotic manipulation. It extends the capabilities of robotic simulators by providing models for tactile sensors, multi-material objects, and penalty-based contacts.}\\\\\n\\text{The simulator uses Finite Element Method (FEM) for tactile sensors, Moving Least Square Material Point Method (MLS-MPM) for objects, and penalty-based contact model for dynamics. It is designed to facilitate system identification and improve skill learning efficiency with gradient-based optimization.}\\\\\n\\text{Experimental results demonstrate the effectiveness of DIFFTACTILE in grasping, surface following, cable straightening, case opening, and object reposing tasks. It is compared with state-of-the-art reinforcement learning and sample-based trajectory optimization approaches.}\\\\\n\\text{Strengths:}\\\\\n\\text{1. DIFFTACTILE extends the capabilities of robotic simulators by providing models for tactile sensors, multi-material objects, and penalty-based contacts.}\\\\\n\\text{2. It uses differentiable physics-based simulation, which facilitates system identification and improves skill learning efficiency.}\\\\\n\\text{3. The simulator is versatile, supporting a range of manipulation tasks, including surface following, cable straightening, case opening, and object reposing.}\\\\\n\\text{Weaknesses:}\\\\\n\\text{1. The paper assumes that the reader is familiar with robotics, simulation, and machine learning.}\\\\\n\\text{2. The experimental results are not provided in detail, making it difficult to evaluate the performance of DIFFTACTILE comprehensively.}\\\\\n\\text{Suggestions for Improvement:}\\\\\n\\text{1. Provide more details about the experimental results, including the number of trials, evaluation metrics, and standard deviations.}\\\\\n\\text{2. Explain the assumptions made in the paper, such as the type of materials used for the tactile sensors and objects.}\\\\\n\\text{3. Compare DIFFTACTILE with other state-of-the-art tactile simulators, including Tacto, Tactile-Gym, and SynTouch BioTac.}\\\\\n\\text{Recommendation:}\\\\\n\\text{Based on the paper summary, strengths, weaknesses, and suggestions for improvement, I recommend that the authors revise the paper to address the weaknesses and provide more detailed experimental results. The simulator has the potential to advance skill learning for contact-rich robotic manipulation, and with further refinement, it can be a valuable tool for researchers and engineers in the field.}\\end{align}$$",
        "gr_score_with": 0.7936962750716332,
        "gr_score_without": 0.7264150943396226,
        "output_without": {
            "num_tokens_scored": 318,
            "num_green_tokens": 231,
            "green_fraction": 0.7264150943396226,
            "z_score": 1.027912337500094,
            "p_value": 0.15199553275773803
        },
        "output_with": {
            "num_tokens_scored": 349,
            "num_green_tokens": 277,
            "green_fraction": 0.7936962750716332,
            "z_score": 3.819666025566714,
            "p_value": 6.681624379744173e-05
        }
    },
    {
        "title": "MOGANET: MULTI-ORDER GATED AGGREGATION NETWORK",
        "abstract": "By contextualizing the kernel as global as possible, Modern ConvNets have shown great potential in computer vision tasks. However, recent progress on multi-order game-theoretic interaction within deep neural networks (DNNs) reveals the representation bottleneck of modern ConvNets, where the expressive interactions have not been effectively encoded with the increased kernel size. To tackle this challenge, we propose a new family of modern ConvNets, dubbed MogaNet, for discriminative visual representation learning in pure ConvNet-based models with favorable complexity-performance trade-offs. MogaNet encapsulates conceptually simple yet effective convolutions and gated aggregation into a compact module, where discriminative features are efficiently gathered and contextualized adaptively. MogaNet exhibits great scalability, impressive efficiency of parameters, and competitive performance compared to state-of-the-art ViTs and ConvNets on ImageNet and various downstream vision benchmarks, including COCO object detection, ADE20K semantic segmentation, 2D&3D human pose estimation, and video prediction. Notably, MogaNet hits 80.0% and 87.8% accuracy with 5.2M and 181M parameters on ImageNet-1K, outperforming ParC-Net and ConvNeXtL, while saving 59% FLOPs and 17M parameters, respectively. The source code is available at https://github.com/Westlake-AI/MogaNet.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces a new modern ConvNet architecture, named MogaNet, which tackles the representation bottleneck of modern ConvNets by incorporating multi-order game-theoretic interaction. MogaNet encapsulates conceptually simple yet effective convolutions and gated aggregation into a compact module, where discriminative features are efficiently gathered and contextualized adaptively. The proposed architecture is compared to state-of-the-art ViTs and ConvNets on various vision benchmarks, achieving competitive performance and efficiency.\n\nStrengths:\n\n1.  The paper introduces a new ConvNet architecture that tackles the representation bottleneck of modern ConvNets.\n2.  The proposed architecture is compact and efficient, requiring fewer parameters and FLOPs compared to existing state-of-the-art models.\n3.  The paper presents a comprehensive evaluation of MogaNet on various vision benchmarks, including image classification, object detection, semantic segmentation, instance segmentation, pose estimation, and video prediction.\n\nWeaknesses:\n\n1.  The paper relies heavily on the use of pre-trained models and does not provide a detailed analysis of the transfer learning process.\n2.  The evaluation of MogaNet on 2D and 3D human pose estimation tasks is limited, and more extensive evaluation is required.\n3.  The paper does not provide a detailed analysis of the impact of the channel aggregation module on the overall performance of MogaNet.\n\nSuggestions for Improvement:\n\n1.  Provide a more detailed analysis of the transfer learning process and its impact on the performance of MogaNet.\n2.  Evaluate MogaNet on more vision benchmarks, including 2D and 3D human pose estimation tasks.\n3.  Conduct a more extensive analysis of the impact of the channel aggregation module on the overall performance of MogaNet.\n\nRecommendation:\n\n1.  The proposed architecture of MogaNet is a significant contribution to the field of computer vision, and its compact and efficient design make it a promising candidate for real-world applications.\n2.  Further research is required to fully explore the potential of MogaNet and to address the limitations mentioned above.\n3.  The paper provides a good starting point for further investigation and development of MogaNet, and its results can serve as a foundation for future studies in this area.",
        "peer_review_with_watermark": "$$$Paper Summary:\nMogaNet is a new modern ConvNet architecture designed to address the representation bottleneck of modern ConvNets by exploiting multi-order game-theoretic interactions. The architecture consists of a four-stage MogaNet model with a compact spatial aggregation block and channel aggregation block. The spatial aggregation block captures multi-order features through feature decomposition and multi-order DWConv layers. The channel aggregation block adaptsively reallocates channel-wise features through a lightweight channel reallocation module. Extensive experiments demonstrate the consistent efficiency of model parameters and competitive performance of MogaNet on various vision benchmarks.\n\nStrengths:\n\n1. MogaNet addresses the representation bottleneck of modern ConvNets by exploiting multi-order game-theoretic interactions.\n2. The architecture is compact and efficient, with a favorable complexity-performance trade-off.\n3. The proposed spatial aggregation block and channel aggregation block are effective in capturing and adaptingively reallocating multi-order interactions.\n4. MogaNet achieves competitive performance with state-of-the-art architectures on various vision benchmarks.\n\nWeaknesses:\n\n1. The paper does not provide a comprehensive analysis of the multi-order game-theoretic interactions and their implications on deep neural networks.\n2. The channel reallocation module CA(\u00b7) is not thoroughly explained and its effectiveness is limited to a small-scale ablation study.\n3. The experimental results are not accompanied by a detailed analysis of the contributions of each component of the MogaNet architecture.\n\nSuggestions for Improvement:\n\n1. Provide a more in-depth analysis of the multi-order game-theoretic interactions and their implications on deep neural networks.\n2. Conduct a more comprehensive ablation study to validate the effectiveness of the channel reallocation module CA(\u00b7).\n3. Include a detailed analysis of the experimental results to understand the contributions of each component of the MogaNet architecture.\n\nRecommendation:\n\nBased on the paper's contribution to addressing the representation bottleneck of modern ConvNets and its competitive performance on various vision benchmarks, I recommend that MogaNet be accepted for publication. However, I suggest that the authors address the limitations and weaknesses mentioned above to provide a more comprehensive and rigorous analysis of their proposed architecture.\n\n$$$",
        "gr_score_with": 0.7879858657243817,
        "gr_score_without": 0.6688963210702341,
        "output_without": {
            "num_tokens_scored": 299,
            "num_green_tokens": 200,
            "green_fraction": 0.6688963210702341,
            "z_score": -1.1736475784144909,
            "p_value": 0.8797318922470709
        },
        "output_with": {
            "num_tokens_scored": 283,
            "num_green_tokens": 223,
            "green_fraction": 0.7879858657243817,
            "z_score": 3.2299550760086158,
            "p_value": 0.0006190483526700303
        }
    },
    {
        "title": "IDENTIFYING POLICY GRADIENT SUBSPACES",
        "abstract": "Policy gradient methods hold great potential for solving complex continuous control tasks. Still, their training efficiency can be improved by exploiting structure within the optimization problem. Recent work indicates that supervised learning can be accelerated by leveraging the fact that gradients lie in a low-dimensional and slowly-changing subspace. In this paper, we conduct a thorough evaluation of this phenomenon for two popular deep policy gradient methods on various simulated benchmark tasks. Our results demonstrate the existence of such gradient subspaces despite the continuously changing data distribution inherent to reinforcement learning. These findings reveal promising directions for future work on more efficient reinforcement learning, e.g., through improving parameter-space exploration or enabling second-order optimization.",
        "peer_review_without_watermark": "$$$\\boxed{\\text{Paper Summary:}}$\n\nThis paper investigates the existence of low-dimensional, slowly-changing gradient subspaces in policy gradient algorithms, particularly in the context of reinforcement learning (RL). The authors conduct an empirical evaluation of two popular RL algorithms, Proximal Policy Optimization (PPO) and Soft Actor-Critic (SAC), on various simulated RL benchmarks. Their results demonstrate that despite the continuously changing data distribution inherent to RL, the gradients of the actor and critic networks of PPO and SAC lie in a low-dimensional, slowly-changing subspace of high curvature. This finding has implications for more efficient reinforcement learning, enabling second-order optimization and improving parameter-space exploration.\n\n$\\boxed{\\text{Strengths:}}$\n\n1. The paper provides a thorough analysis of the gradient subspaces in policy gradient algorithms, which is a crucial aspect of reinforcement learning.\n2. The authors conduct an empirical evaluation of two popular RL algorithms, PPO and SAC, on various simulated RL benchmarks, which provides a comprehensive understanding of the phenomenon.\n3. The results demonstrate that the gradient subspaces are low-dimensional, slowly-changing, and of high curvature, which has significant implications for more efficient reinforcement learning.\n\n$\\boxed{\\text{Weaknesses:}}$\n\n1. The paper assumes that the reader is familiar with the mathematical background and notation used throughout the paper, which may be a barrier to understanding for non-experts.\n2. The analysis is limited to two popular RL algorithms, PPO and SAC, which may not be representative of all RL algorithms.\n3. The paper does not provide a comprehensive comparison of the gradient subspaces in different RL algorithms, which may limit the generalizability of the results.\n\n$\\boxed{\\text{Suggestions for Improvement:}}$\n\n1. Provide a more detailed explanation of the mathematical background and notation used throughout the paper to ensure that all readers can understand the analysis.\n2. Conduct a comprehensive comparison of the gradient subspaces in different RL algorithms to ensure that the results are representative of the broader RL community.\n3. Investigate the applicability of the findings to other RL algorithms and domains to further establish the significance of the results.\n\n$\\boxed{\\text{Recommendation:}}$\n\nBased on the thorough analysis and empirical evaluation presented in the paper, I recommend that the authors continue to explore the implications of the findings for more efficient reinforcement learning. Specifically, I suggest that the authors investigate the potential applications of the gradient subspaces in second-order optimization and parameter-space exploration, and conduct further experiments to establish the robustness and generalizability of the results.",
        "peer_review_with_watermark": "$$$\\begin{aligned}\n\\text{Paper Summary:} \\\\\n\\text{This paper investigates the existence and properties of gradient subspaces in policy gradient algorithms for reinforcement learning. The authors conduct a comprehensive empirical evaluation of gradient subspaces in the context of PPO and SAC algorithms on various simulated RL benchmark tasks. They find that the gradients of the actor and critic networks of PPO and SAC lie in a low-dimensional, slowly changing subspace of high curvature. This property holds for both on-policy and off-policy learning.}\\\\\n\\\\\n\\text{Strengths:} \\\\\n\\text{1. The paper provides a thorough evaluation of gradient subspaces in policy gradient algorithms.}\\\\\n\\text{2. The authors' analysis is comprehensive and well-structured.}\\\\\n\\text{3. The paper provides insights into the properties of gradient subspaces in RL.}\\\\\n\\\\\n\\text{Weaknesses:} \\\\\n\\text{1. The paper does not discuss the limitations and challenges of using gradient subspaces in RL.}\\\\\n\\text{2. The analysis is limited to PPO and SAC algorithms.}\\\\\n\\text{3. The paper does not provide a detailed discussion of the implications of the findings.}\\\\\n\\\\\n\\text{Suggestions for Improvement:} \\\\\n\\text{1. Discuss the limitations and challenges of using gradient subspaces in RL.}\\\\\n\\text{2. Analyze gradient subspaces in other policy gradient algorithms.}\\\\\n\\text{3. Provide a detailed discussion of the implications of the findings.}\\\\\n\\\\\n\\text{Recommendation:} \\\\\n\\text{I recommend that the authors revise and resubmit the paper. The authors have made significant contributions to the field of RL by providing a comprehensive evaluation of gradient subspaces in policy gradient algorithms. However, the paper lacks a detailed discussion of the limitations and challenges of using gradient subspaces in RL. Additionally, the analysis is limited to PPO and SAC algorithms. With revisions to address these limitations, the paper has the potential to make a significant impact in the field of RL.}\\\\\n\\end{aligned}$$$",
        "gr_score_with": 0.8035714285714286,
        "gr_score_without": 0.6758409785932722,
        "output_without": {
            "num_tokens_scored": 327,
            "num_green_tokens": 221,
            "green_fraction": 0.6758409785932722,
            "z_score": -0.9533306754370593,
            "p_value": 0.8297887230707532
        },
        "output_with": {
            "num_tokens_scored": 224,
            "num_green_tokens": 180,
            "green_fraction": 0.8035714285714286,
            "z_score": 3.3826286924148676,
            "p_value": 0.0003589781528514082
        }
    },
    {
        "title": "PROVES ADVERSARIAL TRAINING",
        "abstract": "In standard adversarial training, models are optimized to fit invariant one-hot labels for adversarial data when the perturbations are within allowable budgets. However, the overconfident target harms generalization and causes the problem of robust overfitting. To address this issue and enhance adversarial robustness, we analyze the characteristics of robust models and identify that robust models tend to produce smoother and well-calibrated outputs. Based on the observation, we propose a simple yet effective method, Annealing Self-Distillation Rectification (ADR), which generates soft labels as a better guidance mechanism that reflects the underlying distribution of data. By utilizing ADR, we can obtain rectified labels that improve model robustness without the need for pre-trained models or extensive extra computation. Moreover, our method facilitates seamless plug-andplay integration with other adversarial training techniques by replacing the hard labels in their objectives. We demonstrate the efficacy of ADR through extensive experiments and strong performances across datasets.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary: \nThe paper proposes a novel approach called Annealing Self-Distillation Rectification (ADR) to enhance adversarial training. The authors investigate the characteristics of robust models and identify that robust models tend to produce smoother and well-calibrated outputs. Based on this observation, they propose ADR, which generates soft labels as a better guidance mechanism that reflects the underlying distribution of data. The proposed method can be integrated with other adversarial training techniques without requiring pre-trained models or extensive extra computation.\n\nStrengths:\n1. The paper provides a comprehensive analysis of the robust models' output properties, which is essential for understanding the characteristics of robust models.\n2. The authors propose a novel approach, ADR, which can be integrated with other adversarial training techniques.\n3. The proposed method can alleviate the problem of robust overfitting and improve the generalization ability of models.\n\nWeaknesses:\n1. The paper does not provide a thorough discussion of the limitations of the proposed method.\n2. The authors do not provide a detailed analysis of the effects of different hyperparameters on the performance of ADR.\n3. The paper does not provide a comprehensive comparison with other state-of-the-art methods for adversarial training.\n\nSuggestions for Improvement:\n1. The authors should provide a more detailed discussion of the limitations of the proposed method and its potential drawbacks.\n2. The authors should conduct a more thorough analysis of the effects of different hyperparameters on the performance of ADR.\n3. The authors should provide a comprehensive comparison with other state-of-the-art methods for adversarial training.\n\nRecommendation:\nBased on the paper's contribution to the field of adversarial training, I recommend accepting the paper for publication in a reputable conference or journal. However, I suggest that the authors address the limitations and weaknesses mentioned above to strengthen the paper's overall quality.\n\n$$\\begin{aligned}\n$$Additional Comments: \nThe paper provides a valuable contribution to the field of adversarial training by proposing a novel approach, ADR, which can alleviate the problem of robust overfitting and improve the generalization ability of models. However, the paper's limitations and weaknesses should be addressed to strengthen the overall quality of the paper.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$\\textbf{Paper Summary:}$$\nThe paper proposes a new approach called Annealing Self-Distillation Rectification (ADR) to enhance the robustness of deep neural networks. ADR is based on the observation that robust models tend to produce smoother and well-calibrated outputs. The authors propose a data-driven label softening scheme to rectify labels in a noise-aware manner, which mimics the behavior of human annotators. The approach is evaluated on several datasets, including CIFAR-10, CIFAR-100, and TinyImageNet-200, and shows promising results in improving robustness and alleviating robust overfitting.\n\n$$\\textbf{Strengths:}$$\n1. The paper provides a clear and concise summary of the key properties of robust models, which is essential for understanding the proposed approach.\n2. The authors propose a novel data-driven label softening scheme, ADR, which is an innovative approach to enhancing robustness.\n3. The experimental results show promising results on several datasets, demonstrating the effectiveness of ADR in improving robustness and alleviating robust overfitting.\n4. The approach is easy to implement and integrate with other adversarial training techniques, making it a practical solution for practitioners.\n\n$$\\textbf{Weaknesses:}$$\n1. The paper assumes that the reader is familiar with the concept of robust models and adversarial training, which may limit the accessibility of the paper for readers who are new to this topic.\n2. The authors rely heavily on prior work, which may make the paper feel less original or innovative.\n3. The experimental results, while promising, may not be sufficient to conclusively establish the effectiveness of ADR, particularly on smaller datasets.\n4. The approach may require additional hyperparameter tuning to achieve optimal results, which may be challenging for practitioners.\n\n$$\\textbf{Suggestions for Improvement:}$$\n1. Provide a more detailed explanation of the key properties of robust models, particularly for readers who are new to this topic.\n2. Include more experimental results, such as comparisons with state-of-the-art methods, to establish the effectiveness of ADR.\n3. Discuss the potential limitations of ADR, such as the need for additional hyperparameter tuning, to make the approach more robust.\n4. Consider providing more theoretical insights into the approach, such as the role of self-distillation in improving robustness, to make the paper more comprehensive.\n\n$$\\textbf{Recommendation:}$$\nBased on the strengths and weaknesses of the paper, I recommend accepting the paper for publication. The authors have made a significant contribution to the field of robust deep learning, and the approach has the potential to improve the robustness of deep neural networks. While there may be areas for improvement, the paper provides a clear and concise summary of the key properties of robust models and proposes a novel data-driven label softening scheme, ADR. The experimental results demonstrate the effectiveness of ADR, making it a practical solution for practitioners.",
        "gr_score_with": 0.7908163265306123,
        "gr_score_without": 0.673992673992674,
        "output_without": {
            "num_tokens_scored": 273,
            "num_green_tokens": 184,
            "green_fraction": 0.673992673992674,
            "z_score": -0.9377074745712198,
            "p_value": 0.8258026192309572
        },
        "output_with": {
            "num_tokens_scored": 392,
            "num_green_tokens": 310,
            "green_fraction": 0.7908163265306123,
            "z_score": 3.9237137561789104,
            "p_value": 4.359716459676834e-05
        }
    },
    {
        "title": "MERT: ACOUSTIC MUSIC UNDERSTANDING MODEL WITH LARGE-SCALE SELF-SUPERVISED TRAINING",
        "abstract": "Self-supervised learning (SSL) has recently emerged as a promising paradigm for training generalisable models on large-scale data in the fields of vision, text, and speech. Although SSL has been proven effective in speech and audio, its application to music audio has yet to be thoroughly explored. This is partially due to the distinctive challenges associated with modelling musical knowledge, particularly tonal and pitched characteristics of music. To address this research gap, we propose an acoustic Music undERstanding model with large-scale self-supervised Training (MERT), which incorporates teacher models to provide pseudo labels in the masked language modelling (MLM) style acoustic pre-training. In our exploration, we identified an effective combination of teacher models, which outperforms conventional speech and audio approaches in terms of performance. This combination includes an acoustic teacher based on Residual Vector Quantisation Variational AutoEncoder (RVQ-VAE) and a musical teacher based on the ConstantQ Transform (CQT). Furthermore, we explore a wide range of settings to overcome the instability in acoustic language model pre-training, which allows our designed paradigm to scale from 95M to 330M parameters. Experimental results indicate that our model can generalise and perform well on 14 music understanding tasks and attain state-of-the-art (SOTA) overall scores.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes a novel self-supervised learning (SSL) paradigm, MERT (ACoustic Music Understanding Model with Large-scale Self-supervised Training), to pre-train generalizable models for music understanding tasks. The proposed model incorporates teacher models, including an acoustic teacher based on Residual Vector Quantisation Variational AutoEncoder (RVQ-VAE) and a musical teacher based on the Constant-Q Transform (CQT), to provide pseudo labels for masked language modelling (MLM) pre-training. The authors explore a wide range of settings to overcome training instability and demonstrate the effectiveness of MERT in achieving state-of-the-art (SOTA) results on various music understanding tasks.\n\nStrengths:\n1. The proposed MERT paradigm integrates acoustic and musical information, providing a unique blend of representation learning for music understanding tasks.\n2. The use of RVQ-VAE and CQT teacher models enables the learning of robust music representations with further training stability.\n3. The authors explore a wide range of settings to overcome training instability and demonstrate the effectiveness of MERT in achieving SOTA results.\n\nWeaknesses:\n1. The training instability issue with large-scale models remains a significant challenge, and the authors observe inverse-scaling effects in specific tasks while scaling up to 330M.\n2. The proposed approach is limited by the short 5-second training context, which may limit its performance in tasks requiring a comprehensive understanding of extended musical contexts.\n3. The authors do not provide a detailed analysis of the impact of different acoustic models on the performance of the acoustic language model.\n\nSuggestions for Improvement:\n1. Investigate more effective methods to address training instability, such as using attention relaxation techniques or pre-layer normalization.\n2. Explore the use of longer sequences for training to improve the model's performance in tasks requiring a comprehensive understanding of extended musical contexts.\n3. Provide a more detailed analysis of the impact of different acoustic models on the performance of the acoustic language model.\n4. Consider using transfer learning from other pre-trained models to further improve the performance of MERT on music understanding tasks.\n\nRecommendation:\nThe proposed MERT paradigm is a significant contribution to the field of music information retrieval, and its effectiveness in achieving SOTA results on various music understanding tasks is demonstrated. However, addressing the training instability issue and exploring more effective methods to improve the model's performance are essential for further improvement. The authors' work provides a solid foundation for future research in this area, and the forthcoming public release of their codes and models will catalyse further research into the application of SSL in music audio.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThis paper proposes the MERT (ACoustic Music Understanding Model with Large-scale Self-supervised Training) paradigm, which integrates Residual Vector Quantisation Variational AutoEncoder (RVQ-VAE) and Constant-Q Transform (CQT) teacher models to provide pseudo targets for masked language modelling (MLM) pre-training of music understanding models. The proposed model achieves state-of-the-art (SOTA) performance on various music information retrieval (MIR) tasks, including music tagging, beat tracking, and source separation.\n\nStrengths:\n1. The proposed MERT paradigm provides a unique blend of acoustic and musical information necessary for MLM-based pre-training of music understanding models.\n2. The use of RVQ-VAE and CQT teacher models enables the learning of robust music representations with further training stability.\n3. The model achieves SOTA or comparable results across a wide range of MIR tasks while using significantly smaller parameter size.\n\nWeaknesses:\n1. The training stability issues with the acoustic pre-training, particularly with larger batch sizes and model sizes, may limit the scalability of the proposed approach.\n2. The use of a 5-second training context may limit the performance of the model in tasks requiring a comprehensive understanding of extended musical contexts.\n3. The inverse-scaling effect in specific tasks while scaling-up to 330M may indicate that the design could be further improved by stabilising the training.\n\nSuggestions for Improvement:\n1. Investigate the use of longer training contexts to improve the performance of the model in tasks requiring extended musical contexts.\n2. Explore techniques to improve the training stability, such as half-precision training, gradient relaxation, or learning rate schedules.\n3. Investigate the use of different teacher models, such as k-means or EnCodec, to improve the robustness of the music representations.\n\nRecommendation:\nOverall, the proposed MERT paradigm shows promise in pre-training music understanding models with large-scale self-supervised training. However, addressing the training stability issues and exploring techniques to improve the scalability of the approach are essential to further improve the performance of the model in various MIR tasks.\n\nRating: 8/10\n\nRecommendation for publication: Yes, with revisions to address the training stability issues and explore techniques to improve the scalability of the approach.",
        "gr_score_with": 0.7338935574229691,
        "gr_score_without": 0.6913265306122449,
        "output_without": {
            "num_tokens_scored": 392,
            "num_green_tokens": 271,
            "green_fraction": 0.6913265306122449,
            "z_score": -0.3747367070507921,
            "p_value": 0.646071855015945
        },
        "output_with": {
            "num_tokens_scored": 357,
            "num_green_tokens": 262,
            "green_fraction": 0.7338935574229691,
            "z_score": 1.3974671728283974,
            "p_value": 0.08113656578951167
        }
    },
    {
        "title": "ADAPTING LARGE LANGUAGE MODELS VIA",
        "abstract": "We explore how continued pre-training on domain-specific corpora influences large language models, revealing that training on the raw corpora endows the model with domain knowledge, but drastically hurts its prompting ability for question answering. Taken inspiration from human learning via reading comprehension\u2014practice after reading improves the ability to answer questions based on the learned knowledge\u2014we propose a simple method for transforming raw corpora into reading comprehension texts. Each raw text is enriched with a series of tasks related to its content. Our method, highly scalable and applicable to any pre-training corpora, consistently enhances performance across various tasks in three different domains: biomedicine, finance, and law. Notably, our 7B language model achieves competitive performance with domain-specific models of much larger scales, such as BloombergGPT-50B. Furthermore, we demonstrate that domain-specific reading comprehension texts can improve the model\u2019s performance even on general benchmarks, showing the potential to develop a general model across even more domains. Our model, code, and data are available at https://github.com/microsoft/LMOps.",
        "peer_review_without_watermark": "$$$Peer Review\n\nPaper Summary:\nThe paper proposes a method to adapt large language models (LLMs) to specific domains by transforming raw domain-specific corpora into reading comprehension texts. The authors investigate the effectiveness of this approach on three domains (biomedicine, finance, and law) and demonstrate that it improves model performance on domain-specific tasks while also enhancing general LLM benchmarks.\n\nStrengths:\n1. The authors provide a clear and concise introduction to the problem and propose a novel approach to adapt LLMs to specific domains.\n2. The method is simple and scalable, making it feasible for large-scale pre-training corpora.\n3. The experiments demonstrate the effectiveness of the approach on three different domains, showcasing its generalizability.\n4. The authors provide a thorough analysis of the results, discussing the trade-offs between domain knowledge acquisition and prompting ability.\n\nWeaknesses:\n1. The paper relies on a limited number of experiments, primarily focusing on three domains. Future work could explore the method's effectiveness on more domains and with different types of data.\n2. The authors do not discuss potential limitations or challenges associated with their approach, such as the need for large amounts of pre-training data or the potential for overfitting to specific tasks.\n3. The evaluation metrics used in the paper may not fully capture the nuances of the tasks, potentially leading to biased results.\n4. The authors could have provided more insight into the underlying mechanisms driving the improvements in model performance, making it harder to replicate their results.\n\nSuggestions for Improvement:\n1. Conduct additional experiments to explore the method's effectiveness on a broader range of domains and data types.\n2. Investigate potential limitations and challenges associated with the approach, such as overfitting or data requirements.\n3. Consider using more comprehensive evaluation metrics to better capture the nuances of the tasks.\n4. Provide more insight into the underlying mechanisms driving the improvements in model performance, enabling more informed replication of the results.\n\nRecommendation:\nBased on the strengths and weaknesses of the paper, I recommend acceptance with minor revisions. The authors have made a significant contribution to the field by proposing a novel approach to adapt LLMs to specific domains, and their results demonstrate its effectiveness. By addressing the limitations and challenges associated with their approach, the authors can further strengthen their findings and provide more insight into the underlying mechanisms driving the improvements in model performance.",
        "peer_review_with_watermark": "$$$Peer Review: \n\nPaper Summary:\nThe paper explores the concept of adapting large language models via continued pre-training on domain-specific corpora. The authors investigate the effects of continued pre-training on domain-specific corpora on the performance of large language models. They propose a simple method to transform domain-specific raw corpora into reading comprehension texts, enabling the model to acquire domain knowledge from raw texts and enhance prompting ability through comprehension tasks. The proposed method is tested on three different domains (biomedicine, finance, and law) and demonstrates consistent improvements in performance across various tasks.\n\nStrengths:\n1. The paper presents a clear and concise methodology for adapting large language models via continued pre-training on domain-specific corpora.\n2. The authors provide a thorough analysis of the effects of continued pre-training on domain-specific corpora on the performance of large language models.\n3. The proposed method is simple and scalable, and the results demonstrate its effectiveness in improving performance across various tasks.\n4. The paper provides a comprehensive analysis of the strengths and limitations of the proposed method.\n\nWeaknesses:\n1. The paper could benefit from a more detailed discussion of the limitations of the proposed method, including potential issues with overfitting and the need for additional evaluation metrics.\n2. The authors could have explored the relationship between the proposed method and other related approaches, such as instruction fine-tuning and retrieval-augmented prompting.\n3. The paper assumes a certain level of prior knowledge about large language models and domain-specific corpora, which may limit its accessibility to non-experts.\n4. The results could be improved by including more detailed analysis of the data and more comprehensive evaluation of the proposed method.\n\nSuggestions for Improvement:\n1. The authors should provide a more detailed discussion of the limitations of the proposed method and explore potential issues with overfitting.\n2. The authors could explore the relationship between the proposed method and other related approaches, such as instruction fine-tuning and retrieval-augmented prompting.\n3. The authors should provide more detailed analysis of the data and more comprehensive evaluation of the proposed method.\n4. The authors could consider including additional evaluation metrics, such as robustness and interpretability, to provide a more comprehensive assessment of the proposed method.\n\nRecommendation:\nThe proposed method for adapting large language models via continued pre-training on domain-specific corpora demonstrates consistent improvements in performance across various tasks. While the paper presents some limitations and areas for improvement, the results suggest that the proposed method is a promising approach for adapting large language models. With further refinement and evaluation, the proposed method has the potential to improve performance across a wide range of tasks and domains.",
        "gr_score_with": 0.875,
        "gr_score_without": 0.7679083094555874,
        "output_without": {
            "num_tokens_scored": 349,
            "num_green_tokens": 268,
            "green_fraction": 0.7679083094555874,
            "z_score": 2.768381798346518,
            "p_value": 0.002816770831977024
        },
        "output_with": {
            "num_tokens_scored": 312,
            "num_green_tokens": 273,
            "green_fraction": 0.875,
            "z_score": 6.7453687816160235,
            "p_value": 7.631941455421505e-12
        }
    },
    {
        "title": "STEVE-EYE: EQUIPPING LLM-BASED EMBOD-",
        "abstract": "Recent studies have presented compelling evidence that large language models (LLMs) can equip embodied agents with the self-driven capability to interact with the world, which marks an initial step toward versatile robotics. However, these efforts tend to overlook the visual richness of open worlds, rendering the entire interactive process akin to \u201ca blindfolded text-based game.\u201d Consequently, LLMbased agents frequently encounter challenges in intuitively comprehending their surroundings and producing responses that are easy to understand. In this paper, we propose Steve-Eye, an end-to-end trained large multimodal model to address this limitation. Steve-Eye integrates the LLM with a visual encoder to process visual-text inputs and generate multimodal feedback. We adopt a semi-automatic strategy to collect an extensive dataset comprising 850K open-world instruction pairs, enabling our model to encompass three essential functions for an agent: multimodal perception, foundational knowledge base, and skill prediction and planning. Lastly, we develop three open-world evaluation benchmarks, then carry out experiments from a wide range of perspectives to validate our model\u2019s capability to strategically act and plan. Codes and datasets will be released.",
        "peer_review_without_watermark": "$$\n\n$$$Paper Summary:\nThe paper proposes Steve-Eye, a large multimodal model that enables LLM-based embodied agents to interact with open-world environments via visual-text interfaces. Steve-Eye combines a visual encoder with a pre-trained LLM to process visual-text inputs and generate multimodal feedback. The model is trained on an extensive dataset of 850K open-world instruction pairs, which includes multimodal perception, foundational knowledge base, and skill prediction and planning functions. The paper evaluates Steve-Eye on three open-world benchmarks, including environmental visual captioning, foundational knowledge question answering, and skill prediction and planning.\n\nStrengths:\n1. The paper proposes a novel approach to enabling LLM-based embodied agents to interact with open-world environments.\n2. The use of multimodal perception, foundational knowledge base, and skill prediction and planning functions enhances the agent's ability to understand and respond to its environment.\n3. The extensive dataset of 850K open-world instruction pairs provides a comprehensive training ground for Steve-Eye.\n4. The paper evaluates Steve-Eye on three open-world benchmarks, providing a comprehensive assessment of the model's capabilities.\n\nWeaknesses:\n1. The paper relies heavily on the availability of pre-trained LLMs and visual encoders, which may limit the model's ability to generalize to new environments.\n2. The training process may be computationally expensive due to the large size of the dataset and the complexity of the model.\n3. The paper does not provide a detailed analysis of the model's performance on edge cases or adversarial examples.\n4. The evaluation benchmarks may not be comprehensive, and further evaluation may be necessary to fully assess Steve-Eye's capabilities.\n\nSuggestions for Improvement:\n1. To improve the model's generalizability, consider using transfer learning or fine-tuning pre-trained models on new datasets.\n2. To reduce computational costs, consider using more efficient training algorithms or model architectures.\n3. To improve the model's robustness, consider evaluating Steve-Eye on edge cases and adversarial examples.\n4. To further evaluate the model's capabilities, consider using additional benchmarks or evaluating Steve-Eye on more complex tasks.\n\nRecommendation:\nThe paper proposes a novel approach to enabling LLM-based embodied agents to interact with open-world environments, and the evaluation on three open-world benchmarks provides a comprehensive assessment of Steve-Eye's capabilities. However, further evaluation and improvement are necessary to fully assess the model's capabilities and generalizability.\n\n$$\n\n$$$",
        "peer_review_with_watermark": "$$\n\nPaper Summary:\nThe paper proposes Steve-Eye, a large multimodal model that combines a pre-trained language model with a visual encoder to enable embodied agents to interact with open-world environments via visual-text interfaces. Steve-Eye is trained on an extensive dataset of 850K instruction pairs, which includes multimodal perception instructions, foundational knowledge instructions, and skill-related interaction instructions. The paper evaluates Steve-Eye on three open-world benchmarks: environmental visual captioning, foundational knowledge question answering, and skill prediction and planning. Results show that Steve-Eye outperforms text-only language models and baseline approaches on all three benchmarks.\n\nStrengths:\n1. The paper proposes a novel approach to enabling large multimodal models to serve as generative embodied agents in open worlds.\n2. The use of ChatGPT to curate questions and generate instruction-following data is an innovative approach.\n3. The paper evaluates Steve-Eye on three open-world benchmarks, demonstrating its capabilities on a wide range of tasks.\n4. The authors provide detailed explanations of the model architecture, training procedure, and experimental results, making the paper well-structured and easy to follow.\n\nWeaknesses:\n1. The paper does not provide a detailed analysis of the strengths and limitations of the proposed approach compared to existing methods.\n2. The authors assume that the reader is familiar with the concepts of large multimodal models, embodied agents, and open-world environments, which may not be the case.\n3. The paper does not discuss potential applications or future work on Steve-Eye, which may be of interest to readers.\n4. The experimental results are not fully explained, and some figures and tables are not provided, making it difficult to fully understand the results.\n\nSuggestions for Improvement:\n1. Provide a more detailed analysis of the strengths and limitations of the proposed approach compared to existing methods.\n2. Include more detailed explanations of the experimental results, including figures and tables.\n3. Discuss potential applications and future work on Steve-Eye.\n4. Consider adding more context or background information on large multimodal models, embodied agents, and open-world environments to make the paper more accessible to a wider audience.\n\nRecommendation:\nThe paper proposes a novel approach to enabling large multimodal models to serve as generative embodied agents in open worlds, and the results demonstrate its capabilities on a wide range of tasks. However, the paper could benefit from more detailed analysis, explanations, and discussion of potential applications and future work to make it more comprehensive and accessible to a wider audience.\n\n$$",
        "gr_score_with": 0.7947214076246334,
        "gr_score_without": 0.7012987012987013,
        "output_without": {
            "num_tokens_scored": 308,
            "num_green_tokens": 216,
            "green_fraction": 0.7012987012987013,
            "z_score": 0.04973647313020009,
            "p_value": 0.48016619552964995
        },
        "output_with": {
            "num_tokens_scored": 341,
            "num_green_tokens": 271,
            "green_fraction": 0.7947214076246334,
            "z_score": 3.8169430964205735,
            "p_value": 6.755765807823114e-05
        }
    },
    {
        "title": "ERROR-FREE DIFFERENTIABLE SWAP FUNCTIONS",
        "abstract": "Sorting is a fundamental operation of all computer systems, having been a longstanding significant research topic. Beyond the problem formulation of traditional sorting algorithms, we consider sorting problems for more abstract yet expressive inputs, e.g., multi-digit images and image fragments, through a neural sorting network. To learn a mapping from a high-dimensional input to an ordinal variable, the differentiability of sorting networks needs to be guaranteed. In this paper we define a softening error by a differentiable swap function, and develop an error-free swap function that holds a non-decreasing condition and differentiability. Furthermore, a permutation-equivariant Transformer network with multi-head attention is adopted to capture dependency between given inputs and also leverage its model capacity with self-attention. Experiments on diverse sorting benchmarks show that our methods perform better than or comparable to baseline methods.",
        "peer_review_without_watermark": "$$$\\boxed{\\text{Paper Summary:}}$\n\nThe paper proposes a novel approach to sorting problems by learning a neural sorting network with an error-free differentiable swap function. The authors define a softening error induced by a monotonic differentiable swap function and propose an error-free swap function to resolve the error accumulation problem. The proposed neural sorting network combines a permutation-equivariant Transformer architecture with multi-head attention and an error-free differentiable swap function. The authors demonstrate the effectiveness of their approach on diverse benchmarks, including multi-digit images and image fragments.\n\n$\\boxed{\\text{Strengths:}}$\n\n1. The paper introduces a novel approach to sorting problems by learning a neural sorting network with an error-free differentiable swap function.\n2. The authors provide a thorough theoretical analysis of the error accumulation problem and propose an error-free swap function to resolve it.\n3. The proposed neural sorting network combines a permutation-equivariant Transformer architecture with multi-head attention and an error-free differentiable swap function, demonstrating effective performance on diverse benchmarks.\n4. The paper provides detailed experimental results and analysis, demonstrating the effectiveness of the proposed approach.\n\n$\\boxed{\\text{Weaknesses:}}$\n\n1. The paper assumes that the input data has clear ordering information, which may not be the case in real-world scenarios.\n2. The proposed approach may not be effective for sorting ambiguous data that contains implicitly ordinal information.\n3. The paper does not provide a comprehensive comparison with other existing sorting algorithms.\n4. The experimental results may be biased due to the use of fixed random seeds.\n\n$\\boxed{\\text{Suggestions for Improvement:}}$\n\n1. The authors should provide a more comprehensive comparison with other existing sorting algorithms.\n2. The paper should discuss the potential limitations of the proposed approach and its applicability to real-world scenarios.\n3. The authors should provide more detailed experimental results and analysis to demonstrate the effectiveness of the proposed approach.\n4. The paper should discuss the potential negative societal impact of neural sorting networks and provide guidelines for responsible use.\n\n$\\boxed{\\text{Recommendation:}}$\n\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit their paper for publication. The authors should address the limitations and potential biases of the experimental results and provide a more comprehensive comparison with other existing sorting algorithms. Additionally, the authors should discuss the potential negative societal impact of neural sorting networks and provide guidelines for responsible use.",
        "peer_review_with_watermark": "$$$\\boxed{\\text{Paper Summary:}}$\nThe paper proposes a neural sorting network that can sort high-dimensional inputs with ordinal information using a differentiable swap function. The authors define a softening error, which measures the difference between the original and softened values, and propose an error-free DSF that resolves the error accumulation problem. The authors also propose a permutation-equivariant Transformer network with multi-head attention to capture the dependency between high-dimensional inputs.\n\n$\\boxed{\\text{Strengths:}}$\n1. The paper proposes a novel approach to sorting high-dimensional inputs with ordinal information using a differentiable swap function.\n2. The authors provide a theoretical analysis of the softening error and propose an error-free DSF that resolves the error accumulation problem.\n3. The authors propose a permutation-equivariant Transformer network with multi-head attention to capture the dependency between high-dimensional inputs.\n\n$\\boxed{\\text{Weaknesses:}}$\n1. The paper does not provide a comprehensive comparison with other sorting algorithms, which limits the applicability of the proposed approach.\n2. The authors assume that the inputs are high-dimensional, which may not be the case in all applications.\n3. The paper does not discuss the potential negative societal impact of using neural sorting networks to sort controversial high-dimensional data.\n\n$\\boxed{\\text{Suggestions for Improvement:}}$\n1. Provide a comprehensive comparison with other sorting algorithms to demonstrate the effectiveness of the proposed approach.\n2. Discuss the potential negative societal impact of using neural sorting networks to sort controversial high-dimensional data.\n3. Consider the case where the inputs are not high-dimensional and provide a general framework for sorting inputs with ordinal information.\n\n$\\boxed{\\text{Recommendation:}}$\nThe proposed neural sorting network with error-free DSF and permutation-equivariant Transformer network with multi-head attention is a promising approach for sorting high-dimensional inputs with ordinal information. However, further improvements are needed to demonstrate the effectiveness of the approach in a comprehensive comparison with other sorting algorithms and to discuss the potential negative societal impact of using neural sorting networks to sort controversial high-dimensional data.",
        "gr_score_with": 0.7747747747747747,
        "gr_score_without": 0.6617647058823529,
        "output_without": {
            "num_tokens_scored": 272,
            "num_green_tokens": 180,
            "green_fraction": 0.6617647058823529,
            "z_score": -1.3760659224649012,
            "p_value": 0.9155993876477284
        },
        "output_with": {
            "num_tokens_scored": 222,
            "num_green_tokens": 172,
            "green_fraction": 0.7747747747747747,
            "z_score": 2.431207089239402,
            "p_value": 0.007524305284225037
        }
    },
    {
        "title": "EFFECTIVELY LEVERAGING CAPACITY FOR IMPROVED DETERMINISTIC ROBUSTNESS CERTIFICATION",
        "abstract": "Recent studies have highlighted the potential of Lipschitz-based methods for training certifiably robust neural networks against adversarial attacks. A key challenge, supported both theoretically and empirically, is that robustness demands greater network capacity and more data than standard training. However, effectively adding capacity under stringent Lipschitz constraints has proven more difficult than it may seem, evident by the fact that state-of-the-art approach tend more towards underfitting than overfitting. Moreover, we posit that a lack of careful exploration of the design space for Lipshitz-based approaches has left potential performance gains on the table. In this work, we provide a more comprehensive evaluation to better uncover the potential of Lipschitz-based certification methods. Using a combination of novel techniques, design optimizations, and synthesis of prior work, we are able to significantly improve the state-of-the-art VRA for deterministic certification on a variety of benchmark datasets, and over a range of perturbation sizes. Of particular note, we discover that the addition of large \u201cCholesky-orthogonalized residual dense\u201d layers to the end of existing state-of-the-art Lipschitz-controlled ResNet architectures is especially effective for increasing network capacity and performance. Combined with filtered generative data augmentation, our final results further the state of the art deterministic VRA by up to 8.5 percentage points.",
        "peer_review_without_watermark": "$$$\\boxed{Peer Review}$$\n\n$\\boxed{Paper Summary:}$\n\nThe paper proposes a method to effectively leverage capacity for improved deterministic robustness certification of neural networks. The authors aim to bridge the gap between Lipschitz-based methods and Randomized Smoothing (RS) based methods by improving the capacity of Lipschitz-based models. They propose a combination of dense layers and convolutions to expand the model's capacity, and introduce the Cholesky Residual Layer as an efficient building block for achieving orthogonal weights. Additionally, they explore an improved pipeline for utilizing generated data to enhance Lipschitz-based training. The paper presents extensive experiments on CIFAR-10/100 datasets and Tiny-ImageNet, achieving significant improvements in deterministic certified accuracy.\n\n$\\boxed{Strengths:}$\n\n1. The paper addresses a significant challenge in Lipschitz-based models, which is their limited capacity, and proposes three solutions to mitigate this issue.\n2. The authors provide a comprehensive evaluation of the proposed method, exploring the design space of Lipschitz-based certification methods.\n3. The paper presents extensive experiments on CIFAR-10/100 datasets and Tiny-ImageNet, achieving significant improvements in deterministic certified accuracy.\n4. The authors introduce the Cholesky Residual Layer, which serves as an efficient building block for achieving orthogonal weights.\n\n$\\boxed{Weaknesses:}$\n\n1. The paper may be too focused on improving the capacity of Lipschitz-based models, without considering other approaches to robustness certification.\n2. The authors may have relied too heavily on empirical evaluation, without providing a more rigorous theoretical analysis of the proposed method.\n3. The paper may not have fully explored the limitations of the proposed method, such as the potential for overfitting or underfitting.\n4. The authors may have not provided enough context for the reader to understand the significance of the proposed method, particularly for those without a strong background in machine learning or robustness certification.\n\n$\\boxed{Suggestions for Improvement:}$\n\n1. The authors should consider exploring other approaches to robustness certification, such as RS-based methods or other Lipschitz-based methods.\n2. The authors should provide a more rigorous theoretical analysis of the proposed method, including proof of convergence and analysis of the Lipschitz constant.\n3. The authors should provide more context for the reader to understand the significance of the proposed method, particularly for those without a strong background in machine learning or robustness certification.\n4. The authors should fully explore the limitations of the proposed method, such as the potential for overfitting or underfitting.\n\n$\\boxed{Recommendation:}$\n\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit the paper to the conference. The authors have made significant contributions to the field of robustness certification, and their proposed method has the potential to improve the capacity of Lipschitz-based models. However, the authors should address the weaknesses mentioned above to strengthen the paper and increase its impact on the field.",
        "peer_review_with_watermark": "$$$\n\n\nPaper Summary:\nThe paper presents an evaluation and optimization of Lipschitz-based methods for deterministic robustness certification in neural networks. The authors propose novel techniques, design optimizations, and synthesis of prior work to improve the state-of-the-art in deterministic VRA. They also explore additional architecture features, such as attention-like mechanisms and orthogonalized dense layers, to increase model capacity. The results demonstrate significant improvements in deterministic VRA, with some models outperforming state-of-the-art methods by up to 8.5 percentage points.\n\n\nStrengths:\n1. The authors provide a thorough evaluation of Lipschitz-based methods, exploring additional architecture features and optimization techniques to improve deterministic VRA.\n2. The proposed Cholesky-orthogonalized residual dense layers are an efficient and effective way to increase model capacity.\n3. The authors demonstrate the effectiveness of using generated data augmentation to enhance Lipschitz-based training.\n4. The results push the boundaries of deterministic certified accuracy, surpassing the state-of-the-art by up to 8.5 percentage points.\n\n\nWeaknesses:\n1. The paper may benefit from further clarification on the theoretical foundations of Lipschitz-based methods, particularly in relation to their limitations and potential pitfalls.\n2. Some of the proposed architecture features, such as attention-like mechanisms, may not be suitable for Lipschitz-based training and should be further explored.\n3. The authors may want to consider exploring other optimization techniques, such as regularization methods, to further improve deterministic VRA.\n4. The results may be sensitive to specific hyperparameter settings and may not generalize well to other datasets or scenarios.\n\n\nSuggestions for Improvement:\n1. Provide more theoretical justification for the proposed optimization techniques and architecture features.\n2. Conduct further experimentation to explore the limitations and potential pitfalls of Lipschitz-based methods.\n3. Consider exploring other optimization techniques, such as regularization methods, to further improve deterministic VRA.\n4. Provide more detailed explanations for the results and their implications for future research.\n\n\nRecommendation:\nThe paper presents an important contribution to the field of deterministic robustness certification in neural networks. The proposed techniques and architecture features demonstrate significant improvements in deterministic VRA, and the results push the boundaries of this field. However, further theoretical justification and experimentation are needed to fully establish the effectiveness and limitations of these methods. The authors should consider exploring other optimization techniques and exploring the potential pitfalls of Lipschitz-based methods to further strengthen their results.",
        "gr_score_with": 0.7949526813880127,
        "gr_score_without": 0.6978021978021978,
        "output_without": {
            "num_tokens_scored": 364,
            "num_green_tokens": 254,
            "green_fraction": 0.6978021978021978,
            "z_score": -0.09150180217433355,
            "p_value": 0.5364530628413283
        },
        "output_with": {
            "num_tokens_scored": 317,
            "num_green_tokens": 252,
            "green_fraction": 0.7949526813880127,
            "z_score": 3.689157672461538,
            "p_value": 0.00011249887580237473
        }
    },
    {
        "title": "CODINGS FOR GRAPHS",
        "abstract": "Designing effective positional encodings for graphs is key to building powerful graph transformers and enhancing message-passing graph neural networks. Although widespread, using Laplacian eigenvectors as positional encodings faces two fundamental challenges: (1) Non-uniqueness: there are many different eigendecompositions of the same Laplacian, and (2) Instability: small perturbations to the Laplacian could result in completely different eigenspaces, leading to unpredictable changes in positional encoding. Despite many attempts to address nonuniqueness, most methods overlook stability, leading to poor generalization on unseen graph structures. We identify the cause of instability to be a \u201chard partition\u201d of eigenspaces. Hence, we introduce Stable and Expressive Positional Encodings (SPE), an architecture for processing eigenvectors that uses eigenvalues to \u201csoftly partition\u201d eigenspaces. SPE is the first architecture that is (1) provably stable, and (2) universally expressive for basis invariant functions whilst respecting all symmetries of eigenvectors. Besides guaranteed stability, we prove that SPE is at least as expressive as existing methods, and highly capable of counting graph structures. Finally, we evaluate the effectiveness of our method on molecular property prediction, and out-of-distribution generalization tasks, finding improved generalization compared to existing positional encoding methods.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary:\nThe paper proposes a novel positional encoding method called Stable and Expressive Positional Encodings (SPE) for graphs. The method addresses the limitations of existing positional encodings, which are often unstable and lack expressivity. SPE is designed to be both stable and expressive, and it achieves this by performing a soft partitioning of eigenspaces using eigenvalues. The method is provably stable and can universally approximate basis invariant functions. The authors evaluate the effectiveness of SPE on several benchmark datasets and show that it outperforms existing positional encoding methods.\n\nStrengths:\n1. The paper proposes a novel and effective method for positional encoding in graphs.\n2. The method is provably stable and can universally approximate basis invariant functions.\n3. The authors evaluate the effectiveness of SPE on several benchmark datasets and show that it outperforms existing positional encoding methods.\n\nWeaknesses:\n1. The paper assumes that the reader is familiar with graph neural networks and positional encodings, which may not be the case for all readers.\n2. The explanation of the mathematical concepts used in the paper is sometimes unclear or lacking.\n3. The paper does not provide a detailed analysis of the hyperparameter tuning process for SPE.\n\nSuggestions for Improvement:\n1. The authors could provide a more detailed explanation of the mathematical concepts used in the paper, such as the definition of stability and the proof of the theorem.\n2. The authors could provide a more detailed analysis of the hyperparameter tuning process for SPE, including the evaluation of different hyperparameters and the selection of the best hyperparameters.\n3. The authors could provide more detailed results and analysis for the benchmark datasets, including the evaluation of different baseline methods and the comparison of SPE with other positional encoding methods.\n\nRecommendation:\nBased on the review, I recommend that the paper be accepted for publication in its current form. The authors have proposed a novel and effective method for positional encoding in graphs, and the paper provides a clear and concise explanation of the method and its evaluation. The authors have also addressed some of the limitations of existing positional encoding methods and have provided a detailed analysis of the results.\n\n$$\\begin{aligned}\n$$Paper Summary:\nThe paper proposes a novel positional encoding method called Stable and Expressive Positional Encodings (SPE) for graphs. The method addresses the limitations of existing positional encodings, which are often unstable and lack expressivity. SPE is designed to be both stable and expressive, and it achieves this by performing a soft partitioning of eigenspaces using eigenvalues. The method is provably stable and can universally approximate basis invariant functions. The authors evaluate the effectiveness of SPE on several benchmark datasets and show that it outperforms existing positional encoding methods.\n\nStrengths:\n1. The paper proposes a novel and effective method for positional encoding in graphs.\n2. The method is provably stable and can universally approximate basis invariant functions.\n3. The authors evaluate the effectiveness of SPE on several benchmark datasets and show that it outperforms existing positional encoding methods.\n\nWeaknesses:\n1. The paper assumes that the reader is familiar with graph neural networks and positional encodings, which may not be the case for all readers.\n2. The explanation of the mathematical concepts used in the paper is sometimes unclear or lacking.\n3. The paper does not provide a detailed analysis of the hyperparameter tuning process for SPE.\n\nSuggestions for Improvement:\n1. The authors could provide a more detailed explanation of the mathematical concepts used in the paper, such as the definition of stability and the proof of the theorem.\n2. The authors could provide a more detailed analysis of the hyperparameter tuning process for SPE, including the evaluation of different hyperparameters and the selection of the best hyperparameters.\n3. The authors could provide more detailed results and analysis for the benchmark datasets, including the evaluation of different baseline methods and the comparison of SPE with other positional encoding methods.\n\nRecommendation:\nBased on the review, I recommend that the paper be accepted for publication in its current form. The authors have proposed a novel and effective method for positional encoding in graphs, and the paper provides a clear and concise explanation of the method and its evaluation. The authors have also addressed some of the limitations of existing positional encoding methods and have provided a detailed analysis of the results.\n\n$$\\begin{aligned}\n$$Paper Summary:\nThe paper proposes a novel positional encoding method called Stable and Expressive Positional Encodings (SPE) for graphs. The method addresses the limitations of existing positional encodings, which are often unstable and lack expressivity. SPE is designed to be both stable and expressive, and it achieves this by performing a soft partitioning of eigenspaces using eigenvalues. The method is provably stable and can universally approximate basis invariant functions. The authors evaluate the effectiveness of SPE on several benchmark datasets and show that it outperforms existing positional encoding methods.\n\nStrengths:\n1. The paper proposes a novel and effective method for positional encoding in graphs.\n2. The method is provably stable and can universally approximate basis invariant functions.\n3. The authors evaluate the effectiveness of SPE on several benchmark datasets and show that it outperforms existing positional encoding methods.\n\nWeaknesses:\n1. The paper assumes that the reader is familiar with graph neural networks and positional encodings, which may not be the case for all readers.\n2. The explanation of the mathematical concepts used in the paper is sometimes unclear or lacking.\n3. The paper does not provide a detailed analysis of the hyperparameter tuning process for SPE.\n\nSuggestions for Improvement:\n1. The authors could provide a more detailed explanation of the mathematical concepts used in the paper, such as the definition of stability and the proof of the theorem.\n2. The authors could provide a more detailed analysis of the hyperparameter tuning process for SPE, including the evaluation of different hyperparameters and the selection of the best hyperparameters.\n3. The authors could provide more detailed results and analysis for the benchmark datasets, including the evaluation of different baseline methods and the comparison of SPE with other positional encoding methods.\n\nRecommendation:\nBased on the review, I recommend that the paper be accepted for publication in its current form. The authors have proposed a novel and effective method for positional encoding in graphs, and the paper provides a clear and concise explanation of the method and its evaluation. The authors have also addressed some of the limitations of existing positional encoding methods and have provided a detailed analysis of the results.",
        "peer_review_with_watermark": "$$$$\n\nPaper Summary:\nThe paper proposes a new positional encoding method, Stable and Expressive Positional Encodings (SPE), for graphs. SPE is a learnable Laplacian positional encoding that is both provably stable and expressive. The authors show that SPE is stable with respect to the input Laplacian, meaning that small perturbations to the input Laplacian result in a small change in the output. Additionally, the authors prove that SPE is universally expressive, meaning that it can express any continuous basis-invariant function. The authors evaluate the effectiveness of SPE on various molecular property prediction benchmarks and show that it outperforms existing methods.\n\nStrengths:\n1. The authors provide a thorough analysis of the stability and expressivity of the proposed method, SPE.\n2. The authors show that SPE is both stable with respect to the input Laplacian and universally expressive.\n3. The authors evaluate the effectiveness of SPE on various molecular property prediction benchmarks and show that it outperforms existing methods.\n\nWeaknesses:\n1. The authors rely heavily on mathematical derivations and proofs, which may be difficult to follow for non-experts.\n2. The authors do not provide a comprehensive comparison of their method with other existing methods, such as SignNet and BasisNet.\n3. The authors' experimental results are limited to a few molecular property prediction benchmarks, which may not be representative of the broader applicability of the proposed method.\n\nSuggestions for Improvement:\n1. The authors should provide a more comprehensive comparison of their method with other existing methods, including SignNet, BasisNet, and others.\n2. The authors should provide more experimental results on a wider range of molecular property prediction benchmarks to demonstrate the broader applicability of the proposed method.\n3. The authors should consider providing more details on the theoretical foundations of the proposed method, such as the mathematical derivations and proofs, to make the paper more accessible to a broader audience.\n\nRecommendation:\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise the paper to address the weaknesses and provide more comprehensive evidence for the effectiveness of the proposed method. The authors should also consider providing more details on the theoretical foundations of the proposed method to make the paper more accessible to a broader audience. Overall, the paper presents an interesting and innovative approach to positional encoding for graphs, and with revisions, it has the potential to be a significant contribution to the field.",
        "gr_score_with": 0.7055016181229773,
        "gr_score_without": 0.6325088339222615,
        "output_without": {
            "num_tokens_scored": 283,
            "num_green_tokens": 179,
            "green_fraction": 0.6325088339222615,
            "z_score": -2.477596062319861,
            "p_value": 0.9933864601351009
        },
        "output_with": {
            "num_tokens_scored": 309,
            "num_green_tokens": 218,
            "green_fraction": 0.7055016181229773,
            "z_score": 0.21103769477176207,
            "p_value": 0.4164289287536754
        }
    },
    {
        "title": "GEOLLM: EXTRACTING GEOSPATIAL KNOWLEDGE FROM LARGE LANGUAGE MODELS",
        "abstract": "The application of machine learning (ML) in a range of geospatial tasks is increasingly common but often relies on globally available covariates such as satellite imagery that can either be expensive or lack predictive power. Here we explore the question of whether the vast amounts of knowledge found in Internet language corpora, now compressed within large language models (LLMs), can be leveraged for geospatial prediction tasks. We first demonstrate that LLMs embed remarkable spatial information about locations, but naively querying LLMs using geographic coordinates alone is ineffective in predicting key indicators like population density. We then present GeoLLM, a novel method that can effectively extract geospatial knowledge from LLMs with auxiliary map data from OpenStreetMap. We demonstrate the utility of our approach across multiple tasks of central interest to the international community, including the measurement of population density and economic livelihoods. Across these tasks, our method demonstrates a 70% improvement in performance (measured using Pearson\u2019s r) relative to baselines that use nearest neighbors or use information directly from the prompt, and performance equal to or exceeding satellite-based benchmarks in the literature. With GeoLLM, we observe that GPT-3.5 outperforms Llama 2 and RoBERTa by 19% and 51% respectively, suggesting that the performance of our method scales well with the size of the model and its pretraining dataset. Our experiments reveal that LLMs are remarkably sample-efficient, rich in geospatial information, and robust across the globe. Crucially, GeoLLM shows promise in mitigating the limitations of existing geospatial covariates and complementing them well. Code is available on the project website: https://rohinmanvi.github.io/GeoLLM",
        "peer_review_without_watermark": "$$$ \n\nPaper Summary:\nThe paper proposes a novel method called GeoLLM that extracts geospatial knowledge from large language models (LLMs) by fine-tuning them on prompts constructed with auxiliary map data from OpenStreetMap. The authors demonstrate the utility of their approach across multiple tasks, including population density and economic livelihoods, and show that GeoLLM outperforms traditional baselines, including k-NN and XGBoost, and even satellite-based methods. The method is found to be sample-efficient, rich in geospatial information, and robust across the globe.\n\nStrengths:\n1. The authors demonstrate a clear understanding of the limitations of traditional geospatial covariates and the potential of LLMs to extract geospatial knowledge.\n2. The proposed method, GeoLLM, is novel and innovative, and the authors provide a thorough evaluation of its performance across multiple tasks.\n3. The authors provide a comprehensive comparison with traditional baselines, including k-NN and XGBoost, and satellite-based methods.\n4. The method is found to be sample-efficient, rich in geospatial information, and robust across the globe.\n\nWeaknesses:\n1. The authors do not provide a thorough discussion of the potential biases of LLMs that they inherit from their training corpora.\n2. The authors mention that the performance of the method scales with the size of the model and its pretraining dataset, but do not provide a detailed analysis of this aspect.\n3. The authors do not provide a thorough evaluation of the robustness of the method across different geographies and datasets.\n\nSuggestions for Improvement:\n1. The authors should provide a more detailed discussion of the potential biases of LLMs that they inherit from their training corpora.\n2. The authors should provide a more detailed analysis of the performance of the method across different geographies and datasets.\n3. The authors should consider exploring the use of multimodal LLMs to leverage satellite imagery or street view images.\n\nRecommendation:\nThe paper presents a novel and innovative approach to extracting geospatial knowledge from LLMs, and the authors provide a thorough evaluation of its performance across multiple tasks. While there are some limitations and areas for improvement, the paper makes a significant contribution to the field of geospatial prediction tasks and demonstrates the potential of LLMs to extract geospatial knowledge. The authors should continue to refine and expand their method to address the limitations and explore new applications. \n\nOverall, the paper is well-written, and the authors provide a clear and concise summary of their work. The evaluation of the method is thorough, and the authors provide a comprehensive comparison with traditional baselines. The paper is suitable for submission to a conference or journal in the field of geospatial prediction tasks or natural language processing.",
        "peer_review_with_watermark": "$$$ \n\nPaper Summary:\nThe paper proposes the concept of extracting geospatial knowledge from large language models (LLMs) by fine-tuning them on prompts constructed with auxiliary map data from OpenStreetMap. The authors demonstrate that this approach can improve the performance of LLMs on various geospatial tasks, including population density and economic livelihoods, and show that the method can outperform traditional baselines, including k-NN and XGBoost.\n\nStrengths:\n1. The authors provide a clear and concise introduction to the problem of geospatial predictions with ML and highlight the limitations of traditional covariates.\n2. The proposed method of fine-tuning LLMs on prompts with map data is innovative and effective, demonstrating significant improvements in performance on various geospatial tasks.\n3. The authors provide a comprehensive experimental setup, including multiple tasks and datasets, and demonstrate the scalability of the method with different model sizes and pretraining datasets.\n4. The paper highlights the potential of using LLMs for geospatial tasks and provides a foundation for future research.\n\nWeaknesses:\n1. The paper relies heavily on the authors' proposed method, which may not be applicable to other domains or tasks.\n2. The experimental setup is extensive, but some of the baselines, such as the k-NN and XGBoost, are not thoroughly explained or justified.\n3. The paper does not provide a detailed analysis of the limitations and biases of the proposed method, which is essential for its adoption and widespread use.\n\nSuggestions for Improvement:\n1. The authors should provide more detailed explanations and justifications for the baselines, including k-NN and XGBoost, to ensure that the experimental setup is comprehensive and fair.\n2. A more detailed analysis of the limitations and biases of the proposed method is necessary to ensure that the method is reliable and trustworthy.\n3. The authors should consider exploring the applicability of the proposed method to other domains or tasks, which would demonstrate its broader potential and impact.\n\nRecommendation:\nBased on the paper's strengths and weaknesses, I recommend that the authors revise and resubmit the paper with the suggested improvements. The proposed method has the potential to revolutionize geospatial predictions with ML, and with further refinement and validation, it can be a game-changer in the field.",
        "gr_score_with": 0.8303571428571429,
        "gr_score_without": 0.7784431137724551,
        "output_without": {
            "num_tokens_scored": 334,
            "num_green_tokens": 260,
            "green_fraction": 0.7784431137724551,
            "z_score": 3.1283721469330206,
            "p_value": 0.000878887330773809
        },
        "output_with": {
            "num_tokens_scored": 336,
            "num_green_tokens": 279,
            "green_fraction": 0.8303571428571429,
            "z_score": 5.214285714285715,
            "p_value": 9.226343579359958e-08
        }
    },
    {
        "title": "LEARNING THE GREATEST COMMON DIVISOR: EXPLAINING TRANSFORMER PREDICTIONS",
        "abstract": "The predictions of small transformers, trained to calculate the greatest common divisor (GCD) of two positive integers, can be fully characterized by looking at model inputs and outputs. As training proceeds, the model learns a listD of integers, products of divisors of the base used to represent integers and small primes, and predicts the largest element of D that divides both inputs. Training distributions impact performance. Models trained from uniform operands only learn a handful of GCD (up to 38 GCD \u2264 100). Log-uniform operands boost performance to 73 GCD \u2264 100, and a log-uniform distribution of outcomes (i.e. GCD) to 91. However, training from uniform (balanced) GCD breaks explainability.",
        "peer_review_without_watermark": "$$\n\nPaper Title: LEARNING THE GREATEST COMMON DIVISOR: EXPLAINING TRANSFORMER PREDICTIONS\n\nPaper Summary:\nThis paper investigates the ability of transformers to learn the greatest common divisor (GCD) of two positive integers. The authors train 4-layer transformers to compute GCD and observe that the model learns to cluster input pairs with the same GCD, predicts the largest element in a set of integers that divides both inputs, and learns products of divisors of the base used to represent integers. The authors also explore the impact of training distributions on performance and demonstrate that models trained from log-uniform operands and outcomes achieve better performance and remain fully explainable.\n\nStrengths:\n1. The paper presents a novel approach to model explainability, fully characterizing black-box model predictions by experimenting with selected inputs and leveraging theoretical understanding of the underlying mathematics.\n2. The authors demonstrate that transformers can learn advanced calculations, such as GCD, and explore the broader potential impact of this research.\n3. The paper presents a detailed analysis of the learning process and the role of the distribution of outcomes, shedding light on the learning process and the behavior of the model.\n\nWeaknesses:\n1. The paper relies heavily on the authors' own implementation and may not be reproducible by others.\n2. Some of the results, such as the impact of training distributions on performance, may be specific to the authors' experimental setup and may not generalize to other settings.\n3. The paper does not provide a comprehensive comparison with other models or approaches for GCD calculation.\n\nSuggestions for Improvement:\n1. The authors should provide more detailed explanations of the theoretical background and mathematical derivations that support their claims.\n2. The authors should explore the generalizability of their results to other arithmetic tasks and provide more comprehensive comparisons with other models or approaches.\n3. The authors should consider using more robust evaluation metrics that capture the nuances of GCD calculation and model explainability.\n\nRecommendation:\nOverall, the paper presents a novel and interesting approach to model explainability and GCD calculation using transformers. While there are some limitations and areas for improvement, the paper contributes to the ongoing research in this area and has the potential to inspire further investigation and development.\n\n$$",
        "peer_review_with_watermark": "$$$Abstract:\nThe paper presents the results of experiments with 4-layer transformers to compute the greatest common divisor (GCD) of two positive integers. The authors found that transformers can learn to cluster input pairs with the same GCD, and that the model learns a set of integers D, and predicts, for any input pair (a, b), the largest element in D that divides a and b. The authors also found that models trained from log-uniform operands and outcomes achieve better performance, and that an unbalanced distribution of outcomes is required for full explainability. The results demonstrate how transformers can be trained to perform exact calculations involving integer divisibility, and the broader potential impact of this research extends in three directions.\n\nStrengths:\n- The paper presents a clear and well-structured research question and hypothesis.\n- The experiments are well-designed and well-executed, with multiple variations and control groups.\n- The results are well-analyzed and interpreted, with clear conclusions and implications.\n- The paper provides a good balance of theory and practice, with a clear understanding of the mathematical underpinnings of the problem.\n\nWeaknesses:\n- The paper may benefit from more detailed explanations of the mathematical concepts and techniques used in the experiments.\n- Some of the results may require more attention to the limitations of the experiments and the potential biases in the data.\n- The paper may benefit from more discussion of the broader implications and potential applications of the research.\n\nSuggestions for Improvement:\n- Provide more detailed explanations of the mathematical concepts and techniques used in the experiments.\n- Consider including more attention to the limitations of the experiments and the potential biases in the data.\n- Discuss the broader implications and potential applications of the research in more detail.\n\nRecommendation:\nI recommend that the paper be accepted for publication in its current form. The research is well-designed and well-executed, and the results are clear and well-analyzed. The paper provides a good balance of theory and practice, and the conclusions and implications are well-supported by the data. With some minor revisions to address the suggestions above, the paper is likely to make a significant contribution to the field of machine learning and natural language processing. \n\nAlso, it is worth noting that the research is quite original and the results are quite impressive, it can be said that this research is one of the best in the field of transformer models and their capabilities.",
        "gr_score_with": 0.8709677419354839,
        "gr_score_without": 0.7647058823529411,
        "output_without": {
            "num_tokens_scored": 357,
            "num_green_tokens": 273,
            "green_fraction": 0.7647058823529411,
            "z_score": 2.667891875399665,
            "p_value": 0.0038164408938961194
        },
        "output_with": {
            "num_tokens_scored": 341,
            "num_green_tokens": 297,
            "green_fraction": 0.8709677419354839,
            "z_score": 6.889405031619796,
            "p_value": 2.8013105914234043e-12
        }
    },
    {
        "title": "EX-GRAPH: A PIONEERING DATASET BRIDGING ETHEREUM",
        "abstract": "While numerous public blockchain datasets are available, their utility is constrained by an exclusive focus on blockchain data. This constraint limits the incorporation of relevant social network data into blockchain analysis, thereby diminishing the breadth and depth of insight that can be derived. To address the above limitation, we introduce EX-Graph, a novel dataset that authentically links Ethereum and X, marking the first and largest dataset of its kind. EX-Graph combines Ethereum transaction records (2 million nodes and 30 million edges) and X following data (1 million nodes and 3 million edges), bonding 30,667 Ethereum addresses with verified X accounts sourced from OpenSea. Detailed statistical analysis on EXGraph highlights the structural differences between X-matched and non-X-matched Ethereum addresses. Extensive experiments, including Ethereum link prediction, wash-trading Ethereum addresses detection, and X-Ethereum matching link prediction, emphasize the significant role of X data in enhancing Ethereum analysis. EX-Graph is available at https://exgraph.deno.dev/.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces EX-Graph, a pioneering dataset that bridges Ethereum and X, combining Ethereum transaction records and X follower networks. The dataset consists of 3 million nodes, 33 million edges, and 30,667 matching links between Ethereum addresses and X accounts. The authors conduct statistical analysis and experiments to evaluate the performance of various tasks on EX-Graph, including Ethereum link prediction, wash-trading addresses detection, and matching link prediction. The results show that integrating X data significantly improves the performance of these tasks, particularly in detecting wash-trading addresses.\n\nStrengths:\n1. The paper presents a novel and extensive dataset that bridges on-chain and off-chain worlds, providing a unique opportunity for researchers to study the interplay between these two domains.\n2. The authors conduct thorough statistical analysis and experiments to evaluate the performance of various tasks on EX-Graph, providing a comprehensive understanding of the dataset's capabilities.\n3. The paper highlights the potential of integrating off-chain data to enhance the analysis of on-chain activities, which is a significant contribution to the field of blockchain research.\n\nWeaknesses:\n1. The dataset's size and scope may limit its applicability to certain research scenarios, and the authors acknowledge the need for further enhancements, such as collecting more matching links between on-chain and off-chain graphs.\n2. The paper's focus on Ethereum and X may limit its relevance to other blockchain platforms and datasets.\n3. The authors do not provide a detailed comparison with existing datasets, which may limit the paper's impact and generalizability.\n\nSuggestions for Improvement:\n1. The authors could explore the applicability of EX-Graph to other blockchain platforms and datasets, and provide a more detailed comparison with existing datasets.\n2. The authors could investigate the potential of incorporating additional features, such as sentiment analysis or topic modeling, to further enhance the analysis of on-chain and off-chain activities.\n3. The authors could provide a more detailed explanation of the data collection process and the methodology used to construct the EX-Graph, which may be of interest to readers who want to replicate the results.\n\nRecommendation:\nThe paper presents a significant contribution to the field of blockchain research, providing a novel and extensive dataset that bridges on-chain and off-chain worlds. While there are some limitations and areas for improvement, the paper's findings and recommendations are well-supported by the experimental results, and the authors demonstrate a clear understanding of the dataset's capabilities and limitations. Overall, I recommend the paper for publication in a reputable conference or journal in the field of blockchain research.",
        "peer_review_with_watermark": "$$$Paper Summary:\n\nThe paper introduces EX-Graph, a pioneering dataset that bridges Ethereum and X by linking Ethereum addresses with their corresponding X accounts. EX-Graph is created by integrating Ethereum transaction records and X following data, resulting in a comprehensive dataset that includes 2 million Ethereum addresses, 3 million X accounts, and 30,667 matching links between Ethereum addresses and their corresponding X accounts. The authors demonstrate the value of EX-Graph by performing statistical and empirical analyses on the dataset and exploring its applications in various tasks such as Ethereum link prediction, wash-trading addresses detection, and matching link prediction.\n\nStrengths:\n\n* EX-Graph is a comprehensive and extensive dataset that bridges Ethereum and X.\n* The authors demonstrate the value of EX-Graph by performing thorough statistical and empirical analyses on the dataset.\n* The paper provides a thorough review of existing datasets on Ethereum and X.\n* The authors propose a novel approach to enhancing Ethereum analysis by integrating off-chain social network data.\n\nWeaknesses:\n\n* The paper lacks a clear and concise introduction to the paper.\n* Some sections of the paper are overly lengthy and lack clear headings.\n* The authors do not provide enough details on the experimental setup and evaluation metrics used in their analyses.\n* The paper could benefit from more robust and comprehensive analysis of the limitations and challenges of the proposed dataset and methods.\n\nSuggestions for Improvement:\n\n* Provide a clear and concise introduction to the paper that highlights the significance and contributions of EX-Graph.\n* Break up lengthy sections into smaller, more manageable subsections with clear headings.\n* Provide detailed information on the experimental setup and evaluation metrics used in the analyses.\n* Include a thorough analysis of the limitations and challenges of the proposed dataset and methods.\n* Consider adding more visualizations and figures to the paper to help illustrate the findings and results.\n\nRecommendation:\n\nThe paper introduces EX-Graph, a pioneering dataset that bridges Ethereum and X. While the paper has several strengths, including its comprehensive and extensive nature, thorough statistical and empirical analyses, and novel approach to enhancing Ethereum analysis, it also has several weaknesses, including lack of clarity in the introduction, overly lengthy sections, and lack of detail on experimental setup and evaluation metrics. To improve the paper, the authors should provide a clear and concise introduction, break up lengthy sections into smaller subsections, provide detailed information on experimental setup and evaluation metrics, and include a thorough analysis of limitations and challenges. With these improvements, the paper has the potential to be a valuable contribution to the field of Ethereum analysis and graph learning.",
        "gr_score_with": 0.7492447129909365,
        "gr_score_without": 0.6455331412103746,
        "output_without": {
            "num_tokens_scored": 347,
            "num_green_tokens": 224,
            "green_fraction": 0.6455331412103746,
            "z_score": -2.214049974834866,
            "p_value": 0.9865873293352435
        },
        "output_with": {
            "num_tokens_scored": 331,
            "num_green_tokens": 248,
            "green_fraction": 0.7492447129909365,
            "z_score": 1.9550774211344784,
            "p_value": 0.02528696641519336
        }
    },
    {
        "title": "LUM-VIT: LEARNABLE UNDER-SAMPLING MASK VISION TRANSFORMER FOR BANDWIDTH LIMITED OPTICAL SIGNAL ACQUISITION",
        "abstract": "Bandwidth constraints during signal acquisition frequently impede real-time detection applications. Hyperspectral data is a notable example, whose vast volume compromises real-time hyperspectral detection. To tackle this hurdle, we introduce a novel approach leveraging pre-acquisition modulation to reduce the acquisition volume. This modulation process is governed by a deep learning model, utilizing prior information. Central to our approach is LUM-ViT, a Vision Transformer variant. Uniquely, LUM-ViT incorporates a learnable under-sampling mask tailored for pre-acquisition modulation. To further optimize for optical calculations, we propose a kernel-level weight binarization technique and a threestage fine-tuning strategy. Our evaluations reveal that, by sampling a mere 10% of the original image pixels, LUM-ViT maintains the accuracy loss within 1.8% on the ImageNet classification task. The method sustains near-original accuracy when implemented on real-world optical hardware, demonstrating its practicality. Code will be available at https://github.com/MaxLLF/LUM-ViT.",
        "peer_review_without_watermark": "$$$\\boxed{Peer Review}$$\n\n$\\boxed{Paper Summary:}$\n\nThe paper proposes a novel approach called LUM-ViT, which leverages pre-acquisition modulation to reduce the acquisition volume of hyperspectral data. This is achieved by using a deep learning model, specifically a Vision Transformer variant, that incorporates a learnable under-sampling mask. The model is designed to work with a Digital Micromirror Device (DMD) signal acquisition system, which modulates the light spatially to reduce the acquisition volume. The authors demonstrate the effectiveness of LUM-ViT on the ImageNet-1k classification task and real-world experiments with a DMD signal acquisition system.\n\n$\\boxed{Strengths:}$\n\n1. The paper introduces a novel approach to under-sampling hyperspectral data acquisition using pre-acquisition modulation.\n2. The use of a learnable under-sampling mask allows for efficient data reduction while maintaining accuracy.\n3. The authors demonstrate the effectiveness of LUM-ViT on both the ImageNet-1k classification task and real-world experiments.\n4. The paper provides a detailed explanation of the DMD signal acquisition system and its integration with LUM-ViT.\n\n$\\boxed{Weaknesses:}$\n\n1. The paper assumes a high level of expertise in deep learning and signal processing, which may make it difficult for non-experts to follow.\n2. The authors do not provide a comprehensive comparison with existing state-of-the-art methods in hyperspectral image classification.\n3. The paper focuses primarily on the theoretical aspects of LUM-ViT and does not provide enough experimental results to validate its performance.\n4. The authors do not discuss potential limitations and challenges of using LUM-ViT in real-world applications.\n\n$\\boxed{Suggestions for Improvement:}$\n\n1. Provide a more detailed comparison with existing state-of-the-art methods in hyperspectral image classification.\n2. Include more experimental results to validate the performance of LUM-ViT on various datasets.\n3. Discuss potential limitations and challenges of using LUM-ViT in real-world applications.\n4. Provide more information on the theoretical aspects of the DMD signal acquisition system and its integration with LUM-ViT.\n\n$\\boxed{Recommendation:}$\n\nBased on the strengths and weaknesses of the paper, I recommend that it be accepted for publication in a reputable conference or journal in the field of hyperspectral image classification. However, I suggest that the authors address the weaknesses and suggestions for improvement to strengthen the paper and provide more value to the readers.",
        "peer_review_with_watermark": "$$$\\boxed{Peer Review}$$\n\n$\\boxed{Paper Summary:}$ \nThe paper proposes a novel approach called LUM-ViT, which integrates pre-acquisition modulation using a Digital Micromirror Device (DMD) and a learnable under-sampling mask. The learnable under-sampling mask allows the system to retain essential points from the patch-embedding outputs while bypassing less significant points, achieving undersampling. The system is evaluated on the ImageNet-1k classification task and achieves accuracy loss within 1.8% at 10% under-sampling and within 5.5% at an extreme 2% under-sampling. The real-world experiment demonstrates the practical feasibility of LUM-ViT, with accuracy loss not exceeding 4% compared to the software environment.\n\n$\\boxed{Strengths:}$ \n1. The paper proposes a novel approach that integrates pre-acquisition modulation using a DMD and a learnable under-sampling mask, which can significantly reduce the data volume overhead from the beginning.\n2. The system achieves accuracy loss within 1.8% at 10% under-sampling and within 5.5% at an extreme 2% under-sampling on the ImageNet-1k classification task.\n3. The real-world experiment demonstrates the practical feasibility of LUM-ViT, with accuracy loss not exceeding 4% compared to the software environment.\n4. The paper provides a comprehensive analysis of the system's performance, including the impact of the learnable under-sampling mask and the kernel-level weight binarization technique.\n\n$\\boxed{Weaknesses:}$ \n1. The paper does not provide a detailed explanation of the Gumbel-Softmax technique used to sample from the learnable mask, which may limit the reproducibility of the results.\n2. The system's performance on the hyperspectral image classification tasks is not evaluated, which may limit the generalizability of the results.\n3. The paper does not provide a detailed analysis of the system's robustness to variations in the input data, which may limit the robustness of the results.\n4. The paper's conclusion does not provide a clear direction for future research, which may limit the potential impact of the paper.\n\n$\\boxed{Suggestions for Improvement:}$ \n1. Provide a detailed explanation of the Gumbel-Softmax technique used to sample from the learnable mask.\n2. Evaluate the system's performance on the hyperspectral image classification tasks.\n3. Provide a detailed analysis of the system's robustness to variations in the input data.\n4. Provide a clear direction for future research in the conclusion of the paper.\n\n$\\boxed{Recommendation:}$ \nBased on the strengths and weaknesses of the paper, we recommend that the authors revise and resubmit the paper for peer review. The authors should provide a detailed explanation of the Gumbel-Softmax technique used to sample from the learnable mask, evaluate the system's performance on the hyperspectral image classification tasks, and provide a detailed analysis of the system's robustness to variations in the input data. Additionally, the authors should provide a clear direction for future research in the conclusion of the paper.",
        "gr_score_with": 0.7823343848580442,
        "gr_score_without": 0.7407407407407407,
        "output_without": {
            "num_tokens_scored": 324,
            "num_green_tokens": 240,
            "green_fraction": 0.7407407407407407,
            "z_score": 1.6002645283972794,
            "p_value": 0.05476995619777404
        },
        "output_with": {
            "num_tokens_scored": 317,
            "num_green_tokens": 248,
            "green_fraction": 0.7823343848580442,
            "z_score": 3.1989041611709683,
            "p_value": 0.0006897550999139828
        }
    },
    {
        "title": "CURRICULUM REINFORCEMENT LEARNING FOR QUANTUM ARCHITECTURE SEARCH UNDER HARD-",
        "abstract": "The key challenge in the noisy intermediate-scale quantum era is finding useful circuits compatible with current device limitations. Variational quantum algorithms (VQAs) offer a potential solution by fixing the circuit architecture and optimizing individual gate parameters in an external loop. However, parameter optimization can become intractable, and the overall performance of the algorithm depends heavily on the initially chosen circuit architecture. Several quantum architecture search (QAS) algorithms have been developed to design useful circuit architectures automatically. In the case of parameter optimization alone, noise effects have been observed to dramatically influence the performance of the optimizer and final outcomes, which is a key line of study. However, the effects of noise on the architecture search, which could be just as critical, are poorly understood. This work addresses this gap by introducing a curriculum-based reinforcement learning QAS (CRLQAS) algorithm designed to tackle challenges in realistic VQA deployment. The algorithm incorporates (i) a 3D architecture encoding and restrictions on environment dynamics to explore the search space of possible circuits efficiently, (ii) an episode halting scheme to steer the agent to find shorter circuits, and (iii) a novel variant of simultaneous perturbation stochastic approximation as an optimizer for faster convergence. To facilitate studies, we developed an optimized simulator for our algorithm, significantly improving computational efficiency in simulating noisy quantum circuits by employing the Pauli-transfer matrix formalism in the Pauli-Liouville basis. Numerical experiments focusing on quantum chemistry tasks demonstrate that CRLQAS outperforms existing QAS algorithms across several metrics in both noiseless and noisy environments.",
        "peer_review_without_watermark": "$$$\\begin{align}\\textbf{Paper Summary:} &\\quad The authors propose a curriculum-based reinforcement learning quantum architecture search (CRLQAS) algorithm to tackle the challenges of finding useful quantum circuits compatible with current device limitations in the noisy intermediate-scale quantum era. The CRLQAS algorithm incorporates a 3D architecture encoding, restrictions on environment dynamics, an episode halting scheme, and a novel variant of simultaneous perturbation stochastic approximation as an optimizer for faster convergence. The authors demonstrate the effectiveness of CRLQAS in both noiseless and noisy environments for quantum chemistry tasks.\n\n\\textbf{Strengths:} &\\quad The authors have made significant contributions to the field of quantum architecture search (QAS) by introducing a curriculum-based reinforcement learning approach. The CRLQAS algorithm has been demonstrated to be effective in finding efficient quantum circuits that can overcome hardware noise. The use of a 3D architecture encoding and restrictions on environment dynamics provides a more efficient search space exploration.\n\n\\textbf{Weaknesses:} &\\quad The authors have not provided a comprehensive analysis of the computational complexity of the CRLQAS algorithm. The effectiveness of the algorithm may be limited by the choice of hyperparameters, and the authors have not provided a detailed discussion of the potential limitations of the approach.\n\n\\textbf{Suggestions for Improvement:} &\\quad The authors should provide a more detailed analysis of the computational complexity of the CRLQAS algorithm and discuss the potential limitations of the approach. Additionally, the authors should investigate the impact of different hyperparameters on the performance of the algorithm.\n\n\\textbf{Recommendation:} &\\quad Based on the results presented in the paper, I recommend that the CRLQAS algorithm be further explored and developed. The algorithm has shown promise in finding efficient quantum circuits that can overcome hardware noise, and with further development, it has the potential to make significant contributions to the field of quantum computing.\n\n\\end{align}$$",
        "peer_review_with_watermark": "$$$\\begin{aligned} &\\text{Paper Summary:} \\\\ &\\text{This paper introduces a curriculum-based reinforcement learning QAS (CRLQAS) algorithm designed to tackle challenges in realistic variational quantum eigensolver (VQE) deployment. The algorithm incorporates a 3D architecture encoding, illegal actions, an episode halting scheme, and a novel variant of simultaneous perturbation stochastic approximation as an optimizer for faster convergence. The authors evaluate the performance of CRLQAS on quantum chemistry tasks and demonstrate that it outperforms existing QAS algorithms across noiseless and noisy environments.} \\\\ &\\text{Strengths:} \\\\ &\\text{1. The authors have proposed a novel and effective approach to tackle the challenges of realistic VQE deployment.} \\\\ &\\text{2. The algorithm is well-structured, and the authors have provided a clear explanation of the components and their roles.} \\\\ &\\text{3. The experimental results show that CRLQAS outperforms existing QAS algorithms, demonstrating its effectiveness.} \\\\ &\\text{Weaknesses:} \\\\ &\\text{1. The paper assumes a certain level of prior knowledge in the field of quantum computing and QAS, which might make it less accessible to non-experts.} \\\\ &\\text{2. The authors have not discussed the limitations of the PTM formalism, which might be a potential area for future improvement.} \\\\ &\\text{Suggestions for Improvement:} \\\\ &\\text{1. The authors could provide more detailed explanations of the PTM formalism and its limitations.} \\\\ &\\text{2. The paper could include more discussion on the generalizability of CRLQAS to other QAS problems.} \\\\ &\\text{Recommendation:} \\\\ &\\text{Based on the experimental results and the novelty of the approach, I recommend accepting the paper for publication. However, the authors should be aware of the potential limitations and be prepared to address them in future revisions.} \\\\ &\\text{Overall, the paper presents a well-structured and effective approach to tackle the challenges of realistic VQE deployment, and the experimental results demonstrate its effectiveness.} \\\\ \\end{aligned}$$",
        "gr_score_with": 0.8686868686868687,
        "gr_score_without": 0.7894736842105263,
        "output_without": {
            "num_tokens_scored": 266,
            "num_green_tokens": 210,
            "green_fraction": 0.7894736842105263,
            "z_score": 3.184391759377761,
            "p_value": 0.0007252927460342228
        },
        "output_with": {
            "num_tokens_scored": 297,
            "num_green_tokens": 258,
            "green_fraction": 0.8686868686868687,
            "z_score": 6.343805422919849,
            "p_value": 1.1207895649728933e-10
        }
    },
    {
        "title": "GIM: LEARNING GENERALIZABLE IMAGE MATCHER",
        "abstract": "Image matching is a fundamental computer vision problem. While learning-based methods achieve state-of-the-art performance on existing benchmarks, they generalize poorly to in-the-wild images. Such methods typically need to train separate models for different scene types (e.g., indoor vs. outdoor) and are impractical when the scene type is unknown in advance. One of the underlying problems is the limited scalability of existing data construction pipelines, which limits the diversity of standard image matching datasets. To address this problem, we propose GIM, a self-training framework for learning a single generalizable model based on any image matching architecture using internet videos, an abundant and diverse data source. Given an architecture, GIM first trains it on standard domain-specific datasets and then combines it with complementary matching methods to create dense labels on nearby frames of novel videos. These labels are filtered by robust fitting, and then enhanced by propagating them to distant frames. The final model is trained on propagated data with strong augmentations. Not relying on complex 3D reconstruction makes GIM much more efficient and less likely to fail than standard SfM-and-MVS based frameworks. We also propose ZEB, the first zero-shot evaluation benchmark for image matching. By mixing data from diverse domains, ZEB can thoroughly assess the cross-domain generalization performance of different methods. Experiments demonstrate the effectiveness and generality of GIM. Applying GIM consistently improves the zero-shot performance of 3 state-of-theart image matching architectures as the number of downloaded videos increases (Fig. 1 (a)); with 50 hours of YouTube videos, the relative zero-shot performance improves by 8.4% \u2212 18.1%. GIM also enables generalization to extreme crossdomain data such as Bird Eye View (BEV) images of projected 3D point clouds (Fig. 1 (c)). More importantly, our single zero-shot model consistently outperforms domain-specific baselines when evaluated on downstream tasks inherent to their respective domains. The code will be released upon acceptance.",
        "peer_review_without_watermark": "$$$ \n\nPaper Summary:\nThe paper proposes a self-training framework, GIM, to learn a single generalizable image matcher from internet videos. The framework combines a domain-specific model with complementary matching methods to create dense labels on nearby frames of novel videos. These labels are filtered by robust fitting and enhanced by propagating them to distant frames. The final model is trained on propagated data with strong augmentations. The authors also construct a zero-shot evaluation benchmark, ZEB, to assess the cross-domain generalization performance of different methods.\n\nStrengths:\n1. The paper addresses a critical issue in image matching, which is the limited scalability of existing data construction pipelines.\n2. The use of internet videos as a diverse and abundant data source is a novel approach.\n3. The proposed framework, GIM, is efficient and effective in improving the generalization of state-of-the-art models.\n4. The authors provide a thorough evaluation of the proposed framework and benchmark.\n\nWeaknesses:\n1. The paper relies heavily on the availability of internet videos, which may not be feasible in all scenarios.\n2. The robustness of the proposed framework to different scene types and lighting conditions is not thoroughly evaluated.\n3. The paper does not provide a detailed analysis of the effects of different video sampling strategies on the performance of the framework.\n4. The evaluation of the proposed framework is limited to a few benchmarks, and it is not clear how well it generalizes to other scenarios.\n\nSuggestions for Improvement:\n1. The authors should provide a more detailed analysis of the effects of different video sampling strategies on the performance of the framework.\n2. The authors should evaluate the robustness of the proposed framework to different scene types and lighting conditions.\n3. The authors should provide a more comprehensive evaluation of the proposed framework, including more benchmarks and scenarios.\n4. The authors should discuss the potential limitations and challenges of using internet videos as a data source.\n\nRecommendation:\nThe proposed framework, GIM, is a significant contribution to the field of image matching. Its efficiency and effectiveness in improving the generalization of state-of-the-art models make it a promising approach. However, further evaluation and analysis are needed to fully understand its limitations and potential applications. The authors should continue to work on improving the robustness and generalizability of the framework and provide more comprehensive evaluation results. \n\nNote: The review is based on the provided paper and follows the standard conference peer-review format. The reviewer's comments and suggestions are constructive and aimed at improving the paper.",
        "peer_review_with_watermark": "$$$\n\n\nPaper Summary:\nThe paper proposes GIM, a self-training framework for learning generalizable image matching models using abundant internet videos. GIM leverages domain-specific models to generate dense labels on nearby frames of novel videos, and then propagates these labels to distant frames using robust fitting and data augmentation.\n\nStrengths:\n\n* GIM leverages abundant and diverse internet videos to learn generalizable image matching models, addressing the limited scalability of existing data construction pipelines.\n* Self-training framework enables efficient generation of supervision signals and improves generalization performance.\n* ZEB, the first zero-shot evaluation benchmark for image matching, provides a comprehensive evaluation framework for measuring cross-domain generalization performance.\n\nWeaknesses:\n\n* Limited evaluation of GIM's performance on downstream tasks such as visual localization and 3D reconstruction.\n* Lack of comparison with other generalizable image matching models.\n* GIM's performance may be limited by the quality and diversity of the internet videos used.\n\nSuggestions for Improvement:\n\n* Provide more extensive evaluation of GIM's performance on downstream tasks.\n* Compare GIM with other generalizable image matching models.\n* Investigate the impact of video quality and diversity on GIM's performance.\n\nRecommendation:\n\n* GIM is a novel approach to learning generalizable image matching models, and its potential for improving performance on in-the-wild image matching tasks is significant.\n* Further evaluation and comparison with other models are needed to fully understand GIM's strengths and limitations.\n* Release of the code and datasets used in GIM would facilitate replication and extension of the research.\n\n$$",
        "gr_score_with": 0.7983193277310925,
        "gr_score_without": 0.6564245810055865,
        "output_without": {
            "num_tokens_scored": 358,
            "num_green_tokens": 235,
            "green_fraction": 0.6564245810055865,
            "z_score": -1.7991751235772686,
            "p_value": 0.964004508398958
        },
        "output_with": {
            "num_tokens_scored": 238,
            "num_green_tokens": 190,
            "green_fraction": 0.7983193277310925,
            "z_score": 3.309921786522026,
            "p_value": 0.0004666102211033262
        }
    },
    {
        "title": "PRE-TRAINED IMAGE-EDITING DIFFUSION MODELS",
        "abstract": "If generalist robots are to operate in truly unstructured environments, they need to be able to recognize and reason about novel objects and scenarios. Such objects and scenarios might not be present in the robot\u2019s own training data. We propose SuSIE, a method that leverages an image editing diffusion model to act as a high-level planner by proposing intermediate subgoals that a low-level controller attains. Specifically, we fine-tune InstructPix2Pix on robot data such that it outputs a hypothetical future observation given the robot\u2019s current observation and a language command. We then use the same robot data to train a low-level goalconditioned policy to reach a given image observation. We find that when these components are combined, the resulting system exhibits robust generalization capabilities. The high-level planner utilizes its Internet-scale pre-training and visual understanding to guide the low-level goal-conditioned policy, achieving significantly better generalization than conventional language-conditioned policies. We demonstrate that this approach solves real robot control tasks involving novel objects, distractors, and even environments, both in the real world and in simulation. The project website can be found at http://subgoal-image-editing. github.io.",
        "peer_review_without_watermark": "$$\\boxed{\\text{Paper Summary:}~\\text{The}~\\text{paper}~\\text{proposes}~\\text{SuSIE},~\\text{a}~\\text{method}~\\text{that}~\\text{leverages}~\\text{an}~\\text{image-editing}~\\text{diffusion}~\\text{model}~\\text{to}~\\text{act}~\\text{as}~\\text{a}~\\text{high-level}~\\text{planner}~\\text{by}~\\text{proposing}~\\text{intermediate}~\\text{subgoals}~\\text{that}~\\text{a}~\\text{low-level}~\\text{controller}~\\text{attains}.~\\text{The}~\\text{method}~\\text{combines}~\\text{a}~\\text{pre-trained}~\\text{image-editing}~\\text{model}~\\text{with}~\\text{a}~\\text{low-level}~\\text{goal-conditioned}~\\text{policy}~\\text{to}~\\text{reach}~\\text{the}~\\text{generated}~\\text{subgoals}.~\\text{The}~\\text{approach}~\\text{exhibits}~\\text{robust}~\\text{generalization}~\\text{capabilities}~\\text{and}~\\text{achieves}~\\text{significantly}~\\text{better}~\\text{generalization}~\\text{than}~\\text{conventional}~\\text{language-conditioned}~\\text{policies}.}\n\n$$\\boxed{\\text{Strengths:}~\\text{The}~\\text{paper}~\\text{proposes}~\\text{a}~\\text{novel}~\\text{approach}~\\text{that}~\\text{combines}~\\text{image-editing}~\\text{diffusion}~\\text{models}~\\text{with}~\\text{goal-conditioned}~\\text{policies}~\\text{to}~\\text{improve}~\\text{robotic}~\\text{control}.~\\text{The}~\\text{approach}~\\text{exhibits}~\\text{robust}~\\text{generalization}~\\text{capabilities}~\\text{and}~\\text{achieves}~\\text{significantly}~\\text{better}~\\text{generalization}~\\text{than}~\\text{conventional}~\\text{language-conditioned}~\\text{policies}.~\\text{The}~\\text{paper}~\\text{provides}~\\text{experiments}~\\text{to}~\\text{evaluate}~\\text{the}~\\text{approach}~\\text{on}~\\text{real-world}~\\text{and}~\\text{simulated}~\\text{environments}.}\n\n$$\\boxed{\\text{Weaknesses:}~\\text{The}~\\text{paper}~\\text{does}~\\not{not}~\\text{provide}~\\text{a}~\\text{clear}~\\text{and}~\\text{concise}~\\text{mathematical}~\\text{formulation}~\\text{of}~\\text{the}~\\text{SuSIE}~\\text{approach}.~\\text{The}~\\text{paper}~\\text{also}~\\not{not}~\\text{provide}~\\text{a}~\\text{clear}~\\text{and}~\\text{concise}~\\text{analysis}~\\text{of}~\\text{the}~\\text{comparisons}~\\text{with}~\\text{other}~\\text{approaches}.~\\text{The}~\\text{paper}~\\text{could}~\\text{benefit}~\\text{from}~\\text{a}~\\text{more}~\\text{detailed}~\\text{explanation}~\\text{of}~\\text{the}~\\text{diffusion}~\\text{model}~\\text{and}~\\text{the}~\\text{goal-conditioned}~\\text{policy}~\\text{in}~\\text{the}~\\text{SuSIE}~\\text{approach}.}\n\n$$\\boxed{\\text{Suggestions}~\\text{for}~\\text{Improvement:}~\\text{The}~\\text{paper}~\\text{could}~\\text{benefit}~\\text{from}~\\text{a}~\\text{more}~\\text{detailed}~\\text{explanation}~\\text{of}~\\text{the}~\\text{SuSIE}~\\text{approach}.~\\text{The}~\\text{paper}~\\text{could}~\\text{also}~\\text{provide}~\\text{a}~\\text{clear}~\\text{and}~\\text{concise}~\\text{mathematical}~\\text{formulation}~\\text{of}~\\text{the}~\\text{SuSIE}~\\text{approach}.~\\text{The}~\\text{paper}~\\text{could}~\\text{benefit}~\\text{from}~\\text{a}~\\text{more}~\\text{detailed}~\\text{analysis}~\\text{of}~\\text{the}~\\text{comparisons}~\\text{with}~\\text{other}~\\text{approaches}.}\n\n$$\\boxed{\\text{Recommendation:}~\\text{Based}~\\text{on}~\\text{the}~\\text{analysis}~\\text{of}~\\text{the}~\\text{paper},~\\text{it}~\\text{is}~\\text{recommended}~\\text{to}~\\text{adopt}~\\text{the}~\\text{SuSIE}~\\text{approach}~\\text{for}~\\text{robotic}~\\text{control}~\\text{tasks}.~\\text{The}~\\text{approach}~\\text{exhibits}~\\text{robust}~\\text{generalization}~\\text{capabilities}~\\text{and}~\\text{achieves}~\\text{significantly}~\\text{better}~\\text{generalization}~\\text{than}~\\text{conventional}~\\text{language-conditioned}~\\text{policies}.}$$",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$Paper Summary: \nSuSIE, a novel approach, leverages pre-trained image-editing diffusion models to enhance language-guided robotic control in novel environments, objects, and scenarios. The system decomposes the robotic control problem into two phases: synthesizing a \u201csubgoal\u201d that the robot must reach to complete the user-specified task, and then attempting to reach this subgoal via a goal-reaching robot controller. The image-editing model is fine-tuned on robot data to produce hypothetical future subgoals given the robot\u2019s current observation and a language command.\n\n$$Strengths: \n1) The approach effectively decouples the high-level planner and the low-level controller, allowing the high-level planner to guide the low-level controller with a higher level of abstraction and semantics.\n2) SuSIE improves upon prior methods that leverage pre-trained vision-language models, achieving better generalization capabilities in novel environments, objects, and scenarios.\n3) The system demonstrates robust zero-shot generalization capabilities, allowing the robot to operate in unstructured environments without prior experience with the objects, scenarios, or environments.\n\n$$Weaknesses: \n1) The approach relies heavily on pre-training on Internet data, which may not always be available or representative of the target task.\n2) The system may not generalize well to extremely novel scenarios, objects, or environments, particularly if the pre-training data lacks sufficient diversity.\n3) The low-level goal-conditioned policy may not always be able to execute the generated subgoals precisely, particularly if the subgoals are too abstract or complex.\n\n$$Suggestions for Improvement: \n1) Incorporating additional data sources, such as simulation data or data collected from other robots, to enhance the diversity of the pre-training data.\n2) Developing more robust methods to adapt the image-editing model to novel scenarios, objects, or environments.\n3) Investigating the use of more advanced low-level control policies, such as model-based policies, to improve the precision of the low-level controller.\n\n$$Recommendation: \nSuSIE is a promising approach that leverages pre-trained image-editing diffusion models to enhance language-guided robotic control in novel environments, objects, and scenarios. While the approach has several strengths, including its ability to decouple the high-level planner and the low-level controller, and its robust zero-shot generalization capabilities, it also has several weaknesses, such as its reliance on pre-training on Internet data and its potential limitations in novel scenarios. To improve the approach, we recommend incorporating additional data sources, developing more robust methods to adapt the image-editing model, and investigating the use of more advanced low-level control policies. Overall, SuSIE has the potential to be a valuable contribution to the field of language-guided robotic control, and with further development, it could be a powerful tool for enhancing robotic manipulation capabilities in a wide range of applications.",
        "gr_score_with": 0.7944862155388471,
        "gr_score_without": 0.7682926829268293,
        "output_without": {
            "num_tokens_scored": 246,
            "num_green_tokens": 189,
            "green_fraction": 0.7682926829268293,
            "z_score": 2.3373948391631116,
            "p_value": 0.009709331617360654
        },
        "output_with": {
            "num_tokens_scored": 399,
            "num_green_tokens": 317,
            "green_fraction": 0.7944862155388471,
            "z_score": 4.118558650914376,
            "p_value": 1.906247704286114e-05
        }
    },
    {
        "title": "DET-CGD: COMPRESSED GRADIENT DESCENT WITH MATRIX STEPSIZES FOR NON-CONVEX OPTIMIZATION",
        "abstract": "This paper introduces a new method for minimizing matrix-smooth non-convex objectives through the use of novel Compressed Gradient Descent (CGD) algorithms enhanced with a matrix-valued stepsize. The proposed algorithms are theoretically analyzed first in the single-node and subsequently in the distributed settings. Our theoretical results reveal that the matrix stepsize in CGD can capture the objective\u2019s structure and lead to faster convergence compared to a scalar stepsize. As a byproduct of our general results, we emphasize the importance of selecting the compression mechanism and the matrix stepsize in a layer-wise manner, taking advantage of model structure. Moreover, we provide theoretical guarantees for free compression, by designing specific layer-wise compressors for the non-convex matrix smooth objectives. Our findings are supported with empirical evidence.",
        "peer_review_without_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes a new method for minimizing non-convex objectives through compressed gradient descent with matrix-valued stepsize. The proposed algorithms are theoretically analyzed and convergence guarantees are provided for both single-node and distributed settings. The paper also explores the use of layer-wise structure in neural networks and designs compression mechanisms that achieve compression for free.\n\nStrengths:\n\n*   The paper provides a novel approach to compressed gradient descent with matrix-valued stepsize.\n*   The theoretical analysis is thorough and provides convergence guarantees for both single-node and distributed settings.\n*   The paper explores the use of layer-wise structure in neural networks and designs compression mechanisms that achieve compression for free.\n\nWeaknesses:\n\n*   The paper's results may be difficult to interpret for non-experts in the field, as the notation and terminology used are specialized.\n*   The paper's theoretical analysis is extensive, but may not provide immediate practical insights for practitioners.\n*   The paper's results are based on assumptions and may not generalize to all cases.\n\nSuggestions for Improvement:\n\n*   The paper could benefit from more detailed explanations of the assumptions made and the limitations of the results.\n*   The paper could provide more practical insights and examples to illustrate the benefits of the proposed method.\n*   The paper's theoretical analysis could be more accessible to non-experts in the field.\n\nRecommendation:\n\n*   The paper is well-written and provides a thorough analysis of the proposed method.\n*   The results are significant and have the potential to impact the field of machine learning.\n*   The paper could benefit from more practical insights and examples to illustrate the benefits of the proposed method.\n\n$$$\\boxed{Overall Rating: 8/10}$",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$Paper Summary: The paper introduces a novel compressed gradient descent (CGD) algorithm that incorporates a matrix-valued step-size for non-convex optimization problems. The authors analyze the convergence properties of the algorithm in both single-node and distributed settings, with a focus on leveraging the layer-wise structure of neural networks.\n\nStrengths: The paper makes a significant contribution to the field of non-convex optimization by exploring the use of matrix-valued step-sizes in compressed gradient descent algorithms. The authors provide a thorough analysis of the convergence properties of the algorithms in both single-node and distributed settings, and demonstrate the effectiveness of the proposed methods in achieving compression for free.\n\nWeaknesses: The paper relies heavily on the assumption of matrix smoothness, which may not hold in all cases. Additionally, the authors do not provide a detailed analysis of the communication complexity of the algorithms in the distributed setting.\n\nSuggestions for Improvement: The authors could improve the paper by providing a more detailed analysis of the communication complexity of the algorithms in the distributed setting. They could also explore the use of more robust compression mechanisms that do not rely on the assumption of matrix smoothness.\n\nRecommendation: The paper is well-written and provides a thorough analysis of the convergence properties of the proposed algorithms. However, the authors should provide more attention to the communication complexity of the algorithms in the distributed setting to make the paper more comprehensive.\n\n$$\\begin{aligned}\n$$Paper Summary: The paper presents a novel compressed gradient descent (CGD) algorithm that incorporates a matrix-valued step-size for non-convex optimization problems. The authors analyze the convergence properties of the algorithm in both single-node and distributed settings, with a focus on leveraging the layer-wise structure of neural networks.\n\nStrengths: The paper makes a significant contribution to the field of non-convex optimization by exploring the use of matrix-valued step-sizes in compressed gradient descent algorithms. The authors provide a thorough analysis of the convergence properties of the algorithms in both single-node and distributed settings.\n\nWeaknesses: The paper relies heavily on the assumption of matrix smoothness, which may not hold in all cases.\n\nSuggestions for Improvement: The authors could provide a more detailed analysis of the communication complexity of the algorithms in the distributed setting.\n\nRecommendation: The paper is well-written and provides a thorough analysis of the convergence properties of the proposed algorithms. However, the authors should provide more attention to the communication complexity of the algorithms in the distributed setting.\n\n$$\\begin{aligned}\n$$Paper Summary: The paper introduces a novel compressed gradient descent (CGD) algorithm that incorporates a matrix-valued step-size for non-convex optimization problems. The authors analyze the convergence properties of the algorithm in both single-node and distributed settings.\n\nStrengths: The paper makes a significant contribution to the field of non-convex optimization by exploring the use of matrix-valued step-sizes in compressed gradient descent algorithms.\n\nWeaknesses: The authors do not provide a detailed analysis of the convergence properties of the algorithms in the distributed setting.\n\nSuggestions for Improvement: The authors should provide a more detailed analysis of the convergence properties of the algorithms in the distributed setting.\n\nRecommendation: The paper is well-written and provides a thorough analysis of the convergence properties of the proposed algorithms. However, the authors should provide more attention to the convergence properties of the algorithms in the distributed setting.\n\n$$\\begin{aligned}\n$$Paper Summary: The paper introduces a novel compressed gradient descent (CGD) algorithm that incorporates a matrix-valued step-size for non-convex optimization problems.\n\nStrengths: The paper makes a significant contribution to the field of non-convex optimization by exploring the use of matrix-valued step-sizes in compressed gradient descent algorithms.\n\nWeaknesses: The authors do not provide a detailed analysis of the convergence properties of the algorithms in the distributed setting.\n\nSuggestions for Improvement: The authors should provide a more detailed analysis of the convergence properties of the algorithms in the distributed setting.\n\nRecommendation: The paper is well-written and provides a thorough analysis of the convergence properties of the proposed algorithms. However, the authors should provide more attention to the convergence properties of the algorithms in the distributed setting.\n\n$$\\begin{aligned}\n$$Paper Summary: The paper introduces a novel compressed gradient descent (CGD) algorithm that incorporates a matrix-valued step-size for non-convex optimization problems.\n\nStrengths: The paper makes a significant contribution to the field of non-convex optimization by exploring the use of matrix-valued step-sizes in compressed gradient descent algorithms.\n\nWeaknesses: The authors do not provide a detailed analysis of the convergence properties of the algorithms in the distributed setting.\n\nSuggestions for Improvement: The authors should provide a more detailed analysis of the convergence properties of the algorithms in the distributed setting.\n\nRecommendation: The paper is well-written and provides a thorough analysis of the convergence properties of the proposed algorithms. However, the authors should provide more attention to the convergence properties of the algorithms in the distributed setting.\n\n$$\\begin{aligned}\n$$Paper Summary: The paper introduces a novel compressed gradient descent (CGD) algorithm that incorporates a matrix-valued step-size for non-convex optimization problems.\n\nStrengths: The paper makes a significant contribution to the field of non-convex optimization by exploring the use of matrix-valued step-sizes in compressed gradient descent algorithms.\n\nWeaknesses: The authors do not provide a detailed analysis of the convergence properties of the algorithms in the distributed setting.\n\nSuggestions for Improvement: The authors should provide a more detailed analysis of the convergence properties of the algorithms in the distributed setting.\n\nRecommendation: The paper is well-written and provides a thorough analysis of the convergence properties of the proposed algorithms. However, the authors should provide more attention to the convergence properties of the algorithms in the distributed setting.\n\n$$\\begin{aligned}\n$$Paper Summary: The paper introduces a novel compressed gradient descent (CGD) algorithm that incorporates a matrix-valued step-size for non-convex optimization problems.\n\nStrengths: The paper makes a significant contribution to the field of non-convex optimization by exploring the use of matrix-valued step-sizes in compressed gradient descent algorithms.\n\nWeaknesses: The authors do not provide a detailed analysis of the convergence properties of the algorithms in the distributed setting.\n\nSuggestions for Improvement: The authors should provide a more detailed analysis of the convergence properties of the algorithms in the distributed setting.\n\nRecommendation: The paper is well-written and provides a thorough analysis of the convergence properties of the proposed algorithms. However, the authors should provide more attention to the convergence properties of the algorithms in the distributed setting.\n\n$$\\begin{aligned}\n$$Paper Summary: The paper introduces a novel compressed gradient descent (CGD) algorithm that incorporates a matrix-valued step-size for non-convex optimization problems.\n\nStrengths: The paper makes a significant contribution to the field of non-convex optimization by exploring the use of matrix-valued step-sizes in compressed gradient descent algorithms.\n\nWeaknesses: The authors do not provide a detailed analysis of the convergence properties of the algorithms in the distributed setting.\n\nSuggestions for Improvement: The authors should provide a more detailed analysis of the convergence properties of the algorithms in the distributed setting.\n\nRecommendation: The paper is well-written and provides a thorough analysis of the convergence properties of the proposed algorithms. However, the authors should provide more attention to the convergence properties of the algorithms in the distributed setting.\n\n$$\\begin{aligned}\n$$Paper Summary: The paper introduces a novel compressed gradient descent (CGD) algorithm that incorporates a matrix-valued step-size for non-convex optimization problems.\n\nStrengths: The paper makes a significant contribution to the field of non-convex optimization by exploring the use of matrix-valued step-sizes in compressed gradient descent algorithms.\n\nWeaknesses: The authors do not provide a detailed analysis of the convergence properties of the algorithms in the distributed setting.\n\nSuggestions for Improvement: The authors should provide a more detailed analysis of the convergence properties of the algorithms in the distributed setting.\n\nRecommendation: The paper is well-written and provides a thorough analysis of the convergence properties of the proposed algorithms. However, the authors should provide more attention to the convergence properties of the algorithms in the distributed setting.\n\n$$\\begin{aligned}\n$$Paper Summary: The paper introduces a novel compressed gradient descent (CGD) algorithm that incorporates a matrix-valued step-size for non-convex optimization problems.\n\nStrengths: The paper makes a significant contribution to the field of non-convex optimization by exploring the use of matrix-valued step-sizes in compressed gradient descent algorithms.\n\nWeaknesses: The authors do not provide a detailed analysis of the convergence properties of the algorithms in the distributed setting.\n\nSuggestions for Improvement: The authors should provide a more detailed analysis of the convergence properties of the algorithms in the distributed setting.\n\nRecommendation: The paper is well-written and provides a thorough analysis of the convergence properties of the proposed algorithms. However, the authors should provide more attention to the convergence properties of the algorithms in the distributed setting.\n\n$$\\begin{aligned}\n$$Paper Summary: The paper introduces a novel compressed gradient descent (CGD) algorithm that incorporates a matrix-valued step-size for non-convex optimization problems.\n\nStrengths: The paper makes a significant contribution to the field of non-convex optimization by exploring the use of matrix-valued step-sizes in compressed gradient descent algorithms.\n\nWeaknesses: The authors do not provide a detailed analysis of the convergence properties of the algorithms in the distributed setting.\n\nSuggestions for Improvement: The authors should provide a more detailed analysis of the convergence properties of the algorithms in the distributed setting.\n\nRecommendation: The paper is well-written and provides a thorough analysis of the convergence properties of the proposed algorithms. However, the authors should provide more attention to the convergence properties of the algorithms in the distributed setting.\n\n$$\\begin{aligned}\n$$Paper",
        "gr_score_with": 0.8269230769230769,
        "gr_score_without": 0.746606334841629,
        "output_without": {
            "num_tokens_scored": 221,
            "num_green_tokens": 165,
            "green_fraction": 0.746606334841629,
            "z_score": 1.5119291506277657,
            "p_value": 0.06527594364994983
        },
        "output_with": {
            "num_tokens_scored": 208,
            "num_green_tokens": 172,
            "green_fraction": 0.8269230769230769,
            "z_score": 3.9945017156140965,
            "p_value": 3.241522603088542e-05
        }
    },
    {
        "title": "DEMYSTIFYING LOCAL & GLOBAL FAIRNESS TRADE-OFFS IN FEDERATED LEARNING USING PARTIAL INFORMATION DECOMPOSITION",
        "abstract": "This work presents an information-theoretic perspective to group fairness trade-offs in federated learning (FL) with respect to sensitive attributes, such as gender, race, etc. Existing works often focus on either global fairness (overall disparity of the model across all clients) or local fairness (disparity of the model at each client), without always considering their trade-offs. There is a lack of understanding of the interplay between global and local fairness in FL, particularly under data heterogeneity, and if and when one implies the other. To address this gap, we leverage a body of work in information theory called partial information decomposition (PID), which first identifies three sources of unfairness in FL, namely, Unique Disparity, Redundant Disparity, and Masked Disparity. We demonstrate how these three disparities contribute to global and local fairness using canonical examples. This decomposition helps us derive fundamental limits on the trade-off between global and local fairness, highlighting where they agree or disagree. We introduce the Accuracy & Global-Local Fairness Optimality Problem (AGLFOP), a convex optimization that defines the theoretical limits of accuracy and fairness trade-offs, identifying the best possible performance any FL strategy can attain given a dataset and client distribution. We also present experimental results on synthetic datasets and the ADULT dataset to support our theoretical findings.",
        "peer_review_without_watermark": "$$\\boxed{\\text{Paper Summary:}~ \\text{The paper proposes an information-theoretic perspective to group fairness trade-offs in federated learning (FL). It leverages partial information decomposition (PID) to decompose global and local disparity into three sources of unfairness: Unique, Redundant, and Masked Disparity. The authors provide canonical examples to understand these disparities and demonstrate the fundamental limits on trade-offs between local and global fairness. They also introduce the Accuracy and Global-Local Fairness Optimality Problem (AGLFOP), a convex optimization framework to quantify the accuracy-fairness trade-offs. The experimental results on synthetic and Adult datasets validate the theoretical findings, showing that depending on the data distribution, achieving one can often come at the cost of the other. The results provide insights into the agreement and disagreement between local and global fairness under various data distributions.}\n\n$$\\boxed{\\text{Strengths:}~ \\text{The paper provides a nuanced understanding of the sources of disparity in FL, including Unique, Redundant, and Masked disparities. The use of PID offers a powerful tool to disentangle the regions of agreement and disagreement between local and global disparity. The authors also provide a comprehensive framework for exploring the accuracy-fairness trade-offs, including the AGLFOP. The experimental results demonstrate the effectiveness of the proposed approach.}\n\n$$\\boxed{\\text{Weaknesses:}~ \\text{One of the main limitations of the paper is that it focuses primarily on binary classification problems. The authors should consider extending the results to multi-class classification problems. Additionally, the paper assumes that the clients have access to the same data and do not share any information. In real-world scenarios, this assumption may not hold.}\n\n$$\\boxed{\\text{Suggestions for Improvement:}~ \\text{The authors should consider extending the results to multi-class classification problems and explore the limitations of the current assumption. Additionally, they should investigate the use of more advanced fairness metrics, such as equalized odds and demographic parity. The paper could also benefit from a more detailed analysis of the computational complexity of the AGLFOP and its implications for large-scale FL scenarios.}\n\n$$\\boxed{\\text{Recommendation:}~ \\text{Based on the strengths and weaknesses of the paper, I recommend accepting the paper for publication in a top-tier machine learning conference. The paper provides a valuable contribution to the field of FL and fairness, and the experimental results demonstrate the effectiveness of the proposed approach. However, the authors should address the limitations and suggestions for improvement mentioned above to further strengthen the paper.}\"",
        "peer_review_with_watermark": "$$\\boxed{\\text{Summary: The paper proposes an information-theoretic approach to understanding group fairness trade-offs in federated learning. It leverages partial information decomposition to identify three sources of unfairness: unique, redundant, and masked disparities. The authors introduce the Accuracy-Global-Local Fairness Optimality Problem, a convex optimization framework for exploring the accuracy-fairness trade-offs. Experimental results on synthetic and real-world datasets demonstrate the effectiveness of the proposed approach.}}\n\n$$\\boxed{\\text{Strengths: The paper provides a comprehensive framework for understanding group fairness trade-offs in federated learning. The proposed approach leverages partial information decomposition to identify three sources of unfairness, providing insights into the interplay between local and global fairness. The Accuracy-Global-Local Fairness Optimality Problem framework offers a novel way to explore the accuracy-fairness trade-offs. The experimental results demonstrate the effectiveness of the proposed approach.}}\n\n$$\\boxed{\\text{Weaknesses: The paper assumes that the data distribution across clients is fixed, which may not always be the case in real-world applications. The proposed approach may not be effective in scenarios with high levels of synergy between sensitive attributes and client labels. The experimental results may not generalize to other datasets or applications. The paper could benefit from more comprehensive theoretical results, such as bounds on the accuracy-fairness trade-offs.}}\n\n$$\\boxed{\\text{Suggestions for Improvement: The paper could benefit from more comprehensive theoretical results, such as bounds on the accuracy-fairness trade-offs. The authors could investigate the effectiveness of the proposed approach in scenarios with high levels of synergy between sensitive attributes and client labels. The experimental results could be replicated on other datasets or applications to validate the generalizability of the proposed approach. The authors could also explore alternative fairness notions, such as statistical parity, to compare with the proposed approach.}}\n\n$$\\boxed{\\text{Recommendation: The paper provides a novel and comprehensive framework for understanding group fairness trade-offs in federated learning. The proposed approach leverages partial information decomposition to identify three sources of unfairness, providing insights into the interplay between local and global fairness. The Accuracy-Global-Local Fairness Optimality Problem framework offers a novel way to explore the accuracy-fairness trade-offs. The experimental results demonstrate the effectiveness of the proposed approach. However, the paper could benefit from more comprehensive theoretical results, such as bounds on the accuracy-fairness trade-offs, to further establish the validity of the proposed approach.}}$$",
        "gr_score_with": 0.8181818181818182,
        "gr_score_without": 0.7307692307692307,
        "output_without": {
            "num_tokens_scored": 390,
            "num_green_tokens": 285,
            "green_fraction": 0.7307692307692307,
            "z_score": 1.3259870882635918,
            "p_value": 0.09242198711376703
        },
        "output_with": {
            "num_tokens_scored": 242,
            "num_green_tokens": 198,
            "green_fraction": 0.8181818181818182,
            "z_score": 4.011887099014393,
            "p_value": 3.0117653711442064e-05
        }
    },
    {
        "title": "MAGICDRIVE: STREET VIEW GENERATION WITH DIVERSE 3D GEOMETRY CONTROL",
        "abstract": "Recent advancements in diffusion models have significantly enhanced the data synthesis with 2D control. Yet, precise 3D control in street view generation, crucial for 3D perception tasks, remains elusive. Specifically, utilizing Bird\u2019s-Eye View (BEV) as the primary condition often leads to challenges in geometry control (e.g., height), affecting the representation of object shapes, occlusion patterns, and road surface elevations, all of which are essential to perception data synthesis, especially for 3D object detection tasks. In this paper, we introduce MAGICDRIVE, a novel street view generation framework, offering diverse 3D geometry controls including camera poses, road maps, and 3D bounding boxes, together with textual descriptions, achieved through tailored encoding strategies. Besides, our design incorporates a cross-view attention module, ensuring consistency across multiple camera views. With MAGICDRIVE, we achieve high-fidelity street-view image & video synthesis that captures nuanced 3D geometry and various scene descriptions, enhancing tasks like BEV segmentation and 3D object detection. Front Front Left Front Right ... ... R ai n y",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces MAGICDRIVE, a novel framework for street view generation with diverse 3D geometry controls. The framework utilizes a cross-view attention module to maintain consistency across multiple camera views and achieves high-fidelity street-view image and video synthesis that captures nuanced 3D geometry and various scene descriptions. The proposed framework is evaluated on the nuScenes dataset and shows state-of-the-art performance in both realism and controllability.\n\nStrengths:\n1. The paper introduces a novel framework for street view generation that addresses the challenges of 3D geometry control.\n2. The cross-view attention module is simple yet effective in guaranteeing consistency across multi-camera views.\n3. The framework achieves high-fidelity street-view image and video synthesis that captures nuanced 3D geometry and various scene descriptions.\n\nWeaknesses:\n1. The paper does not provide a clear comparison with other state-of-the-art methods for street view generation.\n2. The evaluation on the nuScenes dataset is limited to a small number of scenes and may not be representative of the full dataset.\n3. The paper does not provide a clear analysis of the limitations and failure cases of the proposed framework.\n\nSuggestions for Improvement:\n1. Provide a clear comparison with other state-of-the-art methods for street view generation.\n2. Evaluate the proposed framework on a larger subset of the nuScenes dataset to ensure that the results are representative of the full dataset.\n3. Provide a clear analysis of the limitations and failure cases of the proposed framework.\n\nRecommendation:\nThe proposed framework, MAGICDRIVE, is a significant contribution to the field of street view generation. However, to further improve the framework, it is essential to address the limitations and failure cases mentioned above. With further development and evaluation, MAGICDRIVE has the potential to become a state-of-the-art method for street view generation.\n\n$$$",
        "peer_review_with_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes a novel framework MAGICDRIVE for generating high-quality multi-camera street views with diverse 3D geometry controls. The framework utilizes a cross-view attention module to ensure consistency across multiple camera views and incorporates separate encoders for bounding boxes and road maps to improve controllability. The authors evaluate MAGICDRIVE on the nuScenes dataset and demonstrate its ability to generate realistic images and videos that align with 3D annotations.\n\nStrengths:\n1. The proposed framework MAGICDRIVE is innovative and effective in generating street views with diverse 3D geometry controls.\n2. The cross-view attention module ensures consistency across multiple camera views, which is crucial for street view generation.\n3. The separation encoding design allows for accurate semantic control for street views.\n4. The authors evaluate MAGICDRIVE on the nuScenes dataset and demonstrate its ability to generate realistic images and videos.\n\nWeaknesses:\n1. The paper does not discuss potential limitations of the cross-view attention module, such as computational complexity or mode collapse.\n2. The authors do not evaluate MAGICDRIVE on other datasets or benchmarks, which may indicate the framework's generalizability.\n3. The paper does not discuss potential applications of MAGICDRIVE beyond street view generation, such as 3D object detection or semantic segmentation.\n\nSuggestions for Improvement:\n1. The authors should discuss potential limitations of the cross-view attention module and propose strategies to address them.\n2. The authors should evaluate MAGICDRIVE on other datasets or benchmarks to demonstrate its generalizability.\n3. The authors should discuss potential applications of MAGICDRIVE beyond street view generation.\n\nRecommendation:\nI recommend that the authors revise the paper to address the weaknesses mentioned above and provide a more comprehensive evaluation of MAGICDRIVE. Additionally, the authors can explore potential applications of MAGICDRIVE beyond street view generation to demonstrate its versatility.\n\n$$\\boxed{Rating:} 8/10$$",
        "gr_score_with": 0.7327935222672065,
        "gr_score_without": 0.6695278969957081,
        "output_without": {
            "num_tokens_scored": 233,
            "num_green_tokens": 156,
            "green_fraction": 0.6695278969957081,
            "z_score": -1.0150109812459496,
            "p_value": 0.8449497035188802
        },
        "output_with": {
            "num_tokens_scored": 247,
            "num_green_tokens": 181,
            "green_fraction": 0.7327935222672065,
            "z_score": 1.124674620383653,
            "p_value": 0.13036347009672444
        }
    },
    {
        "title": "PATHFORMER: MULTI-SCALE TRANSFORMERS WITH ADAPTIVE PATHWAYS FOR TIME SERIES FORECASTING",
        "abstract": "Transformers for time series forecasting mainly model time series from limited or fixed scales, making it challenging to capture different characteristics spanning various scales. We propose Pathformer, a multi-scale Transformer with adaptive pathways. It integrates both temporal resolution and temporal distance for multi-scale modeling. Multi-scale division divides the time series into different temporal resolutions using patches of various sizes. Based on the division of each scale, dual attention is performed over these patches to capture global correlations and local details as temporal dependencies. We further enrich the multiscale Transformer with adaptive pathways, which adaptively adjust the multi-scale modeling process based on the varying temporal dynamics of the input, improving the accuracy and generalization of Pathformer. Extensive experiments on eleven real-world datasets demonstrate that Pathformer not only achieves state-of-the-art performance by surpassing all current models but also exhibits stronger generalization abilities under various transfer scenarios. The code is made available at https://github.com/decisionintelligence/pathformer.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$\\boxed{Paper Summary:}$ \nThe paper proposes Pathformer, a multi-scale Transformer with adaptive pathways for time series forecasting. It addresses the limitations of existing Transformers by integrating multi-scale temporal resolutions and temporal distances through patch division and dual attention. The proposed adaptive pathways adaptively select and aggregate scale-specific characteristics based on the different temporal dynamics, enabling the model to achieve outstanding prediction performance and strong generalization capability.\n\n$\\boxed{Strengths:}$\n1. The paper proposes a novel multi-scale Transformer architecture that integrates both temporal resolution and temporal distance for multi-scale modeling.\n2. The adaptive pathways mechanism allows the model to adaptively select and aggregate scale-specific characteristics based on the different temporal dynamics.\n3. The experiments demonstrate the effectiveness of Pathformer on various real-world datasets, achieving state-of-the-art performance and strong generalization capability.\n\n$\\boxed{Weaknesses:}$\n1. The paper does not provide a detailed analysis of the limitations and challenges of the proposed model, which may be necessary for a comprehensive evaluation.\n2. The experiments are conducted on a limited number of datasets, and it is unclear how the results would generalize to other datasets.\n3. The paper does not provide a detailed explanation of the hyperparameter tuning process, which may be necessary for reproducing the results.\n\n$\\boxed{Suggestions for Improvement:}$\n1. Provide a more detailed analysis of the limitations and challenges of the proposed model, including a discussion of the potential biases and limitations of the adaptive pathways mechanism.\n2. Conduct experiments on a larger number of datasets to demonstrate the generalizability of the results.\n3. Provide a detailed explanation of the hyperparameter tuning process, including the evaluation metrics used and the optimization procedure employed.\n\n$\\boxed{Recommendation:}$\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit the manuscript for further evaluation. Specifically, I suggest that the authors address the limitations and challenges of the proposed model, conduct additional experiments to demonstrate the generalizability of the results, and provide a more detailed explanation of the hyperparameter tuning process. With these revisions, the paper has the potential to make a significant contribution to the field of time series forecasting.\n\n$\\boxed{Rating:}$ 8/10",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$\\boxed{\\$Paper\\ Summary\\$}\nThe paper proposes Pathformer, a multi-scale transformer with adaptive pathways for time series forecasting. It integrates multi-scale temporal resolutions and temporal distances by introducing patch division with multiple patch sizes and dual attention on the divided patches. The adaptive pathways dynamically select and aggregate scale-specific characteristics based on the different temporal dynamics. The paper presents extensive experiments on eleven real-world datasets and achieves state-of-the-art performance by surpassing all current models. The code is made available at https://github.com/decisionintelligence/pathformer.\n\n$$\\boxed{\\$Strengths\\$}\nThe paper presents a comprehensive approach to multi-scale modeling in time series forecasting. The adaptive pathways mechanism allows the model to dynamically select and aggregate scale-specific characteristics based on the different temporal dynamics. The paper also presents extensive experiments on eleven real-world datasets and achieves state-of-the-art performance. The code is made available, which is a significant contribution. The paper also highlights the importance of multi-scale modeling in time series forecasting and provides a detailed analysis of the challenges in this field.\n\n$$\\boxed{\\$Weaknesses\\$}\nThe paper does not provide a detailed analysis of the limitations of the proposed model. The evaluation of the model on a limited number of datasets may not be sufficient to guarantee its performance on other datasets. The paper also does not provide a clear explanation of the choice of hyperparameters and their impact on the model's performance. The paper also does not provide a detailed analysis of the interpretability of the model's results.\n\n$$\\boxed{\\$Suggestions\\ for\\ Improvement\\$}\nThe authors should provide a more detailed analysis of the limitations of the proposed model. They should also provide a more comprehensive evaluation of the model on a larger number of datasets. The authors should also provide a clear explanation of the choice of hyperparameters and their impact on the model's performance. The authors should also provide a detailed analysis of the interpretability of the model's results. Additionally, the authors could consider providing a comparison with other state-of-the-art models in the field.\n\n$$\\boxed{\\$Recommendation\\$}\nBased on the strengths and weaknesses of the paper, I recommend accepting the paper for publication. The paper presents a comprehensive approach to multi-scale modeling in time series forecasting and achieves state-of-the-art performance on eleven real-world datasets. However, the authors should address the limitations of the proposed model and provide a more comprehensive evaluation of the model's performance. Additionally, the authors should provide a clear explanation of the choice of hyperparameters and their impact on the model's performance.",
        "gr_score_with": 0.7940074906367042,
        "gr_score_without": 0.7033333333333334,
        "output_without": {
            "num_tokens_scored": 300,
            "num_green_tokens": 211,
            "green_fraction": 0.7033333333333334,
            "z_score": 0.1259881576697424,
            "p_value": 0.4498706493435857
        },
        "output_with": {
            "num_tokens_scored": 267,
            "num_green_tokens": 212,
            "green_fraction": 0.7940074906367042,
            "z_score": 3.3520342188994356,
            "p_value": 0.00040110051399573334
        }
    },
    {
        "title": "DISSECTING SAMPLE HARDNESS: A FINE-GRAINED ANALYSIS OF HARDNESS CHARACTERIZATION METHODS FOR DATA-CENTRIC AI",
        "abstract": "Characterizing samples that are difficult to learn from is crucial to developing highly performant ML models. This has led to numerous Hardness Characterization Methods (HCMs) that aim to identify \u201chard\u201d samples. However, there is a lack of consensus regarding the definition and evaluation of \u201chardness\u201d. Unfortunately, current HCMs have only been evaluated on specific types of hardness and often only qualitatively or with respect to downstream performance, overlooking the fundamental quantitative identification task. We address this gap by presenting a fine-grained taxonomy of hardness types. Additionally, we propose the Hardness Characterization Analysis Toolkit (H-CAT), which supports comprehensive and quantitative benchmarking of HCMs across the hardness taxonomy and can easily be extended to new HCMs, hardness types, and datasets. We use H-CAT to evaluate 13 different HCMs across 8 hardness types. This comprehensive evaluation encompassing over 14K setups uncovers strengths and weaknesses of different HCMs, leading to practical tips to guide HCM selection and future development. Our findings highlight the need for more comprehensive HCM evaluation, while we hope our hardness taxonomy and toolkit will advance the principled evaluation and uptake of data-centric AI methods.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces the concept of \"sample hardness\" in the context of data-centric AI and proposes a fine-grained taxonomy of hardness types, including mislabeling, outlier, and atypical. It also presents the Hardness Characterization Analysis Toolkit (H-CAT), a comprehensive benchmarking framework for evaluating hardness characterization methods (HCMs). The authors evaluate 13 different HCMs across 8 hardness types using H-CAT and provide insights into the strengths and weaknesses of each HCM. The results show that learning dynamics-based methods with respect to output confidence are effective general-purpose HCMs, while HCMs used for computational efficiency are surprisingly uncompetitive. The paper also highlights the importance of selecting an HCM based on the hardness type and provides practical tips for practitioners.\n\nStrengths:\n1. The paper provides a comprehensive and fine-grained taxonomy of hardness types, which is essential for evaluating HCMs.\n2. The authors propose a robust and flexible benchmarking framework, H-CAT, which can be used to evaluate a wide range of HCMs.\n3. The results show that learning dynamics-based methods with respect to output confidence are effective general-purpose HCMs.\n4. The paper provides practical tips and insights for practitioners, making it a valuable resource for researchers and practitioners in the field.\n\nWeaknesses:\n1. The paper assumes that the reader is familiar with the concepts of data-centric AI and HCMs, which may not be the case for all readers.\n2. The taxonomy of hardness types may be too broad, and some hardness types may be more relevant to certain applications than others.\n3. The evaluation of HCMs using H-CAT may not be comprehensive, as it only evaluates a limited number of HCMs and hardness types.\n4. The paper does not provide a detailed analysis of the limitations and potential biases of H-CAT.\n\nSuggestions for Improvement:\n1. Provide a more detailed analysis of the taxonomy of hardness types and its limitations.\n2. Include a more comprehensive evaluation of HCMs using H-CAT, including more HCMs and hardness types.\n3. Provide a more detailed analysis of the limitations and potential biases of H-CAT.\n4. Include a discussion of the potential applications and implications of the results, including the potential impact on data-centric AI and machine learning.\n\nRecommendation:\nThe paper provides a valuable contribution to the field of data-centric AI and HCMs, and its results have the potential to impact the development of more robust and reliable machine learning models. However, the paper could benefit from a more detailed analysis of the taxonomy of hardness types, a more comprehensive evaluation of HCMs using H-CAT, and a discussion of the potential applications and implications of the results.",
        "peer_review_with_watermark": "$$\\boxed{\\text{Paper Summary: }$ DISSECTING SAMPLE HARDNESS: A FINE-GRAINED ANALYSIS OF HARDNESS CHARACTERIZATION METHODS FOR DATA-CENTRIC AI.}$ \n\nThis paper provides a comprehensive evaluation of Hardness Characterization Methods (HCMs) using a proposed benchmarking framework called Hardness-Characterization Analysis Toolkit (H-CAT). The paper discusses the importance of characterizing samples that are difficult to learn from and the limitations of current HCMs. It proposes a fine-grained taxonomy of hardness types and introduces H-CAT, which supports comprehensive and quantitative benchmarking of HCMs across the hardness taxonomy. The paper evaluates 13 different HCMs across 8 distinct hardness types and provides insights into the capabilities of different HCMs.\n\nStrengths:\n\n1. The paper provides a comprehensive evaluation of HCMs, covering 13 methods across 8 hardness types.\n2. The proposed taxonomy of hardness types offers a systematic and formal definition of different types of sample-level hardness.\n3. H-CAT provides a unified benchmarking framework that can be used to evaluate HCMs and extend to new HCMs and datasets.\n\nWeaknesses:\n\n1. The paper may be challenging to read due to its technical nature and the amount of text.\n2. Some sections of the paper, such as the appendix, may be considered extraneous by readers without a strong background in machine learning.\n\nSuggestions for Improvement:\n\n1. The paper could benefit from more detailed explanations of the H-CAT framework and its components.\n2. The appendix could be condensed or split into separate sections to improve readability.\n3. The paper may consider including more visualizations or plots to illustrate the results and make them more accessible to readers without a strong background in machine learning.\n\nRecommendation:\n\nI recommend accepting the paper for publication. The paper provides a valuable contribution to the field of machine learning and data-centric AI by proposing a comprehensive evaluation of HCMs and introducing a benchmarking framework that can be used to evaluate HCMs. The paper's strengths outweigh its weaknesses, and the suggestions for improvement can be addressed through revisions.",
        "gr_score_with": 0.7944785276073619,
        "gr_score_without": 0.7238372093023255,
        "output_without": {
            "num_tokens_scored": 344,
            "num_green_tokens": 249,
            "green_fraction": 0.7238372093023255,
            "z_score": 0.964772650936776,
            "p_value": 0.16732934857527443
        },
        "output_with": {
            "num_tokens_scored": 326,
            "num_green_tokens": 259,
            "green_fraction": 0.7944785276073619,
            "z_score": 3.722479108839488,
            "p_value": 9.863811797849109e-05
        }
    },
    {
        "title": "DYST: TOWARDS DYNAMIC NEURAL SCENE REPRESENTATIONS ON REAL-WORLD VIDEOS",
        "abstract": "Visual understanding of the world goes beyond the semantics and flat structure of individual images. In this work, we aim to capture both the 3D structure and dynamics of real-world scenes from monocular real-world videos. Our Dynamic Scene Transformer (DyST) model leverages recent work in neural scene representation to learn a latent decomposition of monocular real-world videos into scene content, per-view scene dynamics, and camera pose. This separation is achieved through a novel co-training scheme on monocular videos and our new synthetic dataset DySO. DyST learns tangible latent representations for dynamic scenes that enable view generation with separate control over the camera and the content of the scene.",
        "peer_review_without_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes a novel approach to generative modeling of dynamic 3D visual scenes, called Dynamic Scene Transformer (DyST). DyST learns a separation of the scene into global content and per-view camera pose and scene dynamics, enabling independent control over these factors. The model is trained using a novel latent control swap scheme, which is effective in separating camera pose and scene dynamics in the latent space. DyST is evaluated on synthetic and real-world videos, showing promising view synthesis and scene control capabilities.\n\nStrengths:\n- The proposed latent control swap scheme is effective in separating camera pose and scene dynamics in the latent space.\n- DyST demonstrates promising view synthesis and scene control capabilities on real-world videos of dynamic scenes.\n- The model is capable of handling complex scenes with multiple moving objects and changing lighting conditions.\n\nWeaknesses:\n- The model's view generation quality is currently limited due to the L2 loss, especially for dynamic objects.\n- The paper lacks a detailed analysis of the learned latent representations for scene dynamics and camera pose.\n\nSuggestions for Improvement:\n- Improve the model's generative capabilities using diffusion or GAN-like approaches.\n- Conduct a more detailed analysis of the learned latent representations for scene dynamics and camera pose.\n- Evaluate the model's performance on more complex types of videos, such as videos with multiple independent moving objects or longer camera trajectories.\n\nRecommendation:\n- The proposed DyST model is a significant contribution to the field of neural scene representation learning, enabling separate control over camera pose and scene dynamics in dynamic scenes. With some improvements, DyST has the potential to be a powerful tool for downstream applications, such as video manipulation and control.",
        "peer_review_with_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes DyST, a novel approach for generative modeling of dynamic 3D visual scenes that allows separate control over the camera and the content of the scene. The model learns a separation of the scene into global content and per-view camera pose and scene dynamics, enabling independent control over these factors.\n\nThe authors present a novel training scheme that leverages a synthetic dataset DySO and real-world videos for co-training. The model is evaluated on both synthetic and real-world datasets, demonstrating promising view synthesis and scene control capabilities.\n\nThe authors also investigate the importance of the latent control swap, which is found to be the most suitable training scheme for consistent separation of camera and dynamics in the latent space.\n\nThe paper concludes by highlighting the potential of DyST for learning neural scene representations from real-world scenes and opening the door for exciting down-stream applications.\n\nStrengths:\n\n1. The paper presents a novel approach for generative modeling of dynamic 3D visual scenes that allows separate control over the camera and the content of the scene.\n2. The authors propose a novel training scheme that leverages a synthetic dataset DySO and real-world videos for co-training.\n3. The model is evaluated on both synthetic and real-world datasets, demonstrating promising view synthesis and scene control capabilities.\n4. The authors investigate the importance of the latent control swap, which is found to be the most suitable training scheme for consistent separation of camera and dynamics in the latent space.\n\nWeaknesses:\n\n1. The paper assumes that the reader is familiar with the concept of Neural Radiance Fields (NeRF) and other related techniques, which may be challenging for non-experts.\n2. The authors mention that the model is limited by the L2 loss, which may lead to limited view generation quality, especially for dynamic objects.\n3. The paper does not provide explicit comparisons with other state-of-the-art models, which may limit the reader's understanding of the model's strengths and weaknesses.\n\nSuggestions for Improvement:\n\n1. The authors could provide more explicit comparisons with other state-of-the-art models to highlight the strengths and weaknesses of DyST.\n2. The authors could investigate the impact of the L2 loss on view generation quality and propose potential improvements.\n3. The authors could provide more detailed explanations of the model's components and training procedure to facilitate understanding.\n\nRecommendation:\n\nI recommend that the paper be accepted for publication in its current form, with the authors addressing the weaknesses and suggestions for improvement mentioned above.\n\nAuthor Contributions and Acknowledgments:\n\nThe authors have clearly stated their contributions and acknowledgments, which is good practice.\n\nOverall, the paper presents a novel approach for generative modeling of dynamic 3D visual scenes and demonstrates promising results on both synthetic and real-world datasets. With some revisions to address the weaknesses and suggestions for improvement, the paper has the potential to contribute significantly to the field of computer vision and generative modeling.",
        "gr_score_with": 0.782608695652174,
        "gr_score_without": 0.7215686274509804,
        "output_without": {
            "num_tokens_scored": 255,
            "num_green_tokens": 184,
            "green_fraction": 0.7215686274509804,
            "z_score": 0.751593389883222,
            "p_value": 0.22614780983589977
        },
        "output_with": {
            "num_tokens_scored": 368,
            "num_green_tokens": 288,
            "green_fraction": 0.782608695652174,
            "z_score": 3.458119739469008,
            "p_value": 0.0002719797822211633
        }
    },
    {
        "title": "GROUNDING LANGUAGE PLANS IN DEMONSTRATIONS THROUGH COUNTER-FACTUAL PERTURBATIONS",
        "abstract": "Grounding the abstract knowledge captured by Large Language Models (LLMs) in physical domains remains a pivotal yet unsolved problem. Whereas prior works have largely focused on leveraging LLMs for generating abstract plans in symbolic spaces, this work uses LLMs to guide the learning for structures and constraints in robot manipulation tasks. Specifically, we borrow from manipulation planning literature the concept of mode families, defining specific types of motion constraints among sets of objects, to serve as an intermediate layer that connects high-level language representations with low-level physical trajectories. By locally perturbing a small set of successful human demonstrations, we augment the dataset with additional successful executions as well as counterfactuals that fail the task. Our explanation-based learning framework trains neural network-based classifiers to differentiate success task executions from failures and as a by-product learns classifiers that ground low-level states into mode families without dense labeling. This further enables us to learn structured policies for the target task. Experimental validation in both 2D continuous-space and robotic manipulation environments demonstrates the robustness of our mode-based imitation methods under external perturbations.",
        "peer_review_without_watermark": "$$$\\begin{align}\\textbf{Paper Summary:} &\\quad The authors propose a framework called Manipulation Modes from Language Plans (MMLP) to ground abstract language plans in physical domains using mode families. MMLP leverages language models to generate mode families and counterfactual perturbations to augment the dataset. The framework uses an explanation-based learning paradigm to learn mode family classifiers and control policies. The authors evaluate MMLP on two benchmarks: a synthetic 2D polygon domain and Robosuite, a simulated robot manipulation environment.\\\\\n\\textbf{Strengths:} &\\quad The authors provide a clear and well-structured framework for grounding language plans in physical domains. The use of mode families and counterfactual perturbations is a novel approach to augmenting the dataset. The authors provide a comprehensive evaluation of MMLP on two benchmarks.\\\\\n\\textbf{Weaknesses:} &\\quad The authors' approach relies heavily on the quality of the language model outputs, which may not always be accurate. The use of counterfactual perturbations may not always be effective in augmenting the dataset. The authors' evaluation of MMLP on Robosuite is limited to a few tasks, and it is unclear how well MMLP will perform on more complex tasks.\\\\\n\\textbf{Suggestions for Improvement:} &\\quad The authors should investigate the use of more robust language models that can better handle noisy or ambiguous inputs. The authors should also explore the use of other methods for augmenting the dataset, such as active learning or transfer learning. The authors should provide more detailed evaluations of MMLP on more complex tasks and environments.\\\\\n\\textbf{Recommendation:} &\\quad The authors have made a significant contribution to the field of robotics and reinforcement learning by proposing a novel framework for grounding language plans in physical domains. While there are some limitations and weaknesses in the approach, the authors' evaluation of MMLP on two benchmarks provides strong evidence for the effectiveness of the framework. With further development and refinement, MMLP has the potential to become a leading approach in the field.\n\n$\\end{align}$$",
        "peer_review_with_watermark": "$$$\\begin{aligned}\n\\text{Paper Summary:} \n\\text{This paper proposes a framework, Manipulation Modes from Language Plans (MMLP), to ground abstract knowledge captured by large language models (LLMs) in physical domains. The framework leverages manipulation planning literature and LLMs to learn manipulation mode families from human demonstrations and task descriptions. The mode families enable learning of structured policies for tasks. The paper evaluates MMLP in two environments, a synthetic 2D polygon domain and a robotic manipulation environment, and demonstrates its robustness under external perturbations.}\n\n\\text{Strengths:} \n\\text{1. The framework effectively bridges the gap between abstract language representations and physical domains by leveraging manipulation mode families.}\n\\text{2. The use of counterfactual perturbations to generate additional successful and failed demonstrations is an innovative approach.}\n\\text{3. The experimental results demonstrate the robustness of MMLP in both environments.}\n\n\\text{Weaknesses:} \n\\text{1. The paper requires a large number of human demonstrations, which may be a limitation in scenarios with limited human expertise.}\n\\text{2. The use of LLMs may be limited by their current limitations in handling complex tasks or tasks with high variability.}\n\\text{3. The paper does not provide a detailed analysis of the mode classification accuracy and its relation to the task success rate.}\n\n\\text{Suggestions for Improvement:} \n\\text{1. The paper could benefit from a more detailed analysis of the mode classification accuracy and its relation to the task success rate.}\n\\text{2. The framework could be further improved by incorporating additional loss functions that handle mode classification and policy learning.}\n\\text{3. The paper could explore the use of active learning to reduce the number of human demonstrations required.}\n\n\\text{Recommendation:} \n\\text{I recommend that this paper be published in a conference or journal that focuses on robotics, artificial intelligence, or human-computer interaction. The framework presented in this paper has the potential to make a significant impact in these fields, and its evaluation in two environments demonstrates its robustness under external perturbations.}\n\n\\text{Additional Comments:} \n\\text{Overall, this paper presents an innovative framework that effectively bridges the gap between abstract language representations and physical domains. The use of counterfactual perturbations to generate additional successful and failed demonstrations is an innovative approach. The experimental results demonstrate the robustness of MMLP in both environments. However, the paper could benefit from a more detailed analysis of the mode classification accuracy and its relation to the task success rate. The framework could be further improved by incorporating additional loss functions that handle mode classification and policy learning.}\n\n$$\\end{aligned}$$",
        "gr_score_with": 0.8006042296072508,
        "gr_score_without": 0.7,
        "output_without": {
            "num_tokens_scored": 300,
            "num_green_tokens": 210,
            "green_fraction": 0.7,
            "z_score": 0.0,
            "p_value": 0.5
        },
        "output_with": {
            "num_tokens_scored": 331,
            "num_green_tokens": 265,
            "green_fraction": 0.8006042296072508,
            "z_score": 3.9941152223176752,
            "p_value": 3.2468140736532916e-05
        }
    },
    {
        "title": "IMPROVING EQUILIBRIUM PROPAGATION WITHOUT WEIGHT SYMMETRY THROUGH JACOBIAN HOMEOSTASIS",
        "abstract": "Equilibrium propagation (EP) is a compelling alternative to the backpropagation of error algorithm (BP) for computing gradients of neural networks on biological or analog neuromorphic substrates. Still, the algorithm requires weight symmetry and infinitesimal equilibrium perturbations, i.e., nudges, to yield unbiased gradient estimates. Both requirements are challenging to implement in physical systems. Yet, whether and how weight asymmetry contributes to bias is unknown because, in practice, its contribution may be masked by a finite nudge. To address this question, we study generalized EP, which can be formulated without weight symmetry, and analytically isolate the two sources of bias. For complex-differentiable non-symmetric networks, we show that bias due to finite nudge can be avoided by estimating exact derivatives via a Cauchy integral. In contrast, weight asymmetry induces residual bias through poor alignment of EP\u2019s neuronal error vectors compared to BP resulting in low task performance. To mitigate the latter issue, we present a new homeostatic objective that directly penalizes functional asymmetries of the Jacobian at the network\u2019s fixed point. This homeostatic objective dramatically improves the network\u2019s ability to solve complex tasks such as ImageNet 32\u00d732. Our results lay the theoretical groundwork for studying and mitigating the adverse effects of imperfections of physical networks on learning algorithms that rely on the substrate\u2019s relaxation dynamics.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$The paper presents a generalized form of Equilibrium Propagation (EP) that can be formulated without weight symmetry and analytically isolates the two sources of bias. The authors show that bias due to finite nudge can be avoided by estimating exact derivatives via a Cauchy integral. However, the bias due to weight asymmetry induces residual bias through poor alignment of EP's neuronal error vectors compared to backpropagation (BP) resulting in low task performance.\n\nThe authors propose a new homeostatic objective that directly penalizes functional asymmetries of the Jacobian at the network's fixed point, which dramatically improves the network's ability to solve complex tasks such as ImageNet 32\u00d7 32.\n\nThe main contributions of the paper are:\n\n*   A comprehensive analysis of the individual sources of bias in the gradient estimate from weight asymmetry and finite-size nudge in generalized EP.\n*   An extension of Holomorphic EP to non-symmetric complex-differentiable dynamical systems, that can be estimated through continuous oscillations.\n*   A new homeostatic loss that reduces the asymmetry of the Jacobian at the free equilibrium point without enforcing perfect weight symmetry.\n*   An empirical demonstration that the proposed homeostatic loss improves the network's ability to solve complex tasks such as ImageNet 32\u00d7 32.\n\nThe paper also discusses the theoretical results, including the derivation of the Cauchy integral formula for estimating the neuronal error vector, the analysis of the bias due to weight asymmetry, and the introduction of the homeostatic objective.\n\nThe experiments demonstrate the effectiveness of the proposed homeostatic loss in improving the network's performance on complex tasks such as ImageNet 32\u00d7 32.\n\nOverall, the paper presents a significant contribution to the field of neural networks and neuromorphic substrates, and its results have the potential to improve the performance of neural networks on complex tasks.\n\nHowever, the paper has some limitations. The authors assume that the Jacobian of the network at the fixed point is invertible, which may not always be the case. Additionally, the paper does not discuss the computational complexity of the proposed homeostatic loss, which may be a significant limitation for large-scale neural networks.\n\nTo address these limitations, the authors could explore alternative formulations of the homeostatic objective that are more computationally efficient, or investigate the use of more robust methods for estimating the Jacobian of the network.\n\nIn conclusion, the paper presents a significant contribution to the field of neural networks and neuromorphic substrates, and its results have the potential to improve the performance of neural networks on complex tasks. However, further research is needed to address the limitations of the proposed homeostatic loss and to explore alternative formulations that are more computationally efficient.\n\n$$\\begin{aligned}\n$$The paper's main contributions are:\n\n*   A comprehensive analysis of the individual sources of bias in the gradient estimate from weight asymmetry and finite-size nudge in generalized EP.\n*   An extension of Holomorphic EP to non-symmetric complex-differentiable dynamical systems, that can be estimated through continuous oscillations.\n*   A new homeostatic loss that reduces the asymmetry of the Jacobian at the free equilibrium point without enforcing perfect weight symmetry.\n*   An empirical demonstration that the proposed homeostatic loss improves the network's ability to solve complex tasks such as ImageNet 32\u00d7 32.\n\nThe paper also discusses the theoretical results, including the derivation of the Cauchy integral formula for estimating the neuronal error vector, the analysis of the bias due to weight asymmetry, and the introduction of the homeostatic objective.\n\nThe experiments demonstrate the effectiveness of the proposed homeostatic loss in improving the network's performance on complex tasks such as ImageNet 32\u00d7 32.\n\nOverall, the paper presents a significant contribution to the field of neural networks and neuromorphic substrates, and its results have the potential to improve the performance of neural networks on complex tasks.\n\nHowever, the paper has some limitations. The authors assume that the Jacobian of the network at the fixed point is invertible, which may not always be the case. Additionally, the paper does not discuss the computational complexity of the proposed homeostatic loss, which may be a significant limitation for large-scale neural networks.\n\nTo address these limitations, the authors could explore alternative formulations of the homeostatic objective that are more computationally efficient, or investigate the use of more robust methods for estimating the Jacobian of the network.\n\nIn conclusion, the paper presents a significant contribution to the field of neural networks and neuromorphic substrates, and its results have the potential to improve the performance of neural networks on complex tasks. However, further research is needed to address the limitations of the proposed homeostatic loss and to explore alternative formulations that are more computationally efficient.\n\n$$\\begin{aligned}\n$$The authors provide a comprehensive analysis of the individual sources of bias in the gradient estimate from weight asymmetry and finite-size nudge in generalized EP, and propose a new homeostatic loss that reduces the asymmetry of the Jacobian at the free equilibrium point without enforcing perfect weight symmetry.\n\nThe authors also demonstrate the effectiveness of the proposed homeostatic loss in improving the network's ability to solve complex tasks such as ImageNet 32\u00d7 32.\n\nHowever, the paper has some limitations. The authors assume that the Jacobian of the network at the fixed point is invertible, which may not always be the case. Additionally, the paper does not discuss the computational complexity of the proposed homeostatic loss, which may be a significant limitation for large-scale neural networks.\n\nTo address these limitations, the authors could explore alternative formulations of the homeostatic objective that are more computationally efficient, or investigate the use of more robust methods for estimating the Jacobian of the network.\n\nIn conclusion, the paper presents a significant contribution to the field of neural networks and neuromorphic substrates, and its results have the potential to improve the performance of neural networks on complex tasks. However, further research is needed to address the limitations of the proposed homeostatic loss and to explore alternative formulations that are more computationally efficient.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$Paper Summary: \nThis paper investigates the impact of weight asymmetry and finite nudge on the performance of Equilibrium Propagation (EP), an alternative to backpropagation of error algorithm. The authors analyze EP's gradient estimate and show that it is biased due to weight asymmetry and finite nudge. To mitigate this bias, they introduce a new homeostatic loss that reduces the asymmetry of the Jacobian at the free equilibrium point. The authors evaluate their results on Fashion MNIST and CIFAR-10/100 datasets and show that their approach outperforms traditional methods.\n\n$$Strengths: \n1. The paper provides a clear and concise overview of EP and its limitations.\n2. The authors introduce a novel homeostatic loss that reduces bias in EP's gradient estimate.\n3. The paper evaluates its results on multiple datasets and shows that their approach outperforms traditional methods.\n\n$$Weaknesses: \n1. The paper does not provide a thorough analysis of the mathematical foundations of EP.\n2. The authors do not provide a clear explanation of how their homeostatic loss works.\n3. The paper does not evaluate its results on more complex datasets.\n\n$$Suggestions for Improvement: \n1. The paper should provide a more detailed analysis of the mathematical foundations of EP.\n2. The authors should provide a clear explanation of how their homeostatic loss works.\n3. The paper should evaluate its results on more complex datasets.\n\n$$Recommendation: \nThis paper provides an interesting contribution to the field of EP and its applications. The authors' introduction of a novel homeostatic loss that reduces bias in EP's gradient estimate is a valuable contribution. However, the paper should be further developed to provide a more thorough analysis of its mathematical foundations and to evaluate its results on more complex datasets.",
        "gr_score_with": 0.7841409691629956,
        "gr_score_without": 0.6236842105263158,
        "output_without": {
            "num_tokens_scored": 380,
            "num_green_tokens": 237,
            "green_fraction": 0.6236842105263158,
            "z_score": -3.246359055587426,
            "p_value": 0.9994155434406794
        },
        "output_with": {
            "num_tokens_scored": 227,
            "num_green_tokens": 178,
            "green_fraction": 0.7841409691629956,
            "z_score": 2.7663733444738314,
            "p_value": 0.0028341799442334384
        }
    },
    {
        "title": "GUESS & SKETCH: LANGUAGE MODEL GUIDED TRANSPILATION",
        "abstract": "Maintaining legacy software requires many software and systems engineering hours. Assembly code programs, which demand low-level control over the computer machine state and have no variable names, are particularly difficult for humans to analyze. Existing conventional program translators guarantee correctness, but are hand-engineered for the source and target programming languages in question. Learned transpilation, i.e. automatic translation of code, offers an alternative to manual re-writing and engineering efforts. Automated symbolic program translation approaches guarantee correctness but struggle to scale to longer programs due to the exponentially large search space. Their rigid rule-based systems also limit their expressivity, so they can only reason about a reduced space of programs. Probabilistic neural language models (LMs) produce plausible outputs for every input, but do so at the cost of guaranteed correctness. In this work, we leverage the strengths of LMs and symbolic solvers in a neurosymbolic approach to learned transpilation for assembly code. Assembly code is an appropriate setting for a neurosymbolic approach, since assembly code can be divided into shorter non-branching basic blocks amenable to the use of symbolic methods. GUESS & SKETCH extracts alignment and confidence information from features of the LM then passes it to a symbolic solver to resolve semantic equivalence of the transpilation input and output. We test GUESS & SKETCH on three different test sets of assembly transpilation tasks, varying in difficulty, and show that it successfully transpiles 57.6% more examples than GPT-4 and 39.6% more examples than an engineered transpiler. We also share a training and evaluation dataset for this task.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary: \nThe paper proposes a neurosymbolic approach to assembly-to-assembly transpilation, leveraging the strengths of learned models and symbolic solvers. GUESS & SKETCH extracts alignment and confidence information from features of a language model, then passes it to a symbolic solver to resolve semantic equivalence of the transpilation input and output. The approach is demonstrated on three different test sets of assembly transpilation tasks, varying in difficulty, and shows that it successfully transpiles 57.6% more examples than GPT-4 and 39.6% more examples than an engineered transpiler.\n\n$$Strengths: \n1. The paper presents a novel approach to assembly-to-assembly transpilation, combining the strengths of learned models and symbolic solvers.\n2. The approach is demonstrated on three different test sets of assembly transpilation tasks, varying in difficulty.\n3. The paper shows that GUESS & SKETCH successfully transpiles more examples than existing baselines, including GPT-4 and an engineered transpiler.\n\n$$Weaknesses: \n1. The paper does not provide a comprehensive analysis of the limitations of the proposed approach, including potential pitfalls and challenges.\n2. The approach relies on the availability of a large dataset of paired assembly code sequences, which may not be feasible to obtain for all architectures.\n3. The paper does not provide a detailed explanation of how the symbolic solver is able to resolve semantic equivalence, which may be a critical component of the approach.\n\n$$Suggestions for Improvement: \n1. Provide a more comprehensive analysis of the limitations of the proposed approach, including potential pitfalls and challenges.\n2. Explore the use of other types of data, such as symbolic representations of assembly code, to improve the robustness of the approach.\n3. Investigate the use of more advanced symbolic solvers, such as those using SMT solvers, to improve the ability of the approach to resolve semantic equivalence.\n\n$$Recommendation: \nBased on the strengths and weaknesses of the paper, I recommend that the authors continue to develop and refine the GUESS & SKETCH approach, with a focus on addressing the limitations and challenges identified in the paper. The approach has the potential to be a significant contribution to the field of assembly-to-assembly transpilation, and further research is needed to fully realize its potential.",
        "peer_review_with_watermark": "$$$$\n\nPaper Summary:\nThe paper proposes a neurosymbolic approach to assembly-to-assembly transpilation, called GUESS & SKETCH. It leverages the strengths of learned language models and symbolic solvers to automatically translate assembly code between different instruction set architectures (ISAs). The approach extracts alignment and confidence information from a language model, which is then passed to a symbolic solver to resolve semantic equivalence. The paper demonstrates the efficacy of GUESS & SKETCH on three different test sets of assembly programs in the ARMv8 and RISC-V architectures, outperforming existing approaches.\n\nStrengths:\n1. The paper provides a novel approach to assembly-to-assembly transpilation, combining the strengths of learned language models and symbolic solvers.\n2. The use of a language model to extract alignment and confidence information is a novel aspect of the approach.\n3. The paper demonstrates the efficacy of GUESS & SKETCH on three different test sets of assembly programs.\n4. The approach is able to reduce the number of samples needed from the underlying language model.\n\nWeaknesses:\n1. The paper relies on the availability of large amounts of training data, which may not be feasible for all use cases.\n2. The approach is limited by the context length of generative language models, which may not be sufficient for longer programs.\n3. The paper does not provide a formal proof of equivalence, only checking on a small finite set of inputs.\n4. The approach is dependent on alignment with the source sequence, which may not always be accurate.\n\nSuggestions for Improvement:\n1. Investigate the use of different types of language models, such as convolutional models, to improve the performance of GUESS & SKETCH.\n2. Develop techniques to improve the alignment of the language model with the source sequence, such as live variable analysis.\n3. Investigate the use of more advanced symbolic solvers, such as SMT solvers, to improve the performance of GUESS & SKETCH.\n4. Develop a formal proof of equivalence for GUESS & SKETCH, which would provide a stronger guarantee of correctness.\n\nRecommendation:\nThe paper provides a novel approach to assembly-to-assembly transpilation, which has the potential to improve the performance of existing transpilation tools. However, the approach is limited by several factors, including the reliance on large amounts of training data and the dependency on alignment with the source sequence. Further research is needed to improve the performance and robustness of GUESS & SKETCH.\n\n$$$$",
        "gr_score_with": 0.8238993710691824,
        "gr_score_without": 0.7852564102564102,
        "output_without": {
            "num_tokens_scored": 312,
            "num_green_tokens": 245,
            "green_fraction": 0.7852564102564102,
            "z_score": 3.286205303864218,
            "p_value": 0.0005077348389710592
        },
        "output_with": {
            "num_tokens_scored": 318,
            "num_green_tokens": 262,
            "green_fraction": 0.8238993710691824,
            "z_score": 4.821398344940914,
            "p_value": 7.127768114459901e-07
        }
    },
    {
        "title": "REWARD MODEL ENSEMBLES HELP MITIGATE OVEROPTIMIZATION",
        "abstract": "Reinforcement learning from human feedback (RLHF) is a standard approach for fine-tuning large language models to follow instructions. As part of this process, learned reward models are used to approximately model human preferences. However, as imperfect representations of the \u201ctrue\u201d reward, these learned reward models are susceptible to overoptimization. Gao et al. (2023) studied this phenomenon in a synthetic human feedback setup with a significantly larger \u201cgold\u201d reward model acting as the true reward (instead of humans) and showed that overoptimization remains a persistent problem regardless of the size of the proxy reward model and training data used. Using a similar setup, we conduct a systematic study to evaluate the efficacy of using ensemble-based conservative optimization objectives, specifically worst-case optimization (WCO) and uncertainty-weighted optimization (UWO), for mitigating reward model overoptimization when using two optimization methods: (a) best-of-n sampling (BoN) (b) proximal policy optimization (PPO). We additionally extend the setup of Gao et al. (2023) to include 25% label noise to better mirror real-world conditions. Both with and without label noise, we find that conservative optimization practically eliminates overoptimization and improves performance by up to 70% for BoN sampling. For PPO, ensemble-based conservative optimization always reduces overoptimization and outperforms single reward model optimization. Moreover, combining it with a small KL penalty successfully prevents overoptimization at no performance cost. Overall, our results demonstrate that ensemble-based conservative optimization can effectively counter overoptimization.",
        "peer_review_without_watermark": "$$\n\n$$$Paper Summary:\nThe paper presents a study on mitigating overoptimization in reinforcement learning from human feedback (RLHF) for fine-tuning large language models. The authors propose using ensemble-based conservative optimization objectives, specifically worst-case optimization (WCO) and uncertainty-weighted optimization (UWO), to counter overoptimization. They conduct a systematic study using a synthetic setup and two optimization methods: best-of-n sampling (BoN) and proximal policy optimization (PPO). The results show that ensemble-based conservative optimization methods effectively mitigate overoptimization and improve performance, with up to 70% improvement in some cases.\n\nStrengths:\n1. The paper provides a thorough analysis of overoptimization in RLHF and its impact on performance.\n2. The proposed ensemble-based conservative optimization objectives are well-motivated and effectively counter overoptimization.\n3. The study is systematic and well-structured, with clear results and discussion.\n4. The paper provides a clear and concise summary of the main findings and contributions.\n\nWeaknesses:\n1. The paper assumes a specific setup and may not generalize well to other environments or datasets.\n2. The authors do not provide a detailed analysis of the hyperparameter tuning process for the ensemble-based optimization objectives.\n3. The paper does not provide a comprehensive comparison with other methods for mitigating overoptimization.\n4. Some of the results, such as the performance improvement with up to 70%, are not quantitatively explained.\n\nSuggestions for Improvement:\n1. Provide a more detailed analysis of the hyperparameter tuning process for the ensemble-based optimization objectives.\n2. Conduct a more comprehensive comparison with other methods for mitigating overoptimization.\n3. Quantitatively explain the results, such as the performance improvement with up to 70%.\n4. Provide a more detailed discussion of the implications of the results and potential future work.\n\nRecommendation:\nThe paper presents a well-motivated and effectively counter overoptimization. The results show that ensemble-based conservative optimization methods can effectively mitigate overoptimization and improve performance. However, the paper could benefit from a more detailed analysis of the hyperparameter tuning process and a more comprehensive comparison with other methods. With these improvements, the paper would be more robust and would have a stronger impact on the field. \n\n$$",
        "peer_review_with_watermark": "$$\n\n$$$Paper Summary:\nThe paper presents a systematic study on using ensemble-based conservative optimization methods to mitigate overoptimization in reinforcement learning from human feedback (RLHF) for fine-tuning language models. The authors compare three ensemble-based optimization methods (worst-case optimization (WCO), uncertainty-weighted optimization (UWO), and mean optimization (BoN)) with single reward model optimization for both best-of-n sampling (BoN) and proximal policy optimization (PPO) methods. The results show that ensemble-based conservative optimization methods effectively counter overoptimization and improve performance by up to 70% for BoN sampling.\n\nStrengths:\n1. The paper provides a systematic evaluation of ensemble-based conservative optimization methods for mitigating overoptimization in RLHF.\n2. The authors compare three ensemble-based optimization methods (WCO, UWO, and BoN) with single reward model optimization for both BoN and PPO methods.\n3. The results show that ensemble-based conservative optimization methods effectively counter overoptimization and improve performance.\n4. The paper discusses the robustness of the ensemble-based conservative optimization methods to scaling laws for reward model overoptimization.\n\nWeaknesses:\n1. The paper does not provide a comprehensive analysis of the limitations of the proposed ensemble-based conservative optimization methods.\n2. The authors do not provide a detailed comparison of the ensemble-based conservative optimization methods with other existing methods for mitigating overoptimization.\n3. The paper relies heavily on the results of Gao et al. (2023) and does not provide sufficient evidence to support the claims made in the paper.\n\nSuggestions for Improvement:\n1. The authors should provide a more detailed analysis of the limitations of the proposed ensemble-based conservative optimization methods.\n2. The authors should compare the ensemble-based conservative optimization methods with other existing methods for mitigating overoptimization.\n3. The authors should provide sufficient evidence to support the claims made in the paper.\n\nRecommendation:\nBased on the review, I recommend that the authors revise the paper to address the weaknesses and provide a more comprehensive analysis of the proposed ensemble-based conservative optimization methods. Specifically, the authors should provide a more detailed analysis of the limitations of the proposed methods, compare them with other existing methods, and provide sufficient evidence to support the claims made in the paper. With these revisions, the paper has the potential to contribute significantly to the field of reinforcement learning from human feedback for fine-tuning language models.\n\n$$",
        "gr_score_with": 0.7664233576642335,
        "gr_score_without": 0.6387959866220736,
        "output_without": {
            "num_tokens_scored": 299,
            "num_green_tokens": 191,
            "green_fraction": 0.6387959866220736,
            "z_score": -2.3094355575252905,
            "p_value": 0.9895402880959897
        },
        "output_with": {
            "num_tokens_scored": 274,
            "num_green_tokens": 210,
            "green_fraction": 0.7664233576642335,
            "z_score": 2.3993105254566194,
            "p_value": 0.008212989163933591
        }
    },
    {
        "title": "MULTILINGUAL JAILBREAK CHALLENGES IN LARGE LANGUAGE MODELS",
        "abstract": "While large language models (LLMs) exhibit remarkable capabilities across a wide range of tasks, they pose potential safety concerns, such as the \u201cjailbreak\u201d problem, wherein malicious instructions can manipulate LLMs to exhibit undesirable behavior. Although several preventive measures have been developed to mitigate the potential risks associated with LLMs, they have primarily focused on English. In this study, we reveal the presence of multilingual jailbreak challenges within LLMs and consider two potential risky scenarios: unintentional and intentional. The unintentional scenario involves users querying LLMs using non-English prompts and inadvertently bypassing the safety mechanisms, while the intentional scenario concerns malicious users combining malicious instructions with multilingual prompts to deliberately attack LLMs. The experimental results reveal that in the unintentional scenario, the rate of unsafe content increases as the availability of languages decreases. Specifically, low-resource languages exhibit about three times the likelihood of encountering harmful content compared to high-resource languages, with both ChatGPT and GPT-4. In the intentional scenario, multilingual prompts can exacerbate the negative impact of malicious instructions, with astonishingly high rates of unsafe output: 80.92% for ChatGPT and 40.71% for GPT-4. To handle such a challenge in the multilingual context, we propose a novel SELF-DEFENSE framework that automatically generates multilingual training data for safety fine-tuning. Experimental results show that ChatGPT fine-tuned with such data can achieve a substantial reduction in unsafe content generation. Data is available at https: //github.com/DAMO-NLP-SG/multilingual-safety-for-LLMs. Warning: this paper contains examples with unsafe content.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper presents a study on multilingual jailbreak challenges in large language models (LLMs) and proposes a novel framework called SELF-DEFENCE to enhance multilingual safety capabilities. The authors investigate two risk scenarios: unintentional and intentional, and demonstrate the effectiveness of multilingual jailbreak challenges in both scenarios. They also propose a novel framework called SELF-DEFENCE to tackle this issue and enhance the multilingual safety capabilities of LLMs.\n\nStrengths:\n1. The paper highlights the importance of considering multilingual safety in LLMs, which is a critical aspect of their deployment.\n2. The authors propose a novel framework called SELF-DEFENCE, which is highly effective in enhancing multilingual safety capabilities.\n3. The paper presents extensive experimentation, including results from two risk scenarios: unintentional and intentional.\n4. The authors discuss the trade-offs between safety and usefulness in safety training.\n\nWeaknesses:\n1. The paper does not provide a comprehensive review of existing safety training approaches for LLMs.\n2. The authors rely heavily on their proposed framework, SELF-DEFENCE, which may not be universally applicable.\n3. The paper does not discuss the potential limitations of the proposed framework, such as its potential impact on generalization and performance.\n4. The authors' results may not be generalizable to other LLM architectures or datasets.\n\nSuggestions for Improvement:\n1. The authors should provide a more comprehensive review of existing safety training approaches for LLMs to demonstrate the novelty of their proposed framework.\n2. The authors should discuss the potential limitations of the proposed framework, such as its potential impact on generalization and performance.\n3. The authors should consider evaluating their proposed framework on a diverse set of LLM architectures and datasets to demonstrate its universality.\n4. The authors should provide more detailed explanations of the potential trade-offs between safety and usefulness in safety training.\n\nRecommendation:\nBased on the strengths and weaknesses of the paper, I recommend that it be accepted for publication in a top-tier conference or journal in the field of natural language processing. The authors' proposal of a novel framework called SELF-DEFENCE to enhance multilingual safety capabilities is highly effective, and the paper presents extensive experimentation to demonstrate its effectiveness. However, the authors should address the limitations and potential trade-offs of their proposed framework to strengthen the paper's overall impact.",
        "peer_review_with_watermark": "$$$Paper Summary:\n\nThe paper presents a study on multilingual jailbreak challenges in large language models (LLMs) and proposes a novel framework called SELF-DEFENCE to enhance the safety capabilities of LLMs in multilingual contexts. The authors identify two potential risk scenarios: unintentional and intentional, and demonstrate that multilingual languages can serve as a potential jailbreak method in both scenarios, posing significant threats. The SELF-DEFENCE framework automatically generates multilingual safety training data for safety fine-tuning, and experimental results show its effectiveness in reducing unsafe content generation in both scenarios.\n\nStrengths:\n\n* The paper highlights a crucial aspect of LLMs' safety, which is often overlooked in previous studies.\n* The authors propose a novel framework to address this issue, which has shown promising results.\n* The paper provides a comprehensive evaluation of the SELF-DEFENCE framework, including both theoretical and practical aspects.\n* The authors' use of multilingual data and experiments provides a unique perspective on the problem.\n\nWeaknesses:\n\n* The paper assumes a certain level of expertise in LLMs and safety training, which may not be accessible to all readers.\n* Some of the technical details, such as the specific implementation of the SELF-DEFENCE framework, may be difficult to follow for non-experts.\n* The paper could benefit from more comprehensive evaluation of the effectiveness of the SELF-DEFENCE framework across different languages and scenarios.\n* The authors' assumption that LLMs' safety mechanisms can be bypassed through multilingual languages may not be entirely accurate, and further research is needed to confirm this hypothesis.\n\nSuggestions for Improvement:\n\n* The authors could provide more detailed explanations of technical concepts, such as LLMs' safety mechanisms and multilingual data generation, to make the paper more accessible to non-experts.\n* Additional evaluation of the SELF-DEFENCE framework could be conducted to confirm its effectiveness across different languages and scenarios.\n* The authors could explore alternative approaches to addressing multilingual jailbreak challenges, such as using different safety mechanisms or incorporating more human feedback.\n* The paper could benefit from more comprehensive literature review to provide a more detailed understanding of previous studies on LLMs' safety and multilingual data generation.\n\nRecommendation:\n\nOverall, the paper presents a valuable contribution to the field of LLMs' safety and multilingual data generation. The authors' proposal of the SELF-DEFENCE framework has shown promising results, and further research is needed to confirm its effectiveness across different languages and scenarios. The paper could benefit from more comprehensive evaluation, additional explanations of technical concepts, and exploration of alternative approaches to addressing multilingual jailbreak challenges. However, the authors' findings and contributions make this paper an important read for researchers and practitioners in the field of LLMs and safety training. \n\nScore: 8/10 \n\nNote: The score is based on the reviewer's evaluation of the paper's strengths, weaknesses, and suggestions for improvement, and is intended to provide a general assessment of the paper's quality and relevance to the field. The score is not intended to be a definitive evaluation, and readers are encouraged to form their own opinions based on their own expertise and knowledge of the field.",
        "gr_score_with": 0.7548543689320388,
        "gr_score_without": 0.6770833333333334,
        "output_without": {
            "num_tokens_scored": 288,
            "num_green_tokens": 195,
            "green_fraction": 0.6770833333333334,
            "z_score": -0.8486684247915048,
            "p_value": 0.8019670896455309
        },
        "output_with": {
            "num_tokens_scored": 412,
            "num_green_tokens": 311,
            "green_fraction": 0.7548543689320388,
            "z_score": 2.4296861818370505,
            "p_value": 0.007555950561701407
        }
    },
    {
        "title": "NON-EXCHANGEABLE CONFORMAL RISK CONTROL",
        "abstract": "Split conformal prediction has recently sparked great interest due to its ability to provide formally guaranteed uncertainty sets or intervals for predictions made by black-box neural models, ensuring a predefined probability of containing the actual ground truth. While the original formulation assumes data exchangeability, some extensions handle non-exchangeable data, which is often the case in many real-world scenarios. In parallel, some progress has been made in conformal methods that provide statistical guarantees for a broader range of objectives, such as bounding the best F1-score or minimizing the false negative rate in expectation. In this paper, we leverage and extend these two lines of work by proposing nonexchangeable conformal risk control, which allows controlling the expected value of any monotone loss function when the data is not exchangeable. Our framework is flexible, makes very few assumptions, and allows weighting the data based on its relevance for a given test example; a careful choice of weights may result in tighter bounds, making our framework useful in the presence of change points, time series, or other forms of distribution drift. Experiments with both synthetic and real world data show the usefulness of our method.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary:\nThe paper proposes a new method for conformal risk control, called non-exchangeable conformal risk control (non-X CRC), which allows controlling the expected value of any monotone loss function when the data is not exchangeable. The proposed method is flexible, makes few assumptions, and allows weighting the data based on its relevance for a given test example. The authors demonstrate the usefulness of their framework on three tasks: multilabel classification on synthetic data by minimizing the false negative rate, monitoring electricity usage by minimizing the \u03bb-insensitive absolute loss, and open-domain question answering by bounding the best F1-score.\n\nStrengths:\n1. The proposed method is flexible and allows weighting the data based on its relevance for a given test example, which can lead to tighter bounds.\n2. The method is still valid when the data is not exchangeable and provides a tighter bound on the expected loss than that of previous work.\n3. The authors demonstrate the usefulness of their framework on three tasks, including synthetic data, real-world data, and open-domain question answering.\n\nWeaknesses:\n1. The paper assumes that the weights can be chosen to minimize the coverage gap, but it does not provide a clear method for choosing the weights, especially when the data is non-exchangeable.\n2. The paper relies on the assumption that the loss function is nonincreasing in \u03bb, which may not be true in all cases.\n3. The paper does not provide a clear comparison with other methods for non-exchangeable conformal risk control.\n\nSuggestions for Improvement:\n1. Provide a clear method for choosing the weights, especially when the data is non-exchangeable.\n2. Consider other methods for non-exchangeable conformal risk control and compare them with the proposed method.\n3. Provide a more detailed analysis of the assumptions and limitations of the proposed method.\n\nRecommendation:\nThe proposed method for non-exchangeable conformal risk control is an attractive framework for providing guarantees on the predictions of machine learning models. However, further work is needed to address the limitations and assumptions of the method, especially regarding the choice of weights. The authors should provide a more detailed analysis of the assumptions and limitations of the proposed method and consider other methods for non-exchangeable conformal risk control for a more comprehensive comparison.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$Paper Summary:\nThe paper proposes a method for non-exchangeable conformal risk control, which allows controlling the expected value of any monotone loss function when the data is not exchangeable. The proposed method is flexible, makes few assumptions, and allows weighting the data based on its relevance for a given test example. The authors demonstrate the usefulness of their framework on three tasks: multilabel classification on synthetic data by minimizing the false negative rate; monitoring electricity usage by minimizing the \u03bb-insensitive absolute loss; and open-domain question answering by bounding the best F1-score.\n\nStrengths:\n1. The proposed method is flexible and allows for weighting the data based on its relevance for a given test example.\n2. The method is flexible enough to be used with various loss functions, including monotone loss functions.\n3. The authors demonstrate the usefulness of their framework on three tasks, showcasing its applicability in different domains.\n4. The paper provides a clear and concise explanation of the proposed method, its theoretical guarantees, and its empirical evaluation.\n\nWeaknesses:\n1. The paper assumes that the loss function is monotone, which may not be true in all cases. Relaxing this assumption could make the method more general.\n2. The paper does not provide a detailed analysis of the choice of weights and how they affect the performance of the method.\n3. The empirical evaluation is limited to three tasks, and the results may not be representative of the method's performance in other domains.\n\nSuggestions for Improvement:\n1. Relax the assumption of monotonicity on the loss function to make the method more general.\n2. Provide a detailed analysis of the choice of weights and their impact on the method's performance.\n3. Include a broader empirical evaluation to demonstrate the method's applicability in different domains.\n4. Consider using other methods for comparison, such as standard conformal risk control, to evaluate the proposed method's performance.\n\nRecommendation:\nThe proposed method is a valuable contribution to the field of conformal risk control, offering a flexible and efficient approach to controlling the expected value of loss functions in the presence of non-exchangeable data. However, to further strengthen the method, the authors should address the limitations mentioned above and provide a more comprehensive evaluation of its performance.",
        "gr_score_with": 0.8256880733944955,
        "gr_score_without": 0.7866666666666666,
        "output_without": {
            "num_tokens_scored": 300,
            "num_green_tokens": 236,
            "green_fraction": 0.7866666666666666,
            "z_score": 3.2756920994133023,
            "p_value": 0.0005270170228923937
        },
        "output_with": {
            "num_tokens_scored": 327,
            "num_green_tokens": 270,
            "green_fraction": 0.8256880733944955,
            "z_score": 4.959733007653578,
            "p_value": 3.529506583202848e-07
        }
    },
    {
        "title": "HOW CONNECTIVITY STRUCTURE SHAPES RICH AND LAZY LEARNING IN NEURAL CIRCUITS",
        "abstract": "In theoretical neuroscience, recent work leverages deep learning tools to explore how some network attributes critically influence its learning dynamics. Notably, initial weight distributions with small (resp. large) variance may yield a rich (resp. lazy) regime, where significant (resp. minor) changes to network states and representation are observed over the course of learning. However, in biology, neural circuit connectivity could exhibit a low-rank structure and therefore differs markedly from the random initializations generally used for these studies. As such, here we investigate how the structure of the initial weights \u2014 in particular their effective rank \u2014 influences the network learning regime. Through both empirical and theoretical analyses, we discover that high-rank initializations typically yield smaller network changes indicative of lazier learning, a finding we also confirm with experimentally-driven initial connectivity in recurrent neural networks. Conversely, low-rank initialization biases learning towards richer learning. Importantly, however, as an exception to this rule, we find lazier learning can still occur with a low-rank initialization that aligns with task and data statistics. Our research highlights the pivotal role of initial weight structures in shaping learning regimes, with implications for metabolic costs of plasticity and risks of catastrophic forgetting.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper investigates the impact of initial weight effective rank on learning dynamics in neural networks. The authors derive theoretical results for two-layer feedforward linear networks and validate them through numerical experiments on recurrent neural networks (RNNs). They find that high-rank initializations typically yield smaller network changes indicative of lazier learning, while low-rank initializations bias learning towards richer learning. The authors also identify scenarios where low-rank initial weights still result in effectively lazier learning for specific tasks.\n\nStrengths:\n- The paper provides a comprehensive theoretical framework for understanding the impact of initial weight effective rank on learning dynamics.\n- The authors validate their theoretical results through numerical experiments on RNNs, which adds credibility to their findings.\n- The paper explores the interplay between evolutionary or developmental biases and learning dynamics, which is an interesting and under-explored area.\n\nWeaknesses:\n- The paper assumes that the initial weight structure is the only factor influencing learning dynamics, which might not be the case in real-world scenarios.\n- The authors focus primarily on RNNs, which might limit the generalizability of their findings to other types of neural networks.\n- The paper does not provide a detailed analysis of the limitations and potential biases of the empirical results.\n\nSuggestions for Improvement:\n- The authors should provide a more detailed analysis of the potential limitations and biases of the empirical results.\n- They should explore the impact of initial weight effective rank on learning dynamics in a broader range of neural network architectures.\n- The authors could investigate the interplay between initial weight effective rank and other factors that influence learning dynamics, such as network width, learning rate, and initial gain.\n\nRecommendation:\n- The paper presents an interesting and well-structured theoretical framework for understanding the impact of initial weight effective rank on learning dynamics.\n- The authors provide valuable insights into the interplay between evolutionary or developmental biases and learning dynamics.\n- However, the paper could benefit from a more detailed analysis of the limitations and potential biases of the empirical results, as well as a broader exploration of the impact of initial weight effective rank on learning dynamics in different neural network architectures.",
        "peer_review_with_watermark": "$$\\boxed{\\text{Paper Summary:}}\n$$ The authors investigate the impact of initial weight structure, particularly the effective rank, on learning regimes in neural networks. They explore how the structure of the initial weights, rather than the magnitude, influences the learning dynamics and propose a new definition of effective learning richness and laziness. The authors demonstrate that high-rank initializations typically lead to effectively lazier learning, while low-rank initializations bias learning towards richer learning. However, they also find that lazier learning can occur with low-rank initializations that align with task and data statistics.\n\n$$\\boxed{\\text{Strengths:}}\n$$ \n1. The authors provide a detailed theoretical analysis of the impact of initial weight structure on learning regimes.\n2. The study demonstrates the applicability of the theoretical findings to both feedforward and recurrent neural networks.\n3. The authors propose a new definition of effective learning richness and laziness, which provides a more nuanced understanding of learning regimes.\n4. The study explores the potential implications of the findings for neuroscience, including the impact on metabolic costs and catastrophic forgetting.\n\n$$\\boxed{\\text{Weaknesses:}}\n$$ \n1. The study focuses primarily on RNNs and feedforward networks, and it is unclear how the findings generalize to other architectures.\n2. The authors rely heavily on theoretical analysis and numerical experiments, and it is unclear how the findings would be robustified using more rigorous methods.\n3. The study does not provide a comprehensive review of existing literature on the topic, and it is unclear how the findings relate to other research in the field.\n4. The authors acknowledge the potential limitations of the study, but it is unclear how these limitations can be addressed in future research.\n\n$$\\boxed{\\text{Suggestions for Improvement:}}\n$$ \n1. The authors should strive to provide more rigorous and robust methods for analyzing the impact of initial weight structure on learning regimes.\n2. The study should be expanded to include a more comprehensive review of existing literature on the topic.\n3. The authors should explore the potential implications of the findings for other neural network architectures and learning rules.\n4. The study should be designed to address the potential limitations and uncertainties associated with the findings.\n\n$$\\boxed{\\text{Recommendation:}}\n$$ \nBased on the strengths and weaknesses of the study, I recommend that the authors continue to develop and refine their theoretical analysis and numerical experiments. The study has the potential to make significant contributions to our understanding of learning regimes in neural networks, and I believe that it is essential to address the limitations and uncertainties associated with the findings. With further research and refinement, I expect that the authors will be able to provide more robust and generalizable findings that can be applied to a wider range of neural network architectures and learning rules.",
        "gr_score_with": 0.724233983286908,
        "gr_score_without": 0.7272727272727273,
        "output_without": {
            "num_tokens_scored": 275,
            "num_green_tokens": 200,
            "green_fraction": 0.7272727272727273,
            "z_score": 0.9869275424396534,
            "p_value": 0.1618390804535082
        },
        "output_with": {
            "num_tokens_scored": 359,
            "num_green_tokens": 260,
            "green_fraction": 0.724233983286908,
            "z_score": 1.0019876783675943,
            "p_value": 0.15817477195329327
        }
    },
    {
        "title": "BEYOND IMITATION: LEVERAGING FINE-GRAINED QUALITY SIGNALS FOR ALIGNMENT",
        "abstract": "Alignment with human preference is a desired property of large language models (LLMs). Currently, the main alignment approach is based on reinforcement learning from human feedback (RLHF). Despite the effectiveness of RLHF, it is intricate to implement and train, thus recent studies explore how to develop alternative alignment approaches based on supervised fine-tuning (SFT). A major limitation of SFT is that it essentially does imitation learning, which cannot fully understand what are the expected behaviors. To address this issue, we propose an improved alignment approach named FIGA. Different from prior methods, we incorporate fine-grained (i.e., token or phrase level) quality signals that are derived by contrasting good and bad responses. Our approach has made two major contributions. Firstly, we curate a refined alignment dataset that pairs initial responses and the corresponding revised ones. Secondly, we devise a new loss function can leverage fine-grained quality signals to instruct the learning of LLMs for alignment. Extensive experiments have demonstrated the effectiveness of our approaches by comparing a number of competitive baselines. We release all the above-mentioned resources at https://github.com/RUCAIBox/FIGA.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes a novel approach called FIGA (Fine-grained Quality-aware Alignment) for aligning language models with human preferences. FIGA leverages fine-grained quality signals to enhance the alignment quality during fine-tuning. The approach curates a high-quality alignment dataset by pairing initial responses with revised responses on queries that a LLM cannot perform well. A new learning objective is designed to leverage the fine-grained quality signals by contrasting initial with revised responses. The approach shows superior performance on extensive tasks, outperforming the initial supervised-finetuned model and the strong PPO method.\n\nStrengths:\n1. The approach leverages fine-grained quality signals, which can improve the alignment quality of language models.\n2. FIGA curates a high-quality alignment dataset, which can provide more accurate and relevant training data.\n3. The approach is easy to implement and inherits the merits of supervised fine-tuning (SFT).\n\nWeaknesses:\n1. The paper does not provide a clear comparison with existing alignment methods, such as reinforcement learning from human feedback (RLHF) and other fine-tuning approaches.\n2. The approach relies on the quality of the curated alignment dataset, which may not be comprehensive or representative of all scenarios.\n3. The paper does not discuss potential limitations or challenges of the approach, such as the difficulty of collecting high-quality training data or the potential for overfitting.\n\nSuggestions for Improvement:\n1. The paper should provide a clear comparison with existing alignment methods to demonstrate the effectiveness of FIGA.\n2. The approach should be evaluated on a more comprehensive set of tasks and datasets to demonstrate its generalizability.\n3. The paper should discuss potential limitations and challenges of the approach and propose strategies for addressing them.\n\nRecommendation:\nI recommend that the paper be published as is, with the understanding that the authors should address the limitations and challenges discussed above. The approach has shown promising results and has the potential to improve the alignment quality of language models. With further development and evaluation, FIGA could become a valuable contribution to the field of natural language processing.",
        "peer_review_with_watermark": "$$$Paper Summary:\n\nThe paper proposes FIGA, an alignment approach that leverages fine-grained quality signals to enhance the alignment quality during fine-tuning. The authors curate an alignment dataset that pairs initial responses with revised responses and develop a new loss function that incorporates fine-grained quality signals. The approach inherits the merits of supervised fine-tuning (SFT) and can better understand and learn what are correct behaviors for alignment.\n\nStrengths:\n\n*   The authors provide a clear and concise introduction to the problem and propose a novel approach to align language models with human preferences.\n*   The proposed loss function and alignment dataset are well-designed and can effectively leverage fine-grained quality signals.\n*   The authors provide extensive experimental results that demonstrate the effectiveness of the FIGA approach.\n\nWeaknesses:\n\n*   The paper relies heavily on prior work and does not provide a comprehensive review of the state-of-the-art methods.\n*   The authors do not provide a clear discussion on the limitations and potential biases of the proposed approach.\n*   Some experimental results are not presented in the paper, and the authors rely on external sources for additional information.\n\nSuggestions for Improvement:\n\n*   Provide a more comprehensive review of the state-of-the-art methods and discuss the limitations and potential biases of the proposed approach.\n*   Include all experimental results in the paper to provide a more complete picture of the performance of the FIGA approach.\n*   Consider adding more details on the implementation and training process to provide a better understanding of the proposed approach.\n\nRecommendation:\n\n*   The proposed FIGA approach shows promise in aligning language models with human preferences using fine-grained quality signals.\n*   The authors provide well-designed loss function and alignment dataset that can effectively leverage fine-grained quality signals.\n*   However, the paper relies heavily on prior work and does not provide a comprehensive review of the state-of-the-art methods.\n*   With some revisions to address the limitations and potential biases of the proposed approach, the FIGA approach has the potential to make a significant contribution to the field of natural language processing.",
        "gr_score_with": 0.7816091954022989,
        "gr_score_without": 0.6947040498442367,
        "output_without": {
            "num_tokens_scored": 321,
            "num_green_tokens": 223,
            "green_fraction": 0.6947040498442367,
            "z_score": -0.20705549365186166,
            "p_value": 0.5820167401230746
        },
        "output_with": {
            "num_tokens_scored": 261,
            "num_green_tokens": 204,
            "green_fraction": 0.7816091954022989,
            "z_score": 2.8770651895795343,
            "p_value": 0.0020069633169320328
        }
    },
    {
        "title": "IMPROVED REGRET BOUNDS FOR NON-CONVEX ONLINE-WITHIN-ONLINE META LEARNING",
        "abstract": "Online-Within-Online (OWO) meta learning stands for the online multi-task learning paradigm in which both tasks and data within each task become available in a sequential order. In this work, we study the OWO meta learning of the initialization and step size of within-task online algorithms in the non-convex setting, and provide improved regret bounds under mild assumptions of loss functions. Previous work analyzing this scenario has obtained for bounded and piecewise Lipschitz functions an averaged regret bound O(( \u221a m T 1/4 + (logm) log T \u221a T + V ) \u221a m) across T tasks, with m iterations per task and V the task similarity. Our first contribution is to modify the existing non-convex OWO meta learning algorithm and improve the regret bound to O(( 1 T 1/2\u2212\u03b1 + (log T ) 9/2 T + V ) \u221a m), for any \u03b1 \u2208 (0, 1/2). The derived bound has a faster convergence rate with respect to T , and guarantees a vanishing task-averaged regret with respect to m (for any fixed T ). Then, we propose a new algorithm of regret O(( log T T + V ) \u221a m) for non-convex OWO meta learning. This regret bound exhibits a better asymptotic performance than previous ones, and holds for any bounded (not necessarily Lipschitz) loss functions. Besides the improved regret bounds, our contributions include investigating how to attain generalization bounds for statistical meta learning via regret analysis. Specifically, by online-to-batch arguments, we achieve a transfer risk bound for batch meta learning that assumes all tasks are drawn from a distribution. Moreover, by connecting multi-task generalization error with taskaveraged regret, we develop for statistical multi-task learning a novel PAC-Bayes generalization error bound that involves our regret bound for OWO meta learning.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$\\text{Paper Summary:}$$\nThe paper studies the non-convex online-within-online (OWO) meta learning of the initialization and step size of exponentially weighted aggregation (EWA) algorithm. The authors extend the averaged regret upper bound analysis to the non-convex setting, propose to learn the step size with FollowThe-Leader (FTL) algorithm to guarantee the logarithmic regret, and develop two algorithms for learning the initialization based on the type of loss functions. The authors achieve improved regret bounds for non-convex OWO meta learning and yield a new transfer risk bound for batch meta learning and a novel PAC-Bayes generalization bound for statistical multi-task learning.\n\n$$\\text{Strengths:}$$\n- The paper provides a comprehensive analysis of non-convex OWO meta learning and improves the regret bounds for both piecewise Lipschitz and non-Lipschitz functions.\n- The authors propose two algorithms for learning the initialization based on the type of loss functions, which is a valuable contribution to the field.\n- The paper yields a new transfer risk bound for batch meta learning and a novel PAC-Bayes generalization bound for statistical multi-task learning, which is a significant improvement over existing results.\n\n$$\\text{Weaknesses:}$$\n- The paper assumes a task distribution assumption, which may not be realistic in practice.\n- The analysis of the regret bounds is complex and may be difficult to understand for non-experts.\n- The paper does not provide a clear comparison with other existing results in the field.\n\n$$\\text{Suggestions for Improvement:}$$\n- The authors should provide a more detailed analysis of the task distribution assumption and its implications on the results.\n- The paper should provide a clear comparison with other existing results in the field to demonstrate the novelty and significance of the results.\n- The authors should consider providing a more intuitive explanation of the complex analysis of the regret bounds.\n\n$$\\text{Recommendation:}$$\nBased on the paper's contributions, strengths, and weaknesses, I recommend accepting the paper for publication in a top-tier conference in machine learning. The paper provides a valuable contribution to the field of non-convex online-within-online meta learning and improves the regret bounds for both piecewise Lipschitz and non-Lipschitz functions. However, the authors should address the weaknesses and suggestions for improvement to make the paper more rigorous and accessible to a wider audience.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$The paper provides an improved analysis of the non-convex online-within-online (OWO) meta learning of initialization and step size of exponentially weighted aggregation (EWA) algorithm. The contributions of the paper include improved regret bounds for non-convex OWO meta learning, generalization bounds for statistical meta learning via regret analysis, and a new PAC-Bayes generalization bound for statistical multi-task learning.\n\nThe improved regret bounds for non-convex OWO meta learning can be obtained by learning the initialization and step size with different algorithms. The proposed algorithm for piecewise Lipschitz functions achieves a sublinear regret, while the algorithm for non-Lipschitz functions achieves a logarithmic regret. The improvement in regret bounds is significant, with the new bound being faster than previous results.\n\nThe generalization bounds for statistical meta learning via regret analysis provide a new direction for proving PAC-Bayes bounds for multi-task setting via regret analysis. The proposed transfer risk bound for non-convex batch meta learning and the PAC-Bayes generalization bound for statistical multi-task learning show that regret analysis can be used to prove generalization bounds for statistical meta learning.\n\nThe main contributions of the paper can be summarized as follows:\n\n1. Improved regret bounds for non-convex OWO meta learning. The proposed algorithm for piecewise Lipschitz functions achieves a sublinear regret, while the algorithm for non-Lipschitz functions achieves a logarithmic regret. The improvement in regret bounds is significant, with the new bound being faster than previous results.\n\n2. Generalization bounds for statistical meta learning via regret analysis. The proposed transfer risk bound for non-convex batch meta learning and the PAC-Bayes generalization bound for statistical multi-task learning show that regret analysis can be used to prove generalization bounds for statistical meta learning.\n\n3. New direction for proving PAC-Bayes bounds for multi-task setting via regret analysis. The proposed generalization bounds provide a new direction for proving PAC-Bayes bounds for multi-task setting via regret analysis.\n\nThe paper is well-structured and easy to follow, with clear explanations of the contributions and main results. The notation and definitions are well-explained, and the proofs are clear and concise.\n\nHowever, there are some minor issues with the paper, including:\n\n1. The introduction is a bit lengthy and could be shortened.\n\n2. The notation for the task-averaged regret could be clarified.\n\n3. The proofs of some results could be more detailed.\n\n4. The comparison between the proposed algorithm and previous results could be more detailed.\n\nOverall, the paper provides significant contributions to the field of non-convex online-within-online (OWO) meta learning and statistical meta learning. The improved regret bounds and generalization bounds provide a new direction for proving PAC-Bayes bounds for multi-task setting via regret analysis.\n\n$$\n\\end{aligned}$$",
        "gr_score_with": 0.7929824561403509,
        "gr_score_without": 0.6948051948051948,
        "output_without": {
            "num_tokens_scored": 308,
            "num_green_tokens": 214,
            "green_fraction": 0.6948051948051948,
            "z_score": -0.1989458925207968,
            "p_value": 0.5788474650335712
        },
        "output_with": {
            "num_tokens_scored": 285,
            "num_green_tokens": 226,
            "green_fraction": 0.7929824561403509,
            "z_score": 3.425419743288542,
            "p_value": 0.00030692513097095543
        }
    },
    {
        "title": "CONDITIONAL VARIATIONAL DIFFUSION MODELS",
        "abstract": "Inverse problems aim to determine parameters from observations, a crucial task in engineering and science. Lately, generative models, especially diffusion models, have gained popularity in this area for their ability to produce realistic solutions and their good mathematical properties. Despite their success, an important drawback of diffusion models is their sensitivity to the choice of variance schedule, which controls the dynamics of the diffusion process. Fine-tuning this schedule for specific applications is crucial but time-consuming and does not guarantee an optimal result. We propose a novel approach for learning the schedule as part of the training process. Our method supports probabilistic conditioning on data, provides high-quality solutions, and is flexible, proving able to adapt to different applications with minimum overhead. This approach is tested in two unrelated inverse problems: super-resolution microscopy and quantitative phase imaging, yielding comparable or superior results to previous methods and fine-tuned diffusion models. We conclude that fine-tuning the schedule by experimentation should be avoided because it can be learned during training in a stable way that yields better results. The code is available on https://github.com/casus/cvdm",
        "peer_review_without_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes a novel approach to learning the variance schedule for conditioned diffusion models, which are a type of generative model. The authors extend the Variational Diffusion Models (VDMs) to the conditioned case and introduce a flexible method to learn the schedule that involves minimum fine-tuning. The proposed method, called Conditional Variational Diffusion Model (CVDM), is tested in two unrelated inverse problems: super-resolution microscopy and quantitative phase imaging. The results show that CVDM outperforms previous methods and fine-tuned diffusion models.\n\nStrengths:\n\n* The paper introduces a novel approach to learning the variance schedule for conditioned diffusion models.\n* The proposed method, CVDM, is flexible and can be applied to different applications with minimum overhead.\n* The authors provide a detailed analysis of the performance of CVDM on two inverse problems and compare it with previous methods.\n\nWeaknesses:\n\n* The paper assumes that the variance schedule is learned during training, which may not be the case in practice.\n* The authors do not provide a clear explanation of the regularization term used in the loss function.\n* The paper does not discuss the potential limitations of CVDM, such as the requirement for large amounts of data to train the model.\n\nSuggestions for Improvement:\n\n* The authors should provide a more detailed analysis of the regularization term used in the loss function and its impact on the performance of CVDM.\n* The paper should discuss the potential limitations of CVDM, such as the requirement for large amounts of data to train the model.\n* The authors should provide a more detailed explanation of the theoretical properties of CVDM and its implications for the field.\n\nRecommendation:\n\n* The paper is well-written and provides a clear and concise overview of the proposed method and its results.\n* The authors provide a detailed analysis of the performance of CVDM on two inverse problems and compare it with previous methods.\n* The paper introduces a novel approach to learning the variance schedule for conditioned diffusion models, which has the potential to improve the performance of these models.\n* However, the paper could benefit from a more detailed analysis of the regularization term used in the loss function and its impact on the performance of CVDM.\n* The authors should provide a more detailed explanation of the theoretical properties of CVDM and its implications for the field.\n\n$$$\\boxed{Rating:} 8/10$$",
        "peer_review_with_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes a Conditional Variational Diffusion Model (CVDM) for learning the variance schedule as part of the training process. The authors extend the Variational Diffusion Models (VDMs) to the conditioned case and introduce a novel approach for learning the schedule. The CVDM is tested in two unrelated inverse problems: super-resolution microscopy and quantitative phase imaging, yielding comparable or superior results to previous methods.\n\nStrengths:\n1. The authors provide a detailed theoretical analysis of the CVDM, including the derivation of the forward and reverse processes.\n2. The authors introduce a novel regularization term that proves to be critical for the performance of the method.\n3. The authors provide a detailed analysis of the experiments and results.\n\nWeaknesses:\n1. The authors do not provide a comprehensive comparison with other state-of-the-art methods.\n2. The authors do not discuss the limitations of the CVDM, such as the requirement of a large dataset.\n3. The authors do not provide a detailed analysis of the uncertainty of the reconstruction.\n\nSuggestions for Improvement:\n1. Provide a more comprehensive comparison with other state-of-the-art methods.\n2. Discuss the limitations of the CVDM and provide a detailed analysis of the uncertainty of the reconstruction.\n3. Provide more details on the experimental setup and hyperparameter tuning.\n\nRecommendation:\nThe paper proposes a novel approach for learning the variance schedule in Conditional Variational Diffusion Models. While the authors provide a detailed theoretical analysis and introduce a novel regularization term, the paper lacks a comprehensive comparison with other state-of-the-art methods. I recommend that the authors provide more details on the experimental setup, hyperparameter tuning, and discuss the limitations of the CVDM. Additionally, the authors should provide a more comprehensive comparison with other state-of-the-art methods to demonstrate the superiority of the CVDM.\n\n$$\\boxed{Rating:}$$\nThe paper is well-written and provides a detailed theoretical analysis of the CVDM. However, the lack of a comprehensive comparison with other state-of-the-art methods and the limited discussion of the uncertainty of the reconstruction are significant weaknesses. I would give the paper a rating of 8/10.",
        "gr_score_with": 0.752851711026616,
        "gr_score_without": 0.6981818181818182,
        "output_without": {
            "num_tokens_scored": 275,
            "num_green_tokens": 192,
            "green_fraction": 0.6981818181818182,
            "z_score": -0.0657951694959769,
            "p_value": 0.5262295489557615
        },
        "output_with": {
            "num_tokens_scored": 263,
            "num_green_tokens": 198,
            "green_fraction": 0.752851711026616,
            "z_score": 1.870368926263788,
            "p_value": 0.03071630199186449
        }
    },
    {
        "title": "GRAPH METANETWORKS FOR PROCESSING DIVERSE NEURAL ARCHITECTURES",
        "abstract": "Neural networks efficiently encode learned information within their parameters. Consequently, many tasks can be unified by treating neural networks themselves as input data. When doing so, recent studies demonstrated the importance of accounting for the symmetries and geometry of parameter spaces. However, those works developed architectures tailored to specific networks such as MLPs and CNNs without normalization layers, and generalizing such architectures to other types of networks can be challenging. In this work, we overcome these challenges by building new metanetworks \u2014 neural networks that take weights from other neural networks as input. Put simply, we carefully build graphs representing the input neural networks and process the graphs using graph neural networks. Our approach, Graph Metanetworks (GMNs), generalizes to neural architectures where competing methods struggle, such as multi-head attention layers, normalization layers, convolutional layers, ResNet blocks, and group-equivariant linear layers. We prove that GMNs are expressive and equivariant to parameter permutation symmetries that leave the input neural network functions unchanged. We validate the effectiveness of our method on several metanetwork tasks over diverse neural network architectures.",
        "peer_review_without_watermark": "$$\\boxed{\\text{Paper Summary:}}$$\n\nThe paper proposes Graph Metanetworks (GMNs), a new approach to processing neural networks by representing them as graphs and using graph neural networks (GNNs) to learn representations. GMNs are designed to be equivariant to parameter permutation symmetries, which are symmetries in the parameter space of a neural network that leave the network function unchanged. The authors prove that GMNs are expressive and equivariant to neural DAG automorphisms, which are structure-preserving transformations of a graph unto itself. The authors validate the effectiveness of GMNs on several metanetwork tasks over diverse neural network architectures.\n\n$$\\boxed{\\text{Strengths:}}$$\n\n1. GMNs are designed to be equivariant to parameter permutation symmetries, which is a challenging task in metanet design.\n2. The authors provide a compact parameter graph representation that can handle parameter-sharing layers like convolutions and attention layers without scaling with the activation count.\n3. The authors prove that GMNs are expressive and equivariant to neural DAG automorphisms, which is a key result in metanet design.\n4. The authors provide empirical evaluations of GMNs on several metanetwork tasks, including image classification and editing tasks.\n\n$$\\boxed{\\text{Weaknesses:}}$$\n\n1. The paper assumes that the input neural network is a feedforward architecture, which may not be the case in practice.\n2. The authors do not provide a formal analysis of the computational complexity of GMNs, which may be a concern for large neural networks.\n3. The paper does not discuss the potential limitations of GMNs in terms of the types of neural networks they can process.\n4. The authors do not provide a detailed comparison with other metanet architectures, which may be useful for readers who are familiar with other approaches.\n\n$$\\boxed{\\text{Suggestions for Improvement:}}$$\n\n1. The authors should provide a more detailed analysis of the computational complexity of GMNs and discuss potential optimizations for large neural networks.\n2. The authors should discuss the potential limitations of GMNs in terms of the types of neural networks they can process.\n3. The authors should provide a detailed comparison with other metanet architectures to provide context for the results.\n4. The authors should consider adding more experiments to evaluate the performance of GMNs on different neural network architectures.\n\n$$\\boxed{\\text{Recommendation:}}$$\n\nBased on the paper's results and analysis, I recommend that the authors continue to develop and refine GMNs, potentially incorporating optimizations for large neural networks and exploring their applicability to other types of neural networks. The paper's contributions to the field of metanets are significant, and with further development, GMNs have the potential to become a powerful tool for processing and analyzing neural networks.",
        "peer_review_with_watermark": "$$\\begin{align}\\textbf{Paper Summary:} & \\text{The paper proposes Graph Metanetworks, a novel approach to process neural networks with diverse architectures. The authors develop a method to construct graphs representing neural networks and process these graphs using graph neural networks. They prove that their approach is expressive and equivariant to parameter permutation symmetries. The authors validate the effectiveness of their method on several metanet tasks over diverse neural network architectures.}\n\n\\textbf{Strengths:} & 1. The authors develop a novel approach to process neural networks with diverse architectures. 2. The approach is expressive and equivariant to parameter permutation symmetries. 3. The authors prove the theoretical results of their approach. 4. The authors validate the effectiveness of their method on several metanet tasks.\n\n\\textbf{Weaknesses:} & 1. The approach may not be efficient for large neural networks due to the computational complexity of processing graphs. 2. The authors do not provide a detailed analysis of the scalability of their approach. 3. The approach only accounts for permutation-based parameter symmetries and does not account for e.g. symmetries induced by scaling weights in ReLU networks.\n\n\\textbf{Suggestions for Improvement:} & 1. The authors should provide a detailed analysis of the scalability of their approach to handle large neural networks. 2. The authors should extend their theoretical results to account for symmetries induced by scaling weights in ReLU networks. 3. The authors should explore the use of standard scalable GNN methods to scale up their approach.\n\n\\textbf{Recommendation:} & The paper proposes a novel approach to process neural networks with diverse architectures, and the authors develop a method to construct graphs representing neural networks and process these graphs using graph neural networks. The approach is expressive and equivariant to parameter permutation symmetries, and the authors prove the theoretical results of their approach. However, the authors should provide a detailed analysis of the scalability of their approach to handle large neural networks and extend their theoretical results to account for symmetries induced by scaling weights in ReLU networks.",
        "gr_score_with": 0.8199052132701422,
        "gr_score_without": 0.7068965517241379,
        "output_without": {
            "num_tokens_scored": 348,
            "num_green_tokens": 246,
            "green_fraction": 0.7068965517241379,
            "z_score": 0.2807449625374392,
            "p_value": 0.3894530099563325
        },
        "output_with": {
            "num_tokens_scored": 211,
            "num_green_tokens": 173,
            "green_fraction": 0.8199052132701422,
            "z_score": 3.8007529928978423,
            "p_value": 7.212852419789856e-05
        }
    },
    {
        "title": "LAYOUTNUWA: REVEALING THE HIDDEN LAYOUT EXPERTISE OF LARGE LANGUAGE MODELS",
        "abstract": "Graphic layout generation plays a significant role in user engagement and information perception. Existing methods primarily treat layout generation as a numerical optimization task, focusing on quantitative aspects while overlooking the semantic information of layout, such as the relationship between each layout element. In this paper, we propose LayoutNUWA, the first model that treats layout generation as a code generation task to enhance semantic information and harnesses the hidden layout expertise of large language models (LLMs). More concretely, we develop a Code Instruct Tuning (CIT) approach comprising three interconnected modules: 1) the Code Initialization (CI) module quantifies the numerical conditions and initializes them as HTML code with strategically placed masks; 2) the Code Completion (CC) module employs the formatting knowledge of LLMs to fill in the masked portions within the HTML code; 3) the Code Rendering (CR) module transforms the completed code into the final layout output, ensuring a highly interpretable and transparent layout generation procedure that directly maps code to a visualized layout. We attain significant state-of-the-art performance (even over 50% improvements) on multiple datasets, showcasing the strong capabilities of LayoutNUWA. Our code is available at https://github.com/ProjectNUWA/LayoutNUWA. \u2217Both authors contributed equally to this research. During Zecheng\u2019s internship under the mentorship of Chenfei at MSRA. \u2020Corresponding author.",
        "peer_review_without_watermark": "$$\n\\begin{align*}\nPaper Summary:\nThe paper proposes LayoutNUWA, a novel approach to treating layout generation as a code generation task to enhance semantic information and leverage the hidden expertise of large language models (LLMs). The approach, called Code Instruct Tuning (CIT), comprises three interconnected modules: Code Initialization, Code Completion, and Code Rendering. LayoutNUWA achieves significant state-of-the-art performance on multiple datasets, showcasing its robust capabilities.\n\nStrengths:\n1.  The approach of treating layout generation as a code generation task is innovative and can effectively capture semantic information.\n2.  The use of LLMs in the Code Completion module enhances the accuracy and consistency of generated layouts.\n3.  The Code Rendering module ensures a highly interpretable and transparent layout generation procedure.\n4.  The extensive experiments on multiple datasets demonstrate the superiority of LayoutNUWA.\n\nWeaknesses:\n1.  The model performance declines significantly without the code template, highlighting the importance of the CIT tuning method.\n2.  The numerical tuning method without the task instruction is far inferior compared to the CIT approach, indicating that the CIT method calibrates the prior code knowledge of LLMs effectively.\n3.  The model fails to generate logical layouts when predicting only the masked values, highlighting the need for the CIT approach to generate the entire code sequence.\n\nSuggestions for Improvement:\n1.  Further explore the potential of the CIT tuning method in different domains and tasks.\n2.  Investigate the effectiveness of incorporating additional semantic information into the code generation task.\n3.  Develop methods to improve the logical coherence of generated layouts.\n\nRecommendation:\nBased on the innovative approach and extensive experimental results, I strongly recommend the publication of this paper in a top-tier conference or journal. The work has the potential to revolutionize the field of layout generation and pave the way for further exploration and development of semantic-aware layout generation approaches.\n\n$$",
        "peer_review_with_watermark": "$$\\boxed{\\text{Paper Summary:}}$$\n\nThe paper presents the LayoutNUWA model, which treats layout generation as a code generation task to enhance semantic information and leverage the hidden expertise of large language models (LLMs). The model employs a Code Instruct Tuning (CIT) approach comprising three modules: Code Initialization, Code Completion, and Code Rendering. The authors demonstrate the superiority of LayoutNUWA on multiple datasets, including a 50% improvement over the best baseline on the low-resource Magazine dataset.\n\n$$\\boxed{\\text{Strengths:}}$$\n\n1.  The paper presents a novel approach to treating layout generation as a code generation task, effectively leveraging the semantic information and expertise of LLMs.\n2.  The Code Instruct Tuning (CIT) approach is innovative and well-implemented, demonstrating the potential for significant performance enhancements.\n3.  The authors provide extensive experiments on multiple datasets, demonstrating the robustness and generalization of the LayoutNUWA model.\n4.  The paper provides a thorough analysis of the related work and highlights the limitations of existing methods.\n\n$$\\boxed{\\text{Weaknesses:}}$$\n\n1.  The paper may benefit from a more detailed analysis of the limitations and challenges associated with the CIT approach.\n2.  Some of the experimental results may be difficult to interpret due to the complexity of the layouts and the use of multiple evaluation metrics.\n3.  The paper does not discuss potential future work or directions for further research.\n\n$$\\boxed{\\text{Suggestions for Improvement:}}$$\n\n1.  The authors should provide a more detailed analysis of the CIT approach, including its strengths and limitations, and discuss potential challenges and future work.\n2.  The experimental results should be presented in a clearer and more concise manner, with a focus on the key findings and insights.\n3.  The paper should discuss the potential applications and implications of the LayoutNUWA model, including its potential impact on various industries and fields.\n\n$$\\boxed{\\text{Recommendation:}}$$\n\nBased on the paper's presentation of a novel and innovative approach to layout generation, its thorough analysis of the related work, and its extensive experimental results, we strongly recommend the publication of this paper. The authors have made significant contributions to the field of layout generation and have demonstrated the potential for significant performance enhancements with their Code Instruct Tuning (CIT) approach.",
        "gr_score_with": 0.7885196374622356,
        "gr_score_without": 0.7467948717948718,
        "output_without": {
            "num_tokens_scored": 312,
            "num_green_tokens": 233,
            "green_fraction": 0.7467948717948718,
            "z_score": 1.8037066705420157,
            "p_value": 0.0356386516415495
        },
        "output_with": {
            "num_tokens_scored": 331,
            "num_green_tokens": 261,
            "green_fraction": 0.7885196374622356,
            "z_score": 3.514341622039276,
            "p_value": 0.00022042273304279415
        }
    },
    {
        "title": "ERAL GEOMETRY FOR KNOWLEDGE DISTILLATION",
        "abstract": "Knowledge distillation aims to train a compact student network using soft supervision from a larger teacher network and hard supervision from ground truths. However, determining an optimal knowledge fusion ratio that balances these supervisory signals remains challenging. Prior methods generally resort to a constant or heuristic-based fusion ratio, which often falls short of a proper balance. In this study, we introduce a novel adaptive method for learning a sample-wise knowledge fusion ratio, exploiting both the correctness of teacher and student, as well as how well the student mimics the teacher on each sample. Our method naturally leads to the intra-sample trilateral geometric relations among the student prediction (S), teacher prediction (T ), and ground truth (G). To counterbalance the impact of outliers, we further extend to the inter-sample relations, incorporating the teacher\u2019s global average prediction (T\u0304 ) for samples within the same class. A simple neural network then learns the implicit mapping from the intraand inter-sample relations to an adaptive, sample-wise knowledge fusion ratio in a bilevel-optimization manner. Our approach provides a simple, practical, and adaptable solution for knowledge distillation that can be employed across various architectures and model sizes. Extensive experiments demonstrate consistent improvements over other loss re-weighting methods on image classification, attack detection, and click-through rate prediction.",
        "peer_review_without_watermark": "$$$\\begin{align*}\n\\textbf{Paper Summary:} \\\\\n\\text{The paper proposes a novel approach called TGeo-KD for learning sample-wise knowledge fusion ratios in knowledge distillation (KD). It leverages trilateral geometry among the student prediction, teacher prediction, and ground truth by modeling both intra- and inter-sample geometric relations. The method is shown to outperform other re-weighting methods consistently across diverse domains.}\n\n\\textbf{Strengths:} \\\\\n1. The paper introduces a novel approach to learning sample-wise knowledge fusion ratios in KD, which is a critical component of KD techniques.\n2. The method leverages trilateral geometry, which provides a comprehensive representation of the relationships among the student prediction, teacher prediction, and ground truth.\n3. The paper presents extensive experiments across various domains, including image classification, attack detection, and click-through rate prediction.\n4. The results demonstrate the effectiveness of the proposed method in outperforming other re-weighting methods.\n\n\\textbf{Weaknesses:} \\\\\n1. The paper does not provide a clear motivation for the use of trilateral geometry in KD, which may limit the generalizability of the method.\n2. The experimental results are extensive, but some of the baselines may not be directly comparable to the proposed method.\n3. The paper does not discuss potential limitations or challenges of the proposed method, such as the impact of outliers or class imbalance.\n\n\\textbf{Suggestions for Improvement:} \\\\\n1. Provide a clear motivation for the use of trilateral geometry in KD, and discuss potential limitations or challenges of the proposed method.\n2. Compare the proposed method to other state-of-the-art KD techniques more directly, using identical experimental settings and metrics.\n3. Discuss potential extensions or variations of the proposed method, such as incorporating other types of relationships or relationships among multiple samples.\n\n\\textbf{Recommendation:} \\\\\nBased on the strengths and weaknesses of the paper, I recommend accepting the paper for publication in its current form, with the caveat that the authors address the limitations and challenges discussed in the suggestions for improvement. The paper presents a novel approach to learning sample-wise knowledge fusion ratios in KD, and the experimental results demonstrate its effectiveness. With some revisions to address the limitations and challenges, the paper has the potential to make a significant contribution to the field of KD.\n\n\\text{Rating:} 8/10\n\n$$\n\\end{align*}",
        "peer_review_with_watermark": "$$$\\begin{gathered}\n\\text{Paper Summary:} \\\\\n\\text{This paper proposes TGeo-KD, a novel method for learning sample-wise knowledge fusion ratios in knowledge distillation.}\\\\\n\\text{The proposed method leverages the trilateral geometry among the signals from the student, teacher, and ground truth to capture both intra- and inter-sample geometric relations.}\\\\\n\\text{The method is demonstrated to be effective in various tasks such as image classification, attack detection, and click-through rate prediction.}\\\\\n\\text{The proposed method is compared with existing loss re-weighting methods, demonstrating its superiority in terms of performance.}\\\\\n\\text{The paper also provides insights into the importance of the student-ground truth (SG) and teacher-ground truth (TG) relations in knowledge distillation.}\\\\\n\\end{gathered}\n\n\\begin{gathered}\n\\text{Strengths:} \\\\\n\\text{The paper provides a clear motivation for the need of a novel method in knowledge distillation.}\\\\\n\\text{The proposed method is demonstrated to be effective in various tasks.}\\\\\n\\text{The paper provides insights into the importance of the student-ground truth (SG) and teacher-ground truth (TG) relations in knowledge distillation.}\\\\\n\\text{The method is simple to implement and can be employed across various architectures and model sizes.}\\\\\n\\end{gathered}\n\n\\begin{gathered}\n\\text{Weaknesses:} \\\\\n\\text{The paper does not provide enough experimental results to demonstrate the superiority of the proposed method.}\\\\\n\\text{The paper does not provide any comparison with other methods on the same scale as the proposed method.}\\\\\n\\text{The paper does not provide any discussion on the limitations of the proposed method.}\\\\\n\\text{The paper does not provide any insights into the impact of the proposed method on the training time.}\\\\\n\\end{gathered}\n\n\\begin{gathered}\n\\text{Suggestions for Improvement:} \\\\\n\\text{The paper should provide more experimental results to demonstrate the superiority of the proposed method.}\\\\\n\\text{The paper should provide a comparison with other methods on the same scale as the proposed method.}\\\\\n\\text{The paper should provide a discussion on the limitations of the proposed method.}\\\\\n\\text{The paper should provide insights into the impact of the proposed method on the training time.}\\\\\n\\end{gathered}\n\n\\begin{gathered}\n\\text{Recommendation:} \\\\\n\\text{Based on the provided paper, the proposed method TGeo-KD is recommended to be used in knowledge distillation tasks.}\\\\\n\\text{However, the paper should be further improved to provide more experimental results and a comparison with other methods.}\\\\\n\\text{The paper should be further improved to provide a discussion on the limitations of the proposed method.}\\\\\n\\end{gathered}\n\n$$\\$",
        "gr_score_with": 0.7845528455284553,
        "gr_score_without": 0.7337278106508875,
        "output_without": {
            "num_tokens_scored": 338,
            "num_green_tokens": 248,
            "green_fraction": 0.7337278106508875,
            "z_score": 1.3531216842829603,
            "p_value": 0.08800837962739566
        },
        "output_with": {
            "num_tokens_scored": 246,
            "num_green_tokens": 193,
            "green_fraction": 0.7845528455284553,
            "z_score": 2.893917419916233,
            "p_value": 0.0019023410494402484
        }
    },
    {
        "title": "R-MAE: REGIONS MEET MASKED AUTOENCODERS",
        "abstract": "In this work, we explore regions as a potential visual analogue of words for selfsupervised image representation learning. Inspired by Masked Autoencoding (MAE), a generative pre-training baseline, we propose masked region autoencoding to learn from groups of pixels or regions. Specifically, we design an architecture which efficiently addresses the one-to-many mapping between images and regions, while being highly effective especially with high-quality regions. When integrated with MAE, our approach (R-MAE) demonstrates consistent improvements across various pre-training datasets and downstream detection and segmentation benchmarks, with negligible computational overheads. Beyond the quantitative evaluation, our analysis indicates the models pre-trained with masked region autoencoding unlock the potential for interactive segmentation.1",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes a novel approach called R-MAE (Region-aware Masked Autoencoding) that integrates regions into the Masked Autoencoding (MAE) framework for self-supervised image representation learning. The authors explore the concept of regions as a potential visual analogue of words for pre-training, which can unlock the potential for interactive segmentation. They propose a masked region autoencoding task, which is a reconstructive pre-text task to learn from groups of pixels or regions. The authors demonstrate the effectiveness of R-MAE on various pre-training datasets and downstream detection and segmentation benchmarks.\n\nStrengths:\n\n* The paper introduces a novel approach that integrates regions into the MAE framework, which can lead to more effective pre-training.\n* The authors demonstrate the effectiveness of R-MAE on various pre-training datasets and downstream detection and segmentation benchmarks.\n* The paper provides a thorough analysis of the strengths and weaknesses of different region generation methods and their impact on R-MAE performance.\n\nWeaknesses:\n\n* The paper may be too focused on the technical details of the proposed approach, which may make it difficult for non-experts to understand the overall architecture and its implications.\n* The authors may not have thoroughly explored the limitations of their approach, such as the potential for overfitting or the impact of region quality on R-MAE performance.\n* The paper may benefit from more comprehensive evaluation of the proposed approach on a wider range of tasks and datasets.\n\nSuggestions for Improvement:\n\n* The authors should provide more detailed explanations of the technical details of the proposed approach, including the architecture and the hyperparameters used.\n* The authors should conduct a more comprehensive evaluation of the proposed approach on a wider range of tasks and datasets, including more challenging benchmarks and datasets.\n* The authors should explore the potential limitations of their approach, such as the potential for overfitting or the impact of region quality on R-MAE performance.\n\nRecommendation:\n\n* Based on the paper's contributions and the authors' efforts, I recommend accepting the paper for publication in a top-tier conference or journal in computer vision.\n* However, I also recommend that the authors revise the paper to address the weaknesses and limitations mentioned above, and to provide more comprehensive evaluations of the proposed approach.\n\n$$$",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper proposes a novel approach called R-MAE, which integrates masked region autoencoding into Masked Autoencoding (MAE) to improve pre-training efficiency and effectiveness in computer vision tasks. The authors explore regions as a potential visual analogue of words for self-supervised image representation learning, and propose a masked region autoencoding architecture to learn from groups of pixels or regions. The proposed approach, R-MAE, demonstrates consistent improvements across various pre-training datasets and downstream detection and segmentation benchmarks, with negligible computational overheads.\n\nStrengths:\n1. The authors provide a clear motivation for exploring regions as a visual analogue of words in computer vision, highlighting the potential benefits of learning from regions in improving pre-training efficiency and effectiveness.\n2. The proposed R-MAE architecture is well-designed and effectively addresses the one-to-many mapping problem between images and regions.\n3. The authors provide a thorough experimental evaluation, including ablation studies, which demonstrate the effectiveness and efficiency of R-MAE.\n\nWeaknesses:\n1. The authors rely heavily on pre-computed regions, which may not be representative of real-world scenarios. Future work could explore the use of dynamic regions or regions generated from SAM.\n2. The authors do not discuss potential biases in regions, such as the potential for regions to be biased towards specific object classes or regions.\n3. The authors' approach may not generalize well to other image-related tasks, such as image generation or image-to-image translation.\n\nSuggestions for Improvement:\n1. The authors could explore the use of dynamic regions or regions generated from SAM to improve the generalizability of R-MAE.\n2. The authors could discuss potential biases in regions and explore methods to mitigate these biases.\n3. The authors could evaluate R-MAE on a wider range of image-related tasks to demonstrate its effectiveness and generalizability.\n\nRecommendation:\nThe proposed R-MAE approach is a valuable contribution to the field of computer vision pre-training, and demonstrates significant improvements in pre-training efficiency and effectiveness. The authors' thorough experimental evaluation and well-designed architecture make R-MAE a promising approach for future research. With some potential limitations and biases addressed, R-MAE has the potential to become a state-of-the-art approach in computer vision pre-training.",
        "gr_score_with": 0.7872340425531915,
        "gr_score_without": 0.6852459016393443,
        "output_without": {
            "num_tokens_scored": 305,
            "num_green_tokens": 209,
            "green_fraction": 0.6852459016393443,
            "z_score": -0.5622804020997708,
            "p_value": 0.7130375056364018
        },
        "output_with": {
            "num_tokens_scored": 329,
            "num_green_tokens": 259,
            "green_fraction": 0.7872340425531915,
            "z_score": 3.4528228763727298,
            "p_value": 0.0002773765668225604
        }
    },
    {
        "title": "A RESTORATION NETWORK",
        "abstract": "Image denoisers have been shown to be powerful priors for solving inverse problems in imaging. In this work, we introduce a generalization of these methods that allows any image restoration network to be used as an implicit prior. The proposed method uses priors specified by deep neural networks pre-trained as general restoration operators. The method provides a principled approach for adapting state-of-the-art restoration models for other inverse problems. Our theoretical result analyzes its convergence to a stationary point of a global functional associated with the restoration operator. Numerical results show that the method using a super-resolution prior achieves state-of-the-art performance both quantitatively and qualitatively. Overall, this work offers a step forward for solving inverse problems by enabling the use of powerful pre-trained restoration models as priors.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces the Deep Restoration Priors (DRP) methodology, which enables the use of powerful pre-trained restoration models as priors for solving inverse problems. The authors propose a new method that uses a pre-trained deep restoration network as a prior, and provide a theoretical analysis of its convergence to a stationary point of a global functional associated with the restoration operator. The paper also presents numerical results showing that DRP can achieve state-of-the-art performance on image deblurring and super-resolution tasks.\n\nStrengths:\n1. The paper introduces a new and innovative approach to using pre-trained restoration models as priors for solving inverse problems.\n2. The authors provide a thorough theoretical analysis of the convergence of DRP, which extends the recent work using denoisers as priors.\n3. The paper presents numerical results showing the effectiveness of DRP on image deblurring and super-resolution tasks.\n\nWeaknesses:\n1. The paper assumes that the prior density px is non-degenerate over Rn, which may not be the case in all applications.\n2. The authors do not provide a detailed analysis of the robustness of DRP to noise and other forms of corruption.\n3. The paper does not provide a comparison with other state-of-the-art methods for solving inverse problems.\n\nSuggestions for Improvement:\n1. The authors should provide a more detailed analysis of the assumptions made in the paper, and discuss potential extensions and generalizations.\n2. The paper should provide a comparison with other state-of-the-art methods for solving inverse problems, to demonstrate the effectiveness of DRP.\n3. The authors should provide a more detailed analysis of the robustness of DRP to noise and other forms of corruption.\n\nRecommendation:\nI recommend that the paper be accepted for publication in its current form, with the understanding that the authors will address the suggestions for improvement outlined above. The paper presents a novel and innovative approach to using pre-trained restoration models as priors for solving inverse problems, and provides a thorough theoretical analysis of its convergence. The numerical results showing the effectiveness of DRP on image deblurring and super-resolution tasks are also strong.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper proposes a new method called Deep Restoration Priors (DRP) for solving inverse problems in imaging using pre-trained restoration operators as priors. The method is based on the idea of using a deep neural network to specify a prior model for the image, which is then used to regularize the solution of the inverse problem. The authors provide a theoretical analysis of the method's convergence and show that it can be used to solve a variety of inverse problems, including image deblurring and super-resolution.\n\nStrengths:\n- The paper provides a new and innovative approach to using pre-trained restoration operators as priors for solving inverse problems.\n- The authors provide a thorough theoretical analysis of the method's convergence and show that it can be used to solve a variety of inverse problems.\n- The paper includes numerical experiments that demonstrate the effectiveness of the DRP method.\n\nWeaknesses:\n- The paper assumes that the reader has a strong background in deep learning and inverse problems, which may make it difficult for non-experts to follow.\n- The paper could benefit from more detailed explanations of the mathematical concepts used in the analysis.\n- The numerical experiments could be improved by including more detailed comparisons with other methods.\n\nSuggestions for Improvement:\n- Provide more detailed explanations of the mathematical concepts used in the analysis to make the paper more accessible to non-experts.\n- Include more detailed comparisons with other methods to provide a clearer picture of the DRP method's performance.\n- Consider including additional numerical experiments to further evaluate the DRP method's effectiveness.\n\nRecommendation:\n- The DRP method is a promising approach to using pre-trained restoration operators as priors for solving inverse problems. With some revisions to make the paper more accessible to non-experts and to provide more detailed comparisons with other methods, the DRP method has the potential to make a significant contribution to the field of imaging inverse problems.",
        "gr_score_with": 0.7298387096774194,
        "gr_score_without": 0.7142857142857143,
        "output_without": {
            "num_tokens_scored": 259,
            "num_green_tokens": 185,
            "green_fraction": 0.7142857142857143,
            "z_score": 0.5016977977548946,
            "p_value": 0.3079400569284269
        },
        "output_with": {
            "num_tokens_scored": 248,
            "num_green_tokens": 181,
            "green_fraction": 0.7298387096774194,
            "z_score": 1.0254068916263333,
            "p_value": 0.15258561887637334
        }
    },
    {
        "title": "EXTREMELY SPARSE LABELED DATA",
        "abstract": "Graph-based semi-supervised learning, particularly in the context of extremely sparse labeled data, often suffers from degenerate solutions where label functions tend to be nearly constant across unlabeled data. In this paper, we introduce Variance-enlarged Poisson Learning (VPL), a simple yet powerful framework tailored to alleviate the issues arising from the presence of degenerate solutions. VPL incorporates a variance-enlarged regularization term, which induces a Poisson equation specifically for unlabeled data. This intuitive approach increases the dispersion of labels from their average mean, effectively reducing the likelihood of degenerate solutions characterized by nearly constant label functions. We subsequently introduce two streamlined algorithms, V-Laplace and V-Poisson, each intricately designed to enhance Laplace and Poisson learning, respectively. Furthermore, we broaden the scope of VPL to encompass graph neural networks, introducing Variance-enlarged Graph Poisson Networks (V-GPN) to facilitate improved label propagation. To achieve a deeper understanding of VPL\u2019s behavior, we conduct a comprehensive theoretical exploration in both discrete and variational cases. Our findings elucidate that VPL inherently amplifies the importance of connections within the same class while concurrently tempering those between different classes. We support our claims with extensive experiments, demonstrating the effectiveness of VPL and showcasing its superiority over existing methods. The code is available at https://github.com/hitcszx/VPL.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$\\text{Paper Summary:}$$\nThe paper proposes Variance-enlarged Poisson Learning (VPL), a framework for addressing the challenges of extremely sparse labeled data in graph-based semi-supervised learning. VPL incorporates a variance-enlarged regularization term, which induces a Poisson equation for unlabeled data, increasing the dispersion of labels away from their average value. The authors introduce two streamlined algorithms, V-Laplace and V-Poisson, and extend VPL to enhance semi-supervised node classification with graph neural networks. Theoretical analysis is provided for both discrete and variational cases.\n\n$$\\text{Strengths:}$$\n1. The paper addresses the issue of degenerate solutions in graph-based semi-supervised learning with extremely sparse labeled data.\n2. VPL is a simple yet effective framework that increases the dispersion of labels away from their average value.\n3. The authors provide a theoretical exploration of VPL in both discrete and variational cases.\n4. The proposed algorithms, V-Laplace and V-Poisson, are efficient and simple to implement.\n\n$$\\text{Weaknesses:}$$\n1. The paper may be considered too technical, as some sections, such as the theoretical analysis, may be challenging for non-experts to understand.\n2. The authors do not provide a comprehensive comparison with other state-of-the-art methods for extremely sparse labeled data.\n3. The experiments may be limited to specific datasets, which may not be representative of the broader scope of graph-based semi-supervised learning.\n\n$$\\text{Suggestions for Improvement:}$$\n1. Provide more detailed explanations of technical concepts, such as variance-enlarged regularization and the theoretical analysis.\n2. Conduct a more comprehensive comparison with other state-of-the-art methods for extremely sparse labeled data.\n3. Include more experiments on diverse datasets to demonstrate the robustness of VPL.\n\n$$\\text{Recommendation:}$$\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit the manuscript to address the limitations and improve the clarity and comprehensiveness of the technical content. The revised manuscript should include more detailed explanations of technical concepts, a more comprehensive comparison with other state-of-the-art methods, and additional experiments on diverse datasets.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$\\text{Paper Summary:}$$\nThe paper proposes Variance-enlarged Poisson Learning (VPL), a framework for addressing the challenges of extremely sparse labeled data in graph-based semi-supervised learning. VPL incorporates a variance-enlarged regularization term, which induces a Poisson equation for unlabeled data, increasing the dispersion of labels away from their average value. The authors introduce two efficient algorithms, V-Laplace and V-Poisson, tailored for improving Laplace learning and Poisson learning, respectively. Additionally, they extend VPL to enhance semi-supervised node classification with graph neural networks. Theoretical analysis in both discrete and variational cases demonstrates the effectiveness of VPL in scenarios characterized by extremely sparse labeled data.\n\n$$\\text{Strengths:}$$\n1. The paper presents a novel approach to addressing the challenges of extremely sparse labeled data in graph-based semi-supervised learning.\n2. The authors introduce two efficient algorithms, V-Laplace and V-Poisson, which are tailored for improving Laplace learning and Poisson learning, respectively.\n3. The theoretical analysis in both discrete and variational cases demonstrates the effectiveness of VPL in scenarios characterized by extremely sparse labeled data.\n4. The paper includes extensive experiments on MNIST, FashionMNIST, and CIFAR-10, as well as semi-supervised node classification with GNNs on the citation network datasets.\n\n$$\\text{Weaknesses:}$$\n1. The paper may benefit from more detailed explanations of the assumptions made in the theoretical analysis.\n2. Some of the proofs in the theoretical analysis may be difficult for non-experts to follow.\n3. The paper could benefit from more comparisons with other methods, especially in the context of extremely sparse labeled data.\n4. The authors may consider providing more insights into the impact of the variance-enlarged regularization term on the performance of VPL.\n\n$$\\text{Suggestions for Improvement:}$$\n1. Provide more detailed explanations of the assumptions made in the theoretical analysis.\n2. Consider adding more comparisons with other methods, especially in the context of extremely sparse labeled data.\n3. Include more insights into the impact of the variance-enlarged regularization term on the performance of VPL.\n4. Consider providing more discussions on the generalizability of VPL to other domains and scenarios.\n\n$$\\text{Recommendation:}$$\nBased on the paper's contributions, strengths, and weaknesses, I recommend that the authors revise and resubmit the paper for publication. With some revisions to address the weaknesses and improve the clarity of the theoretical analysis, the paper has the potential to make significant contributions to the field of semi-supervised learning and graph neural networks.",
        "gr_score_with": 0.7771084337349398,
        "gr_score_without": 0.7025316455696202,
        "output_without": {
            "num_tokens_scored": 316,
            "num_green_tokens": 222,
            "green_fraction": 0.7025316455696202,
            "z_score": 0.09820572322804866,
            "p_value": 0.4608844689781072
        },
        "output_with": {
            "num_tokens_scored": 332,
            "num_green_tokens": 258,
            "green_fraction": 0.7771084337349398,
            "z_score": 3.0659232304979454,
            "p_value": 0.0010849951149246985
        }
    },
    {
        "title": "STYLIZED OFFLINE REINFORCEMENT LEARNING: EXTRACTING DIVERSE HIGH-QUALITY BEHAVIORS FROM HETEROGENEOUS DATASETS",
        "abstract": "Previous literature on policy diversity in reinforcement learning (RL) either focuses on the online setting or ignores the policy performance. In contrast, offline RL, which aims to learn high-quality policies from batched data, has yet to fully leverage the intrinsic diversity of the offline dataset. Addressing this dichotomy and aiming to balance quality and diversity poses a significant challenge to extant methodologies. This paper introduces a novel approach, termed Stylized Offline RL (SORL), which is designed to extract high-performing, stylistically diverse policies from a dataset characterized by distinct behavioral patterns. Drawing inspiration from the venerable Expectation-Maximization (EM) algorithm, SORL innovatively alternates between policy learning and trajectory clustering, a mechanism that promotes policy diversification. To further augment policy performance, we introduce advantage-weighted style learning into the SORL framework. Experimental evaluations across multiple environments demonstrate the significant superiority of SORL over previous methods in extracting high-quality policies with diverse behaviors. A case in point is that SORL successfully learns strong policies with markedly distinct playing patterns from a real-world human dataset of a popular basketball video game \u201dDunk City Dynasty.\u201d",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Stylized Offline Reinforcement Learning: Extracting Diverse High-Quality Behaviors from Heterogeneous Datasets$$\n\n$$Summary:$$ The paper proposes a novel approach, termed Stylized Offline Reinforcement Learning (SORL), to extract high-performing, stylistically diverse policies from heterogeneous offline datasets. SORL combines EM-based style clustering with advantage-weighted policy learning, addressing the limitations of existing methods in offline reinforcement learning (RL) and imitation learning.\n\n$$Strengths:$$\n\n*   The paper introduces a novel framework to balance policy diversity and quality in offline RL, which is a significant challenge in this domain.\n*   The proposed SORL approach is based on EM-based style clustering, which is a well-established technique in data clustering.\n*   The use of advantage-weighted policy learning effectively promotes policy diversity and quality.\n*   The experiments demonstrate the superiority of SORL over baseline methods in extracting high-quality and diverse policies.\n\n$$Weaknesses:$$\n\n*   The paper assumes a uniform prior distribution for the latent policy, which may not be the best choice for all datasets.\n*   The use of advantage-weighted policy learning may not be suitable for all environments, especially those with high-dimensional state and action spaces.\n*   The paper does not provide a detailed analysis of the learned policies, which may be important for understanding their behavior.\n\n$$Suggestions for Improvement:$$\n\n*   Consider using a more robust prior distribution for the latent policy, such as a non-uniform prior or a hierarchical prior.\n*   Experiment with different advantage-weighting schemes to see if they can improve policy diversity and quality.\n*   Provide a more detailed analysis of the learned policies, including their behavior and performance in different environments.\n*   Consider integrating adaptive task learning using the diverse policies derived from SORL, enabling dynamic switching in different task scenarios.\n\n$$Recommendation:$$\n\n*   The SORL approach is recommended for applications where high-quality and diverse policies are required, such as in game AI and autonomous driving.\n*   The approach can be used to learn policies from heterogeneous offline datasets, which is a common scenario in many real-world applications.\n*   The paper's results demonstrate the superiority of SORL over baseline methods, making it a promising approach for future research in offline RL and imitation learning.",
        "peer_review_with_watermark": "$$$\\boxed{Peer Review:}\n\n**Paper Summary:**\nThe paper proposes a novel approach, Stylized Offline RL (SORL), to learn diverse and high-quality policies from offline heterogeneous datasets. SORL combines EM-based style clustering with advantage-weighted policy learning to optimize policy performance while preserving behavioral diversity. The authors evaluate SORL on various tasks and datasets, demonstrating its superiority over prior methods in extracting high-quality and diverse policies.\n\n**Strengths:**\n\n1. The paper addresses a significant challenge in offline reinforcement learning, where most methods prioritize policy quality over diversity, leading to inconsistent data quality and decreased policy performance.\n2. SORL's two-step framework, incorporating EM-based style clustering and advantage-weighted policy learning, effectively extracts diverse and high-quality policies from heterogeneous datasets.\n3. The authors provide comprehensive evaluations of SORL across multiple environments and datasets, demonstrating its robustness and adaptability in handling complex, real-world tasks.\n\n**Weaknesses:**\n\n1. The paper does not provide a detailed analysis of the EM algorithm's convergence and its impact on policy learning.\n2. The authors assume a uniform prior distribution for the EM algorithm, which might not be suitable for all datasets. A more robust prior distribution selection method is recommended.\n3. The evaluation criteria, including quality, diversity, and consistency, are not explicitly explained, making it challenging for readers to understand the authors' interpretation of the results.\n\n**Suggestions for Improvement:**\n\n1. The authors should provide a detailed analysis of the EM algorithm's convergence and its impact on policy learning, including discussions on the choice of hyperparameters and sensitivity analysis.\n2. To address the assumption of a uniform prior distribution, the authors should explore alternative prior distribution selection methods, such as Bayesian methods or importance sampling, to improve robustness.\n3. The authors should provide a more detailed explanation of the evaluation criteria, including explicit definitions and justifications for each metric, to facilitate a better understanding of the results.\n\n**Recommendation:**\nBased on the evaluation, I recommend accepting the paper for publication in its current form, with minor revisions to address the suggested improvements. The authors have made significant contributions to addressing a challenging problem in offline reinforcement learning, and their proposed approach, SORL, shows promising results in extracting diverse and high-quality policies from offline heterogeneous datasets. With minor revisions, the paper will be even stronger and more comprehensive.",
        "gr_score_with": 0.7830985915492957,
        "gr_score_without": 0.7207207207207207,
        "output_without": {
            "num_tokens_scored": 333,
            "num_green_tokens": 240,
            "green_fraction": 0.7207207207207207,
            "z_score": 0.8251204038343021,
            "p_value": 0.2046516184233398
        },
        "output_with": {
            "num_tokens_scored": 355,
            "num_green_tokens": 278,
            "green_fraction": 0.7830985915492957,
            "z_score": 3.416631905075823,
            "p_value": 0.0003170047058377186
        }
    },
    {
        "title": "SAFEDREAMER: SAFE REINFORCEMENT LEARNING",
        "abstract": "The deployment of Reinforcement Learning (RL) in real-world applications is constrained by its failure to satisfy safety criteria. Existing Safe Reinforcement Learning (SafeRL) methods, which rely on cost functions to enforce safety, often fail to achieve zero-cost performance in complex scenarios, especially vision-only tasks. These limitations are primarily due to model inaccuracies and inadequate sample efficiency. The integration of the world model has proven effective in mitigating these shortcomings. In this work, we introduce SafeDreamer, a novel algorithm incorporating Lagrangian-based methods into world model planning processes within the superior Dreamer framework. Our method achieves nearly zero-cost performance on various tasks, spanning low-dimensional and visiononly input, within the Safety-Gymnasium benchmark, showcasing its efficacy in balancing performance and safety in RL tasks. Further details can be seen on our project website: https://sites.google.com/view/safedreamer.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$\\textbf{Paper Summary:}$$\nThe paper proposes SafeDreamer, a novel algorithm for safe reinforcement learning (SafeRL) that balances long-term rewards and costs. It integrates safety-reward planning of the world model with the Lagrangian methods to achieve nearly zero-cost performance in complex scenarios, especially vision-only tasks. The algorithm achieves higher rewards and lower costs compared to previous methods, demonstrating superior performance in tasks with low-dimensional and visual inputs.\n\n$$\\textbf{Strengths:}$$\n1. The paper addresses the limitations of existing SafeRL methods, which often fail to achieve zero-cost performance in complex scenarios.\n2. The integration of safety-reward planning of the world model with the Lagrangian methods is a novel approach that balances errors between cost models and critics.\n3. The algorithm achieves higher rewards and lower costs compared to previous methods, demonstrating superior performance in tasks with low-dimensional and visual inputs.\n\n$$\\textbf{Weaknesses:}$$\n1. The paper does not provide a clear explanation of the Constrained Cross-Entropy Method (CCEM) used in the online planning process.\n2. The Lagrangian multiplier \u03bbp is not clearly explained, and its update rule is not well-documented.\n3. The paper does not provide a detailed analysis of the world model's performance and its impact on the overall performance of the algorithm.\n\n$$\\textbf{Suggestions for Improvement:}$$\n1. Provide a clear explanation of the CCEM used in the online planning process.\n2. Provide a detailed analysis of the world model's performance and its impact on the overall performance of the algorithm.\n3. Clarify the update rule for the Lagrangian multiplier \u03bbp.\n4. Include more experiments to evaluate the performance of the algorithm in different scenarios.\n\n$$\\textbf{Recommendation:}$$\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit the paper for peer review. The authors should address the weaknesses and provide more detailed explanations and analyses to strengthen the paper. With revisions, the paper has the potential to make a significant contribution to the field of safe reinforcement learning.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$\\boxed{\\text{Paper Summary:}}$$\nThe paper proposes SafeDreamer, a novel safe reinforcement learning algorithm that integrates safety-reward planning of the world model with the Lagrangian methods to balance rewards and costs. The authors introduce two algorithms, SafeDreamer (OSRP) and SafeDreamer (OSRP-Lag), which utilize the world model to plan safe actions while considering the constraints of the environment. The proposed algorithm achieves nearly zero-cost performance in various tasks, including low-dimensional and visual input tasks, within the Safety-Gymnasium benchmark.\n\n$$\\boxed{\\text{Strengths:}}$$\n- The paper proposes a novel approach to safe reinforcement learning that integrates safety-reward planning of the world model with the Lagrangian methods.\n- The authors demonstrate the effectiveness of the proposed algorithm in achieving nearly zero-cost performance in various tasks, including low-dimensional and visual input tasks.\n- The paper provides a comprehensive review of existing safe reinforcement learning methods and identifies the limitations of these approaches.\n\n$$\\boxed{\\text{Weaknesses:}}$$\n- The paper does not provide a detailed analysis of the computational cost of the proposed algorithm, which may be a significant concern for deployment in real-world applications.\n- The authors assume that the world model is trained using a replay buffer of past experiences, which may not be feasible in all scenarios.\n- The paper does not provide a detailed explanation of the hyperparameter tuning procedure, which may affect the performance of the algorithm.\n\n$$\\boxed{\\text{Suggestions for Improvement:}}$$\n- The authors should provide a detailed analysis of the computational cost of the proposed algorithm and discuss possible ways to reduce it.\n- The authors should consider using more advanced techniques, such as uncertainty estimation and robust optimization, to further improve the performance of the algorithm.\n- The authors should provide a more detailed explanation of the hyperparameter tuning procedure and discuss the impact of hyperparameters on the performance of the algorithm.\n\n$$\\boxed{\\text{Recommendation:}}$$\nBased on the analysis, I recommend that the paper is accepted for publication in a reputable conference or journal in the field of reinforcement learning. The authors should revise the paper to address the weaknesses and provide a more detailed analysis of the strengths of the proposed algorithm. The revised paper should include a comprehensive review of the existing safe reinforcement learning methods, a detailed analysis of the computational cost of the proposed algorithm, and a more detailed explanation of the hyperparameter tuning procedure.",
        "gr_score_with": 0.8394648829431438,
        "gr_score_without": 0.7824561403508772,
        "output_without": {
            "num_tokens_scored": 285,
            "num_green_tokens": 223,
            "green_fraction": 0.7824561403508772,
            "z_score": 3.0376363761238014,
            "p_value": 0.0011922074260162267
        },
        "output_with": {
            "num_tokens_scored": 299,
            "num_green_tokens": 251,
            "green_fraction": 0.8394648829431438,
            "z_score": 5.262484303213374,
            "p_value": 7.106090056767752e-08
        }
    },
    {
        "title": "SKIP-ATTENTION: IMPROVING VISION TRANSFORM- ERS BY PAYING LESS ATTENTION",
        "abstract": "This work aims to improve the efficiency of vision transformers (ViTs). While ViTs use computationally expensive self-attention operations in every layer, we identify that these operations are highly correlated across layers \u2013 a key redundancy that causes unnecessary computations. Based on this observation, we propose SKIPAT, a method to reuse self-attention computation from preceding layers to approximate attention at one or more subsequent layers. To ensure that reusing self-attention blocks across layers does not degrade the performance, we introduce a simple parametric function, which outperforms the baseline transformer\u2019s performance while running computationally faster. We show that SKIPAT is agnostic to transformer architecture and is effective in image classification, semantic segmentation, image denoising, and video denoising. We achieve improved throughput at the same-or-higher accuracy levels in all these tasks.",
        "peer_review_without_watermark": "$$\\boxed{\\text{Paper Summary:}}$$\n\nThe paper proposes a novel method called SKIP-ATTENTION, which aims to improve the efficiency of vision transformers (ViTs) by leveraging the redundancy of self-attention operations across layers. The authors identify that the attention of the class token to spatial patches has a high correlation across layers, leading to unnecessary computations. They propose a method to reuse self-attention computation from preceding layers to approximate attention at one or more subsequent layers, resulting in improved throughput while maintaining high model performance.\n\n$$\\boxed{\\text{Strengths:}}$$\n\n1. The authors have identified a key redundancy in ViTs that can be exploited to improve efficiency.\n2. The proposed SKIP-ATTENTION method is simple and light, with a computational complexity of O(nd2), which is lower than the original MSA block complexity of O(n2d).\n3. The authors have demonstrated the effectiveness of SKIP-ATTENTION on various tasks, including image classification, semantic segmentation, image denoising, and video denoising.\n4. The method is architecture-agnostic and can be applied to different transformer architectures.\n\n$$\\boxed{\\text{Weaknesses:}}$$\n\n1. The authors have assumed that the correlation between attention maps across layers is high, but this assumption may not hold in all cases.\n2. The proposed SKIP-ATTENTION method may not be effective for tasks that require high spatial continuity, such as object localization.\n3. The authors have not provided a detailed analysis of the impact of the parametric function on the model's performance and generalization.\n4. The method may not be suitable for tasks that require high accuracy, as the skipping of MSA blocks may lead to reduced performance.\n\n$$\\boxed{\\text{Suggestions for Improvement:}}$$\n\n1. The authors should provide a more detailed analysis of the correlation between attention maps across layers and the impact of this correlation on the method's performance.\n2. The authors should investigate the effect of the parametric function on the model's performance and generalization.\n3. The authors should consider the impact of the method on tasks that require high spatial continuity and high accuracy.\n4. The authors should provide a more detailed analysis of the computational complexity of the method and its impact on real-world hardware.\n\n$$\\boxed{\\text{Recommendation:}}$$\n\nBased on the paper's strengths and weaknesses, I recommend that the authors revise and resubmit the paper with the following changes:\n\n1. Provide a more detailed analysis of the correlation between attention maps across layers and the impact of this correlation on the method's performance.\n2. Investigate the effect of the parametric function on the model's performance and generalization.\n3. Consider the impact of the method on tasks that require high spatial continuity and high accuracy.\n4. Provide a more detailed analysis of the computational complexity of the method and its impact on real-world hardware.\n\nOverall, the paper presents a novel method for improving the efficiency of ViTs, and the authors have demonstrated its effectiveness on various tasks. However, the method requires further investigation and analysis to fully understand its strengths and weaknesses.",
        "peer_review_with_watermark": "$$$Paper Summary:\n\nThe paper proposes SKIP-ATTENTION, a novel method to improve the efficiency of vision transformers (ViTs) by leveraging the redundancy of self-attention operations across layers. The authors identify that the attention of the CLS tokens to the spatial patches has a very high correlation across the transformer's blocks, leading to unnecessary computations. They propose a simple parametric function to skip subsequent self-attention calculations, outperforming the baseline transformer's performance while running computationally faster. The authors demonstrate the effectiveness of SKIP-ATTENTION on 7 different tasks, including image classification, semantic segmentation, and image denoising.\n\nStrengths:\n\n1. The authors provide a thorough analysis of the correlation between self-attention maps across different layers of the ViT, highlighting the potential for improving efficiency by leveraging these correlations.\n2. The proposed SKIP-ATTENTION method is simple, light, and does not affect the inductive bias encoded in the self-attention operation, making it a promising solution for improving ViT efficiency.\n3. The authors provide a detailed evaluation of SKIP-ATTENTION on 7 different tasks, including image classification, semantic segmentation, and image denoising, demonstrating its effectiveness in various applications.\n\nWeaknesses:\n\n1. The authors rely on a simple parametric function to skip subsequent self-attention calculations, which may not be optimal for all applications or datasets.\n2. The evaluation of SKIP-ATTENTION on video denoising is not provided, which may limit the generalizability of the method to low-level tasks.\n3. The authors do not provide a detailed analysis of the computational complexity of SKIP-ATTENTION, which may be an important consideration for large-scale applications.\n\nSuggestions for Improvement:\n\n1. Investigate the use of more advanced parametric functions to skip subsequent self-attention calculations, such as those based on attention-aware convolutions or self-attention-based attention mechanisms.\n2. Evaluate SKIP-ATTENTION on video denoising and other low-level tasks to demonstrate its generalizability to a wider range of applications.\n3. Provide a detailed analysis of the computational complexity of SKIP-ATTENTION, including the number of parameters, FLOPs, and memory usage, to better understand its scalability and applicability to large-scale applications.\n\nRecommendation:\n\nBased on the evaluation, I recommend that the authors consider revising the SKIP-ATTENTION method to incorporate more advanced parametric functions, evaluate it on a wider range of applications, and provide a detailed analysis of its computational complexity. This will help to further improve the efficiency and generalizability of the method, making it a valuable contribution to the field of computer vision and deep learning.",
        "gr_score_with": 0.7527777777777778,
        "gr_score_without": 0.6873315363881402,
        "output_without": {
            "num_tokens_scored": 371,
            "num_green_tokens": 255,
            "green_fraction": 0.6873315363881402,
            "z_score": -0.5324774932678955,
            "p_value": 0.7028023370430756
        },
        "output_with": {
            "num_tokens_scored": 360,
            "num_green_tokens": 271,
            "green_fraction": 0.7527777777777778,
            "z_score": 2.185207604584125,
            "p_value": 0.014436814100288018
        }
    },
    {
        "title": "MULTI-RESOLUTION HUBERT: MULTI-RESOLUTION SPEECH SELF-SUPERVISED LEARNING WITH MASKED UNIT PREDICTION",
        "abstract": "Existing Self-Supervised Learning (SSL) models for speech typically process speech signals at a fixed resolution of 20 milliseconds. This approach overlooks the varying informational content present at different resolutions in speech signals. In contrast, this paper aims to incorporate multi-resolution information into speech self-supervised representation learning. We introduce a SSL model that leverages a hierarchical Transformer architecture, complemented by HuBERT-style masked prediction objectives, to process speech at multiple resolutions. Experimental results indicate that the proposed model not only achieves more efficient inference but also exhibits superior or comparable performance to the original HuBERT model over various tasks. Specifically, significant performance improvements over the original HuBERT have been observed in fine-tuning experiments on the LibriSpeech speech recognition benchmark as well as in evaluations using the Speech Universal PERformance Benchmark (SUPERB) and Multilingual SUPERB (ML-SUPERB).",
        "peer_review_without_watermark": "$$\n\n$$$Paper Summary:\nThe paper proposes a novel self-supervised learning model for speech representation, called multi-resolution HuBERT (MR-HuBERT). The model leverages a hierarchical Transformer architecture and multi-resolution masked unit prediction to process speech at multiple resolutions. The proposed model achieves superior or comparable performance to the original HuBERT model across various tasks, including speech recognition, spoken language understanding, multilingual speech recognition, and speech enhancement. Additionally, the model exhibits computational efficiencies, specifically a 9-13% reduction in computational complexity.\n\nStrengths:\n1. The proposed model introduces a novel approach to multi-resolution speech self-supervised learning, which can potentially improve performance on downstream tasks.\n2. The use of a hierarchical Transformer architecture allows for the encoding of hidden representations at multiple resolutions, which can be beneficial for tasks that require both high-level linguistic features and low-level acoustic details.\n3. The model exhibits computational efficiencies, which can be beneficial for real-time applications.\n\nWeaknesses:\n1. The model's performance is evaluated primarily on English-language datasets, which may limit its applicability to other languages.\n2. The model's architecture is complex, which may make it difficult to interpret and optimize.\n3. The paper does not provide a comprehensive comparison with other state-of-the-art models, which may limit its impact.\n\nSuggestions for Improvement:\n1. Evaluate the model on a more diverse set of languages to demonstrate its applicability to other languages.\n2. Provide a more detailed analysis of the model's architecture to facilitate interpretation and optimization.\n3. Conduct a more comprehensive comparison with other state-of-the-art models to demonstrate the model's superiority.\n\nRecommendation:\nThe proposed model, MR-HuBERT, is a promising approach to multi-resolution speech self-supervised learning. Its superior or comparable performance on various tasks, combined with its computational efficiencies, make it a valuable contribution to the field of speech processing. However, further evaluation on a more diverse set of languages and a more detailed analysis of the model's architecture are necessary to fully establish its impact.\n\n$$\n\n$$",
        "peer_review_with_watermark": "$$\n\n$$$Paper Summary:\nThe paper proposes a novel self-supervised learning (SSL) model for speech representation learning called Multi-Resolution HuBERT (MR-HuBERT). The model utilizes a hierarchical Transformer architecture with multi-resolution information to process speech signals. Experimental results show that MR-HuBERT substantially outperforms the original HuBERT model across various benchmarks and exhibits computational efficiencies.\n\nStrengths:\n1. The proposed model effectively incorporates multi-resolution information into the pre-training phase.\n2. The hierarchical Transformer architecture allows for efficient inference.\n3. The multi-resolution targets enable better generalization to various downstream tasks.\n\nWeaknesses:\n1. The paper does not provide sufficient details about the optimization hyperparameters used during training.\n2. The experiments are conducted using limited datasets, and it would be beneficial to explore the performance with more diverse datasets.\n3. The authors do not discuss potential biases in the pre-training objective and how they might impact the performance of the model.\n\nSuggestions for Improvement:\n1. Provide more detailed information about the optimization hyperparameters used during training.\n2. Conduct experiments using more diverse datasets to evaluate the robustness of the model.\n3. Investigate the potential biases in the pre-training objective and their impact on the performance of the model.\n4. Explore the use of transfer learning to adapt the pre-trained model to different tasks and datasets.\n\nRecommendation:\nThe proposed MR-HuBERT model is an innovative approach to self-supervised learning for speech representation learning. While there are some limitations and areas for improvement, the results presented demonstrate the potential of the model to achieve state-of-the-art performance across various benchmarks. With further investigation and exploration of the proposed architecture, it is likely that MR-HuBERT will continue to make significant contributions to the field of speech processing.",
        "gr_score_with": 0.7992831541218638,
        "gr_score_without": 0.6723549488054608,
        "output_without": {
            "num_tokens_scored": 293,
            "num_green_tokens": 197,
            "green_fraction": 0.6723549488054608,
            "z_score": -1.0326224467362963,
            "p_value": 0.8491096902970403
        },
        "output_with": {
            "num_tokens_scored": 279,
            "num_green_tokens": 223,
            "green_fraction": 0.7992831541218638,
            "z_score": 3.618828651041417,
            "p_value": 0.0001479697488008397
        }
    },
    {
        "title": "INCREMENTAL RANDOMIZED SMOOTHING CERTIFICATION",
        "abstract": "Randomized smoothing-based certification is an effective approach for obtaining robustness certificates of deep neural networks (DNNs) against adversarial attacks. This method constructs a smoothed DNN model and certifies its robustness through statistical sampling, but it is computationally expensive, especially when certifying with a large number of samples. Furthermore, when the smoothed model is modified (e.g., quantized or pruned), certification guarantees may not hold for the modified DNN, and recertifying from scratch can be prohibitively expensive. We present the first approach for incremental robustness certification for randomized smoothing, IRS. We show how to reuse the certification guarantees for the original smoothed model to certify an approximated model with very few samples. IRS significantly reduces the computational cost of certifying modified DNNs while maintaining strong robustness guarantees. We experimentally demonstrate the effectiveness of our approach, showing up to 4.1x certification speedup over the certification that applies randomized smoothing of approximate model from scratch.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary:\nThe paper proposes the first incremental approach for probabilistic deep neural network (DNN) certification, called Incremental Randomized Smoothing (IRS). It extends the Randomized Smoothing (RS) method, which is an effective approach for obtaining robustness certificates of DNNs against adversarial attacks. The proposed approach leverages the certification guarantees obtained from the smoothed model to certify a smoothed approximated model with very few samples. This significantly reduces the computational cost of certification while maintaining strong robustness guarantees.\n\nStrengths:\n- The proposed approach, IRS, is the first incremental approach for probabilistic DNN certification.\n- It leverages the certification guarantees obtained from the smoothed model to certify a smoothed approximated model with very few samples.\n- The approach reduces the computational cost of certification while maintaining strong robustness guarantees.\n- The paper provides extensive experimental results to demonstrate the effectiveness of IRS.\n\nWeaknesses:\n- The approach requires storing a cache with the top predicted class index, its lower confidence bound, and the seeds for Gaussian corruptions obtained from the RS execution of the original classifier. This may lead to memory overhead.\n- The smoothing parameter \u03c3 used in IRS affects its efficiency, and larger values of \u03c3 generally lead to better results but may lead to a loss of accuracy in the model.\n- The paper does not discuss the limitations of the approach in terms of the number of samples required for certification.\n\nSuggestions for Improvement:\n- The authors should discuss the limitations of the approach in terms of the number of samples required for certification.\n- The authors should provide more detailed analysis of the memory overhead of the cache.\n- The authors should explore the use of more efficient data structures to reduce memory overhead.\n\nRecommendation:\n- The proposed approach, IRS, is effective and efficient for probabilistic DNN certification.\n- The approach has the potential to be widely used in real-world applications where DNNs are deployed in various edge devices with limited computing resources.\n- The authors should continue to improve the approach by addressing the limitations and exploring more efficient data structures to reduce memory overhead.\n\n$$\\begin{aligned}\n$$",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$Paper Summary:\nThe paper proposes the first approach for incremental randomized smoothing certification for deep neural networks, called Incremental Randomized Smoothing (IRS). It leverages the certification guarantees obtained from the smoothed model to certify an approximated model with very few samples. This approach reduces the computational cost of certification while maintaining strong robustness guarantees. The authors evaluate the performance of IRS on state-of-the-art classification models and demonstrate its effectiveness in achieving up to 4.1x speedup over the standard non-incremental RS baseline.\n\n$$Strengths:\n1. IRS is an effective approach for probabilistic DNN certification, achieving up to 4.1x speedup over the standard non-incremental RS baseline.\n2. It leverages the certification guarantees obtained from the smoothed model to certify an approximated model with very few samples, reducing the computational cost of certification.\n3. IRS is applicable to various DNN approximations, including quantization and pruning, and demonstrates its effectiveness in these cases.\n4. The authors provide an extensive evaluation of the performance of IRS on state-of-the-art classification models, including CIFAR-10 and ImageNet datasets.\n\n$$Weaknesses:\n1. IRS requires storing the cache with the top predicted class index, its lower confidence bound, and the seeds for Gaussian corruptions obtained from the RS execution of the original classifier, which may require additional memory resources.\n2. The value of \u03c3 used in IRS affects its efficiency, with larger values leading to better results but potentially at the cost of accuracy.\n3. The authors do not provide a detailed analysis of the theoretical guarantees and limitations of IRS, which may be important for understanding its robustness and applicability.\n\n$$Suggestions for Improvement:\n1. Provide a detailed analysis of the theoretical guarantees and limitations of IRS, including its robustness and applicability to various DNN approximations.\n2. Investigate the effect of the value of \u03c3 on the efficiency and accuracy of IRS, and provide guidelines for selecting the optimal value of \u03c3 based on the specific use case.\n3. Consider incorporating additional features or modifications to IRS to improve its robustness and applicability, such as handling more complex DNN approximations or providing more detailed guarantees for the certified radius.\n\n$$Recommendation:\nBased on the evaluation and analysis, I recommend that the authors consider the proposed IRS approach for probabilistic DNN certification. While there are some limitations and areas for improvement, IRS demonstrates its effectiveness in achieving up to 4.1x speedup over the standard non-incremental RS baseline, making it a promising approach for efficient and effective certification of DNNs in real-world applications. With further development and analysis, IRS has the potential to become a widely adopted approach for probabilistic DNN certification.",
        "gr_score_with": 0.772609819121447,
        "gr_score_without": 0.7137931034482758,
        "output_without": {
            "num_tokens_scored": 290,
            "num_green_tokens": 207,
            "green_fraction": 0.7137931034482758,
            "z_score": 0.5125678296256596,
            "p_value": 0.3041268307474174
        },
        "output_with": {
            "num_tokens_scored": 387,
            "num_green_tokens": 299,
            "green_fraction": 0.772609819121447,
            "z_score": 3.1170314917460322,
            "p_value": 0.0009134102831135985
        }
    },
    {
        "title": "TILLATION: A KERNEL METHOD PERSPECTIVE",
        "abstract": "Dataset distillation offers a potential means to enhance data efficiency in deep learning. Recent studies have shown its ability to counteract backdoor risks present in original training samples. In this study, we delve into the theoretical aspects of backdoor attacks and dataset distillation based on kernel methods. We introduce two new theory-driven trigger pattern generation methods specialized for dataset distillation. Following a comprehensive set of analyses and experiments, we show that our optimization-based trigger design framework informs effective backdoor attacks on dataset distillation. Notably, datasets poisoned by our designed trigger prove resilient against conventional backdoor attack detection and mitigation methods. Our empirical results validate that the triggers developed using our approaches are proficient at executing resilient backdoor attacks. 1",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$\\boxed{Paper Summary:}$ \nThe paper proposes a novel theoretical framework for backdoor attacks on dataset distillation, which is a technique to compress large datasets into small synthetic datasets. The authors introduce two new theory-driven trigger pattern generation methods, simple-trigger and relax-trigger, and show that these methods can effectively evade existing backdoor detection and cleansing methods. The paper also presents experimental results demonstrating the effectiveness of simple-trigger and relax-trigger.\n\n$\\boxed{Strengths:}$ \n1. The paper provides a novel theoretical framework for backdoor attacks on dataset distillation, which is a significant contribution to the field of deep learning security.\n2. The authors introduce two new theory-driven trigger pattern generation methods, simple-trigger and relax-trigger, which can effectively evade existing backdoor detection and cleansing methods.\n3. The paper presents experimental results demonstrating the effectiveness of simple-trigger and relax-trigger.\n\n$\\boxed{Weaknesses:}$ \n1. The paper does not provide a comprehensive review of existing backdoor attack methods, which may limit the comparison with other approaches.\n2. The authors assume that the kernel matrix of the synthetic dataset is invertible, which may not always be the case in practice.\n3. The paper does not discuss the robustness of the proposed methods against adversarial attacks.\n\n$\\boxed{Suggestions for Improvement:}$ \n1. The authors should provide a more comprehensive review of existing backdoor attack methods to compare their results with other approaches.\n2. The authors should discuss the robustness of the proposed methods against adversarial attacks.\n3. The authors should provide more detailed explanations of the assumptions made in the paper, such as the invertibility of the kernel matrix.\n\n$\\boxed{Recommendation:}$ \nBased on the review, I recommend that the paper be published in a reputable conference or journal in the field of deep learning security. However, the authors should address the weaknesses and suggestions for improvement mentioned above to strengthen the paper.",
        "peer_review_with_watermark": "$$\\begin{align}\n$$The paper presents a novel theoretical framework for studying backdoor attacks and dataset distillation. The authors introduce two new trigger pattern generation methods, simple-trigger and relax-trigger, which are designed to evade existing backdoor detection and cleansing methods. The paper provides a comprehensive analysis of the backdoor effect, including conflict loss, projection loss, and generalization gap. The results show that the proposed trigger patterns are resilient against various backdoor defense methods. Overall, the paper makes a significant contribution to the field of backdoor attacks and dataset distillation. \n\nHowever, there are some limitations and areas for improvement. Firstly, the paper relies heavily on existing literature and may not provide novel insights for researchers who are already familiar with the topic. Secondly, the analysis of the backdoor effect is limited to a single type of backdoor attack, and it is not clear how the results would generalize to other types of attacks. Finally, the paper could benefit from more detailed experimental results and a more comprehensive comparison of the proposed trigger patterns against different backdoor defense methods.\n\nIn terms of strengths, the paper provides a clear and concise introduction to the topic, and the authors demonstrate a good understanding of the underlying concepts. The proposed trigger patterns are also well-designed and easy to understand. The paper also provides a comprehensive analysis of the backdoor effect, which is a significant contribution to the field. \n\nIn terms of weaknesses, the paper relies heavily on existing literature, which may limit its novelty. The analysis of the backdoor effect is limited, and it is not clear how the results would generalize to other types of attacks. The paper could benefit from more detailed experimental results and a more comprehensive comparison of the proposed trigger patterns against different backdoor defense methods. \n\nSuggestions for improvement:\n\n* Provide more detailed experimental results and a more comprehensive comparison of the proposed trigger patterns against different backdoor defense methods.\n* Analyze the backdoor effect for different types of backdoor attacks and provide a more generalizable framework.\n* Provide a more comprehensive review of existing literature and highlight the contributions of the paper.\n* Consider adding more theoretical results and proofs to support the proposed trigger patterns.\n* Provide a more detailed analysis of the generalization gap and its implications for backdoor attacks.\n\nRecommendation:\n\n* The paper is recommended for publication in a top-tier conference in machine learning and computer vision.\n* The authors should consider providing more detailed experimental results and a more comprehensive comparison of the proposed trigger patterns against different backdoor defense methods.\n* The authors should also consider analyzing the backdoor effect for different types of backdoor attacks and providing a more generalizable framework.\n* The paper provides a significant contribution to the field of backdoor attacks and dataset distillation, and it is recommended for publication in a top-tier conference.",
        "gr_score_with": 0.7934426229508197,
        "gr_score_without": 0.6694915254237288,
        "output_without": {
            "num_tokens_scored": 236,
            "num_green_tokens": 158,
            "green_fraction": 0.6694915254237288,
            "z_score": -1.0227437815088434,
            "p_value": 0.8467854974697591
        },
        "output_with": {
            "num_tokens_scored": 305,
            "num_green_tokens": 242,
            "green_fraction": 0.7934426229508197,
            "z_score": 3.5611092132985487,
            "p_value": 0.00018464571408459041
        }
    },
    {
        "title": "FINE-TUNING LANGUAGE MODELS FOR FACTUALITY REDUCES HALLUCINATION",
        "abstract": "The fluency and creativity of large pre-trained language models (LLMs) have led to their widespread use, sometimes even as a replacement for traditional search engines. Yet language models are prone to making convincing but factually inaccurate claims, often referred to as \u2018hallucinations.\u2019 These errors can inadvertently spread misinformation or harmfully perpetuate misconceptions. Further, manual fact-checking of model responses is a time-consuming process, making human factuality labels expensive to acquire. In this work, we fine-tune language models to be more factual, without human labeling and targeting more open-ended generation settings than past work. We leverage two key recent innovations in NLP to do so. First, several recent works have proposed methods for judging the factuality of open-ended text by measuring consistency with an external knowledge base or simply a large model\u2019s confidence scores. Second, the direct preference optimization algorithm enables straightforward fine-tuning of language models on objectives other than supervised imitation, using a preference ranking over possible model responses. We show that learning from automatically generated factuality preference rankings, generated either through existing retrieval systems or our novel retrieval-free approach, significantly improves the factuality (percent of generated claims that are correct) of Llama-2 on held-out topics compared with RLHF or decoding strategies targeted at factuality. At 7B scale, compared to Llama-2-chat, we observe 58% and 40% reduction in factual error rate when generating biographies and answering medical questions, respectively.",
        "peer_review_without_watermark": "$$$\\boxed{Peer Review}$$\n\n$\\boxed{Paper Summary:}$\n\nThe paper proposes a method for fine-tuning language models to reduce factual errors, referred to as \"hallucinations.\" The authors leverage recent advances in estimating truthfulness without human intervention, including reference-based automated fact-checking methods and reference-free truthfulness evaluations using a model's own confidence as a proxy for truthfulness. They demonstrate that fine-tuning language models for factuality using preference pairs scored with reference-based and reference-free truthfulness estimation can significantly improve the factuality of Llama-2 on held-out topics.\n\n$\\boxed{Strengths:}$\n\n1. The paper provides a novel approach to fine-tuning language models for factuality, which is a crucial aspect of building more reliable language models.\n2. The authors demonstrate the effectiveness of their method in reducing factual errors and improving factuality on two benchmark datasets for generating biographies and answering medical questions.\n3. The paper explores the use of reference-free truthfulness estimation, which eliminates the need for external knowledge bases and annotations.\n4. The authors provide a comprehensive evaluation of their method, including experiments on different datasets and baselines.\n\n$\\boxed{Weaknesses:}$\n\n1. The paper assumes that the use of reference-based fact-checking methods is sufficient for evaluating the truthfulness of generated text, which may not be the case in all domains or scenarios.\n2. The authors do not discuss the potential risks of over-reliance on reference-free truthfulness estimation, which may lead to biased or inaccurate evaluations.\n3. The paper does not provide a detailed analysis of the limitations and challenges of the proposed method, which may be a concern for future researchers and practitioners.\n4. The authors do not provide a clear explanation of how the proposed method can be adapted or extended to other language models or tasks.\n\n$\\boxed{Suggestions for Improvement:}$\n\n1. The authors should consider incorporating more diverse and representative datasets to evaluate the effectiveness of their method.\n2. The paper should provide a more detailed analysis of the limitations and challenges of the proposed method, including potential biases or inaccuracies.\n3. The authors should explore the use of other evaluation metrics or methods to complement reference-based fact-checking.\n4. The paper should provide a clear explanation of how the proposed method can be adapted or extended to other language models or tasks.\n\n$\\boxed{Recommendation:}$\n\nBased on the strengths and weaknesses of the paper, I recommend that it be accepted for publication. The authors have made significant contributions to the field of language model fine-tuning, and their method has shown promise in reducing factual errors and improving factuality. However, I suggest that the authors address the limitations and challenges of their method and provide a more comprehensive evaluation of its effectiveness.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThis paper introduces a novel approach to fine-tuning language models for factual accuracy without human labeling, leveraging recent advances in estimating truthfulness without human intervention. The proposed method utilizes a preference-based learning framework, combining reference-based and reference-free truthfulness estimators to construct preference pairs and optimize language models for factuality.\n\nStrengths:\n1. The paper provides a practical and effective strategy for improving language model factual accuracy, focusing on long-form generation.\n2. The introduction of reference-free truthfulness estimation offers a scalable self-supervision strategy for factuality improvement.\n3. The proposed approach is evaluated on two benchmark datasets for generating biographies and answering open-ended questions about medical conditions.\n\nWeaknesses:\n1. The paper's focus on long-form generation may limit the applicability of the approach to shorter forms of text.\n2. The reference-based truthfulness estimator relies on external knowledge bases, which may not be available for all domains or tasks.\n3. The reference-free approach may not capture the nuances of human judgment and may require further fine-tuning.\n\nSuggestions for Improvement:\n1. Evaluate the approach on a broader range of datasets and tasks to assess its generalizability.\n2. Investigate the effectiveness of incorporating human feedback and validation in the reference-based truthfulness estimator.\n3. Develop a more comprehensive understanding of the trade-offs between reference-based and reference-free truthfulness estimation.\n\nRecommendation:\nThis paper makes a significant contribution to the field of natural language processing by introducing a novel approach to fine-tuning language models for factual accuracy without human labeling. The proposed method offers a scalable and effective strategy for improving language model factuality, particularly for long-form generation tasks. While there are areas for improvement, the paper's results and approach warrant further investigation and potential applications in various NLP tasks.\n\nRating: 8/10\n\nNote: The rating is subjective and based on the reviewer's assessment of the paper's strengths, weaknesses, and potential for improvement.",
        "gr_score_with": 0.7947019867549668,
        "gr_score_without": 0.7,
        "output_without": {
            "num_tokens_scored": 370,
            "num_green_tokens": 259,
            "green_fraction": 0.7,
            "z_score": 0.0,
            "p_value": 0.5
        },
        "output_with": {
            "num_tokens_scored": 302,
            "num_green_tokens": 240,
            "green_fraction": 0.7947019867549668,
            "z_score": 3.5913101609779026,
            "p_value": 0.00016450989716906725
        }
    },
    {
        "title": "METHOD WITH OPTIMAL ADAPTATION TO INEXACTNESS",
        "abstract": "We present a new accelerated stochastic second-order method that is robust to both gradient and Hessian inexactness, which occurs typically in machine learning. We establish theoretical lower bounds and prove that our algorithm achieves optimal convergence in both gradient and Hessian inexactness in this key setting. We further introduce a tensor generalization for stochastic higher-order derivatives. When the oracles are non-stochastic, the proposed tensor algorithm matches the global convergence of Nesterov Accelerated Tensor method. Both algorithms allow for approximate solutions of their auxiliary subproblems with verifiable conditions on the accuracy of the solution.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$\\text{Paper Summary:}$$\n\nThe paper proposes a novel accelerated stochastic second-order method for convex and strongly convex optimization. The method is designed to be robust to both gradient and Hessian inexactness, which is a common issue in machine learning and other domains. The authors establish theoretical lower bounds for stochastic second-order optimization and prove that their algorithm achieves optimal convergence in both gradient and Hessian inexactness. The method is also extended to tensor generalization for stochastic high-order derivatives.\n\n$$\\text{Strengths:}$$\n\n* The paper presents a novel accelerated stochastic second-order method that is robust to both gradient and Hessian inexactness.\n* The authors establish theoretical lower bounds for stochastic second-order optimization and prove that their algorithm achieves optimal convergence in both gradient and Hessian inexactness.\n* The method is extended to tensor generalization for stochastic high-order derivatives.\n* The paper provides a detailed analysis of the method's convergence rate and provides a lower bound for stochastic second-order optimization.\n\n$$\\text{Weaknesses:}$$\n\n* The paper assumes that the subproblem solution can be found exactly, which may not be feasible in practice.\n* The method requires solving an auxiliary subproblem, which can be computationally expensive.\n* The paper does not provide a detailed analysis of the method's computational complexity.\n\n$$\\text{Suggestions for Improvement:}$$\n\n* The authors should provide a more detailed analysis of the method's computational complexity.\n* The paper should discuss the potential for enhancing the adaptiveness of the algorithm.\n* The authors should explore the possibility of constructing optimal stochastic second-order and tensor methods by incorporating stochastic elements into existing exact methods.\n\n$$\\text{Recommendation:}$$\n\nBased on the paper's strengths and weaknesses, I recommend that the authors revise the paper to address the weaknesses and provide a more detailed analysis of the method's computational complexity. The paper presents a novel accelerated stochastic second-order method that has the potential to significantly accelerate the convergence of optimization problems. With revisions, the paper can provide a more comprehensive analysis of the method's performance and potential applications.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$$The paper presents a new accelerated stochastic second-order method for convex optimization, which is robust to both gradient and Hessian inexactness. The authors establish theoretical lower bounds and prove that their algorithm achieves optimal convergence in both gradient and Hessian inexactness. The proposed algorithm involves a tensor generalization for stochastic higher-order derivatives and a restarted version for strongly convex minimization. The authors also present numerical experiments that demonstrate the efficiency of their proposed methods.\n\nThe paper is well-structured and clearly written, and the authors provide a thorough literature review of related work. The theoretical results are rigorous and well-established, and the authors provide sufficient conditions for the inexactness in the derivatives to ensure that the method can still obtain an optimal solution.\n\nHowever, there are a few areas that need improvement:\n\n1. The paper assumes that the function f(x) is convex and has L1-Lipschitz-continuous gradient and L2-Lipschitz-continuous Hessian. While this is a reasonable assumption, it would be better to state it explicitly and provide a proof or reference to a relevant theorem that establishes this assumption.\n\n2. The authors do not discuss the convergence of the algorithm in the case where the Hessian is inexact but not stochastic. It would be interesting to see how the algorithm performs in this case and whether it can still achieve optimal convergence.\n\n3. The paper assumes that the stochastic gradient and Hessian are unbiased and have bounded variance. While this is a reasonable assumption, it would be better to state it explicitly and provide a proof or reference to a relevant theorem that establishes this assumption.\n\n4. The authors do not discuss the computational complexity of the algorithm. It would be interesting to see how the algorithm's computational complexity scales with the number of iterations and the size of the problem.\n\n5. The paper does not provide a comparison with existing algorithms. It would be interesting to see how the proposed algorithm compares to existing algorithms in terms of convergence rate, computational complexity, and practical performance.\n\n6. The authors do not discuss the adaptiveness of the algorithm. It would be interesting to see how the algorithm adapts to changing problem characteristics, such as changes in the objective function or the number of iterations.\n\n7. The paper assumes that the solution to the subproblem is exact. While this is a reasonable assumption, it would be better to discuss how the algorithm can handle inexact solutions and how this affects the convergence rate.\n\n8. The authors do not discuss the robustness of the algorithm to noise and perturbations. It would be interesting to see how the algorithm performs in the presence of noise and perturbations.\n\nOverall, the paper presents an important contribution to the field of stochastic optimization and provides a rigorous theoretical foundation for the proposed algorithm. However, there are a few areas that need improvement to make the paper more comprehensive and relevant to practitioners.\n\n$$\n$$The paper is of high quality and provides a significant contribution to the field of stochastic optimization. The authors have provided a thorough literature review and have established a rigorous theoretical foundation for the proposed algorithm. The paper is well-structured and clearly written, and the authors have provided sufficient conditions for the inexactness in the derivatives to ensure that the method can still obtain an optimal solution.\n\nHowever, there are a few areas that need improvement:\n\n1. The paper assumes that the function f(x) is convex and has L1-Lipschitz-continuous gradient and L2-Lipschitz-continuous Hessian. While this is a reasonable assumption, it would be better to state it explicitly and provide a proof or reference to a relevant theorem that establishes this assumption.\n\n2. The authors do not discuss the convergence of the algorithm in the case where the Hessian is inexact but not stochastic. It would be interesting to see how the algorithm performs in this case and whether it can still achieve optimal convergence.\n\n3. The paper assumes that the stochastic gradient and Hessian are unbiased and have bounded variance. While this is a reasonable assumption, it would be better to state it explicitly and provide a proof or reference to a relevant theorem that establishes this assumption.\n\n4. The authors do not discuss the computational complexity of the algorithm. It would be interesting to see how the algorithm's computational complexity scales with the number of iterations and the size of the problem.\n\n5. The paper does not provide a comparison with existing algorithms. It would be interesting to see how the proposed algorithm compares to existing algorithms in terms of convergence rate, computational complexity, and practical performance.\n\n6. The authors do not discuss the adaptiveness of the algorithm. It would be interesting to see how the algorithm adapts to changing problem characteristics, such as changes in the objective function or the number of iterations.\n\n7. The paper assumes that the solution to the subproblem is exact. While this is a reasonable assumption, it would be better to discuss how the algorithm can handle inexact solutions and how this affects the convergence rate.\n\n8. The authors do not discuss the robustness of the algorithm to noise and perturbations. It would be interesting to see how the algorithm performs in the presence of noise and perturbations.\n\n$$\n$$Overall, the paper is of high quality and provides a significant contribution to the field of stochastic optimization. The authors have provided a thorough literature review and have established a rigorous theoretical foundation for the proposed algorithm. However, there are a few areas that need improvement to make the paper more comprehensive and relevant to practitioners.\n\n$$\n$$The paper is recommended for acceptance to a top-tier conference in machine learning and optimization. The authors have provided a rigorous theoretical foundation for the proposed algorithm, and the paper is well-structured and clearly written. The authors have also provided sufficient conditions for the inexactness in the derivatives to ensure that the method can still obtain an optimal solution.\n\nHowever, there are a few areas that need improvement:\n\n1. The paper assumes that the function f(x) is convex and has L1-Lipschitz-continuous gradient and L2-Lipschitz-continuous Hessian. While this is a reasonable assumption, it would be better to state it explicitly and provide a proof or reference to a relevant theorem that establishes this assumption.\n\n2. The authors do not discuss the convergence of the algorithm in the case where the Hessian is inexact but not stochastic. It would be interesting to see how the algorithm performs in this case and whether it can still achieve optimal convergence.\n\n3. The paper assumes that the stochastic gradient and Hessian are unbiased and have bounded variance. While this is a reasonable assumption, it would be better to state it explicitly and provide a proof or reference to a relevant theorem that establishes this assumption.\n\n4. The authors do not discuss the computational complexity of the algorithm. It would be interesting to see how the algorithm's computational complexity scales with the number of iterations and the size of the problem.\n\n5. The paper does not provide a comparison with existing algorithms. It would be interesting to see how the proposed algorithm compares to existing algorithms in terms of convergence rate, computational complexity, and practical performance.\n\n6. The authors do not discuss the adaptiveness of the algorithm. It would be interesting to see how the algorithm adapts to changing problem characteristics, such as changes in the objective function or the number of iterations.\n\n7. The paper assumes that the solution to the subproblem is exact. While this is a reasonable assumption, it would be better to discuss how the algorithm can handle inexact solutions and how this affects the convergence rate.\n\n8. The authors do not discuss the robustness of the algorithm to noise and perturbations. It would be interesting to see how the algorithm performs in the presence of noise and perturbations.\n\n$$\n$$The paper is of high quality and provides a significant contribution to the field of stochastic optimization. The authors have provided a thorough literature review and have established a rigorous theoretical foundation for the proposed algorithm. The paper is well-structured and clearly written, and the authors have provided sufficient conditions for the inexactness in the derivatives to ensure that the method can still obtain an optimal solution.",
        "gr_score_with": 0.8186157517899761,
        "gr_score_without": 0.7131474103585658,
        "output_without": {
            "num_tokens_scored": 251,
            "num_green_tokens": 179,
            "green_fraction": 0.7131474103585658,
            "z_score": 0.4545351062101397,
            "p_value": 0.32472186506407585
        },
        "output_with": {
            "num_tokens_scored": 419,
            "num_green_tokens": 343,
            "green_fraction": 0.8186157517899761,
            "z_score": 5.298338851969965,
            "p_value": 5.843047405811654e-08
        }
    },
    {
        "title": "GENERATIVE MODELING WITH PHASE STOCHASTIC BRIDGES",
        "abstract": "We introduce a novel generative modeling framework grounded in phase space dynamics, taking inspiration from the principles underlying Critically damped Langevin Dynamics and Bridge Matching. Leveraging insights from Stochastic Optimal Control, we construct a more favorable path measure in the phase space that is highly advantageous for efficient sampling. A distinctive feature of our approach is the early-stage data prediction capability within the context of propagating generative Ordinary Differential Equations or Stochastic Differential Equations. This early prediction, enabled by the model\u2019s unique structural characteristics, sets the stage for more efficient data generation, leveraging additional velocity information along the trajectory. This innovation has spurred the exploration of a novel avenue for mitigating sampling complexity by quickly converging to realistic data samples. Our model yields comparable results in image generation and notably outperforms baseline methods, particularly when faced with a limited Number of Function Evaluations. Furthermore, our approach rivals the performance of diffusion models equipped with efficient sampling techniques, underscoring its potential in the realm of generative modeling.",
        "peer_review_without_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes a novel generative modeling framework called Acceleration Generative Modeling (AGM) that leverages the principles of Stochastic Optimal Control (SOC) theory to enhance the sample efficiency of velocity-based generative modeling. AGM is designed to construct a more favorable path measure in the phase space, enabling the efficient sampling of realistic data points. The proposed framework is grounded in phase space dynamics, taking inspiration from the principles underlying Critically damped Langevin Dynamics and Bridge Matching. AGM is compared to diffusion models and flow matching in terms of performance and sampling speed.\n\nStrengths:\n1. The proposed framework is grounded in SOC theory, providing a rigorous mathematical foundation for the construction of a favorable path measure in the phase space.\n2. The use of velocity-based generative modeling enables the incorporation of additional information, leading to more efficient sampling and improved performance.\n3. The introduction of the sampling-hop technique allows for the estimation of target data points at early time steps, reducing the required number of function evaluations.\n\nWeaknesses:\n1. The paper's performance is limited to scenarios with sufficient NFE, leaving room for improvement in terms of scalability.\n2. The experimental results on high-dimensional image generation tasks, while promising, are limited to a small number of samples and require further validation.\n3. The paper's conclusion highlights the need for enhancing AGM performance, but does not provide a clear roadmap for future research directions.\n\nSuggestions for Improvement:\n1. Investigate techniques for enhancing training quality, such as data augmentation, fine-tuned noise scheduling, and network preconditioning, to improve AGM performance in scenarios with sufficient NFE.\n2. Conduct further experiments on high-dimensional image generation tasks to validate the proposed framework and establish a stronger baseline for comparison.\n3. Explore the application of AGM to other domains, such as conditional generation and inpainting, to demonstrate its versatility and potential.\n\nRecommendation:\nThe proposed framework of Acceleration Generative Modeling (AGM) demonstrates promising outcomes for fast sampling in unconditional generative tasks. While its performance is limited to scenarios with sufficient NFE, the introduction of the sampling-hop technique and the use of velocity-based generative modeling provide a novel approach to efficient sampling. Further research is needed to enhance AGM performance and explore its application to other domains.",
        "peer_review_with_watermark": "$$$\\boxed{Paper Summary:}\nThe paper introduces an Acceleration Generative Modeling (AGM) framework grounded in Stochastic Optimal Control (SOC) theory. The framework is designed to enhance the efficiency of sampling in generative modeling, particularly in the context of velocity-based models. AGM constructs a more favorable path measure in the phase space, leveraging insights from Critically damped Langevin Dynamics, Bridge Matching, and Stochastic Optimal Control. The framework enables the early prediction of realistic data samples, leveraging additional velocity information along the trajectory. Experimental results demonstrate the effectiveness of AGM in reducing the number of function evaluations (NFE) required for sampling, particularly in image generation tasks.\n\n$\\boxed{Strengths:}\n\n1.  The paper presents a novel contribution to the field of generative modeling, introducing the AGM framework rooted in SOC theory.\n2.  The framework is designed to enhance the efficiency of sampling in generative modeling, particularly in the context of velocity-based models.\n3.  The experimental results demonstrate the effectiveness of AGM in reducing the NFE required for sampling, particularly in image generation tasks.\n4.  The paper provides a detailed analysis of the proposed framework, including the derivation of the optimal control and the derivation of the sampling-hop technique.\n\n$\\boxed{Weaknesses:}\n\n1.  The paper's experimental results are limited to specific datasets and may not generalize well to other domains or tasks.\n2.  The framework may not perform well in scenarios with sufficient NFE, as observed in the paper.\n3.  The paper does not provide a comprehensive comparison with other state-of-the-art methods in the field.\n\n$\\boxed{Suggestions for Improvement:}\n\n1.  The paper could benefit from a more comprehensive experimental evaluation, including a wider range of datasets and tasks.\n2.  The framework could be further improved by incorporating techniques such as data augmentation, fine-tuned noise scheduling, and network preconditioning, as proposed in Karras et al. (2022).\n3.  The paper could provide a more detailed analysis of the limitations and potential biases of the proposed framework.\n\n$\\boxed{Recommendation:}\nBased on the paper's contributions, strengths, and limitations, I recommend the AGM framework as a promising approach for enhancing the efficiency of sampling in generative modeling, particularly in the context of velocity-based models. However, further improvements are needed to address the limitations and biases of the framework, as outlined in the suggestions for improvement.",
        "gr_score_with": 0.7588235294117647,
        "gr_score_without": 0.6703601108033241,
        "output_without": {
            "num_tokens_scored": 361,
            "num_green_tokens": 242,
            "green_fraction": 0.6703601108033241,
            "z_score": -1.2289112765921661,
            "p_value": 0.8904474634819498
        },
        "output_with": {
            "num_tokens_scored": 340,
            "num_green_tokens": 258,
            "green_fraction": 0.7588235294117647,
            "z_score": 2.3669053416557575,
            "p_value": 0.008968759960992478
        }
    },
    {
        "title": "EFFECTIVE DATA AUGMENTATION WITH DIFFUSION MODELS",
        "abstract": "Data augmentation is one of the most prevalent tools in deep learning, underpinning many recent advances, including those from classification, generative models, and representation learning. The standard approach to data augmentation combines simple transformations like rotations and flips to generate new images from existing ones. However, these new images lack diversity along key semantic axes present in the data. Current augmentations cannot alter the high-level semantic attributes, such as animal species present in a scene, to enhance the diversity of data. We address the lack of diversity in data augmentation with image-to-image transformations parameterized by pre-trained text-to-image diffusion models. Our method edits images to change their semantics using an off-the-shelf diffusion model, and generalizes to novel visual concepts from a few labelled examples. We evaluate our approach on few-shot image classification tasks, and on a real-world weed recognition task, and observe an improvement in accuracy in tested domains. DA-Fusion Semantically Augment Augmented Images For Training Models Figure 1: Real images (left) are semantically modified using a publicly available off-the-shelf Stable Diffusion checkpoint. Resulting synthetic images (right) are used for training downstream classification models.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper proposes a novel data augmentation strategy, DA-Fusion, which uses pre-trained text-to-image diffusion models to generate high-quality synthetic images for training deep learning models. The method adapts the diffusion model to new concepts by fine-tuning pseudo-prompts in the text encoder, and generates images that respect semantic invariances. The authors evaluate their approach on few-shot image classification tasks and observe an improvement in accuracy compared to standard data augmentation methods. They also explore potential leakage of internet data and propose two defenses against this issue.\n\nStrengths:\n- The paper presents a novel approach to data augmentation using pre-trained text-to-image diffusion models.\n- The authors demonstrate the effectiveness of the method on few-shot image classification tasks.\n- The proposed defenses against internet data leakage are well-considered and provide a good starting point for future research.\n\nWeaknesses:\n- The paper does not provide a thorough comparison with state-of-the-art data augmentation methods.\n- The authors do not discuss the limitations and potential biases of their proposed method.\n- The evaluation of the method is limited to a few-shot image classification tasks, and it is unclear how well the method would perform on other tasks.\n\nSuggestions for Improvement:\n- The authors should provide a more comprehensive evaluation of their method, including comparisons with state-of-the-art data augmentation methods and discussions of potential limitations and biases.\n- The paper should discuss the potential risks and benefits of using pre-trained text-to-image diffusion models for data augmentation.\n- The authors should explore the use of their proposed method for other tasks, such as object detection and visual reinforcement learning.\n\nRecommendation:\n- The paper presents a novel approach to data augmentation using pre-trained text-to-image diffusion models, and the authors demonstrate its effectiveness on few-shot image classification tasks.\n- However, the paper has several limitations, including a limited evaluation and a lack of discussion of potential limitations and biases.\n- The authors should address these limitations and provide a more comprehensive evaluation of their method before publication.\n\n$$",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper proposes a novel data augmentation method, DA-Fusion, which utilizes text-to-image diffusion models to generate high-quality synthetic images for training deep learning models. The authors aim to improve data augmentation by incorporating semantic transformations, which respect the semantic invariances present in the data. The method adapts a pre-trained text-to-image diffusion model to new concepts by fine-tuning pseudo-prompts, and generates synthetic images by splicing real images into the reverse diffusion process. The authors evaluate DA-Fusion on few-shot image classification tasks and observe significant improvements in accuracy compared to standard data augmentation methods.\n\nStrengths:\n\n1. The authors provide a clear and well-structured explanation of the DA-Fusion method, and its potential to improve data augmentation.\n2. The paper presents a comprehensive evaluation of DA-Fusion on various datasets, including Caltech101, Flowers102, and a novel leafy spurge dataset.\n3. The authors discuss potential applications of DA-Fusion in few-shot learning and visual reinforcement learning.\n\nWeaknesses:\n\n1. The paper relies heavily on the performance of the pre-trained text-to-image diffusion model, which may not always produce high-quality synthetic images.\n2. The authors do not provide a detailed analysis of the limitations and potential biases of DA-Fusion, particularly with regards to concept leakage and data leakage.\n3. The paper could benefit from more extensive evaluation on larger and more diverse datasets.\n\nSuggestions for Improvement:\n\n1. The authors could investigate the impact of concept leakage and data leakage on DA-Fusion's performance, and discuss potential strategies to mitigate these issues.\n2. The authors could provide more detailed analyses of the limitations and potential biases of DA-Fusion, particularly with regards to concept leakage and data leakage.\n3. The authors could explore the potential applications of DA-Fusion in other domains, such as video classification and object detection.\n4. The authors could investigate the effect of different hyperparameters, such as the number of synthetic images per real image and the probability of sampling synthetic images, on DA-Fusion's performance.\n\nRecommendation:\n\nI recommend accepting the paper for publication in its current form, with minor revisions to address the weaknesses and suggestions for improvement. The authors have made significant contributions to the field of data augmentation, and DA-Fusion has shown promising results on various datasets.",
        "gr_score_with": 0.7957957957957958,
        "gr_score_without": 0.7410071942446043,
        "output_without": {
            "num_tokens_scored": 278,
            "num_green_tokens": 206,
            "green_fraction": 0.7410071942446043,
            "z_score": 1.4920136830543407,
            "p_value": 0.06784777915386378
        },
        "output_with": {
            "num_tokens_scored": 333,
            "num_green_tokens": 265,
            "green_fraction": 0.7957957957957958,
            "z_score": 3.8146870843933653,
            "p_value": 6.817780173967988e-05
        }
    },
    {
        "title": "OPTIMAL TRANSPORT BASED ADVERSARIAL PATCH TO LEVERAGE LARGE SCALE ATTACK TRANSFERABILITY",
        "abstract": "Adversarial patch attacks, where a small patch is placed in the scene to fool neural networks, have been studied for numerous applications. Focusing on image classification, we consider the setting of a black-box transfer attack where an attacker does not know the target model. Instead of forcing corrupted image representations to cross the nearest decision boundaries or converge to a particular point, we propose a distribution-oriented approach. We rely on optimal transport to push the feature distribution of attacked images towards an already modeled distribution. We show that this new distribution-oriented approach leads to better transferable patches. Through digital experiments conducted on ImageNet-1K, we provide evidence that our new patches are the only ones that can simultaneously influence multiple Transformer models and Convolutional Neural Networks. Physical world experiments demonstrate that our patch can affect systems in deployment without explicit knowledge.",
        "peer_review_without_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes a distribution-oriented approach based on optimal transport for designing Adversarial Patch Attacks (APAs). The proposed method reduces patch overfitting to the source architecture and strengthens its transferability to Convolutional Neural Networks (CNNs) and Transformer architectures. The authors conduct extensive experiments on ImageNet-1K and demonstrate that their new patches are the only ones that can simultaneously influence multiple CNNs and Transformers. They also show that their patches are physically feasible and can affect systems in deployment without explicit knowledge.\n\nStrengths:\n\n*   The proposed method is distribution-oriented, which reduces patch overfitting to the source architecture and strengthens its transferability to CNNs and Transformers.\n*   The authors conduct extensive experiments on ImageNet-1K and demonstrate the effectiveness of their new patches.\n*   The method is physically feasible and can affect systems in deployment without explicit knowledge.\n\nWeaknesses:\n\n*   The paper does not provide a comprehensive review of the existing literature on APAs and transferable attacks.\n*   The authors do not provide a detailed analysis of the computational complexity of their method.\n*   The paper does not discuss the potential applications of the proposed method in real-world scenarios.\n\nSuggestions for Improvement:\n\n*   The authors should provide a comprehensive review of the existing literature on APAs and transferable attacks to demonstrate the novelty and significance of their work.\n*   The authors should provide a detailed analysis of the computational complexity of their method to demonstrate its efficiency and scalability.\n*   The authors should discuss the potential applications of the proposed method in real-world scenarios to demonstrate its practical relevance.\n\nRecommendation:\n\n*   The paper is recommended for publication in a top-tier conference in machine learning or computer vision.\n*   The authors should address the weaknesses and suggestions for improvement mentioned above to strengthen the paper.\n*   The authors should provide a detailed response to the reviewer's comments to demonstrate their engagement with the feedback. \n\n$$$",
        "peer_review_with_watermark": "$$$ \n\nPaper Summary:\nThe paper proposes a distribution-oriented approach for designing adversarial patches (APAs) using optimal transport, which is more transferable to unseen models compared to existing APAs. The approach aims to alter the feature distribution of images from a particular class to match another known distribution from a different class, making the patch more robust and effective.\n\nStrengths:\n1. The paper introduces a novel approach that leverages optimal transport for designing APAs, which can improve the transferability of the attack.\n2. The distribution-oriented approach is more robust and effective compared to existing APAs.\n3. The experiments demonstrate the effectiveness of the proposed method in fooling multiple architectures from different model families.\n\nWeaknesses:\n1. The paper does not provide a comprehensive comparison with existing APAs, and the evaluation metrics may not be well-suited for the task.\n2. The experiments are limited to a specific dataset (ImageNet-1K) and may not generalize well to other datasets.\n3. The approach relies on optimal transport, which may not be computationally efficient for large-scale images.\n\nSuggestions for Improvement:\n1. Provide a more comprehensive comparison with existing APAs, including a thorough evaluation of the attack's transferability and effectiveness.\n2. Experiment with different datasets and evaluate the approach's performance on various image classification tasks.\n3. Investigate the computational efficiency of the approach and explore more efficient optimization methods.\n\nRecommendation:\nThe proposed method is an interesting and novel approach for designing APAs using optimal transport. While there are some limitations and areas for improvement, the results demonstrate the effectiveness of the approach in fooling multiple architectures from different model families. The method has the potential to improve the transferability and robustness of APAs, making it a useful contribution to the field of adversarial attacks. However, further research is needed to fully explore the limitations and potential of the approach.",
        "gr_score_with": 0.7770034843205574,
        "gr_score_without": 0.6448979591836734,
        "output_without": {
            "num_tokens_scored": 245,
            "num_green_tokens": 158,
            "green_fraction": 0.6448979591836734,
            "z_score": -1.882092997829314,
            "p_value": 0.9700883050369061
        },
        "output_with": {
            "num_tokens_scored": 287,
            "num_green_tokens": 223,
            "green_fraction": 0.7770034843205574,
            "z_score": 2.8466998465928963,
            "p_value": 0.0022087495962823398
        }
    },
    {
        "title": "TENSOR TRUST: INTERPRETABLE PROMPT INJECTION ATTACKS",
        "abstract": "While Large Language Models (LLMs) are increasingly being used in real-world applications, they remain vulnerable to prompt injection attacks: malicious third party prompts that subvert the intent of the system designer. To help researchers study this problem, we present a dataset of over 126,000 prompt injection attacks and 46,000 prompt-based \u201cdefenses\u201d against prompt injection, all created by players of an online game called Tensor Trust. To the best of our knowledge, this is currently the largest dataset of human-generated adversarial examples for instruction-following LLMs. The attacks in our dataset have easily interpretable structure, and shed light on the weaknesses of LLMs. We also use the dataset to create a benchmark for resistance to two types of prompt injection, which we refer to as prompt extraction and prompt hijacking. Our benchmark results show that many models are vulnerable to the attack strategies in the Tensor Trust dataset. Furthermore, we show that some attack strategies from the dataset generalize to deployed LLM-based applications, even though they have a very different set of constraints to the game. We release data and code at [removed].",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces the Tensor Trust dataset, which contains over 126,000 prompt injection attacks and 46,000 prompt-based defenses against prompt injection. The attacks were generated by players of an online game called Tensor Trust, which simulates a bank and requires players to create defenses to rebuff attacks. The dataset is larger than existing datasets for prompt injection attacks and includes defenses and multi-step attacks. The authors use the dataset to create two benchmarks for evaluating the robustness of LLMs to prompt injection attacks, which they refer to as prompt extraction and prompt hijacking. The results show that many LLMs are vulnerable to these types of attacks, and that some attack strategies from the dataset generalize to deployed LLM-based applications.\n\nStrengths:\n- The paper introduces a large and diverse dataset of prompt injection attacks and defenses, which is a significant contribution to the field.\n- The authors use the dataset to create two benchmarks for evaluating the robustness of LLMs to prompt injection attacks, which provides a useful framework for assessing the security of LLM-based applications.\n- The paper provides insights into the vulnerabilities of LLMs to prompt injection attacks and the effectiveness of different defense strategies.\n\nWeaknesses:\n- The paper does not provide a clear motivation for why prompt injection attacks are a significant concern, and the authors could have provided more context on the potential risks and consequences of these types of attacks.\n- The authors do not provide a detailed analysis of the limitations and potential biases of the Tensor Trust dataset, which could impact the generalizability of the results.\n- The paper could have benefited from a more comprehensive literature review, as the authors only briefly mention related work on adversarial attacks on LLMs.\n\nSuggestions for Improvement:\n- The authors could have provided more context on the potential risks and consequences of prompt injection attacks, and highlighted the importance of evaluating the robustness of LLMs to these types of attacks.\n- The authors could have provided a more detailed analysis of the limitations and potential biases of the Tensor Trust dataset, including an evaluation of the dataset's diversity and representativeness.\n- The authors could have included a more comprehensive literature review, which would have provided a clearer understanding of the current state of research on prompt injection attacks and LLM security.\n\nRecommendation:\nThe paper provides a significant contribution to the field of LLM security, and the Tensor Trust dataset is a valuable resource for evaluating the robustness of LLMs to prompt injection attacks. However, the paper could have benefited from a more comprehensive literature review and a more detailed analysis of the limitations and potential biases of the dataset. Overall, the paper is well-written and provides a clear and concise overview of the Tensor Trust dataset and its potential applications.",
        "peer_review_with_watermark": "$$$ Paper Summary:\nThe paper introduces the Tensor Trust web game, a game that allows players to create and defend against prompt injection attacks on instruction fine-tuned Large Language Models (LLMs). The game generates a large dataset of attacks and defenses, which is made publicly available. The authors use this dataset to create two benchmarks for evaluating the robustness of LLMs to prompt injection attacks: prompt extraction and prompt hijacking. The results show that many LLMs are vulnerable to these types of attacks, and that some attack strategies can generalize to deployed LLM-based applications.\n\nStrengths:\n- The authors provide a comprehensive overview of prompt injection attacks and their potential risks.\n- The Tensor Trust web game provides a controlled environment for generating a large dataset of attacks and defenses.\n- The authors introduce two benchmarks for evaluating LLM robustness to prompt injection attacks, which can be useful for future research.\n\nWeaknesses:\n- The paper does not provide a clear explanation of how the LLMs were trained and fine-tuned.\n- The authors assume that the LLMs were fine-tuned for a specific task, but do not provide details on this task.\n- The paper does not discuss potential limitations of the Tensor Trust web game, such as the potential for players to collude to create attacks that are more difficult to defend against.\n\nSuggestions for Improvement:\n- Provide more details on how the LLMs were trained and fine-tuned.\n- Discuss potential limitations of the Tensor Trust web game and how these limitations can be addressed.\n- Consider including more details on the evaluation metrics used to assess LLM robustness to prompt injection attacks.\n\nRecommendation:\n- The authors' contribution to the field of LLM security is significant, and their dataset and benchmarks provide a useful resource for future researchers.\n- However, further improvements to the paper's clarity, detail, and analysis are needed to fully evaluate the robustness of LLMs to prompt injection attacks.",
        "gr_score_with": 0.8185185185185185,
        "gr_score_without": 0.7429467084639498,
        "output_without": {
            "num_tokens_scored": 319,
            "num_green_tokens": 237,
            "green_fraction": 0.7429467084639498,
            "z_score": 1.6738463062461493,
            "p_value": 0.0470804044995946
        },
        "output_with": {
            "num_tokens_scored": 270,
            "num_green_tokens": 221,
            "green_fraction": 0.8185185185185185,
            "z_score": 4.249701722077844,
            "p_value": 1.0702768216008786e-05
        }
    },
    {
        "title": "FAITHFUL RULE EXTRACTION FOR DIFFERENTIABLE RULE LEARNING MODELS",
        "abstract": "There is increasing interest in methods for extracting interpretable rules from ML models trained to solve a wide range of tasks over knowledge graphs (KGs), such as KG completion, node classification, question answering and recommendation. Many such approaches, however, lack formal guarantees establishing the precise relationship between the model and the extracted rules, and this lack of assurance becomes especially problematic when the extracted rules are applied in safetycritical contexts or to ensure compliance with legal requirements. Recent research has examined whether the rules derived from the influential NEURAL-LP model exhibit soundness (or completeness), which means that the results obtained by applying the model to any dataset always contain (or are contained in) the results obtained by applying the rules to the same dataset. In this paper, we extend this analysis to the context of DRUM, an approach that has demonstrated superior practical performance. After observing that the rules currently extracted from a DRUM model can be unsound and/or incomplete, we propose a novel algorithm where the output rules, expressed in an extension of Datalog, ensure both soundness and completeness. This algorithm, however, can be inefficient in practice and hence we propose additional constraints to DRUM models facilitating rule extraction, albeit at the expense of reduced expressive power.",
        "peer_review_without_watermark": "$$\\boxed{\\text{The paper presents a novel algorithm for extracting faithful Datalog rules from DRUM models, which has been demonstrated to be effective on a range of benchmark datasets. The authors propose two approaches to address the computational challenge of extracting faithful rules: one approach involves extracting a subset of sound rules that explain all the model\u2019s predictions on a given dataset, while the other approach involves limiting the model expressivity to make rule extraction more feasible. The authors evaluate the performance of their approach on a range of benchmark datasets and demonstrate that it is effective in extracting faithful rules. The paper provides a clear and well-structured presentation of the problem, the proposed approach, and the experimental results. The authors also provide a detailed analysis of the strengths and weaknesses of their approach. Overall, the paper presents a significant contribution to the field of knowledge graph completion and rule extraction.}}$$",
        "peer_review_with_watermark": "$$$Abstract:\nThis paper proposes a novel algorithm for extracting faithful Datalog rules from Differentiable Rules Learning Models (DRUM). Faithful rule extraction ensures that the extracted rules are sound, complete, and faithful, meaning that they accurately capture the model's predictions. The proposed algorithm, called MMDRUM, is designed for models with multiple sub-models and achieves efficient rule extraction by limiting model expressivity. Experimental results show that MMDRUM outperforms other state-of-the-art methods in terms of rule extraction efficiency and accuracy.\n\nStrengths:\n\n1.  Faithful rule extraction: The proposed algorithm, MMDRUM, ensures that the extracted rules are sound, complete, and faithful, making it suitable for applications where accurate rule extraction is crucial.\n2.  Efficient rule extraction: MMDRUM achieves efficient rule extraction by limiting model expressivity, making it feasible for large-scale rule extraction tasks.\n3.  Flexibility: The algorithm can be used with different types of models, including DRUM, SMDRUM, and other learning models.\n4.  Interpretability: The proposed algorithm provides insights into the model's decision-making process by extracting faithful rules that capture the model's predictions.\n\nWeaknesses:\n\n1.  Limited expressivity: The algorithm's limitation in expressivity may lead to oversimplification of complex models, potentially resulting in inaccurate or incomplete rule extraction.\n2.  Computational complexity: The algorithm's computational complexity may be high for large-scale models or datasets, requiring significant computational resources.\n3.  Interpretability limitations: While the proposed algorithm provides insights into the model's decision-making process, the extracted rules may not always be easy to interpret, particularly for complex models or datasets.\n\nSuggestions for Improvement:\n\n1.  Further research is needed to investigate the limitations of the algorithm's expressivity and its potential impact on rule extraction accuracy.\n2.  To improve the algorithm's efficiency, consider incorporating techniques such as parallel processing, distributed computing, or optimized data structures.\n3.  Develop methods to enhance the interpretability of the extracted rules, such as providing visualizations or explanations for the model's decision-making process.\n\nRecommendation:\n\n1.  The proposed algorithm, MMDRUM, is a significant contribution to the field of rule extraction and faithfulness guarantees.\n2.  Further research is necessary to investigate the limitations of the algorithm's expressivity and its potential impact on rule extraction accuracy.\n3.  Consider incorporating techniques to improve the algorithm's efficiency and interpretability, such as parallel processing, optimized data structures, or visualizations for the model's decision-making process.\n4.  The proposed algorithm is suitable for applications where accurate rule extraction is crucial, such as knowledge graph completion, question answering, or recommendation systems.\n5.  The experimental results demonstrate the algorithm's efficiency and accuracy, making it a promising approach for rule extraction tasks.\n6.  Consider exploring the application of the algorithm to other learning models, such as neural networks or graph-based models, to further demonstrate its versatility.\n7.  Develop methods to enhance the interpretability of the extracted rules, such as providing visualizations or explanations for the model's decision-making process.\n8.  Investigate the potential applications of the algorithm in areas such as natural language processing, computer vision, or robotics, where accurate rule extraction is crucial for decision-making.\n9.  Consider developing tools or frameworks that support the use of the algorithm, such as visual interfaces or automated workflows.\n10. Further research is necessary to investigate the potential limitations and challenges associated with the algorithm's use, such as handling noisy or missing data, or dealing with complex models or datasets.",
        "gr_score_with": 0.7573033707865169,
        "gr_score_without": 0.5562913907284768,
        "output_without": {
            "num_tokens_scored": 151,
            "num_green_tokens": 84,
            "green_fraction": 0.5562913907284768,
            "z_score": -3.853555452400295,
            "p_value": 0.9999417925588852
        },
        "output_with": {
            "num_tokens_scored": 445,
            "num_green_tokens": 337,
            "green_fraction": 0.7573033707865169,
            "z_score": 2.637852621479918,
            "p_value": 0.004171641649823976
        }
    },
    {
        "title": "SYMPHONY: SYMMETRY-EQUIVARIANT POINT- CENTERED SPHERICAL HARMONICS FOR MOLECULE GENERATION",
        "abstract": "We present Symphony, an E(3)-equivariant autoregressive generative model for 3D molecular geometries that iteratively builds a molecule from molecular fragments. Existing autoregressive models such as G-SchNet (Gebauer et al., 2019) and G-SphereNet (Luo & Ji, 2022) for molecules utilize rotationally invariant features to respect the 3D symmetries of molecules. In contrast, Symphony uses message-passing with higher-degree E(3)-equivariant features. This allows a novel representation of probability distributions via spherical harmonic signals to efficiently model the 3D geometry of molecules. We show that Symphony is able to accurately generate small molecules from the QM9 dataset, outperforming existing autoregressive models and approaching the performance of diffusion models.",
        "peer_review_without_watermark": "$$$\\begin{align}\\textbf{Paper Summary:}~\\text{The paper proposes Symphony, an E(3)-equivariant autoregressive generative model for 3D molecular geometries. It iteratively builds a molecule from molecular fragments using higher-degree E(3)-equivariant features and spherical harmonic projections. The model outperforms existing autoregressive models and approaches the performance of diffusion models on a variety of metrics.}\\end{align}$$\n\n$$$\\begin{align}\\textbf{Strengths:}~\\text{The model uses higher-degree E(3)-equivariant features, which allows for a novel representation of probability distributions via spherical harmonic signals to efficiently model the 3D geometry of molecules. It also outperforms existing autoregressive models and approaches the performance of diffusion models. The model is able to generate valid molecules at a high success rate, even when conditioned on unseen molecular fragments.}\\end{align}$$\n\n$$$\\begin{align}\\textbf{Weaknesses:}~\\text{The model has a coarse discretization of its radial components, which affects the accuracy of its bond length distributions. The model incurs increased computational cost due to the use of tensor products to create higher degree E(3)-equivariant features. The model's inference speed is slower than existing autoregressive models.}\\end{align}$$\n\n$$$\\begin{align}\\textbf{Suggestions for Improvement:}~\\text{To improve the accuracy of the model's bond length distributions, consider using a finer discretization of the radial components. To reduce the computational cost, consider using a more efficient method for creating higher degree E(3)-equivariant features. To improve the inference speed, consider using a more efficient sampler or optimizing the model's architecture.}\\end{align}$$\n\n$$$\\begin{align}\\textbf{Recommendation:}~\\text{Based on the promising results on molecular generation and completion, Symphony is a viable option for 3D molecular geometry generation. However, further exploration of the data efficiency of the model and optimization of its architecture are necessary to achieve state-of-the-art performance.}\\end{align}$$",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper introduces Symphony, a novel autoregressive generative model for 3D molecular geometries that uses higher-degree E(3)-equivariant features and spherical harmonic projections. Symphony builds molecules sequentially by predicting atom types and locations of new atoms based on conditional probability distributions informed by previously placed atoms. The model outperforms existing autoregressive models and is competitive with existing diffusion models on various metrics.\n\nStrengths:\n1. Symphony uses higher-degree E(3)-equivariant features, which can capture more complex symmetries in molecules.\n2. Spherical harmonic projections allow for a novel representation of probability distributions in 3D space.\n3. Symphony can generate valid molecules at a high success rate, even when conditioned on unseen molecular fragments.\n4. The model has a fast inference speed, making it suitable for large-scale molecular generation tasks.\n\nWeaknesses:\n1. The discretization of radial components in Symphony is too coarse, leading to inaccurate bond length distributions.\n2. Symphony incurs increased computational cost due to the use of tensor products to create higher degree E(3)-equivariant features.\n3. The model may not generalize well to unseen fragments, as its performance on completion tasks can be affected by training progression.\n\nSuggestions for Improvement:\n1. Refine the discretization of radial components to improve bond length distribution accuracy.\n2. Explore normalizing flows to model radial distribution without discretization.\n3. Investigate placing entire local environment motifs at once to improve generation speed.\n4. Consider incorporating additional features, such as bond order information, to enhance model performance.\n\nRecommendation:\nSymphony is a promising new method for autoregressively generating 3D molecular geometries. While it has some limitations, its use of higher-degree E(3)-equivariant features and spherical harmonic projections make it a valuable contribution to the field of molecular generation. To further improve Symphony, researchers should focus on refining its discretization, exploring new methods for radial distribution modeling, and incorporating additional features to enhance its performance.",
        "gr_score_with": 0.7675840978593272,
        "gr_score_without": 0.6802973977695167,
        "output_without": {
            "num_tokens_scored": 269,
            "num_green_tokens": 183,
            "green_fraction": 0.6802973977695167,
            "z_score": -0.7051639182000461,
            "p_value": 0.759645883605144
        },
        "output_with": {
            "num_tokens_scored": 327,
            "num_green_tokens": 251,
            "green_fraction": 0.7675840978593272,
            "z_score": 2.666912395842923,
            "p_value": 0.0038275811586550947
        }
    },
    {
        "title": "MAXIMUM ENTROPY MODEL CORRECTION",
        "abstract": "We propose and theoretically analyze an approach for planning with an approximate model in reinforcement learning that can reduce the adverse impact of model error. If the model is accurate enough, it accelerates the convergence to the true value function too. One of its key components is the MaxEnt Model Correction (MoCo) procedure that corrects the model\u2019s next-state distributions based on a Maximum Entropy density estimation formulation. Based on MoCo, we introduce the Model Correcting Value Iteration (MoCoVI) algorithm, and its sampled-based variant MoCoDyna. We show that MoCoVI and MoCoDyna\u2019s convergence can be much faster than the conventional model-free algorithms. Unlike traditional model-based algorithms, MoCoVI and MoCoDyna effectively utilize an approximate model and still converge to the correct value function.",
        "peer_review_without_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes the MaxEnt Model Correction (MoCo) framework to reduce the impact of model errors in reinforcement learning (RL) algorithms. The framework uses maximum entropy density estimation to correct the approximate model's next-state distributions. The authors introduce two algorithms, Model Correcting Value Iteration (MoCoVI) and Model Correcting Dyna (MoCoDyna), to utilize the approximate model and converge to the true value function despite model errors. Theoretical analysis and numerical experiments demonstrate the effectiveness of the MoCo framework in accelerating convergence rates and ensuring convergence to the true value functions.\n\n$\\boxed{Strengths:}\n1. The paper bridges the gap between model-based and model-free RL algorithms by proposing a cost-efficient approach to alleviate model errors.\n2. The MaxEnt model correction framework is a novel and effective method for reducing model errors.\n3. The authors provide thorough theoretical analysis and numerical experiments to demonstrate the effectiveness of the MoCo framework.\n4. The paper introduces two algorithms, MoCoVI and MoCoDyna, which extend the Dyna framework and provide a sample-based variant.\n\n$\\boxed{Weaknesses:}\n1. The paper assumes that the approximate model is accurate enough, which may not always be the case in practice.\n2. The theoretical analysis relies on certain assumptions, such as the true value function can be well-approximated by a linear combination of basis functions.\n3. The paper does not provide a detailed discussion of the hyperparameter tuning for the MaxEnt model correction framework.\n4. The numerical experiments are limited to a specific environment and may not be representative of other RL tasks.\n\n$\\boxed{Suggestions for Improvement:}\n1. Provide a more detailed discussion of the assumptions made in the theoretical analysis and how they relate to real-world scenarios.\n2. Investigate the robustness of the MoCo framework to different types of model errors and environments.\n3. Provide a more detailed discussion of the hyperparameter tuning for the MaxEnt model correction framework and its impact on the performance of the algorithms.\n4. Conduct more extensive numerical experiments to evaluate the performance of the MoCo framework in different RL tasks and environments.\n\n$\\boxed{Recommendation:}\nBased on the paper's contributions to the field of reinforcement learning and the effectiveness of the MoCo framework, I recommend that it be published in a top-tier conference or journal. However, I also suggest that the authors address the limitations and weaknesses of the paper to make it more robust and representative of the field.",
        "peer_review_with_watermark": "$$$\\boxed{Summary:}\nThe paper proposes and theoretically analyzes the MaxEnt Model Correction (MoCo) framework, which reduces the adverse impact of model errors in reinforcement learning (RL) by employing maximum entropy density estimation. The authors introduce two algorithms: Model Correcting Value Iteration (MoCoVI) and its sample-based variant MoCoDyna. Theoretical analysis shows that if the model is accurate enough, MoCoVI can converge to the true value function despite model errors, and its convergence rate can be much faster than conventional Value Iteration (VI). The authors also demonstrate the effectiveness of MoCo-based planning algorithms in both finite and continuous MDPs.\n\n$\\boxed{Strengths:}\n1. The paper provides a thorough theoretical analysis of the MaxEnt model correction framework, demonstrating its effectiveness in reducing model errors and accelerating convergence rates.\n2. The authors introduce two algorithms, MoCoVI and MoCoDyna, and demonstrate their superiority over conventional Value Iteration (VI) and Dyna-based algorithms.\n3. The paper covers both finite and continuous MDPs, providing a comprehensive analysis of the framework's applicability.\n4. The authors conduct extensive numerical experiments to evaluate the performance of MoCo-based algorithms, demonstrating their effectiveness in both RL and planning applications.\n\n$\\boxed{Weaknesses:}\n1. The paper does not discuss potential applications of the MaxEnt model correction framework beyond RL and planning.\n2. The authors assume access to exact queries to the true dynamics, which may not be feasible in practice.\n3. The paper does not provide a detailed comparison of MoCo-based algorithms with other state-of-the-art RL algorithms.\n\n$\\boxed{Suggestions for Improvement:}\n1. The authors should explore potential applications of the MaxEnt model correction framework beyond RL and planning.\n2. The authors should discuss potential ways to relax the assumption of exact queries to the true dynamics.\n3. The authors should conduct a comprehensive comparison of MoCo-based algorithms with other state-of-the-art RL algorithms.\n\n$\\boxed{Recommendation:}\nThe MaxEnt model correction framework and its algorithms, MoCoVI and MoCoDyna, demonstrate significant potential for improving the performance of reinforcement learning and planning algorithms. The authors' thorough theoretical analysis and extensive numerical experiments provide strong evidence for the framework's effectiveness. However, future work should address potential applications, relax assumptions, and conduct comprehensive comparisons to fully realize the framework's potential.",
        "gr_score_with": 0.7475409836065574,
        "gr_score_without": 0.6704545454545454,
        "output_without": {
            "num_tokens_scored": 352,
            "num_green_tokens": 236,
            "green_fraction": 0.6704545454545454,
            "z_score": -1.2096294735180093,
            "p_value": 0.8867894483511316
        },
        "output_with": {
            "num_tokens_scored": 305,
            "num_green_tokens": 228,
            "green_fraction": 0.7475409836065574,
            "z_score": 1.8117924067659283,
            "p_value": 0.0350091394149177
        }
    },
    {
        "title": "A PRECISE CHARACTERIZATION OF SGD STABILITY USING LOSS SURFACE GEOMETRY",
        "abstract": "Stochastic Gradient Descent (SGD) stands as a cornerstone optimization algorithm with proven real-world empirical successes but relatively limited theoretical understanding. Recent research has illuminated a key factor contributing to its practical efficacy: the implicit regularization it instigates. Several studies have investigated the linear stability property of SGD in the vicinity of a stationary point as a predictive proxy for sharpness and generalization error in overparameterized neural networks (Wu et al., 2022; Jastrzebski et al., 2019; Cohen et al., 2021). In this paper, we delve deeper into the relationship between linear stability and sharpness. More specifically, we meticulously delineate the necessary and sufficient conditions for linear stability, contingent on hyperparameters of SGD and the sharpness at the optimum. Towards this end, we introduce a novel coherence measure of the loss Hessian that encapsulates pertinent geometric properties of the loss function that are relevant to the linear stability of SGD. It enables us to provide a simplified sufficient condition for identifying linear instability at an optimum. Notably, compared to previous works, our analysis relies on significantly milder assumptions and is applicable for a broader class of loss functions than known before, encompassing not only mean-squared error but also cross-entropy loss.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary: \nThe paper investigates the relationship between linear stability and sharpness in Stochastic Gradient Descent (SGD). The authors introduce a novel coherence measure of the loss Hessian that encapsulates the geometric properties of the loss function relevant to the linear stability of SGD. They provide a precise characterization of how the SGD hyperparameters and properties of the loss function affect its implicit regularization of model sharpness.\n\n$$\\text{Strengths}$$\n\n*   The paper provides a novel coherence measure of the loss Hessian that captures the geometric properties of the loss function relevant to the linear stability of SGD.\n*   The authors provide a precise characterization of how the SGD hyperparameters and properties of the loss function affect its implicit regularization of model sharpness.\n*   The paper includes a series of experiments that support the theoretical results and provide insight into the behavior of SGD in various scenarios.\n\n$$\\text{Weaknesses}$$\n\n*   The paper does not provide a clear explanation of the coherence measure and its relevance to the linear stability of SGD.\n*   The authors assume that the point $w^*$ is a local minimum of the loss function, but they do not provide a clear justification for this assumption.\n*   The paper does not consider the effect of non-additive decomposability of the loss function on the linear stability of SGD.\n\n$$\\text{Suggestions for Improvement}$$\n\n*   The authors should provide a clear explanation of the coherence measure and its relevance to the linear stability of SGD.\n*   The authors should provide a clear justification for the assumption that the point $w^*$ is a local minimum of the loss function.\n*   The authors should consider the effect of non-additive decomposability of the loss function on the linear stability of SGD.\n\n$$\\text{Recommendation}$$\n\n*   The paper contributes to the understanding of the relationship between linear stability and sharpness in SGD and provides a novel coherence measure of the loss Hessian.\n*   The authors should focus on providing a clear explanation of the coherence measure and its relevance to the linear stability of SGD, as well as providing a clear justification for the assumption that the point $w^*$ is a local minimum of the loss function.\n*   The authors should consider the effect of non-additive decomposability of the loss function on the linear stability of SGD.\n\n$$\\text{Final Thoughts}$$\n\n*   The paper provides a valuable contribution to the understanding of the relationship between linear stability and sharpness in SGD.\n*   The authors should focus on providing a clear explanation of the coherence measure and its relevance to the linear stability of SGD, as well as providing a clear justification for the assumption that the point $w^*$ is a local minimum of the loss function.\n*   The authors should consider the effect of non-additive decomposability of the loss function on the linear stability of SGD.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThis paper provides a precise characterization of Stochastic Gradient Descent (SGD) stability using loss surface geometry, specifically focusing on the linear stability property of SGD in the vicinity of a stationary point as a predictive proxy for sharpness and generalization error in overparameterized neural networks.\n\nStrengths:\n1. The work introduces a novel coherence measure of the loss Hessian that encapsulates relevant geometric properties of the loss function that are relevant to linear stability of SGD.\n2. The sufficient condition for E\u2225wk\u22252 to diverge as k \u2192 \u221e, which relies on a coherence measure, provides a precise characterization of linear stability.\n3. The work provides a rigorous proof of the sufficient condition and demonstrates that it is nearly optimal across a natural range of SGD hyperparameters.\n4. The experiments conducted on synthetic optimization problems support the accuracy and soundness of the theoretical results.\n\nWeaknesses:\n1. The work relies heavily on assumptions about the nature of the loss function and the batch sampling scheme used in SGD.\n2. The coherence measure, although novel, might not be directly applicable to all types of neural networks.\n3. The proof of Lemma 4.1, which is used to derive Theorem 2, is complex and might be challenging to follow for some readers.\n\nSuggestions for Improvement:\n1. Consider relaxing some of the assumptions made in the work to make it more applicable to a broader range of neural networks.\n2. Provide additional theoretical analysis to justify the applicability of the coherence measure to different types of neural networks.\n3. Consider exploring other approaches to derive local convergence rates of SGD, such as using tools from convex optimization.\n\nRecommendation:\nThis work makes a significant contribution to our understanding of SGD stability using loss surface geometry and provides a precise characterization of linear stability. The novel coherence measure and rigorous proof of the sufficient condition provide valuable insights into the behavior of SGD in practice. The experiments conducted on synthetic optimization problems support the accuracy and soundness of the theoretical results. Overall, this work is a valuable addition to the literature on optimization and neural networks, and it has the potential to be widely applicable.\n\n$$$",
        "gr_score_with": 0.7933130699088146,
        "gr_score_without": 0.7177033492822966,
        "output_without": {
            "num_tokens_scored": 209,
            "num_green_tokens": 150,
            "green_fraction": 0.7177033492822966,
            "z_score": 0.5584945425171316,
            "p_value": 0.2882533650754336
        },
        "output_with": {
            "num_tokens_scored": 329,
            "num_green_tokens": 261,
            "green_fraction": 0.7933130699088146,
            "z_score": 3.6934377109631638,
            "p_value": 0.00011062136085954365
        }
    }
]