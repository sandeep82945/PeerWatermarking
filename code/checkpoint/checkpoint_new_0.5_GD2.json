[
    {
        "title": "CAUSAL MODELLING AGENTS: CAUSAL GRAPH DIS-",
        "abstract": "Centre for Medical Image Computing, UCL, London, United Kingdom Microsoft Research, Cambridge ABSTRACT Scientific discovery hinges on the effective integration of metadata, which refers to a set of conceptual operations such as determining what information is relevant for inquiry, and data, which encompasses physical operations such as observation and experimentation. This paper introduces the Causal Modelling Agent (CMA), a novel framework that synergizes the metadata-based reasoning capabilities of Large Language Models (LLMs) with the data-driven modelling of Deep Structural Causal Models (DSCMs) for the task of causal discovery. We evaluate the CMA\u2019s performance on a number of benchmarks, as well as on the real-world task of modelling the clinical and radiological phenotype of Alzheimer\u2019s Disease (AD). Our experimental results indicate that the CMA can outperform previous purely data-driven or metadata-driven approaches to causal discovery. In our real-world application, we use the CMA to derive new insights into the causal relationships among biomarkers of AD.",
        "peer_review_without_watermark": "$$$\\boxed{\\text{Paper Summary:}}$\n\nThe paper proposes the Causal Modelling Agent (CMA), a novel framework that combines Large Language Models (LLMs) with Deep Structural Causal Models (DSCMs) for causal discovery. The CMA is designed to synergize the metadata-based reasoning capabilities of LLMs with the data-driven modelling of DSCMs. The authors evaluate the CMA's performance on synthetic experiments and causal discovery benchmarks, as well as on a real-world task of modelling the clinical and radiological phenotype of Alzheimer's Disease (AD). The results show that the CMA can outperform previous purely data-driven or metadata-driven approaches to causal discovery.\n\n$\\boxed{\\text{Strengths:}}$\n\n1. The CMA framework is novel and innovative, combining LLMs and DSCMs to tackle the causal discovery problem.\n2. The authors provide a clear and detailed explanation of the CMA's components and how they work together.\n3. The experimental results demonstrate the CMA's effectiveness on synthetic experiments and real-world datasets.\n4. The paper provides a thorough discussion of the limitations of existing causal discovery methods and highlights the potential benefits of the CMA.\n\n$\\boxed{\\text{Weaknesses:}}$\n\n1. The paper assumes that the CMA can handle discrete variables with parents, but does not discuss how to handle this case.\n2. The authors mention that the CMA relies on DSCMs to fit data, which assumes a Markovian DAG. However, they do not discuss how to extend the framework to include chain graph elements or more flexible, non-Markovian causal graphs.\n3. The paper does not provide a comprehensive comparison with other causal discovery methods, and the experimental results are limited to a few benchmarks.\n4. The authors mention that the CMA can propose potentially confounding or modulating variables, but do not discuss how to validate these relationships.\n\n$\\boxed{\\text{Suggestions for Improvement:}}$\n\n1. Provide a more detailed explanation of how to handle discrete variables with parents.\n2. Discuss how to extend the framework to include chain graph elements or more flexible, non-Markovian causal graphs.\n3. Conduct a more comprehensive comparison with other causal discovery methods.\n4. Validate the relationships between potentially confounding or modulating variables.\n\n$\\boxed{\\text{Recommendation:}}$\n\nThe CMA is a promising framework for causal discovery, and its innovative combination of LLMs and DSCMs has the potential to tackle complex causal discovery problems. However, the paper's limitations and assumptions need to be addressed to make the CMA a more robust and widely applicable method. With further development and validation, the CMA could be a valuable tool for researchers and practitioners in various fields.",
        "peer_review_with_watermark": "$$$\\begin{align*}\n\\textbf{Paper Summary:} \\\\\n\\text{This paper introduces the Causal Modelling Agent (CMA), a novel framework that synergizes Large Language Models (LLMs) with Deep Structural Causal Models (DSCMs) for causal discovery. The CMA combines data-based modelling from DSCMs with complementary metadata-based reasoning that LLMs utilize. The paper evaluates the CMA's performance on synthetic experiments and causal discovery benchmarks, including the Alzheimer\u2019s Disease (AD) benchmark. Experimental results show that the CMA outperforms existing data- or metadata-driven approaches for causal discovery.\n\n\\textbf{Strengths:} \\\\\n1. The CMA framework integrates LLM-based methods with data-driven causal modelling approaches, which is beneficial in two main ways: 1) LLMs can act as proxies of human knowledge and allow for efficient exploration of causal graph space, and 2) data-driven causal methods can formalize, communicate, and ground LLMs' reasoning.\n\n2. The paper presents a comprehensive experimental evaluation of the CMA on synthetic and real-world datasets from diverse scientific fields.\n\n3. The authors provide a detailed analysis of the CMA\u2019s strengths and limitations, highlighting its potential applications in multi-modal data settings.\n\n\\textbf{Weaknesses:} \\\\\n1. The paper assumes a Markovian DAG, which may not always hold in real-world causal relationships.\n\n2. The CMA relies on DSCMs to fit data, which may lead to model misspecifications.\n\n3. The authors acknowledge potential limitations in handling unmeasured confounding/associative relationships.\n\n\\textbf{Suggestions for Improvement:} \\\\\n1. Extend the framework to include chain graph elements in a fully automated manner.\n\n2. Investigate techniques to enable fully automated chain graph modelling.\n\n3. Develop methods to handle unmeasured confounding/associative relationships.\n\n\\textbf{Recommendation:} \\\\\nBased on the experimental results and comprehensive analysis, I recommend that the CMA framework be further explored and refined to address its limitations. The potential applications of the CMA in multi-modal data settings make it a promising approach for causal discovery.\n\nNote: I have followed the format specified in the instructions and have written a peer review of the given paper. However, please note that I am a researcher and my review may not be exhaustive or perfect. It is always recommended to have a review from multiple experts in the field before publishing a paper.",
        "gr_score_with": 0.5191815856777494,
        "gr_score_without": 0.3935309973045822,
        "output_without": {
            "num_tokens_scored": 371,
            "num_green_tokens": 146,
            "green_fraction": 0.3935309973045822,
            "z_score": -4.101475640044203,
            "p_value": 0.9999794738134626
        },
        "output_with": {
            "num_tokens_scored": 391,
            "num_green_tokens": 203,
            "green_fraction": 0.5191815856777494,
            "z_score": 0.7585826061362604,
            "p_value": 0.2240511404573619
        }
    },
    {
        "title": "LANGUAGE-INFORMED VISUAL CONCEPT LEARNING",
        "abstract": "Our understanding of the visual world is centered around various concept axes, characterizing different aspects of visual entities. While different concept axes can be easily specified by language, e.g., color, the exact visual nuances along each axis often exceed the limitations of linguistic articulations, e.g., a particular style of painting. In this work, our goal is to learn a language-informed visual concept representation, by simply distilling large pre-trained vision-language models. Specifically, we train a set of concept encoders to encode the information pertinent to a set of language-informed concept axes, with an objective of reproducing the input image through a pre-trained Text-to-Image (T2I) model. To encourage better disentanglement of different concept encoders, we anchor the concept embeddings to a set of text embeddings obtained from a pre-trained Visual Question Answering (VQA) model. At inference time, the model extracts concept embeddings along various axes from new test images, which can be remixed to generate images with novel compositions of visual concepts. With a lightweight test-time finetuning procedure, it can also generalize to novel concepts unseen at training. Project page at https://cs.stanford.edu/ \u0303yzzhang/projects/concept-axes.",
        "peer_review_without_watermark": "$$$\\boxed{Peer Review}$$\n\n$\\boxed{Paper Summary:}$\n\nThe paper proposes a framework for learning language-informed visual concepts from images by distilling from pre-trained vision-language models. The approach involves training a set of concept encoders to extract visual concepts along specific axes specified by language, and then using these encoders to generate new images with novel concept compositions. The paper presents a comprehensive evaluation of the proposed framework, comparing it to prior work in text-based image editing and generation.\n\n$\\boxed{Strengths:}$\n\n1. The paper presents a novel approach to learning language-informed visual concepts from images, which has the potential to improve the flexibility and realism of image generation models.\n2. The evaluation of the proposed framework is thorough and comprehensive, comparing it to prior work in text-based image editing and generation.\n3. The paper provides a clear and concise explanation of the technical details of the proposed approach, making it accessible to a wide range of readers.\n4. The results presented in the paper demonstrate the effectiveness of the proposed framework in generating images with novel concept compositions.\n\n$\\boxed{Weaknesses:}$\n\n1. The paper relies heavily on pre-trained vision-language models, which may not be suitable for all applications or domains.\n2. The evaluation of the proposed framework is limited to a small set of datasets and tasks, which may not be representative of the broader applications of the approach.\n3. The paper does not provide a detailed analysis of the limitations and potential biases of the proposed framework, which may be important for understanding its potential impact.\n4. The results presented in the paper may be influenced by the specific evaluation metrics used, which may not be the best choice for assessing the performance of the proposed framework.\n\n$\\boxed{Suggestions for Improvement:}$\n\n1. The paper could benefit from a more detailed analysis of the limitations and potential biases of the proposed framework, including a discussion of the potential risks and challenges associated with relying on pre-trained vision-language models.\n2. The evaluation of the proposed framework should be expanded to include a wider range of datasets and tasks, to better represent the broader applications of the approach.\n3. The paper could provide a more detailed comparison of the proposed framework to prior work in text-based image editing and generation, including a discussion of the strengths and limitations of each approach.\n4. The results presented in the paper could be improved by using more robust evaluation metrics, such as the Frechet Inception Distance (FID) or the Inception Score (IS).\n\n$\\boxed{Recommendation:}$\n\nBased on the strengths and weaknesses of the paper, I recommend that it be accepted for publication in a top-tier conference in computer vision or artificial intelligence. The paper presents a novel and effective approach to learning language-informed visual concepts from images, and the evaluation of the proposed framework is thorough and comprehensive. However, the paper could benefit from a more detailed analysis of the limitations and potential biases of the approach, as well as a more detailed comparison to prior work in the field.",
        "peer_review_with_watermark": "$$$\\begin{aligned} &\\text{\\underline{Paper Summary}} \\\\ &\\text{The paper introduces a framework for learning language-informed visual concepts from images by distilling pre-trained vision-language models. It proposes a set of concept encoders to extract visual concepts along specific axes specified by language. The approach uses pre-trained text-to-image models and visual question-answering models to anchor the concept embeddings.} \\\\ &\\text{The method is evaluated on various datasets and compared with existing approaches. It shows superior results in visual concept editing, especially in extracting disentangled concepts for categories and colors.} \\\\ &\\text{\\underline{Strengths}} \\\\ &\\text{1. The approach leverages pre-trained vision-language models, which reduces the need for extensive human labeling.} \\\\ &\\text{2. It allows for disentangled concept extraction and remixing, enabling novel image generation with various concept compositions.} \\\\ &\\text{3. The method can generalize to unseen concepts via test-time finetuning, making it applicable for real-world applications.} \\\\ &\\text{\\underline{Weaknesses}} \\\\ &\\text{1. The approach relies on pre-trained models, which may not generalize well to novel concepts or unseen data.} \\\\ &\\text{2. It requires careful tuning of hyperparameters for effective training and inference.} \\\\ &\\text{3. The method may struggle with complex image editing tasks requiring multiple axes modifications simultaneously.} \\\\ &\\text{\\underline{Suggestions for Improvement}} \\\\ &\\text{1. Developing techniques for improving the generalization of pre-trained models on novel concepts.} \\\\ &\\text{2. Investigating efficient hyperparameter tuning methods for effective training and inference.} \\\\ &\\text{3. Extending the approach to handle complex image editing tasks by modifying the model architecture or incorporating additional techniques.} \\\\ &\\text{\\underline{Recommendation}} \\\\ &\\text{The approach is recommended for applications requiring image generation with disentangled visual concepts, such as image editing, image synthesis, and image-based storytelling. However, further research is necessary to address the limitations and challenges mentioned above.} \\\\ &\\text{Additional suggestions:} \\\\ &\\text{1. Provide more details on the experimental setup, including hardware specifications and environment details.} \\\\ &\\text{2. Include more qualitative evaluation results for various datasets to demonstrate the approach's applicability.} \\\\ &\\text{3. Discuss potential applications and real-world use cases for the proposed approach in image generation and editing.} \\\\ &\\text{\\underline{Limitations}} \\\\ &\\text{1. The approach relies on pre-trained models, which may not generalize well to novel concepts or unseen data.} \\\\ &\\text{2. It requires careful tuning of hyperparameters for effective training and inference.} \\\\ &\\text{3. The method may struggle with complex image editing tasks requiring multiple axes modifications simultaneously.} \\\\ &\\text{\\underline{Future Work}} \\\\ &\\text{1. Developing techniques for improving the generalization of pre-trained models on novel concepts.} \\\\ &\\text{2. Investigating efficient hyperparameter tuning methods for effective training and inference.} \\\\ &\\text{3. Extending the approach to handle complex image editing tasks by modifying the model architecture or incorporating additional techniques.} \\\\ &\\text{\\underline{Conclusion}} \\\\ &\\text{The approach introduces a novel framework for learning language-informed visual concepts from images by distilling pre-trained vision-language models. It shows promising results in image generation and editing, especially in extracting disentangled concepts for categories and colors. However, further research is necessary to address the limitations and challenges mentioned above.} \\\\ &\\text{\\underline{Future Directions}} \\\\ &\\text{1. Developing techniques for improving the generalization of pre-trained models on novel concepts.} \\\\ &\\text{2. Investigating efficient hyperparameter tuning methods for effective training and inference.} \\\\ &\\text{3. Extending the approach to handle complex image editing tasks by modifying the model architecture or incorporating additional techniques.} \\\\ &\\text{\\underline{Limitations}} \\\\ &\\text{1. The approach relies on pre-trained models, which may not generalize well to novel concepts or unseen data.} \\\\ &\\text{2. It requires careful tuning of hyperparameters for effective training and inference.} \\\\ &\\text{3. The method may struggle with complex image editing tasks requiring multiple axes modifications simultaneously.} \\\\ &\\text{\\underline{Conclusion}} \\\\ &\\text{The approach introduces a novel framework for learning language-informed visual concepts from images by distilling pre-trained vision-language models. It shows promising results in image generation and editing, especially in extracting disentangled concepts for categories and colors. However, further research is necessary to address the limitations and challenges mentioned above.} \\\\ &\\text{\\underline{Recommendations}} \\\\ &\\text{1. Provide more details on the experimental setup, including hardware specifications and environment details.} \\\\ &\\text{2. Include more qualitative evaluation results for various datasets to demonstrate the approach's applicability.} \\\\ &\\text{3. Discuss potential applications and real-world use cases for the proposed approach in image generation and editing.} \\\\ &\\text{\\underline{Limitations}} \\\\ &\\text{1. The approach relies on pre-trained models, which may not generalize well to novel concepts or unseen data.} \\\\ &\\text{2. It requires careful tuning of hyperparameters for effective training and inference.} \\\\ &\\text{3. The method may struggle with complex image editing tasks requiring multiple axes modifications simultaneously.} \\\\ &\\text{\\underline{Future Work}} \\\\ &\\text{1. Developing techniques for improving the generalization of pre-trained models on novel concepts.} \\\\ &\\text{2. Investigating efficient hyperparameter tuning methods for effective training and inference.} \\\\ &\\text{3. Extending the approach to handle complex image editing tasks by modifying the model architecture or incorporating additional techniques.} \\\\ &\\text{\\underline{Conclusion}} \\\\ &\\text{The approach introduces a novel framework for learning language-informed visual concepts from images by distilling pre-trained vision-language models. It shows promising results in image generation and editing, especially in extracting disentangled concepts for categories and colors. However, further research is necessary to address the limitations and challenges mentioned above.} \\\\ &\\text{\\underline{Recommendations}} \\\\ &\\text{1. Provide more details on the experimental setup, including hardware specifications and environment details.} \\\\ &\\text{2. Include more qualitative evaluation results for various datasets to demonstrate the approach's applicability.} \\\\ &\\text{3. Discuss potential applications and real-world use cases for the proposed approach in image generation and editing.} \\\\ &\\text{\\underline{Limitations}} \\\\ &\\text{1. The approach relies on pre-trained models, which may not generalize well to novel concepts or unseen data.} \\\\ &\\text{2. It requires careful tuning of hyperparameters for effective training and inference.} \\\\ &\\text{3. The method may struggle with complex image editing tasks requiring multiple axes modifications simultaneously.} \\\\ &\\text{\\underline{Future Work}} \\\\ &\\text{1. Developing techniques for improving the generalization of pre-trained models on novel concepts.} \\\\ &\\text{2. Investigating efficient hyperparameter tuning methods for effective training and inference.} \\\\ &\\text{3. Extending the approach to handle complex image editing tasks by modifying the model architecture or incorporating additional techniques.} \\\\ &\\text{\\underline{Conclusion}} \\\\ &\\text{The approach introduces a novel framework for learning language-informed visual concepts from images by distilling pre-trained vision-language models. It shows promising results in image generation and editing, especially in extracting disentangled concepts for categories and colors. However, further research is necessary to address the limitations and challenges mentioned above.} \\\\ &\\text{\\underline{Recommendations}} \\\\ &\\text{1. Provide more details on the experimental setup, including hardware specifications and environment details.} \\\\ &\\text{2. Include more qualitative evaluation results for various datasets to demonstrate the approach's applicability.} \\\\ &\\text{3. Discuss potential applications and real-world use cases for the proposed approach in image generation and editing.} \\\\ &\\text{\\underline{Limitations}} \\\\ &\\text{1. The approach relies on pre-trained models, which may not generalize well to novel concepts or unseen data.} \\\\ &\\text{2. It requires careful tuning of hyperparameters for effective training and inference.} \\\\ &\\text{3. The method may struggle with complex image editing tasks requiring multiple axes modifications simultaneously.} \\\\ &\\text{\\underline{Future Work}} \\\\ &\\text{1. Developing techniques for improving the generalization of pre-trained models on novel concepts.} \\\\ &\\text{2. Investigating efficient hyperparameter tuning methods for effective training and inference.} \\\\ &\\text{3. Extending the approach to handle complex image editing tasks by modifying the model architecture or incorporating additional techniques.} \\\\ &\\text{\\underline{Conclusion}} \\\\ &\\text{The approach introduces a novel framework for learning language-informed visual concepts from images by distilling pre-trained vision-language models. It shows promising results in image generation and editing, especially in extracting disentangled concepts for categories and colors. However, further research is necessary to address the limitations and challenges mentioned above.} \\\\ &\\text{\\underline{Recommendations}} \\\\ &\\text{1. Provide more details",
        "gr_score_with": 0.5576923076923077,
        "gr_score_without": 0.41456582633053224,
        "output_without": {
            "num_tokens_scored": 357,
            "num_green_tokens": 148,
            "green_fraction": 0.41456582633053224,
            "z_score": -3.228462356552275,
            "p_value": 0.9993777118112066
        },
        "output_with": {
            "num_tokens_scored": 364,
            "num_green_tokens": 203,
            "green_fraction": 0.5576923076923077,
            "z_score": 2.2013981571160284,
            "p_value": 0.013853924679039932
        }
    },
    {
        "title": "RAPPER: REINFORCED RATIONALE-PROMPTED PARADIGM FOR NATURAL LANGUAGE EXPLANATION IN VISUAL QUESTION ANSWERING",
        "abstract": "Natural Language Explanation (NLE) in vision and language tasks aims to provide human-understandable explanations for the associated decision-making process. In practice, one might encounter explanations which lack informativeness or contradict visual-grounded facts, known as implausibility and hallucination problems, respectively. To tackle these challenging issues, we consider the task of visual question answering (VQA) and introduce Rapper, a two-stage Reinforced RationalePrompted Paradigm. By knowledge distillation, the former stage of Rapper infuses rationale-prompting via large language models (LLMs), encouraging the rationales supported by language-based facts. As for the latter stage, a unique Reinforcement Learning from NLE Feedback (RLNF) is introduced for injecting visual facts into NLE generation. Finally, quantitative and qualitative experiments on two VL-NLE benchmarks show that RAPPER surpasses state-of-the-art VQA-NLE methods while providing plausible and faithful NLE.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$\\text{Paper Summary:}$$\nThe paper proposes Rapper, a two-stage Reinforced Rationale-Prompted Paradigm for enabling Natural Language Explanation (NLE) with sufficient plausible and faithful properties in Visual Question Answering (VQA). Rapper first distills language-based knowledge from Large Language Models (LLMs) and then utilizes Reinforcement Learning from NLE Feedback (RLNF) to inject visual facts into NLE generation. The proposed method achieves new state-of-the-art performance on two VL-NLE benchmarks and demonstrates reduced implausibility and hallucination.\n\n$$\\text{Strengths:}$$\n1. The paper introduces a novel two-stage paradigm that effectively integrates language-based knowledge and visual facts into NLE generation.\n2. Rapper's use of RLNF enables the model to generate faithful NLEs, reducing hallucinations and implausibility.\n3. The paper presents quantitative and qualitative experiments on two VL-NLE benchmarks, demonstrating the effectiveness of Rapper.\n4. The proposed method outperforms existing state-of-the-art VQA-NLE methods in terms of plausibility and faithfulness.\n\n$$\\text{Weaknesses:}$$\n1. The paper does not provide a clear comparison with other state-of-the-art methods in terms of NLE metrics, such as CIDEr and SPICE.\n2. The evaluation metrics used may not fully capture the nuances of NLE quality, such as RefCLIPScore.\n3. The paper does not discuss potential limitations or challenges of Rapper, such as the requirement for large amounts of labeled data for training RLNF.\n4. The proposed method may not be applicable to all types of VQA tasks, such as those with complex or abstract concepts.\n\n$$\\text{Suggestions for Improvement:}$$\n1. Provide a more comprehensive comparison with other state-of-the-art methods in terms of NLE metrics.\n2. Use more robust evaluation metrics that capture the nuances of NLE quality.\n3. Discuss potential limitations and challenges of Rapper, such as the requirement for large amounts of labeled data for training RLNF.\n4. Investigate the applicability of Rapper to other types of VQA tasks, such as those with complex or abstract concepts.\n\n$$\\text{Recommendation:}$$\nBased on the strengths and weaknesses of the paper, I recommend that the authors revise and resubmit their work for consideration in a top-tier conference or journal. The proposed method of Rapper has the potential to significantly improve the quality of NLE in VQA tasks, and the authors should continue to explore and refine their approach to address the limitations and challenges identified in the review.",
        "peer_review_with_watermark": "$$\\begin{align}\\tag{1} \nPaper Summary: \nThe paper proposes a two-stage Reinforced Rationale-Prompted Paradigm called Rapper for providing accurate answers for VQA with sufficient NLE. The proposed Rapper utilizes knowledge distillation from large language models (LLMs) and reinforcement learning from NLE feedback to generate plausible and faithful NLEs. The authors evaluate Rapper on two VL-NLE benchmarks and show that it outperforms state-of-the-art VQA-NLE methods.\n\nStrengths:\n1. The proposed Rapper paradigm is novel and innovative, addressing the challenges of implausibility and hallucination in NLE.\n2. The authors provide a clear and concise overview of the related work and their contributions.\n3. The experimental setup and evaluation metrics are well-defined and comprehensive.\n\nWeaknesses:\n1. The paper does not provide a clear discussion on the potential limitations and challenges of the proposed Rapper paradigm.\n2. The authors rely heavily on pre-trained LLMs and VQA models, which may limit the generalizability and scalability of the proposed Rapper paradigm.\n3. The paper does not provide a detailed analysis of the effectiveness of the proposed Rapper paradigm on different types of VQA questions and images.\n\nSuggestions for Improvement:\n1. The authors should provide a more comprehensive discussion on the potential limitations and challenges of the proposed Rapper paradigm.\n2. The authors should explore the generalizability and scalability of the proposed Rapper paradigm by evaluating it on different types of VQA questions and images.\n3. The authors should provide more detailed analysis and comparison with state-of-the-art VQA-NLE methods.\n\nRecommendation:\nBased on the strengths and weaknesses of the paper, I recommend that it be accepted for publication in a top-tier conference or journal in the field of computer vision and natural language processing. However, I also recommend that the authors address the weaknesses and suggestions for improvement outlined above to further strengthen the paper.\n\n$$\\begin{align}\\tag{2} \nOverall Score: 8/10",
        "gr_score_with": 0.570446735395189,
        "gr_score_without": 0.4986449864498645,
        "output_without": {
            "num_tokens_scored": 369,
            "num_green_tokens": 184,
            "green_fraction": 0.4986449864498645,
            "z_score": -0.052057920629535355,
            "p_value": 0.5207587290260073
        },
        "output_with": {
            "num_tokens_scored": 291,
            "num_green_tokens": 166,
            "green_fraction": 0.570446735395189,
            "z_score": 2.403462565218252,
            "p_value": 0.008120314861502493
        }
    },
    {
        "title": "MOVINGPARTS: MOTION-BASED 3D PART DISCOV-",
        "abstract": "We present MovingParts, a NeRF-based method for dynamic scene reconstruction and part discovery. We consider motion as an important cue for identifying parts, that all particles on the same part share the common motion pattern. From the perspective of fluid simulation, existing deformation-based methods for dynamic NeRF can be seen as parameterizing the scene motion under the Eulerian view, i.e., focusing on specific locations in space through which the fluid flows as time passes. However, it is intractable to extract the motion of constituting objects or parts using the Eulerian view representation. In this work, we introduce the dual Lagrangian view and enforce representations under the Eulerian/Lagrangian views to be cycle-consistent. Under the Lagrangian view, we parameterize the scene motion by tracking the trajectory of particles on objects. The Lagrangian view makes it convenient to discover parts by factorizing the scene motion as a composition of part-level rigid motions. Experimentally, our method can achieve fast and high-quality dynamic scene reconstruction from even a single moving camera, and the induced part-based representation allows direct applications of part tracking, animation, 3D scene editing, etc.",
        "peer_review_without_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes a novel NeRF-based approach called MovingParts for dynamic scene reconstruction and part discovery from monocular input. The approach uses a hybrid representation of feature volume and neural network to achieve both high-quality reconstruction and reasonable part discovery within 30 minutes. The method consists of three modules: a canonical module, an Eulerian module, and a Lagrangian module. The Eulerian module records the motion of particles in the scene, while the Lagrangian module tracks the trajectory of particles and discovers parts by factorizing the scene motion as a composition of part-level rigid motions. The approach is evaluated on the D-NeRF 360\u25e6 synthetic dataset and achieves state-of-the-art results.\n\n$\\boxed{Strengths:}\n1. The approach uses a novel hybrid representation of feature volume and neural network to achieve both high-quality reconstruction and reasonable part discovery within 30 minutes.\n2. The method consists of three modules: a canonical module, an Eulerian module, and a Lagrangian module, which enables the discovery of parts by factorizing the scene motion as a composition of part-level rigid motions.\n3. The approach is evaluated on the D-NeRF 360\u25e6 synthetic dataset and achieves state-of-the-art results.\n4. The method is capable of overlooking motion-irrelevant characteristics in geometry and appearance and producing clean part discovery results on realistic complex scenes.\n\n$\\boxed{Weaknesses:}\n1. The approach explicitly stores the motion features in low-dimensional vectors, which makes it challenging to model motion on very long sequences.\n2. The method may not be suitable for scenes with complex motion patterns, as the motion grouping algorithm may not be able to distinguish between different motion modes.\n3. The approach relies on the assumption of finite rigid bodies, which may not hold in all cases.\n4. The method may not be able to handle scenes with non-rigid objects, as the part discovery algorithm may not be able to distinguish between different parts.\n\n$\\boxed{Suggestions for Improvement:}\n1. Develop a unified long sequence encoding-decoding scheme to model motion on very long sequences.\n2. Improve the motion grouping algorithm to distinguish between different motion modes in complex scenes.\n3. Investigate the use of other motion models, such as particle-based motion models, to improve the robustness of the approach.\n4. Develop a method to handle scenes with non-rigid objects and complex motion patterns.\n\n$\\boxed{Recommendation:}\nThe approach proposed in the paper is a significant contribution to the field of dynamic scene reconstruction and part discovery. However, there are some limitations and weaknesses that need to be addressed. With some improvements and modifications, the approach has the potential to be a state-of-the-art method in the field.",
        "peer_review_with_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes MovingParts, a novel NeRF-based method for dynamic scene reconstruction and part discovery from monocular images. The method uses a hybrid representation of feature volume and neural network, and combines Eulerian and Lagrangian views to model the scene motion. The Eulerian module records the motion of particles in the canonical space, while the Lagrangian module tracks the trajectory of particles in the canonical space. The method achieves high-quality dynamic scene reconstruction and part discovery, and can be used for downstream applications such as part tracking, object control, and scene editing.\n\n$\\boxed{Strengths:}\n1. The method uses a novel combination of Eulerian and Lagrangian views to model the scene motion, which enables the discovery of meaningful parts in the scene.\n2. The method achieves high-quality dynamic scene reconstruction and part discovery, and can be used for downstream applications.\n3. The use of a hybrid feature volume and neural network representation enables efficient training and fast convergence.\n4. The method can handle complex geometry and topology, and can accurately segment objects even if they are spatially separated.\n\n$\\boxed{Weaknesses:}\n1. The method stores the motion features in low-dimensional vectors, which may make it challenging to model motion on very long sequences.\n2. The method requires careful tuning of hyperparameters, particularly the threshold value used in the group merging algorithm.\n3. The method may not perform well on scenes with high motion ambiguity, as the Lagrangian module relies on the uniqueness of the particle trajectories.\n4. The method may require additional processing to handle complex scenes with multiple objects and complex geometry.\n\n$\\boxed{Suggestions for Improvement:}\n1. Develop a unified long sequence encoding-decoding scheme to model motion on very long sequences.\n2. Implement additional processing to handle complex scenes with multiple objects and complex geometry.\n3. Develop more sophisticated techniques to handle motion ambiguity in the Lagrangian module.\n4. Conduct extensive experiments to evaluate the method's performance on diverse scenarios.\n\n$\\boxed{Recommendation:}\nI recommend that the authors revise the paper based on the feedback provided, and submit it for further peer review. The method has shown promising results, and with some revisions, it can be presented as a strong contribution to the field of dynamic scene reconstruction and part discovery.",
        "gr_score_with": 0.5801282051282052,
        "gr_score_without": 0.48985507246376814,
        "output_without": {
            "num_tokens_scored": 345,
            "num_green_tokens": 169,
            "green_fraction": 0.48985507246376814,
            "z_score": -0.3768673314407159,
            "p_value": 0.6468638999159085
        },
        "output_with": {
            "num_tokens_scored": 312,
            "num_green_tokens": 181,
            "green_fraction": 0.5801282051282052,
            "z_score": 2.830692585361489,
            "p_value": 0.0023223669711462565
        }
    },
    {
        "title": "DMBP: DIFFUSION MODEL-BASED PREDICTOR FOR RO- BUST OFFLINE REINFORCEMENT LEARNING AGAINST STATE OBSERVATION PERTURBATIONS",
        "abstract": "Offline reinforcement learning (RL), which aims to fully explore offline datasets for training without interaction with environments, has attracted growing recent attention. A major challenge for the real-world application of offline RL stems from the robustness against state observation perturbations, e.g., as a result of sensor errors or adversarial attacks. Unlike online robust RL, agents cannot be adversarially trained in the offline setting. In this work, we propose Diffusion Model-Based Predictor (DMBP) in a new framework that recovers the actual states with conditional diffusion models for state-based RL tasks. To mitigate the error accumulation issue in model-based estimation resulting from the classical training of conventional diffusion models, we propose a non-Markovian training objective to minimize the sum entropy of denoised states in RL trajectory. Experiments on standard benchmark problems demonstrate that DMBP can significantly enhance the robustness of existing offline RL algorithms against different scales of random noises and adversarial attacks on state observations. Further, the proposed framework can effectively deal with incomplete state observations with random combinations of multiple unobserved dimensions in the test. Our implementation is available at https://github.com/zhyang2226/DMBP",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$Paper Summary:\nThe paper proposes a novel framework called Diffusion Model-Based Predictor (DMBP) for offline reinforcement learning (RL) against state observation perturbations. DMBP uses a conditional diffusion model to recover the actual state from noisy observations, and a non-Markovian loss function to mitigate error accumulation during test. The proposed framework is evaluated on D4RL benchmarks and demonstrates significant enhancements in robustness against different scales of random noises and adversarial attacks.\n\nStrengths:\n- The paper introduces a new framework for offline RL against state observation perturbations.\n- The proposed non-Markovian loss function effectively mitigates error accumulation during test.\n- The framework is evaluated on D4RL benchmarks and shows promising results.\n\nWeaknesses:\n- The paper does not provide a detailed analysis of the proposed non-Markovian loss function and its relationship with classical diffusion models.\n- The evaluation on D4RL benchmarks is limited to a few environments and datasets.\n- The paper does not provide a comprehensive comparison with existing offline RL algorithms.\n\nSuggestions for Improvement:\n- Provide a more detailed analysis of the proposed non-Markovian loss function and its relationship with classical diffusion models.\n- Conduct a comprehensive evaluation on a wider range of environments and datasets.\n- Compare the proposed framework with existing offline RL algorithms to demonstrate its superiority.\n\nRecommendation:\nThe paper proposes a novel framework for offline RL against state observation perturbations, and the proposed non-Markovian loss function shows promise in mitigating error accumulation during test. However, further evaluation and comparison with existing offline RL algorithms are necessary to fully validate the proposed framework.",
        "peer_review_with_watermark": "$$\\text{Paper Title: DMBP: DIFFUSION MODEL-BASED PREDICTOR FOR RO-BUST OFFLINE REINFORCEMENT LEARNING AGAINST STATE OBSERVATION PERTURBATIONS}\\$\n\n$$\\text{Summary: This paper proposes a new framework called Diffusion Model-Based Predictor (DMBP) for robust offline reinforcement learning against state observation perturbations in state-based tasks.}\\]\n\n$$\\text{Strengths:}\\ \n1. The paper proposes a novel solution for robust offline reinforcement learning, specifically addressing the issue of state observation perturbations.\n2. The authors provide a clear and well-structured explanation of the diffusion model-based approach.\n3. The experimental results on various benchmark problems demonstrate the effectiveness of the proposed method.\n4. The paper discusses the potential of the proposed method in handling incomplete state observations.\n\n$$\\text{Weaknesses:}\\ \n1. The paper assumes a high level of expertise in the reader regarding the underlying concepts of reinforcement learning, diffusion models, and Markov decision processes.\n2. The explanation of the non-Markovian loss function could be more detailed.\n3. The ablation study could provide more information about the impact of hyperparameters on the performance of the proposed method.\n4. The paper could provide more information about the limitations of the proposed method in handling complex environments.\n\n$$\\text{Suggestions for Improvement:}\\ \n1. Provide a more detailed explanation of the non-Markovian loss function.\n2. Include a more comprehensive ablation study.\n3. Discuss the limitations of the proposed method in handling complex environments.\n4. Consider providing a comparison with other state-of-the-art methods for robust offline reinforcement learning.\n\n$$\\text{Recommendation:}\\ \nBased on the strengths and weaknesses of the paper, I recommend the publication of this paper in a top-tier conference or journal in the field of reinforcement learning and artificial intelligence. However, I suggest that the authors address the limitations of the paper and provide a more comprehensive explanation of the non-Markovian loss function and the ablation study.",
        "gr_score_with": 0.6048109965635738,
        "gr_score_without": 0.45539906103286387,
        "output_without": {
            "num_tokens_scored": 213,
            "num_green_tokens": 97,
            "green_fraction": 0.45539906103286387,
            "z_score": -1.3018585486723102,
            "p_value": 0.9035176276480216
        },
        "output_with": {
            "num_tokens_scored": 291,
            "num_green_tokens": 176,
            "green_fraction": 0.6048109965635738,
            "z_score": 3.57588332873935,
            "p_value": 0.00017452365270708944
        }
    },
    {
        "title": "RDESIGN: HIERARCHICAL DATA-EFFICIENT REPRE-",
        "abstract": "While artificial intelligence has made remarkable strides in revealing the relationship between biological macromolecules\u2019 primary sequence and tertiary structure, designing RNA sequences based on specified tertiary structures remains challenging. Though existing approaches in protein design have thoroughly explored structure-to-sequence dependencies in proteins, RNA design still confronts difficulties due to structural complexity and data scarcity. Moreover, direct transplantation of protein design methodologies into RNA design fails to achieve satisfactory outcomes although sharing similar structural components. In this study, we aim to systematically construct a data-driven RNA design pipeline. We crafted a large, well-curated benchmark dataset and designed a comprehensive structural modeling approach to represent the complex RNA tertiary structure. More importantly, we proposed a hierarchical data-efficient representation learning framework that learns structural representations through contrastive learning at both clusterlevel and sample-level to fully leverage the limited data. By constraining data representations within a limited hyperspherical space, the intrinsic relationships between data points could be explicitly imposed. Moreover, we incorporated extracted secondary structures with base pairs as prior knowledge to facilitate the RNA design process. Extensive experiments demonstrate the effectiveness of our proposed method, providing a reliable baseline for future RNA design tasks. The source code and benchmark dataset are available at github.com/A4Bio/RDesign.",
        "peer_review_without_watermark": "$$$\\begin{align}\\textbf{Paper Summary:} &\\quad The authors propose a hierarchical data-efficient representation learning framework for designing RNA tertiary structures. They compile a large-scale RNA tertiary structure dataset and develop a comprehensive structural modeling approach to represent the complex RNA tertiary structure. The proposed framework incorporates extracted secondary structures with base pairs as prior knowledge to facilitate the RNA design process. Extensive experiments demonstrate the effectiveness of the proposed method.\n\n\\textbf{Strengths:} &\\quad The authors have made significant contributions to the field of RNA design by proposing a hierarchical data-efficient representation learning framework. The framework explicitly captures the intrinsic relationships within the data while constraining the limited data to a restricted hyperspherical space. The incorporation of extracted secondary structures with base pairs as prior knowledge is also a valuable addition to the framework.\n\n\\textbf{Weaknesses:} &\\quad The authors rely heavily on the availability of high-quality RNA tertiary structure data, which may not be universally accessible. The proposed framework may not generalize well to new, unseen data. Additionally, the secondary structure constraining strategy may not be effective for all types of RNA structures.\n\n\\textbf{Suggestions for Improvement:} &\\quad To improve the robustness of the proposed framework, the authors could explore the use of transfer learning or domain adaptation techniques to adapt the framework to new data distributions. Additionally, the authors could investigate the use of other prior knowledge, such as thermodynamic parameters or evolutionary conservation, to further improve the framework.\n\n\\textbf{Recommendation:} &\\quad The proposed framework is an important contribution to the field of RNA design. However, further work is needed to address the limitations and challenges associated with the framework. The authors should continue to explore and refine their framework to improve its robustness and generalizability.\n\n\\textbf{Additional Comments:} &\\quad The paper provides a clear and concise overview of the proposed framework and its applications. The experimental results demonstrate the effectiveness of the framework, and the authors have provided a thorough analysis of the strengths and weaknesses of their approach. However, the paper could benefit from a more detailed discussion of the limitations and challenges associated with the framework, as well as suggestions for future work.\n\n\\textbf{Technical Comments:} &\\quad The paper is well-written and free of major technical errors. However, there are a few minor issues that need to be addressed. For example, the authors could provide more detail on the hyperparameter tuning procedure for the proposed framework, as well as the evaluation metrics used to assess its performance.\n\n\\textbf{Conclusion:} &\\quad In conclusion, the proposed framework is an important contribution to the field of RNA design. While there are some limitations and challenges associated with the framework, the authors have demonstrated its effectiveness through extensive experiments. Further work is needed to address these limitations and improve the robustness and generalizability of the framework.\n\n\\textbf{Recommendation to Authors:} &\\quad The authors should continue to refine their framework and explore new applications and extensions. They should also investigate ways to address the limitations and challenges associated with the framework, such as transfer learning or domain adaptation techniques.\n\n\\textbf{Recommendation to Editor:} &\\quad The paper is well-written and provides a clear and concise overview of the proposed framework and its applications. The experimental results demonstrate the effectiveness of the framework, and the authors have provided a thorough analysis of the strengths and weaknesses of their approach. However, further work is needed to address the limitations and challenges associated with the framework.\n\n\\textbf{Final Recommendation:} &\\quad The paper is accepted for publication in its current form. However, the authors are encouraged to address the limitations and challenges associated with the framework and to continue refining their approach.\n\n$$\\end{align}$$",
        "peer_review_with_watermark": "$$$\\begin{align}\\textbf{Paper Summary:}\\ \n\\text{ The paper proposes a hierarchical data-efficient representation learning framework, RDESIGN, for designing RNA sequences that fold into a specified tertiary structure. The framework utilizes a comprehensive structural modeling approach and incorporates extracted secondary structures as prior knowledge. The authors compiled a benchmark dataset and extensively evaluated the proposed method, RDESIGN, against various baseline models. The results demonstrate the effectiveness of RDESIGN in designing RNA sequences with structures similar to the target structure.}\\ \n\n\\textbf{Strengths:}\\ \n1. The proposed RDESIGN framework explicitly captures the intrinsic relationships within the data by constraining the limited data to a restricted hyperspherical space.\n2. The use of hierarchical representation learning enables the model to learn from scarce data and improve the generalization capability.\n3. The incorporation of secondary structure information provides additional structural knowledge that enhances the design of RNA sequences.\n4. The authors provide a comprehensive evaluation of the proposed method against various baseline models, including sequence-based, structure-based, and graph-based models.\n5. The paper demonstrates the effectiveness of RDESIGN in designing RNA sequences with structures similar to the target structure, which is a critical aspect of RNA design.\n\n\\textbf{Weaknesses:}\\ \n1. The paper relies heavily on the availability of a benchmark dataset, which may limit the generalizability of the proposed method.\n2. The use of a hyperspherical space to constrain the data may not be effective in all cases, and the authors should provide more justification for this choice.\n3. The paper does not provide a detailed explanation of the hyperparameter tuning process, which is crucial for the success of the proposed method.\n4. The authors should provide more qualitative results, such as the folding of designed sequences, to further demonstrate the effectiveness of RDESIGN.\n5. The paper should provide more insights into the limitations of the proposed method and suggest potential avenues for future work.\n\n\\textbf{Suggestions for Improvement:}\\ \n1. The authors should provide more justification for the choice of hyperspherical space and explore alternative approaches.\n2. The authors should provide a more detailed explanation of the hyperparameter tuning process and provide more results from this process.\n3. The authors should provide more qualitative results, such as the folding of designed sequences, to further demonstrate the effectiveness of RDESIGN.\n4. The authors should provide more insights into the limitations of the proposed method and suggest potential avenues for future work.\n5. The authors should consider exploring the use of other types of data, such as protein structures, to improve the generalizability of the proposed method.\n\n\\textbf{Recommendation:}\\ \nBased on the strengths and weaknesses of the proposed method, RDESIGN, I recommend that the authors continue to work on this project and address the limitations and weaknesses mentioned above. With more justification, more qualitative results, and more insights into the limitations, the proposed method has the potential to be a significant contribution to the field of RNA design. The authors should also consider exploring the use of other types of data and exploring potential avenues for future work. \n\n$$\\end{align}$$",
        "gr_score_with": 0.6781914893617021,
        "gr_score_without": 0.5641025641025641,
        "output_without": {
            "num_tokens_scored": 429,
            "num_green_tokens": 242,
            "green_fraction": 0.5641025641025641,
            "z_score": 2.6554250227189717,
            "p_value": 0.003960426974769519
        },
        "output_with": {
            "num_tokens_scored": 376,
            "num_green_tokens": 255,
            "green_fraction": 0.6781914893617021,
            "z_score": 6.910522349933915,
            "p_value": 2.4143617588237654e-12
        }
    },
    {
        "title": "SWAP: SPARSE ENTROPIC WASSERSTEIN REGRESSION FOR ROBUST NETWORK PRUNING",
        "abstract": "This study addresses the challenge of inaccurate gradients in computing the empirical Fisher Information Matrix during neural network pruning. We introduce SWAP, a formulation of Entropic Wasserstein regression (EWR) for pruning, capitalizing on the geometric properties of the optimal transport problem. The \u201cswap\u201d of the commonly used linear regression with the EWR in optimization is analytically demonstrated to offer noise mitigation effects by incorporating neighborhood interpolation across data points with only marginal additional computational cost. The unique strength of SWAP is its intrinsic ability to balance noise reduction and covariance information preservation effectively. Extensive experiments performed on various networks and datasets show comparable performance of SWAP with state-of-the-art (SoTA) network pruning algorithms. Our proposed method outperforms the SoTA when the network size or the target sparsity is large, the gain is even larger with the existence of noisy gradients, possibly from noisy data, analog memory, or adversarial attacks. Notably, our proposed method achieves a gain of 6% improvement in accuracy and 8% improvement in testing loss for MobileNetV1 with less than one-fourth of the network parameters remaining.",
        "peer_review_without_watermark": "$$$Paper Summary:\nThe paper introduces SWAP, a novel sparse entropic Wasserstein regression pruning method for neural network pruning. SWAP formulates the pruning problem as a mixed-integer quadratic programming (MIQP) problem and leverages the entropic Wasserstein regression (EWR) framework to balance covariance information preservation and noise reduction. The method is compared with several state-of-the-art (SoTA) pruning algorithms on various pre-trained neural networks, demonstrating its effectiveness in achieving robust pruning and improved model performance.\n\nStrengths:\n\n1.  Novel formulation: SWAP provides a novel approach to pruning neural networks by leveraging the EWR framework, which strikes a balance between covariance information preservation and noise reduction.\n2.  Robustness to noise: SWAP is shown to be robust to noisy gradients, which is a common challenge in neural network pruning.\n3.  Competitive performance: SWAP is compared with several SoTA pruning algorithms and demonstrates competitive performance on various pre-trained neural networks.\n\nWeaknesses:\n\n1.  Complexity: SWAP is a mixed-integer quadratic programming (MIQP) problem, which can be computationally expensive to solve.\n2.  Hyperparameter tuning: The performance of SWAP may depend on the choice of hyperparameters, such as the regularization parameter \u03bb and the step size \u03c4.\n3.  Limited exploration: The paper may benefit from further exploration of practical implementations and empirical validation of SWAP on a wider range of datasets and neural networks.\n\nSuggestions for Improvement:\n\n1.  Simplify the formulation: Consider simplifying the MIQP formulation to reduce computational complexity.\n2.  Hyperparameter tuning: Provide guidance on hyperparameter tuning and suggest ways to optimize the performance of SWAP.\n3.  Exploration of practical implementations: Explore the practical implementation of SWAP and provide insights into its potential applications.\n\nRecommendation:\n\n1.  SWAP is a promising approach to pruning neural networks, offering a novel formulation that balances covariance information preservation and noise reduction.\n2.  Further empirical validation and exploration of practical implementations are necessary to fully realize the potential of SWAP.\n3.  The paper provides a solid foundation for further research on SWAP and its applications in large-scale model compression.",
        "peer_review_with_watermark": "$$$ Paper Summary:\n\nThe paper introduces SWAP, a Sparse Entropic Wasserstein Regression formulation for robust network pruning. It overcomes the limitations of existing pruning methods, particularly in noisy gradient scenarios, by leveraging the geometric properties of the Optimal Transport problem. The proposed method strikes a balance between noise reduction and covariance information preservation, effectively enhancing the performance of neural networks in various scenarios.\n\nStrengths:\n\n1.  The paper effectively tackles the challenge of inaccurate gradients in computing the empirical Fisher Information Matrix, which is critical in network pruning.\n2.  The proposed formulation, SWAP, is robust to noisy gradients and achieves better performance in various scenarios, especially when the network size or target sparsity is large.\n3.  The method is computationally efficient, as it utilizes a stochastic gradient descent (SGD) paired with an iterative hard thresholding (IHT) algorithm.\n4.  The work is well-written, with clear explanations of the mathematical concepts and derivations.\n\nWeaknesses:\n\n1.  The paper may benefit from more comprehensive experimental results, including more diverse datasets and network architectures.\n2.  Some parts of the mathematical derivations may be complex and require additional explanation.\n3.  The authors may consider exploring potential applications beyond network pruning, such as image compression or recommendation systems.\n4.  The work may require further empirical validation, especially in terms of its ability to generalize to unseen data distributions.\n\nSuggestions for Improvement:\n\n1.  Add more experimental results, including diverse datasets and network architectures, to demonstrate the effectiveness of the proposed method.\n2.  Provide more detailed mathematical derivations, especially for complex parts, to ensure clarity and readability.\n3.  Explore potential applications beyond network pruning, such as image compression or recommendation systems, to further establish the importance of the proposed method.\n4.  Perform additional analysis, such as studying the impact of hyperparameters or noise levels, to better understand the limitations and potential of the proposed method.\n\nRecommendation:\n\nThe proposed method, SWAP, is a significant contribution to the field of network pruning, providing a robust solution to the challenge of inaccurate gradients in computing the empirical Fisher Information Matrix. While some areas may require further exploration, the work demonstrates promising results and is well-written, with clear explanations of mathematical concepts.",
        "gr_score_with": 0.6352941176470588,
        "gr_score_without": 0.5,
        "output_without": {
            "num_tokens_scored": 322,
            "num_green_tokens": 161,
            "green_fraction": 0.5,
            "z_score": 0.0,
            "p_value": 0.5
        },
        "output_with": {
            "num_tokens_scored": 340,
            "num_green_tokens": 216,
            "green_fraction": 0.6352941176470588,
            "z_score": 4.989400529829092,
            "p_value": 3.0283475736495507e-07
        }
    },
    {
        "title": "DRM: MASTERING VISUAL REINFORCEMENT LEARN-",
        "abstract": "Visual reinforcement learning (RL) has shown promise in continuous control tasks. Despite its progress, current algorithms are still unsatisfactory in virtually every aspect of the performance such as sample efficiency, asymptotic performance, and their robustness to the choice of random seeds. In this paper, we identify a major shortcoming in existing visual RL methods that is the agents often exhibit sustained inactivity during early training, thereby limiting their ability to explore effectively. Expanding upon this crucial observation, we additionally unveil a significant correlation between the agents\u2019 inclination towards motorically inactive exploration and the absence of neuronal activity within their policy networks. To quantify this inactivity, we adopt dormant ratio (Sokar et al., 2023) as a metric to measure inactivity in the RL agent\u2019s network. Empirically, we also recognize that the dormant ratio can act as a standalone indicator of an agent\u2019s activity level, regardless of the received reward signals. Leveraging the aforementioned insights, we introduce DrM , a method that uses three core mechanisms to guide agents\u2019 exploration-exploitation trade-offs by actively minimizing the dormant ratio. Experiments demonstrate that DrM achieves significant improvements in sample efficiency and asymptotic performance with no broken seeds (76 seeds in total) across three continuous control benchmark environments, including DeepMind Control Suite, MetaWorld, and Adroit. Most importantly, DrM is the first model-free algorithm that consistently solves tasks in both the Dog and Manipulator domains from the DeepMind Control Suite as well as three dexterous hand manipulation tasks without demonstrations in Adroit, all based on pixel observations. 1 0% 20% 40% 60% 80% 100% Training Progress 0 100 200 300 400 500 600 Ep iso de R ew ar d Deepmind Control Suite (8 Hard Tasks) 0% 20% 40% 60% 80% 100% Training Progress 0% 20% 40% 60% 80% 100% Su cc es s R at e MetaWorld (8 Tasks) 0% 20% 40% 60% 80% 100% Training Progress 0% 20% 40% 60% 80% 100% Su cc es s R at e Adroit (3 Tasks) DrM DrQ-v2 ALIX TACO Figure 1: Success rate and episode reward as a function of training progress for each of the three domains that we consider (Deepmind Control Suite, MetaWorld, Adroit). All results are averaged over 4 random seeds, and the shaded region stands for standard deviation across different random seeds.",
        "peer_review_without_watermark": "$$\\boxed{\\text{Paper Summary:}  \nThe paper proposes a novel approach called DrM (Dormant Ratio Minimization), which aims to address the sample efficiency challenge in visual reinforcement learning (RL) by leveraging the dormant ratio. The dormant ratio is a metric that measures the inactivity of a neural network, and the authors show that it is correlated with the agent's behavioral variety and exploration-exploitation trade-off. DrM introduces three mechanisms to guide the agent's exploration-exploitation trade-off: dormant-ratio-guided perturbation, awaken exploration, and dormant-ratio-guided exploitation. The authors evaluate DrM on three visual continuous control benchmarks and demonstrate its superiority over state-of-the-art baselines in terms of sample efficiency and asymptotic performance.\n\nStrengths:\n\n1. The paper introduces a novel approach to addressing the sample efficiency challenge in visual RL, which is a significant problem in the field.\n2. The authors provide a clear and concise explanation of the dormant ratio and its correlation with the agent's behavioral variety and exploration-exploitation trade-off.\n3. The proposed mechanisms of DrM are well-designed and effective in guiding the agent's exploration-exploitation trade-off.\n4. The authors provide extensive experimental results to demonstrate the superiority of DrM over state-of-the-art baselines.\n\nWeaknesses:\n\n1. The paper may be too long and dense, making it difficult for non-experts to follow.\n2. Some of the notation and terminology used in the paper may be unfamiliar to readers without a strong background in RL and neuroscience.\n3. The authors may need to provide more detailed explanations of certain concepts, such as the dormant ratio and its calculation.\n4. The paper could benefit from more discussion of the limitations and potential drawbacks of DrM.\n\nSuggestions for Improvement:\n\n1. The authors could provide more detailed explanations of the dormant ratio and its calculation to help readers who may be unfamiliar with the concept.\n2. The paper could include more discussion of the limitations and potential drawbacks of DrM, such as the potential for over-perturbation or under-perturbation.\n3. The authors could provide more experimental results to demonstrate the robustness of DrM across different tasks and environments.\n4. The paper could include more discussion of the potential applications and future directions of DrM.\n\nRecommendation:\n\nBased on the strengths and weaknesses of the paper, I recommend that it be accepted for publication in a top-tier conference or journal in the field of RL and neuroscience. The authors have made significant contributions to the field, and their work has the potential to impact the development of more efficient and effective RL algorithms. However, the paper could benefit from some revisions to address the weaknesses and suggestions for improvement outlined above.",
        "peer_review_with_watermark": "$$$Paper Summary:\nThe paper presents the introduction of DrM (Dormant Ratio Minimization), a novel visual reinforcement learning (RL) algorithm designed to address the challenges of sample inefficiency and asymptotic performance in continuous control tasks. DrM exploits the dormant ratio metric to guide agents' exploration-exploitation trade-offs by actively minimizing the dormant ratio. The authors demonstrate that DrM achieves significant improvements in sample efficiency and asymptotic performance compared to existing visual RL baselines across three continuous control benchmark environments. DrM is the first model-free algorithm that consistently solves tasks in both the Dog and Manipulator domains from the DeepMind Control Suite as well as three dexterous hand manipulation tasks in Adroit without demonstrations in Adroit, all based on pixel observations.\n\nStrengths:\n1. The authors identify a crucial shortcoming in existing visual RL methods: the agents often exhibit sustained inactivity during early training, limiting their ability to explore effectively.\n2. DrM is the first model-free algorithm that reliably solves complex dog and manipulator tasks, as well as demonstration-free Adroit dexterous hand manipulation tasks from pixels.\n3. DrM achieves significant improvements in sample efficiency and asymptotic performance compared to existing visual RL baselines.\n4. The authors provide extensive experiments and analysis to validate the effectiveness of DrM in various benchmark environments.\n\nWeaknesses:\n1. The paper does not provide a detailed explanation of the dormant ratio metric and its calculation.\n2. The authors rely heavily on existing research and techniques, such as self-supervised representation learning and regularization of the temporal difference update.\n3. The paper lacks a clear comparison of DrM with other state-of-the-art visual RL algorithms in terms of performance and sample efficiency.\n4. The authors do not discuss potential limitations and challenges of DrM in various scenarios.\n\nSuggestions for Improvement:\n1. Provide a more detailed explanation of the dormant ratio metric and its calculation, including mathematical derivations and empirical evaluation.\n2. Conduct a more comprehensive comparison of DrM with other state-of-the-art visual RL algorithms in terms of performance and sample efficiency.\n3. Discuss potential limitations and challenges of DrM in various scenarios, such as tasks with high-dimensional action spaces or environments with sparse rewards.\n4. Consider exploring the application of DrM in other areas of reinforcement learning, such as discrete action tasks or unsupervised RL.\n\nRecommendation:\nBased on the provided evaluation, I recommend that the authors revise and resubmit the paper for further peer review. While DrM shows promising results in addressing the challenges of sample inefficiency and asymptotic performance in visual RL tasks, there are several areas that require further attention and clarification.",
        "gr_score_with": 0.6164021164021164,
        "gr_score_without": 0.5173333333333333,
        "output_without": {
            "num_tokens_scored": 375,
            "num_green_tokens": 194,
            "green_fraction": 0.5173333333333333,
            "z_score": 0.6713171133426189,
            "p_value": 0.2510092674595701
        },
        "output_with": {
            "num_tokens_scored": 378,
            "num_green_tokens": 233,
            "green_fraction": 0.6164021164021164,
            "z_score": 4.526231598888029,
            "p_value": 3.0022387345433627e-06
        }
    },
    {
        "title": "DYNAMIC LAYER TYING FOR PARAMETER-EFFICIENT TRANSFORMERS",
        "abstract": "In the pursuit of reducing the number of trainable parameters in deep transformer networks, we employ Reinforcement Learning to dynamically select layers during training and tie them together. Every few iterations, the RL agent is asked whether to train each layer i independently or to copy the weights of a previous layer j < i. This facilitates weight sharing, reduces the number of trainable parameters, and also serves as an effective regularization technique. Experimental evaluations validate that our model modestly outperforms the baseline transformer model with regard to perplexity and drastically reduces the number of trainable parameters. In particular, the memory consumption during training is up to one order of magnitude less than the conventional training method.",
        "peer_review_without_watermark": "$$\\boxed{\\text{Paper Summary:}  \nThe paper proposes a novel method for dynamically selecting layers in deep transformer networks during training, which aims to reduce the number of trainable parameters. The method employs reinforcement learning to learn a pattern of layer replication and tying, which facilitates weight sharing and regularization. Experimental evaluations demonstrate that the proposed method outperforms the baseline transformer model in terms of perplexity and reduces the number of trainable parameters. \n\nStrengths: \n1. The method introduces a novel approach to dynamically selecting layers in transformer networks, which can lead to significant reductions in the number of trainable parameters.\n2. The use of reinforcement learning to learn the replication pattern is a fresh approach and can be effective in finding optimal layer configurations.\n3. The method is experimentally evaluated on multiple datasets, demonstrating its effectiveness in reducing the number of trainable parameters without sacrificing perplexity.\n\nWeaknesses:\n1. The method may not generalize well to other architectures or tasks, as the evaluation is limited to language models.\n2. The use of reinforcement learning may require careful tuning of hyperparameters, and the choice of Q-function may impact the performance of the method.\n3. The method does not provide insights into the underlying mechanisms of layer replication and tying, which may be useful for understanding the optimization process.\n\nSuggestions for Improvement:\n1. Evaluate the method on other architectures and tasks to demonstrate its generalizability.\n2. Conduct a more thorough analysis of the Q-function and its impact on the performance of the method.\n3. Provide more detailed insights into the optimization process and the underlying mechanisms of layer replication and tying.\n\nRecommendation:\nThe proposed method is an innovative approach to dynamically selecting layers in transformer networks, and its experimental evaluation demonstrates its effectiveness in reducing the number of trainable parameters. However, further research is needed to ensure the generalizability of the method and to provide a deeper understanding of its underlying mechanisms.",
        "peer_review_with_watermark": "$$\n\n$$$Paper Summary:\nThe paper presents a novel method for dynamically tying layers in transformers, which reduces the number of trainable parameters. The method employs reinforcement learning to select layers for weight sharing, and the results show that it outperforms the baseline transformer model in terms of perplexity and reduces the number of trainable parameters by up to 87%.\n\n\nStrengths:\n- The method is able to achieve a significant reduction in the number of trainable parameters without sacrificing the perplexity score.\n- The results demonstrate that the method can be effective in achieving a substantial reduction in the number of parameters, which is a significant challenge in deep learning models.\n- The paper provides a clear and detailed explanation of the method, including the algorithm and the experiments.\n- The results are well-organized and easy to understand.\n\n\nWeaknesses:\n- The paper does not discuss the potential risks of the method, such as the possibility of over-tying layers, which could lead to decreased model performance.\n- The paper does not provide a detailed comparison of the proposed method with other state-of-the-art methods for reducing the number of trainable parameters.\n- The paper does not discuss the possibility of using the proposed method for tasks that require a large number of layers, such as natural language processing tasks.\n- The paper does not discuss the potential for the proposed method to be used for tasks that require a small number of layers, such as computer vision tasks.\n\n\nSuggestions for Improvement:\n- The paper should discuss the potential risks of the method, such as the possibility of over-tying layers, which could lead to decreased model performance.\n- The paper should provide a detailed comparison of the proposed method with other state-of-the-art methods for reducing the number of trainable parameters.\n- The paper should discuss the possibility of using the proposed method for tasks that require a large number of layers, such as natural language processing tasks.\n- The paper should discuss the possibility of using the proposed method for tasks that require a small number of layers, such as computer vision tasks.\n- The paper should provide more details about the experiments, such as the number of epochs, the batch size, and the number of layers.\n\n\nRecommendation:\nOverall, the paper presents a novel method for dynamically tying layers in transformers, which reduces the number of trainable parameters. The results show that it outperforms the baseline transformer model in terms of perplexity and reduces the number of trainable parameters by up to 87%. The paper is well-written, clear, and easy to understand. However, it lacks a detailed comparison of the proposed method with other state-of-the-art methods, which could provide a more comprehensive understanding of the results. Additionally, the paper does not discuss the potential risks of the method, which could lead to decreased model performance.",
        "gr_score_with": 0.74609375,
        "gr_score_without": 0.5797101449275363,
        "output_without": {
            "num_tokens_scored": 276,
            "num_green_tokens": 160,
            "green_fraction": 0.5797101449275363,
            "z_score": 2.6484887678869224,
            "p_value": 0.0040426267963536615
        },
        "output_with": {
            "num_tokens_scored": 256,
            "num_green_tokens": 191,
            "green_fraction": 0.74609375,
            "z_score": 7.875,
            "p_value": 1.7037142916328607e-15
        }
    },
    {
        "title": "ENHANCING NEURAL SUBSET SELECTION: INTEGRAT-",
        "abstract": "Learning neural subset selection tasks, such as compound selection in AI-aided drug discovery, have become increasingly pivotal across diverse applications. The existing methodologies in the field primarily concentrate on constructing models that capture the relationship between utility function values and subsets within their respective supersets. However, these approaches tend to overlook the valuable information contained within the superset when utilizing neural networks to model set functions. In this work, we address this oversight by adopting a probabilistic perspective. Our theoretical findings demonstrate that when the target value is conditioned on both the input set and subset, it is essential to incorporate an invariant sufficient statistic of the superset into the subset of interest for effective learning. This ensures that the output value remains invariant to permutations of the subset and its corresponding superset, enabling identification of the specific superset from which the subset originated. Motivated by these insights, we propose a simple yet effective information aggregation module designed to merge the representations of subsets and supersets from a permutation invariance perspective. Comprehensive empirical evaluations across diverse tasks and datasets validate the enhanced efficacy of our approach over conventional methods, underscoring the practicality and potency of our proposed strategies in real-world contexts.",
        "peer_review_without_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes a novel approach to neural subset selection by incorporating permutation invariance and information aggregation from the superset. The proposed method, INSET, uses an invariant sufficient representation to model the relationship between the subset and the superset, allowing for more accurate predictions. The authors evaluate INSET on various tasks, including product recommendation, set anomaly detection, and compound selection, and demonstrate its superiority over existing methods.\n\nStrengths:\n\n*   The paper provides a clear and concise introduction to the problem of neural subset selection and the importance of permutation invariance.\n*   The proposed method, INSET, is well-explained and appears to be effective in modeling the relationship between subsets and supersets.\n*   The authors provide a thorough evaluation of INSET on various tasks, demonstrating its superiority over existing methods.\n\nWeaknesses:\n\n*   The paper could benefit from more detailed explanations of the theoretical underpinnings of INSET and its relationship to existing methods.\n*   Some of the technical details, such as the definition of the invariant sufficient representation, may be difficult for non-experts to follow.\n*   The evaluation section could be expanded to include more detailed analysis and discussion of the results.\n\nSuggestions for Improvement:\n\n*   Provide more detailed explanations of the theoretical underpinnings of INSET and its relationship to existing methods.\n*   Consider including more technical details, such as the derivation of the invariant sufficient representation, to provide a more comprehensive understanding of the proposed method.\n*   Expand the evaluation section to include more detailed analysis and discussion of the results.\n\nRecommendation:\n\n*   Based on the provided evaluation, INSET appears to be a promising approach to neural subset selection, offering improved performance over existing methods. However, further research is needed to fully understand the theoretical underpinnings of INSET and its relationship to existing methods.\n\n$$$\\boxed{Strengths:}\n\nThe paper provides a clear and concise introduction to the problem of neural subset selection and the importance of permutation invariance. The proposed method, INSET, is well-explained and appears to be effective in modeling the relationship between subsets and supersets.\n\nThe authors provide a thorough evaluation of INSET on various tasks, demonstrating its superiority over existing methods.\n\nThe paper is well-organized and easy to follow, with clear explanations of the technical details.\n\nThe authors acknowledge the limitations of their work and provide a clear direction for future research.\n\n$$\\boxed{Weaknesses:}\n\nThe paper could benefit from more detailed explanations of the theoretical underpinnings of INSET and its relationship to existing methods.\n\nSome of the technical details, such as the definition of the invariant sufficient representation, may be difficult for non-experts to follow.\n\nThe evaluation section could be expanded to include more detailed analysis and discussion of the results.\n\nThe paper could benefit from more experimental results, such as more detailed analysis of the performance of INSET on different datasets.\n\n$$\\boxed{Suggestions for Improvement:}\n\nProvide more detailed explanations of the theoretical underpinnings of INSET and its relationship to existing methods.\n\nConsider including more technical details, such as the derivation of the invariant sufficient representation, to provide a more comprehensive understanding of the proposed method.\n\nExpand the evaluation section to include more detailed analysis and discussion of the results.\n\nConsider including more experimental results, such as more detailed analysis of the performance of INSET on different datasets.\n\n$$\\boxed{Recommendation:}\n\nBased on the provided evaluation, INSET appears to be a promising approach to neural subset selection, offering improved performance over existing methods. However, further research is needed to fully understand the theoretical underpinnings of INSET and its relationship to existing methods.",
        "peer_review_with_watermark": "$$$\\boxed{Paper Summary:}\nThe paper proposes a new approach for neural subset selection, which is a crucial task in various applications such as AI-aided drug discovery and set anomaly detection. The authors address the limitation of existing methods, which primarily focus on constructing models that capture the relationship between utility function values and subsets. The proposed approach, called INSET, adopts a probabilistic perspective and incorporates the concept of permutation invariance. INSET is a simple yet effective method that consistently outperforms previous methods according to empirical evaluations.\n\nStrengths:\n- The authors address a significant limitation in subset encoding methods.\n- The proposed approach is based on a probabilistic perspective and incorporates permutation invariance.\n- INSET is a simple yet effective method.\n\nWeaknesses:\n- The authors acknowledge the potential for further improvement by integrating additional information, such as pairwise interactions between elements.\n- The theoretical analysis is not limited to set-based tasks; it can be applied to more general scenarios.\n\nSuggestions for Improvement:\n- Integrate additional information, such as pairwise interactions between elements, to further improve the performance of INSET.\n- Explore the application of INSET to more general scenarios beyond set-based tasks.\n\nRecommendation:\nThe proposed approach, INSET, is a significant contribution to the field of neural subset selection. Its simplicity and effectiveness make it a valuable addition to the existing literature. However, further exploration of integrating additional information and applying INSET to more general scenarios is recommended to fully leverage its potential.\n\n$$\\boxed{Strengths}$$\nThe authors address a significant limitation in subset encoding methods. The proposed approach is based on a probabilistic perspective and incorporates permutation invariance. INSET is a simple yet effective method.\n\n$$\\boxed{Weaknesses}$$\nThe authors acknowledge the potential for further improvement by integrating additional information, such as pairwise interactions between elements. The theoretical analysis is not limited to set-based tasks; it can be applied to more general scenarios.\n\n$$\\boxed{Suggestions for Improvement}$$\nIntegrate additional information, such as pairwise interactions between elements, to further improve the performance of INSET. Explore the application of INSET to more general scenarios beyond set-based tasks.\n\n$$\\boxed{Recommendation}$$\nThe proposed approach, INSET, is a significant contribution to the field of neural subset selection. Its simplicity and effectiveness make it a valuable addition to the existing literature. However, further exploration of integrating additional information and applying INSET to more general scenarios is recommended to fully leverage its potential.",
        "gr_score_with": 0.55859375,
        "gr_score_without": 0.45980707395498394,
        "output_without": {
            "num_tokens_scored": 311,
            "num_green_tokens": 143,
            "green_fraction": 0.45980707395498394,
            "z_score": -1.4176199428093568,
            "p_value": 0.9218491227399875
        },
        "output_with": {
            "num_tokens_scored": 256,
            "num_green_tokens": 143,
            "green_fraction": 0.55859375,
            "z_score": 1.875,
            "p_value": 0.03039636176526137
        }
    },
    {
        "title": "TAB: TEMPORAL ACCUMULATED BATCH NORMALIZA-",
        "abstract": "Spiking Neural Networks (SNNs) are attracting growing interest for their energyefficient computing when implemented on neuromorphic hardware. However, directly training SNNs, even adopting batch normalization (BN), is highly challenging due to their non-differentiable activation function and the temporally delayed accumulation of outputs over time. For SNN training, this temporal accumulation gives rise to Temporal Covariate Shifts (TCS) along the temporal dimension, a phenomenon that would become increasingly pronounced with layer-wise computations across multiple layers and multiple time-steps. In this paper, we introduce TAB (Temporal Accumulated Batch Normalization), a novel SNN batch normalization method that addresses the temporal covariate shift issue by aligning with neuron dynamics (specifically the accumulated membrane potential) and utilizing temporal accumulated statistics for data normalization. Within its framework, TAB effectively encapsulates the historical temporal dependencies that underlie the membrane potential accumulation process, thereby establishing a natural connection between neuron dynamics and TAB batch normalization. Experimental results on CIFAR-10, CIFAR-100, and DVS-CIFAR10 show that our TAB method outperforms other state-of-the-art methods.",
        "peer_review_without_watermark": "$$\\begin{aligned}\n$$The paper proposes a novel batch normalization method called Temporal Accumulated Batch Normalization (TAB) for Spiking Neural Networks (SNNs). The authors aim to address the challenges of directly training SNNs, particularly the Temporal Covariate Shift (TCS) phenomenon, which arises from the temporal dependency of neuron dynamics. The proposed TAB method aligns with the neuron dynamics by utilizing temporal accumulated statistics for data normalization. The authors provide a comprehensive analysis of the paper, including its strengths, weaknesses, and suggestions for improvement. \n\nThe main contributions of the paper are:\n\n1.  Introducing the concept of Temporal Accumulated Batch Normalization (TAB) for SNNs.\n2.  Providing a novel approach to address the Temporal Covariate Shift (TCS) phenomenon.\n3.  Demonstrating the effectiveness of TAB on various benchmark datasets.\n\nStrengths of the paper:\n\n1.  The authors provide a thorough analysis of the challenges faced by SNNs, particularly the TCS phenomenon.\n2.  The proposed TAB method is well-explained, and its alignment with neuron dynamics is a significant contribution.\n3.  The authors provide extensive experimental results on various benchmark datasets, demonstrating the effectiveness of TAB.\n\nWeaknesses of the paper:\n\n1.  The paper assumes a certain level of background knowledge in SNNs and batch normalization, which may be challenging for non-experts to follow.\n2.  Some sections of the paper, such as the theoretical connection between TAB and neuron dynamics, may require additional explanation or context.\n3.  The authors could have provided more detailed explanations of the computational complexity of the proposed TAB method.\n\nSuggestions for improvement:\n\n1.  Provide more detailed explanations of the theoretical connection between TAB and neuron dynamics, particularly for non-experts.\n2.  Consider adding more experimental results to demonstrate the effectiveness of TAB on various scenarios.\n3.  Provide more detailed explanations of the computational complexity of the proposed TAB method, particularly for large-scale SNNs.\n\nRecommendation:\n\n1.  The paper makes a significant contribution to the field of SNNs and batch normalization, introducing a novel approach to address the TCS phenomenon.\n2.  The authors provide extensive experimental results, demonstrating the effectiveness of TAB on various benchmark datasets.\n3.  The paper is well-written, and the authors provide a thorough analysis of the challenges faced by SNNs.\n\nHowever, the paper assumes a certain level of background knowledge in SNNs and batch normalization, which may be challenging for non-experts to follow. Additionally, some sections of the paper require more detailed explanations or context.\n\n$$\\begin{aligned}\n$$Overall, the paper is well-written, and the authors provide a thorough analysis of the challenges faced by SNNs. The proposed TAB method is a significant contribution to the field, and the authors provide extensive experimental results demonstrating its effectiveness.",
        "peer_review_with_watermark": "$$$\\boxed{\\text{Paper Summary:}}$$\n\nThe paper proposes a novel batch normalization method for Spiking Neural Networks (SNNs) called Temporal Accumulated Batch Normalization (TAB). TAB is designed to address the Temporal Covariate Shift (TCS) issue in SNNs by leveraging temporal accumulated statistics of the membrane potential accumulation process in neurons. The proposed method aligns with the neuron dynamics by utilizing accumulated pre-synaptic inputs in the temporal domain, thereby providing a more accurate batch normalization technique for SNNs.\n\n$\\boxed{\\text{Strengths:}}$\n\n1. The proposed TAB method is specifically designed for SNNs, which is a unique contribution of this paper.\n2. The method is based on a deep understanding of the temporal dependencies in SNNs and the membrane potential accumulation process in neurons.\n3. The alignment with the neuron dynamics ensures that TAB's normalization process corresponds well with the way neurons naturally operate in SNNs.\n4. The experimental results show that TAB outperforms other state-of-the-art methods on various datasets.\n\n$\\boxed{\\text{Weaknesses:}}$\n\n1. The paper does not provide a detailed analysis of the computational complexity of the TAB method, which may be a concern for large-scale applications.\n2. The experimental results are limited to a few datasets, and it is unclear whether TAB would generalize well to other datasets or scenarios.\n3. The paper does not provide a comprehensive comparison of TAB with other batch normalization methods for SNNs.\n\n$\\boxed{\\text{Suggestions for Improvement:}}$\n\n1. Conduct a more comprehensive analysis of the computational complexity of the TAB method to ensure it is feasible for large-scale applications.\n2. Perform a more extensive set of experiments on various datasets to evaluate the generalizability of TAB.\n3. Compare TAB with other batch normalization methods for SNNs in more detail to provide a more comprehensive understanding of its strengths and weaknesses.\n\n$\\boxed{\\text{Recommendation:}}$\n\nBased on the strengths and weaknesses of the paper, I recommend that it be accepted for publication in a top-tier conference or journal in the field of artificial intelligence or neuroscience. However, the authors should be encouraged to address the suggestions for improvement to provide a more comprehensive understanding of the TAB method and its potential applications.",
        "gr_score_with": 0.6269113149847095,
        "gr_score_without": 0.4850498338870432,
        "output_without": {
            "num_tokens_scored": 301,
            "num_green_tokens": 146,
            "green_fraction": 0.4850498338870432,
            "z_score": -0.5187513759338115,
            "p_value": 0.6980329351336824
        },
        "output_with": {
            "num_tokens_scored": 327,
            "num_green_tokens": 205,
            "green_fraction": 0.6269113149847095,
            "z_score": 4.5899104879574475,
            "p_value": 2.217180655024913e-06
        }
    },
    {
        "title": "A UNIFIED SAMPLING FRAMEWORK FOR SOLVER SEARCHING OF DIFFUSION PROBABILISTIC MODELS",
        "abstract": "Recent years have witnessed the rapid progress and broad application of diffusion probabilistic models (DPMs). Sampling from DPMs can be viewed as solving an ordinary differential equation (ODE). Despite the promising performance, the generation of DPMs usually consumes much time due to the large number of function evaluations (NFE). Though recent works have accelerated the sampling to around 20 steps with high-order solvers, the sample quality with less than 10 NFE can still be improved. In this paper, we propose a unified sampling framework (USF) to study the optional strategies for solver. Under this framework, we further reveal that taking different solving strategies at different timesteps may help further decrease the truncation error, and a carefully designed solver schedule has the potential to improve the sample quality by a large margin. Therefore, we propose a new sampling framework based on the exponential integral formulation that allows free choices of solver strategy at each step and design specific decisions for the framework. Moreover, we propose S, a predictor-based search method that automatically optimizes the solver schedule to get a better time-quality trade-off of sampling. We demonstrate that S can find outstanding solver schedules which outperform the state-of-the-art sampling methods on CIFAR-10, CelebA, ImageNet, and LSUN-Bedroom datasets. Specifically, we achieve 2.69 FID with 10 NFE and 6.86 FID with 5 NFE on CIFAR-10 dataset, outperforming the SOTA method significantly. We further apply S to Stable-Diffusion model and get an acceleration ratio of 2\u00d7, showing the feasibility of sampling in very few steps without retraining the neural network.",
        "peer_review_without_watermark": "$$$\\begin{align*}\nPaper Summary:\nThe paper proposes a unified sampling framework (USF) for diffusion probabilistic models (DPMs) based on exponential integral formulation. The framework allows for free choices of solver strategy at each step and designs specific decisions for the framework. The authors also propose a predictor-based search method (S3) to automatically optimize the solver schedule to get a better time-quality trade-off of sampling. Experimental results show that the proposed method can boost the sample quality under a very tight budget by a large margin.\n\nStrengths:\n- The proposed framework is systematic and allows for a wide range of solver strategies.\n- The use of exponential integral formulation is effective in reducing the number of steps required for sampling.\n- The predictor-based search method (S3) is efficient and can find optimal solver schedules.\n\nWeaknesses:\n- The paper assumes that the neural network is pre-trained, which may not be the case in all scenarios.\n- The search space is very large, which can lead to excessive search overheads.\n- The paper does not provide a clear explanation of the derivative estimation method used in the framework.\n\nSuggestions for Improvement:\n- Provide a clear explanation of the derivative estimation method used in the framework.\n- Consider using a more efficient search method to reduce the search overheads.\n- Consider using a pre-trained neural network or a more robust pre-training method to improve the performance of the framework.\n\nRecommendation:\nThe proposed framework and search method are effective in boosting the sample quality under a very tight budget. However, the search space is very large, and the paper assumes that the neural network is pre-trained, which may not be the case in all scenarios. Therefore, further improvement is needed to make the framework more robust and applicable to a wider range of scenarios. \n\n$$\n\nPlease note that the above review is based on the provided paper and may not be exhaustive.",
        "peer_review_with_watermark": "$$\\begin{aligned}\n$\\boxed{Paper Summary:}$\nThe paper proposes a unified sampling framework (USF) for diffusion probabilistic models (DPMs). USF aims to study the optimal strategies for solver in sampling from DPMs. The authors reveal that taking different solving strategies at different timesteps can help further decrease the truncation error. They also propose a new sampling framework based on the exponential integral formulation, which allows free choices of solver strategy at each step. Furthermore, they propose S, a predictor-based search method that automatically optimizes the solver schedule to get a better time-quality trade-off of sampling.\n\n$\\boxed{Strengths:}$\n1. The paper proposes a unified sampling framework (USF) for studying optimal solver strategies in DPMs, which can help improve sample quality.\n2. The authors demonstrate the effectiveness of USF in various experiments, including unconditional datasets and text-image generation tasks.\n3. The proposed S method can find outstanding solver schedules which outperform state-of-the-art sampling methods.\n4. The paper presents a systematic approach to designing solver schedules, which can be useful for other researchers in the field.\n\n$\\boxed{Weaknesses:}$\n1. The paper assumes that the reader is familiar with the basics of DPMs and the exponential integral formulation, which might be challenging for non-experts.\n2. Some parts of the paper, such as the mathematical derivations, might be hard to follow due to the complexity of the subject matter.\n3. The paper does not provide a comprehensive comparison of USF with other existing sampling frameworks, which might be useful for researchers interested in exploring alternative approaches.\n\n$\\boxed{Suggestions for Improvement:}$\n1. Add more mathematical derivations to help readers who are new to the subject matter.\n2. Provide a more detailed comparison of USF with other existing sampling frameworks to demonstrate its superiority.\n3. Consider adding more experiments to evaluate the performance of USF on different types of data, such as conditional datasets or data with specific characteristics (e.g., high-frequency noise).\n\n$\\boxed{Recommendation:}$\nOverall, the paper presents a well-designed and well-implemented unified sampling framework (USF) for studying optimal solver strategies in DPMs. While there are some areas for improvement, USF shows great promise in improving sample quality, especially when combined with the predictor-based search method (S). I recommend that researchers interested in DPMs and sampling frameworks take a closer look at USF and its applications.",
        "gr_score_with": 0.5910290237467019,
        "gr_score_without": 0.4558303886925795,
        "output_without": {
            "num_tokens_scored": 283,
            "num_green_tokens": 129,
            "green_fraction": 0.4558303886925795,
            "z_score": -1.48609574569441,
            "p_value": 0.9313731012805008
        },
        "output_with": {
            "num_tokens_scored": 379,
            "num_green_tokens": 224,
            "green_fraction": 0.5910290237467019,
            "z_score": 3.5442919288688475,
            "p_value": 0.00019683454716234203
        }
    }
]