[
    {
        "title": "CONCEPT BOTTLENECK GENERATIVE MODELS",
        "abstract": "We introduce a generative model with an intrinsically interpretable layer\u2014a concept bottleneck layer\u2014that constrains the model to encode human-understandable concepts. The concept bottleneck layer partitions the generative model into three parts: the pre-concept bottleneck portion, the CB layer, and the post-concept bottleneck portion. To train CB generative models, we complement the traditional task-based loss function for training generative models with a concept loss and an orthogonality loss. The CB layer and these loss terms are model agnostic, which we demonstrate by applying the CB layer to three different families of generative models: generative adversarial networks, variational autoencoders, and diffusion models. On multiple datasets across different types of generative models, steering a generative model, with the CB layer, outperforms all baselines\u2014in some cases, it is 10 times more effective. In addition, we show how the CB layer can be used to interpret the output of the generative model and debug the model during or post training.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper introduces concept bottleneck generative models (CBGMs), a novel approach to generative modeling that incorporates an intrinsically interpretable layer, the concept bottleneck (CB) layer. This layer is designed to constrain the model to encode human-understandable concepts, enabling the model to be steered, interpreted, and debugged. The CB layer is model-agnostic, meaning it can be applied to various generative model families, including variational autoencoders (VAEs), generative adversarial networks (GANs), and diffusion models. The authors demonstrate the effectiveness of CBGMs in steering generative models, interpreting their output, and debugging them during and post-training.\n\nStrengths:\n\n1. The paper presents a novel and innovative approach to generative modeling, addressing a significant limitation of current generative models, which are largely inscrutable and difficult to steer.\n2. The concept bottleneck layer is model-agnostic, allowing it to be applied to various generative model families, increasing its versatility and potential impact.\n3. The authors provide a comprehensive evaluation of CBGMs, including steering, interpretation, and debugging experiments, which demonstrate their effectiveness and robustness.\n4. The paper discusses the limitations of current approaches to interpreting and steering generative models, highlighting the need for more interpretable and controllable models.\n\nWeaknesses:\n\n1. The paper requires a significant amount of background knowledge in generative modeling, which may make it challenging for readers without a strong foundation in the field.\n2. The authors rely heavily on existing work, which may make it difficult to distinguish the novelty and contributions of the paper.\n3. The paper does not provide a clear explanation of how the concept bottleneck layer is trained, which is a critical aspect of the method.\n4. The authors do not discuss the potential limitations and challenges of applying the concept bottleneck layer to more complex and realistic settings.\n\nSuggestions for Improvement:\n\n1. Provide a more detailed explanation of the training process for the concept bottleneck layer, including the loss functions and hyperparameters used.\n2. Discuss the potential limitations and challenges of applying the concept bottleneck layer to more complex and realistic settings, such as text or 3D data.\n3. Provide more qualitative and quantitative evaluations of the concept bottleneck layer, including its performance on more challenging datasets and tasks.\n4. Consider incorporating more visualizations and illustrations to help readers understand the concept bottleneck layer and its applications.\n\nRecommendation:\n\nThis paper presents a novel and innovative approach to generative modeling, addressing a significant limitation of current generative models. The concept bottleneck layer is model-agnostic, allowing it to be applied to various generative model families, increasing its versatility and potential impact. While the paper has some limitations, it provides a comprehensive evaluation of CBGMs and demonstrates their effectiveness and robustness. I recommend this paper to readers interested in generative modeling, interpretability, and controllability.",
        "peer_review_with_watermark": "$$$\n\nPaper Summary:\n\nThis paper proposes concept bottleneck generative models (CBGMs) to address the challenges of interpreting and steering current generative models. The proposed architecture consists of three parts: the pre-concept bottleneck portion, the concept bottleneck (CB) layer, and the post-concept bottleneck portion. The CB layer is model-agnostic and can be applied to different types of generative models, including VAEs, GANs, and diffusion models. The authors demonstrate the effectiveness of the proposed method by showing that steering a generative model with the CB layer outperforms several input conditioning baselines across multiple datasets and generative models.\n\nStrengths:\n\n* The proposed method is model-agnostic and can be applied to different types of generative models.\n* The authors demonstrate the effectiveness of the proposed method by showing that steering a generative model with the CB layer outperforms several input conditioning baselines across multiple datasets and generative models.\n* The method allows for the identification of important concepts that are responsible for a model's generated output.\n* The method can be used to debug a generative model during and post-training.\n\nWeaknesses:\n\n* The proposed method requires that the entire training set be annotated with pre-defined concepts, which can be a laborious requirement in practice.\n* The method has not been tested on text tasks, and it is unclear how it would perform in this domain.\n* The method requires a large amount of labeled data to train the concept bottleneck layer.\n\nSuggestions for Improvement:\n\n* The authors should explore methods to reduce the laborious requirement of annotating the entire training set with pre-defined concepts.\n* The authors should investigate how to apply the proposed method to text tasks and explore its performance in this domain.\n* The authors should provide more details on how to handle cases where the pre-defined concepts are not complete or are not sufficient to capture all the nuances of the data.\n\nRecommendation:\n\nThis paper proposes a novel and effective method for interpreting and steering generative models. The method is model-agnostic and can be applied to different types of generative models. However, the method requires significant labeled data and may not be applicable to all domains. The authors should address these limitations and provide more details on how to handle cases where the pre-defined concepts are not complete or are not sufficient to capture all the nuances of the data.\n\nIn terms of novelty and impact, I would rate this paper 8 out of 10. The proposed method is novel and effective, and it has the potential to impact the field of generative models. However, the method requires significant labeled data and may not be applicable to all domains.\n\nIn terms of presentation and clarity, I would rate this paper 9 out of 10. The authors provide a clear and well-structured presentation of their method and its results.\n\nIn terms of relevance and significance, I would rate this paper 9 out of 10. The proposed method addresses a significant challenge in the field of generative models and has the potential to impact the field.\n\nIn terms of overall quality, I would rate this paper 8.5 out of 10. The proposed method is novel and effective, and it has the potential to impact the field of generative models. However, the method requires significant labeled data and may not be applicable to all domains.\n\nOverall, I would recommend this paper for publication in a top-tier conference or journal.\n\n$$$",
        "gr_score_with": 0.5390835579514824,
        "gr_score_without": 0.442159383033419,
        "output_without": {
            "num_tokens_scored": 389,
            "num_green_tokens": 172,
            "green_fraction": 0.442159383033419,
            "z_score": -2.2815905695352723,
            "p_value": 0.9887432379973862
        },
        "output_with": {
            "num_tokens_scored": 371,
            "num_green_tokens": 200,
            "green_fraction": 0.5390835579514824,
            "z_score": 1.5056049817883785,
            "p_value": 0.06608430442282844
        }
    },
    {
        "title": "SWAP: SPARSE ENTROPIC WASSERSTEIN REGRESSION FOR ROBUST NETWORK PRUNING",
        "abstract": "This study addresses the challenge of inaccurate gradients in computing the empirical Fisher Information Matrix during neural network pruning. We introduce SWAP, a formulation of Entropic Wasserstein regression (EWR) for pruning, capitalizing on the geometric properties of the optimal transport problem. The \u201cswap\u201d of the commonly used linear regression with the EWR in optimization is analytically demonstrated to offer noise mitigation effects by incorporating neighborhood interpolation across data points with only marginal additional computational cost. The unique strength of SWAP is its intrinsic ability to balance noise reduction and covariance information preservation effectively. Extensive experiments performed on various networks and datasets show comparable performance of SWAP with state-of-the-art (SoTA) network pruning algorithms. Our proposed method outperforms the SoTA when the network size or the target sparsity is large, the gain is even larger with the existence of noisy gradients, possibly from noisy data, analog memory, or adversarial attacks. Notably, our proposed method achieves a gain of 6% improvement in accuracy and 8% improvement in testing loss for MobileNetV1 with less than one-fourth of the network parameters remaining.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel method for neural network pruning called Sparse Entropic Wasserstein Regression Pruning (SWAP), which leverages the Entropic Wasserstein regression (EWR) to mitigate the effect of noisy gradients in computing the empirical Fisher Information Matrix (FIM). The proposed method, SWAP, is shown to outperform state-of-the-art (SoTA) network pruning algorithms, especially in the presence of noisy gradients.\n\nStrengths:\n\n1. The paper provides a comprehensive analysis of the network pruning problem and its relation to the optimization problem, which is a significant contribution to the field.\n2. The proposed method, SWAP, is shown to be robust to noisy gradients, which is a critical aspect of neural network pruning.\n3. The paper provides a thorough comparison of SWAP with other SoTA methods, including magnitude pruning, WoodFisher, and Combinatorial Brain Surgeon.\n4. The authors provide a clear and concise algorithmic framework for SWAP, which is easy to implement and understand.\n\nWeaknesses:\n\n1. The paper assumes that the neural network is pre-trained, which may not be the case in practice.\n2. The proposed method requires the computation of the empirical FIM, which can be computationally expensive for large neural networks.\n3. The paper does not provide a thorough analysis of the computational complexity of SWAP, which is an important aspect of neural network pruning.\n4. The authors do not provide a clear explanation of how to choose the hyperparameters of SWAP, which can affect its performance.\n\nSuggestions for Improvement:\n\n1. The authors should provide a more detailed analysis of the computational complexity of SWAP and its relation to the size of the neural network.\n2. The paper should provide a clear explanation of how to choose the hyperparameters of SWAP, which can affect its performance.\n3. The authors should provide more experimental results to demonstrate the robustness of SWAP to noisy gradients.\n4. The paper should provide a more detailed comparison of SWAP with other SoTA methods, including a more thorough analysis of their strengths and weaknesses.\n\nRecommendation:\n\nThe paper proposes a novel method for neural network pruning that is robust to noisy gradients, which is a critical aspect of neural network pruning. The proposed method, SWAP, is shown to outperform state-of-the-art (SoTA) network pruning algorithms, especially in the presence of noisy gradients. However, the paper assumes that the neural network is pre-trained, which may not be the case in practice, and the computational complexity of SWAP is not thoroughly analyzed. Therefore, I recommend that the authors provide a more detailed analysis of the computational complexity of SWAP and its relation to the size of the neural network, as well as a clear explanation of how to choose the hyperparameters of SWAP.\n\nOverall, the paper is well-written and provides a significant contribution to the field of neural network pruning. However, there are some areas that need improvement, and I hope that the authors will address these issues in future work.\n\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel method for neural network pruning, called Sparse Entropic Wasserstein Regression (SWAP), which utilizes Entropic Wasserstein regression (EWR) to optimize the network. The method is designed to mitigate the effects of noisy gradients, which are common in large-scale model training. SWAP is based on the idea of using the Wasserstein distance to model the dissimilarity between two distributions, capturing geometric properties of the loss at the weights before and after pruning. The method is shown to outperform existing state-of-the-art methods, especially in noisy conditions.\n\nStrengths:\n\n1. The paper proposes a novel method for neural network pruning that is designed to mitigate the effects of noisy gradients.\n2. The method is based on the idea of using the Wasserstein distance, which is a well-established concept in mathematics.\n3. The paper provides a comprehensive analysis of the method, including theoretical aspects, algorithmic framework, and experimental results.\n4. The method is shown to outperform existing state-of-the-art methods, especially in noisy conditions.\n5. The paper provides a clear and well-written explanation of the method, making it easy to follow and understand.\n\nWeaknesses:\n\n1. The paper assumes that the noisy gradients are due to sample noise or vanishing gradients, which may not be the case in all scenarios.\n2. The method requires the computation of the Wasserstein distance, which can be computationally expensive.\n3. The paper does not provide a detailed analysis of the computational complexity of the method.\n4. The method is based on the idea of using the Wasserstein distance, which may not be applicable in all scenarios.\n5. The paper does not provide a comprehensive comparison with existing methods, especially in terms of computational cost.\n\nSuggestions for Improvement:\n\n1. Provide a more detailed analysis of the computational complexity of the method.\n2. Investigate the applicability of the method in scenarios where the noisy gradients are due to other sources.\n3. Provide a more comprehensive comparison with existing methods, especially in terms of computational cost.\n4. Investigate the robustness of the method to different types of noise.\n5. Provide more experimental results to support the claims made in the paper.\n\nRecommendation:\n\nThe paper proposes a novel method for neural network pruning that is designed to mitigate the effects of noisy gradients. The method is based on the idea of using the Wasserstein distance, which is a well-established concept in mathematics. The paper provides a comprehensive analysis of the method, including theoretical aspects, algorithmic framework, and experimental results. While the method shows promising results, there are some weaknesses that need to be addressed. Overall, the paper is well-written, and the method is worth further investigation. I recommend acceptance of the paper with some revisions to address the weaknesses mentioned above. $$",
        "gr_score_with": 0.565625,
        "gr_score_without": 0.5045592705167173,
        "output_without": {
            "num_tokens_scored": 329,
            "num_green_tokens": 166,
            "green_fraction": 0.5045592705167173,
            "z_score": 0.1653953539259914,
            "p_value": 0.43431640517280523
        },
        "output_with": {
            "num_tokens_scored": 320,
            "num_green_tokens": 181,
            "green_fraction": 0.565625,
            "z_score": 2.347871376374779,
            "p_value": 0.0094405200780494
        }
    },
    {
        "title": "BEYOND IMITATION: LEVERAGING FINE-GRAINED QUALITY SIGNALS FOR ALIGNMENT",
        "abstract": "Alignment with human preference is a desired property of large language models (LLMs). Currently, the main alignment approach is based on reinforcement learning from human feedback (RLHF). Despite the effectiveness of RLHF, it is intricate to implement and train, thus recent studies explore how to develop alternative alignment approaches based on supervised fine-tuning (SFT). A major limitation of SFT is that it essentially does imitation learning, which cannot fully understand what are the expected behaviors. To address this issue, we propose an improved alignment approach named FIGA. Different from prior methods, we incorporate fine-grained (i.e., token or phrase level) quality signals that are derived by contrasting good and bad responses. Our approach has made two major contributions. Firstly, we curate a refined alignment dataset that pairs initial responses and the corresponding revised ones. Secondly, we devise a new loss function can leverage fine-grained quality signals to instruct the learning of LLMs for alignment. Extensive experiments have demonstrated the effectiveness of our approaches by comparing a number of competitive baselines. We release all the above-mentioned resources at https://github.com/RUCAIBox/FIGA.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel approach called FIGA (Fine-grained Quality-Aware Alignment) for aligning language models with human preferences. The approach leverages fine-grained quality signals derived by contrasting good and bad responses to instruct the learning of language models for alignment. The authors curate a refined alignment dataset called SPA (SubPar Alignment) that pairs initial responses with revised responses on queries where a language model performs less well. They also design a new loss function that incorporates fine-grained quality signals to encourage the model to learn good behaviors and penalize bad behaviors. The approach is evaluated on several benchmarks, showing superior performance compared to existing alignment methods.\n\nStrengths:\n\n1. The paper presents a novel approach for aligning language models with human preferences, which is a critical problem in natural language processing.\n2. The approach leverages fine-grained quality signals, which provides more detailed information about what makes a response good or bad.\n3. The authors curate a refined alignment dataset called SPA, which is a significant contribution to the field.\n4. The approach is evaluated on several benchmarks, showing superior performance compared to existing alignment methods.\n\nWeaknesses:\n\n1. The paper assumes the availability of a reward model, which may not always be the case in real-world scenarios.\n2. The approach relies on the quality of the revised responses, which may not always be available or reliable.\n3. The paper does not provide a detailed analysis of the Levenshtein distance metric used to quantify the similarity between initial and revised responses.\n4. The approach may not generalize well to out-of-distribution scenarios, where the reward model may not perform well.\n\nSuggestions for Improvement:\n\n1. Investigate alternative methods for deriving fine-grained quality signals, such as using other metrics or incorporating additional information.\n2. Evaluate the approach on more diverse and challenging datasets to assess its generalizability.\n3. Provide more detailed analysis of the Levenshtein distance metric and its limitations.\n4. Investigate the use of other reward models or alternative methods for aligning language models with human preferences.\n\nRecommendation:\n\nThe paper presents a novel and promising approach for aligning language models with human preferences. While there are some limitations and areas for improvement, the approach shows superior performance compared to existing alignment methods. I recommend this paper for publication in a top-tier conference, with the suggestion to address the weaknesses and improve the approach as mentioned above.\n\nRating: 8/10\n\nReviewer's Name: [Your Name]\n\nReviewer's Affiliation: [Your Affiliation]\n\nDate: [Today's Date]",
        "peer_review_with_watermark": "$$$ \nPaper Summary:\n\nThe paper presents a novel alignment approach for large language models (LLMs) called FIGA, which leverages fine-grained quality signals to improve alignment quality during fine-tuning. The proposed approach involves curating a high-quality alignment dataset that pairs initial responses with revised responses on queries that a LLM cannot perform well. The authors design a new learning objective that can leverage the fine-grained quality signals by contrasting initial with revised responses. The approach inherits the merits of supervised fine-tuning (SFT) and can better understand and learn what are correct behaviors for alignment.\n\nStrengths:\n\n1. The paper presents a novel and effective approach to align LLMs with human preferences, which can improve alignment quality during fine-tuning.\n2. The proposed approach inherits the merits of SFT and can better understand and learn what are correct behaviors for alignment.\n3. The paper provides a comprehensive experimental evaluation of the proposed approach, which demonstrates its effectiveness on various benchmarks.\n\nWeaknesses:\n\n1. The paper assumes that a reward model for assessing the alignment level is available, which may not be the case in practice.\n2. The proposed approach requires careful selection of hyperparameters, which can be time-consuming and challenging.\n3. The paper does not provide a detailed analysis of the computational complexity of the proposed approach.\n\nSuggestions for Improvement:\n\n1. The authors should provide more details on how to select and train the reward model, which can be challenging in practice.\n2. The paper should provide a more detailed analysis of the computational complexity of the proposed approach, which can help readers understand its scalability and feasibility.\n3. The authors should provide more experimental evaluation of the proposed approach on other benchmarks and datasets to demonstrate its robustness and generalizability.\n\nRecommendation:\n\nThe paper presents a novel and effective approach to align LLMs with human preferences, which can improve alignment quality during fine-tuning. The proposed approach inherits the merits of SFT and can better understand and learn what are correct behaviors for alignment. However, the paper assumes that a reward model for assessing the alignment level is available, which may not be the case in practice. The authors should provide more details on how to select and train the reward model, which can be challenging in practice. The paper should also provide a more detailed analysis of the computational complexity of the proposed approach and more experimental evaluation of the proposed approach on other benchmarks and datasets to demonstrate its robustness and generalizability.\n\nTherefore, I recommend that the paper be accepted for publication after addressing the above concerns and providing more details and experimental evaluation. $$",
        "gr_score_with": 0.5587188612099644,
        "gr_score_without": 0.49326145552560646,
        "output_without": {
            "num_tokens_scored": 371,
            "num_green_tokens": 183,
            "green_fraction": 0.49326145552560646,
            "z_score": -0.2595870658255825,
            "p_value": 0.6024088428129317
        },
        "output_with": {
            "num_tokens_scored": 281,
            "num_green_tokens": 157,
            "green_fraction": 0.5587188612099644,
            "z_score": 1.9686149546972487,
            "p_value": 0.024498661976836228
        }
    },
    {
        "title": "GUAGE MODEL POWERED DIALOGUE AGENTS",
        "abstract": "Proactive dialogues serve as a practical yet challenging dialogue problem in the era of large language models (LLMs), where the dialogue policy planning is the key to improving the proactivity of LLMs. Most existing studies enable the dialogue policy planning of LLMs using various prompting schemes or iteratively enhance this capability in handling the given case with verbal AI feedback. However, these approaches are either bounded by the policy planning capability of the frozen LLMs or hard to be transferred to new cases. In this work, we introduce a new dialogue policy planning paradigm to strategize LLMs for proactive dialogue problems with a tunable language model plug-in as a plug-and-play dialogue policy planner, named PPDPP. Specifically, we develop a novel training framework to facilitate supervised fine-tuning over available human-annotated data as well as reinforcement learning from goal-oriented AI feedback with dynamic interaction data collected by the LLM-based self-play simulation. In this manner, the LLM-powered dialogue agent can not only be generalized to different cases after the training, but also be applicable to different applications by just substituting the learned plug-in. In addition, we propose to evaluate the policy planning capability of dialogue systems under the interactive setting. Experimental results demonstrate that PPDPP consistently and substantially outperforms existing approaches on three different proactive dialogue applications, including negotiation, emotional support, and tutoring dialogues.1",
        "peer_review_without_watermark": "$$$\nPaper Summary:\nThe paper proposes a novel paradigm for strategizing large language models (LLMs) powered dialogue agents, called Plug-and-Play Dialogue Policy Planner (PPDPP). PPDPP is designed to tackle the challenges of proactive dialogue problems, where the dialogue agent needs to strategically take the initiative to steer the conversation towards an anticipated goal. The proposed framework consists of a tunable language model plug-in that can be fine-tuned with available human-annotated data and reinforced learning from goal-oriented AI feedback. The authors demonstrate the effectiveness of PPDPP on three different proactive dialogue problems, including negotiation, emotional support, and tutoring dialogues.\n\nStrengths:\n1. The paper proposes a novel and effective approach to tackle the challenges of proactive dialogue problems.\n2. The framework is designed to be modular and flexible, allowing for easy adaptation to different applications and domains.\n3. The authors provide a thorough evaluation of PPDPP on three different datasets, demonstrating its superiority over existing approaches.\n4. The paper highlights the potential of tunable plug-ins to address specific shortcomings in LLMs and integrate with multiple plug-ins to tackle more complex dialogue challenges.\n\nWeaknesses:\n1. The paper assumes the availability of human-annotated data, which may not be feasible in all scenarios.\n2. The framework relies on the quality of the goal-oriented AI feedback, which may not always be available or reliable.\n3. The paper does not provide a detailed analysis of the computational resources required for training and deploying PPDPP.\n4. The authors do not discuss the potential limitations and biases of using LLMs in dialogue systems.\n\nSuggestions for Improvement:\n1. Provide more detailed information on the data requirements and preprocessing steps for training PPDPP.\n2. Discuss the potential limitations and biases of using LLMs in dialogue systems and propose potential solutions.\n3. Provide a more comprehensive analysis of the computational resources required for training and deploying PPDPP.\n4. Consider exploring other types of goal-oriented AI feedback, such as multi-modal feedback, to improve the robustness of PPDPP.\n\nRecommendation:\nThe paper proposes a novel and effective approach to tackle the challenges of proactive dialogue problems. While there are some limitations and areas for improvement, the framework shows promise for a wide range of applications. I recommend the paper for publication, with the understanding that the authors will address the suggested improvements in future work.\n\nRating: 8/10\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\nThe paper proposes a plug-and-play dialogue policy planner (PPDPP) to enhance the policy planning capability of large language models (LLMs) in proactive dialogue problems, such as negotiation, emotional support, and tutoring dialogues. The authors develop a novel training framework that combines supervised fine-tuning with available human-annotated data and reinforcement learning from goal-oriented AI feedback to optimize the dialogue policy planner. The framework enables the LLM-powered dialogue agent to generalize to different cases and exhibit versatility across diverse applications by simply substituting the learned plug-in.\n\nStrengths:\n1. The paper presents a comprehensive solution to the challenge of improving the policy planning capability of LLMs in proactive dialogue problems.\n2. The authors develop a novel training framework that combines supervised fine-tuning and reinforcement learning to optimize the dialogue policy planner.\n3. The framework enables the LLM-powered dialogue agent to generalize to different cases and exhibit versatility across diverse applications.\n4. The authors conduct extensive experiments on three different proactive dialogue problems and demonstrate the superiority of the proposed method over existing baselines.\n\nWeaknesses:\n1. The paper relies heavily on the quality of the human-annotated data and the goal-oriented AI feedback, which may be biased or incomplete.\n2. The authors do not provide a thorough analysis of the impact of the plug-and-play dialogue policy planner on the response quality and coherence of the dialogue agent.\n3. The paper does not discuss the potential risks and limitations of using reinforcement learning to optimize the dialogue policy planner, such as the risk of overfitting or the difficulty of tuning the hyperparameters.\n4. The authors do not provide a clear explanation of how the plug-and-play dialogue policy planner can be integrated with other plug-ins to tackle more complex dialogue challenges.\n\nSuggestions for Improvement:\n1. The authors should investigate the impact of the quality of the human-annotated data and the goal-oriented AI feedback on the performance of the dialogue agent.\n2. The authors should conduct a thorough analysis of the response quality and coherence of the dialogue agent and provide a clear explanation of how the plug-and-play dialogue policy planner affects these metrics.\n3. The authors should discuss the potential risks and limitations of using reinforcement learning to optimize the dialogue policy planner and provide suggestions for mitigating these risks.\n4. The authors should provide a clear explanation of how the plug-and-play dialogue policy planner can be integrated with other plug-ins to tackle more complex dialogue challenges.\n\nRecommendation:\nThe paper presents a comprehensive solution to the challenge of improving the policy planning capability of LLMs in proactive dialogue problems. While there are some limitations and areas for improvement, the authors' work provides valuable insights and contributions to the field of conversational AI research. The proposed method has the potential to be widely applicable and can be used to enhance the performance of dialogue agents in various applications. Therefore, I recommend accepting this paper for publication in the conference proceedings.\n\nRating: 7/10\n$$$",
        "gr_score_with": 0.5626822157434402,
        "gr_score_without": 0.5097493036211699,
        "output_without": {
            "num_tokens_scored": 359,
            "num_green_tokens": 183,
            "green_fraction": 0.5097493036211699,
            "z_score": 0.3694458697784817,
            "p_value": 0.35589770663609754
        },
        "output_with": {
            "num_tokens_scored": 343,
            "num_green_tokens": 193,
            "green_fraction": 0.5626822157434402,
            "z_score": 2.321781762770967,
            "p_value": 0.010122344868300081
        }
    },
    {
        "title": "THE EFFECTIVENESS OF RANDOM FORGETTING FOR ROBUST GENERALIZATION",
        "abstract": "Deep neural networks are susceptible to adversarial attacks, which can compromise their performance and accuracy. Adversarial Training (AT) has emerged as a popular approach for protecting neural networks against such attacks. However, a key challenge of AT is robust overfitting, where the network\u2019s robust performance on test data deteriorates with further training, thus hindering generalization. Motivated by the concept of active forgetting in the brain, we introduce a novel learning paradigm called \u201cForget to Mitigate Overfitting (FOMO)\". FOMO alternates between the forgetting phase, which randomly forgets a subset of weights and regulates the model\u2019s information through weight reinitialization, and the relearning phase, which emphasizes learning generalizable features. Our experiments on benchmark datasets and adversarial attacks show that FOMO alleviates robust overfitting by significantly reducing the gap between the best and last robust test accuracy while improving the state-of-the-art robustness. Furthermore, FOMO provides a better trade-off between standard and robust accuracy, outperforming baseline adversarial methods. Finally, our framework is robust to AutoAttacks and increases generalization in many real-world scenarios.1",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel adversarial training paradigm called Forget to Mitigate Overfitting (FOMO) to address the problem of robust overfitting in deep neural networks (DNNs). FOMO alternates between the forgetting phase, where a subset of weights is randomly forgotten through reinitialization, and the relearning phase, where the network emphasizes learning generalizable features. The authors demonstrate the efficacy of FOMO on benchmark datasets and adversarial attacks, showing that it alleviates robust overfitting, improves robustness, and provides a better trade-off between standard and robust accuracy.\n\nStrengths:\n\n1. The paper provides a comprehensive overview of the problem of robust overfitting in adversarial training and its significance in real-world applications.\n2. The authors propose a novel and innovative solution, FOMO, which is grounded in the concept of active forgetting and relearning, inspired by the human brain's learning mechanisms.\n3. The experimental results demonstrate the effectiveness of FOMO in alleviating robust overfitting, improving robustness, and providing a better trade-off between standard and robust accuracy.\n4. The authors conduct extensive experiments on multiple datasets, architectures, and perturbation types, showcasing the scalability and robustness of FOMO.\n\nWeaknesses:\n\n1. The paper assumes that the forgetting phase is beneficial for generalization, but it is unclear whether this assumption holds in all cases.\n2. The authors do not provide a thorough analysis of the convergence properties of FOMO, which is crucial for understanding its robustness and generalization capabilities.\n3. The paper relies heavily on empirical results, and more theoretical analysis is needed to understand the underlying mechanisms of FOMO.\n4. The authors do not discuss the computational costs and scalability of FOMO, which is essential for its practical adoption.\n\nSuggestions for Improvement:\n\n1. Provide a more detailed analysis of the forgetting phase, including its effect on the network's capacity and generalization.\n2. Conduct a thorough convergence analysis of FOMO to understand its robustness and generalization capabilities.\n3. Investigate the effect of different forgetting rates and relearning phases on the performance of FOMO.\n4. Discuss the computational costs and scalability of FOMO, including its potential applications in real-world scenarios.\n\nRecommendation:\n\nThe paper proposes a novel and innovative solution to the problem of robust overfitting in adversarial training. While there are some limitations and areas for improvement, the experimental results demonstrate the effectiveness of FOMO in alleviating robust overfitting, improving robustness, and providing a better trade-off between standard and robust accuracy. Therefore, I recommend accepting this paper for publication, with the understanding that the authors will address the suggested improvements in future work.",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel adversarial training paradigm called Forget to Mitigate Overfitting (FOMO) to improve the performance and generalization of Deep Neural Networks (DNNs) in adversarial training. FOMO alternates between a forgetting phase, where a random subset of weights is reinitialized, and a relearning phase, where the network emphasizes learning generalizable features. The proposed framework effectively alleviates robust overfitting and achieves state-of-the-art robustness on multiple datasets and architectures. FOMO also provides a better trade-off between standard and robust accuracy and exhibits robustness to AutoAttacks and natural corruptions.\n\nStrengths:\n\n1. FOMO presents a novel and effective approach to addressing robust overfitting in adversarial training, a long-standing challenge in the field of adversarial robustness.\n2. The proposed framework alternates between forgetting and relearning phases, which effectively consolidates generalizable features and achieves robust generalization.\n3. FOMO outperforms existing baseline methods on multiple datasets and architectures, demonstrating its effectiveness in improving robustness and generalization.\n4. The proposed framework exhibits robustness to AutoAttacks and natural corruptions, making it a promising solution for real-world applications.\n\nWeaknesses:\n\n1. The paper assumes that the forgetting phase should be applied to the later layers of the network, but it would be beneficial to provide a more comprehensive analysis of this assumption and explore other possibilities.\n2. The paper relies on a binary mask to select the subset of weights to be forgotten, but it would be interesting to explore other methods for weight selection, such as gradient-based methods or clustering-based methods.\n3. The paper focuses on the forgetting phase, but it would be beneficial to provide more details on the relearning phase and how it affects the overall performance of the network.\n\nSuggestions for Improvement:\n\n1. Provide a more comprehensive analysis of the forgetting phase, including a detailed exploration of the effects of forgetting on the network's performance and a comparison with other methods for weight selection.\n2. Investigate the use of more advanced methods for weight selection, such as gradient-based methods or clustering-based methods, and evaluate their performance in the context of FOMO.\n3. Provide more details on the relearning phase, including the effects of the consistency regularization loss on the network's performance and a comparison with other methods for regularization.\n\nRecommendation:\n\nThe paper presents a novel and effective approach to addressing robust overfitting in adversarial training, and its effectiveness in improving robustness and generalization makes it a promising solution for real-world applications. However, further research is needed to explore the limitations and potential improvements of the proposed framework. I recommend this paper for acceptance, but with the suggestion that the authors provide a more comprehensive analysis of the forgetting phase and the relearning phase, and explore more advanced methods for weight selection and regularization.",
        "gr_score_with": 0.6902173913043478,
        "gr_score_without": 0.6049723756906077,
        "output_without": {
            "num_tokens_scored": 362,
            "num_green_tokens": 219,
            "green_fraction": 0.6049723756906077,
            "z_score": 3.994471317330039,
            "p_value": 3.2419384893565013e-05
        },
        "output_with": {
            "num_tokens_scored": 368,
            "num_green_tokens": 254,
            "green_fraction": 0.6902173913043478,
            "z_score": 7.2980044919976175,
            "p_value": 1.4603344498541394e-13
        }
    },
    {
        "title": "SYMPHONY: SYMMETRY-EQUIVARIANT POINT- CENTERED SPHERICAL HARMONICS FOR MOLECULE GENERATION",
        "abstract": "We present Symphony, an E(3)-equivariant autoregressive generative model for 3D molecular geometries that iteratively builds a molecule from molecular fragments. Existing autoregressive models such as G-SchNet (Gebauer et al., 2019) and G-SphereNet (Luo & Ji, 2022) for molecules utilize rotationally invariant features to respect the 3D symmetries of molecules. In contrast, Symphony uses message-passing with higher-degree E(3)-equivariant features. This allows a novel representation of probability distributions via spherical harmonic signals to efficiently model the 3D geometry of molecules. We show that Symphony is able to accurately generate small molecules from the QM9 dataset, outperforming existing autoregressive models and approaching the performance of diffusion models.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper presents Symphony, an E(3)-equivariant autoregressive generative model for 3D molecular geometries that iteratively builds a molecule from molecular fragments. Unlike existing autoregressive models that use rotationally invariant features, Symphony uses higher-degree E(3)-equivariant features and spherical harmonic projections to build molecules while respecting the E(3) symmetries of molecular fragments. The authors demonstrate that Symphony outperforms existing autoregressive models and approaches the performance of diffusion models on various metrics.\n\nStrengths:\n\n1. The paper presents a novel approach to autoregressive molecular generation using higher-degree E(3)-equivariant features and spherical harmonic projections.\n2. The authors demonstrate that Symphony outperforms existing autoregressive models and approaches the performance of diffusion models on various metrics.\n3. The paper proposes a comprehensive set of tests to evaluate the quality of generated 3D structures, including validity, capturing training set statistics, and generalization capabilities.\n4. The authors provide a detailed comparison between their approach and existing methods, highlighting the advantages of their approach.\n\nWeaknesses:\n\n1. The paper assumes that the training set molecules are representative of the underlying distribution, which may not always be the case.\n2. The authors use a lookup table to assign bond orders, which may not be accurate for all molecules.\n3. The paper does not provide a clear explanation of how the spherical harmonic projections are used to model the radial distribution.\n4. The authors do not provide a detailed comparison between their approach and existing diffusion models, such as EDM.\n\nSuggestions for Improvement:\n\n1. Provide a more detailed explanation of how the spherical harmonic projections are used to model the radial distribution.\n2. Use a more accurate method to assign bond orders, such as using a neural network to predict bond orders.\n3. Provide a more detailed comparison between the approach and existing diffusion models, such as EDM.\n4. Investigate the use of normalizing flows to smoothly model the radial distribution without any discretization.\n\nRecommendation:\n\nThe paper presents a novel and promising approach to autoregressive molecular generation using higher-degree E(3)-equivariant features and spherical harmonic projections. While there are some limitations and areas for improvement, the paper provides a comprehensive evaluation of the approach and demonstrates its effectiveness on various metrics. I recommend accepting the paper for publication, subject to the suggested improvements.\n\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\nThe paper presents Symphony, an E(3)-equivariant autoregressive generative model for 3D molecular geometries that builds molecules from molecular fragments. Symphony uses message-passing with higher-degree E(3)-equivariant features and spherical harmonic projections to efficiently model the 3D geometry of molecules. The authors demonstrate that Symphony outperforms existing autoregressive models and approaches the performance of diffusion models on various metrics.\n\nStrengths:\nThe paper presents a novel method for autoregressively generating 3D molecular geometries, which is a challenging task in molecular generation. The use of spherical harmonic projections and higher-degree E(3)-equivariant features allows Symphony to efficiently model complex molecular structures. The authors demonstrate promising results on molecular generation and completion, outperforming existing autoregressive models.\n\nWeaknesses:\nThe paper relies heavily on existing work, particularly on E(3)-equivariant neural networks, and does not provide a thorough comparison of its performance with state-of-the-art methods. Additionally, the authors mention that the discretization of the radial components is too coarse, affecting the accuracy of bond length distributions. Furthermore, the computational cost of Symphony is higher due to the use of tensor products.\n\nSuggestions for Improvement:\nTo address the weaknesses mentioned above, the authors should provide a more thorough comparison of Symphony's performance with state-of-the-art methods, including diffusion models. Additionally, they should explore normalizing flows to smoothly model the radial distribution without discretization, which would improve the accuracy of bond length distributions. Finally, they should investigate methods to reduce the computational cost of Symphony.\n\nRecommendation:\nThe paper presents a promising method for autoregressively generating 3D molecular geometries, but requires further development to address its weaknesses. With improvements in performance, comparison, and computational cost, Symphony has the potential to become a leading method in molecular generation. Therefore, I recommend acceptance of this paper, subject to revision.\n\nRating: 7/10\n$$$",
        "gr_score_with": 0.5819397993311036,
        "gr_score_without": 0.474025974025974,
        "output_without": {
            "num_tokens_scored": 308,
            "num_green_tokens": 146,
            "green_fraction": 0.474025974025974,
            "z_score": -0.9116846116771036,
            "p_value": 0.8190326165394038
        },
        "output_with": {
            "num_tokens_scored": 299,
            "num_green_tokens": 174,
            "green_fraction": 0.5819397993311036,
            "z_score": 2.833743166634577,
            "p_value": 0.00230031454613681
        }
    },
    {
        "title": "ONE-HOT GENERALIZED LINEAR MODEL FOR SWITCHING BRAIN STATE DISCOVERY",
        "abstract": "Exposing meaningful and interpretable neural interactions is critical to understanding neural circuits. Inferred neural interactions from neural signals primarily reflect functional connectivity. In a long experiment, subject animals may experience different stages defined by the experiment, stimuli, or behavioral states, and hence functional connectivity can change over time. To model dynamically changing functional connectivity, prior work employs state-switching generalized linear models with hidden Markov models (i.e., HMM-GLMs). However, we argue they lack biological plausibility, as functional connectivities are shaped and confined by the underlying anatomical connectome. Here, we propose two novel priorinformed state-switching GLMs, called Gaussian HMM-GLM (Gaussian prior) and one-hot HMM-GLM (Gumbel-Softmax one-hot prior). We show that the learned prior should capture the state-invariant interaction, shedding light on the underlying anatomical connectome and revealing more likely physical neuron interactions. The state-dependent interaction modeled by each GLM offers traceability to capture functional variations across multiple brain states. Our methods effectively recover true interaction structures in simulated data, achieve the highest predictive likelihood, and enhance the interpretability of interaction patterns and hidden states when applied to real neural data. The code is available at https://github.com/JerrySoybean/onehot-hmmglm.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel approach for estimating time-varying functional connectivity in multi-state neural systems, called One-Hot Generalized Linear Model for Switching Brain State Discovery. The model, referred to as One-Hot HMM-GLM (OHG), decomposes the traditional weight matrix in GLMs into a discrete adjacency matrix representing the connection type and a positive-valued strength matrix. The authors argue that the regulated adjacency matrices with their shared prior should inform us about the underlying anatomical connectome, while the less restricted strength matrices can provide flexibility to capture functional variations across multiple brain states. The model is compared to several baseline methods on simulated and real neural datasets, showing superior performance in terms of log-likelihood, state accuracy, weight error, and adjacency accuracy.\n\nStrengths:\n\n1. The paper proposes a novel approach for estimating time-varying functional connectivity in multi-state neural systems, which is a significant contribution to the field.\n2. The model is well-motivated and biologically plausible, taking into account the underlying anatomical connectome and the need for flexibility in capturing functional variations.\n3. The authors provide a thorough comparison of their model to several baseline methods on simulated and real neural datasets, demonstrating its superior performance.\n4. The paper is well-written and easy to follow, with clear explanations of the methods and results.\n\nWeaknesses:\n\n1. The paper assumes that the number of hidden states is known, which may not be the case in real-world applications.\n2. The model requires the choice of several hyperparameters, including the temperature hyperparameter \u03c4, which may not be well-defined.\n3. The paper does not provide a thorough analysis of the computational complexity of the model, which may be a limitation for large-scale datasets.\n4. The results on real neural datasets are limited to two datasets, and it would be beneficial to see more extensive results on a wider range of datasets.\n\nSuggestions for Improvement:\n\n1. Consider adding a method for estimating the number of hidden states, which would be beneficial for real-world applications.\n2. Provide a more thorough analysis of the computational complexity of the model, including the time and space requirements.\n3. Consider adding more results on real neural datasets, including a wider range of datasets and more extensive analysis of the results.\n4. Provide a more detailed discussion of the implications of the results, including the potential applications and limitations of the model.\n\nRecommendation:\n\nThe paper is well-written and presents a novel approach for estimating time-varying functional connectivity in multi-state neural systems. The model is well-motivated and biologically plausible, and the results demonstrate its superior performance compared to several baseline methods. However, there are some limitations and areas for improvement, including the assumption of known hidden states, the choice of hyperparameters, and the computational complexity of the model. With some additional work to address these limitations, the paper has the potential to make a significant contribution to the field.\n\nOverall, I recommend accepting the paper with some revisions to address the limitations and areas for improvement.\n\nRating: 8/10\n\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThis paper proposes a novel one-hot generalized linear model (OHG) for switching brain state discovery. The authors aim to uncover the underlying anatomical connectome and reveal more likely physical interactions between neurons. The proposed model, OHG, decomposes the traditional weight matrix in GLMs into a discrete adjacency matrix representing the connection type and a positive-valued strength matrix. The authors place a common Gumbel-Softmax prior over the adjacency matrices for all states, enforcing the adjacency matrices to learn shared information. The less restricted strength matrices are allowed to change freely without a shared prior across different states, providing sufficient flexibility to capture functional variations across multiple brain states. The authors compare OHG with several baseline models on simulated data and real neural datasets, demonstrating its superiority in recovering true interaction structures and achieving the best predictive likelihood.\n\nStrengths:\n\n1. The proposed model, OHG, is biologically plausible and provides a more realistic representation of the underlying anatomical connectome.\n2. The use of Gumbel-Softmax prior over the adjacency matrices allows the model to learn shared information and uncover more likely physical interactions between neurons.\n3. The decomposition of the weight matrix into an adjacency matrix and a strength matrix provides sufficient flexibility to capture functional variations across multiple brain states.\n4. The authors provide a comprehensive evaluation of the proposed model on simulated data and real neural datasets, demonstrating its superiority over several baseline models.\n\nWeaknesses:\n\n1. The proposed model assumes a common Gumbel-Softmax prior over the adjacency matrices for all states, which may not be applicable in all scenarios.\n2. The use of Gumbel-Softmax prior may not be suitable for all types of data, and the choice of temperature hyperparameter \u03c4 requires careful consideration.\n3. The model assumes a Gaussian prior over the log of the strength matrix, which may not be biologically realistic.\n4. The authors do not provide a comprehensive analysis of the model's performance on datasets with varying numbers of hidden states.\n\nSuggestions for Improvement:\n\n1. Investigate the use of alternative priors, such as Dirichlet or Cauchy, over the adjacency matrices to explore their impact on the model's performance.\n2. Analyze the effect of varying the temperature hyperparameter \u03c4 on the model's performance and explore its robustness to different values.\n3. Evaluate the model on datasets with varying numbers of hidden states and explore its performance in recovering true interaction structures.\n4. Provide a more comprehensive analysis of the model's performance on datasets with varying levels of noise and signal.\n\nRecommendation:\n\nThis paper proposes a novel and biologically plausible model for switching brain state discovery. The proposed model, OHG, demonstrates its superiority over several baseline models on simulated data and real neural datasets. However, further investigation is required to explore the model's robustness and performance on datasets with varying numbers of hidden states and levels of noise and signal. I recommend the paper for publication in a reputable journal, with the hope that the authors will address the suggested areas for improvement.\n\n$$",
        "gr_score_with": 0.6987012987012987,
        "gr_score_without": 0.6086956521739131,
        "output_without": {
            "num_tokens_scored": 414,
            "num_green_tokens": 252,
            "green_fraction": 0.6086956521739131,
            "z_score": 4.423258684646914,
            "p_value": 4.861160726510194e-06
        },
        "output_with": {
            "num_tokens_scored": 385,
            "num_green_tokens": 269,
            "green_fraction": 0.6987012987012987,
            "z_score": 7.797602028995671,
            "p_value": 3.1547309971454963e-15
        }
    },
    {
        "title": "DRM: MASTERING VISUAL REINFORCEMENT LEARN-",
        "abstract": "Visual reinforcement learning (RL) has shown promise in continuous control tasks. Despite its progress, current algorithms are still unsatisfactory in virtually every aspect of the performance such as sample efficiency, asymptotic performance, and their robustness to the choice of random seeds. In this paper, we identify a major shortcoming in existing visual RL methods that is the agents often exhibit sustained inactivity during early training, thereby limiting their ability to explore effectively. Expanding upon this crucial observation, we additionally unveil a significant correlation between the agents\u2019 inclination towards motorically inactive exploration and the absence of neuronal activity within their policy networks. To quantify this inactivity, we adopt dormant ratio (Sokar et al., 2023) as a metric to measure inactivity in the RL agent\u2019s network. Empirically, we also recognize that the dormant ratio can act as a standalone indicator of an agent\u2019s activity level, regardless of the received reward signals. Leveraging the aforementioned insights, we introduce DrM , a method that uses three core mechanisms to guide agents\u2019 exploration-exploitation trade-offs by actively minimizing the dormant ratio. Experiments demonstrate that DrM achieves significant improvements in sample efficiency and asymptotic performance with no broken seeds (76 seeds in total) across three continuous control benchmark environments, including DeepMind Control Suite, MetaWorld, and Adroit. Most importantly, DrM is the first model-free algorithm that consistently solves tasks in both the Dog and Manipulator domains from the DeepMind Control Suite as well as three dexterous hand manipulation tasks without demonstrations in Adroit, all based on pixel observations. 1 0% 20% 40% 60% 80% 100% Training Progress 0 100 200 300 400 500 600 Ep iso de R ew ar d Deepmind Control Suite (8 Hard Tasks) 0% 20% 40% 60% 80% 100% Training Progress 0% 20% 40% 60% 80% 100% Su cc es s R at e MetaWorld (8 Tasks) 0% 20% 40% 60% 80% 100% Training Progress 0% 20% 40% 60% 80% 100% Su cc es s R at e Adroit (3 Tasks) DrM DrQ-v2 ALIX TACO Figure 1: Success rate and episode reward as a function of training progress for each of the three domains that we consider (Deepmind Control Suite, MetaWorld, Adroit). All results are averaged over 4 random seeds, and the shaded region stands for standard deviation across different random seeds.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel method, DrM, for visual reinforcement learning (RL) that aims to improve sample efficiency and asymptotic performance. The authors identify a major shortcoming in existing visual RL methods, where agents often exhibit sustained inactivity during early training, limiting their ability to explore effectively. They introduce three simple mechanisms to guide agents' exploration-exploitation trade-offs by actively minimizing the dormant ratio, a metric that measures inactivity in the RL agent's network. The proposed method, DrM, is evaluated across three continuous control benchmark environments, including DeepMind Control Suite, MetaWorld, and Adroit, and achieves significant improvements in sample efficiency and asymptotic performance compared to existing state-of-the-art model-free algorithms.\n\nStrengths:\n\n1. The paper identifies a crucial shortcoming in existing visual RL methods and proposes a novel solution to address this issue.\n2. The authors introduce a new metric, dormant ratio, which provides valuable insights into agent behavior and can be used to balance exploration and exploitation.\n3. The proposed method, DrM, is evaluated extensively across three benchmark environments and achieves significant improvements in sample efficiency and asymptotic performance.\n4. The authors provide a clear and concise explanation of the method and its components, making it easy to follow and understand.\n\nWeaknesses:\n\n1. The paper assumes that the dormant ratio is a good indicator of agent behavior, but it is not clear if this is always the case.\n2. The authors do not provide a detailed analysis of the dormant ratio's correlation with agent behavior, which could be an interesting direction for future research.\n3. The paper focuses primarily on continuous control tasks, and it is not clear if the proposed method can be adapted for discrete action tasks.\n4. The authors do not provide a detailed comparison with other exploration strategies, which could be an interesting direction for future research.\n\nSuggestions for Improvement:\n\n1. Provide a more detailed analysis of the dormant ratio's correlation with agent behavior.\n2. Evaluate the proposed method on a wider range of tasks and environments.\n3. Compare the proposed method with other exploration strategies to provide a more comprehensive understanding of its strengths and weaknesses.\n4. Consider adapting the proposed method for discrete action tasks and evaluating its performance on these tasks.\n\nRecommendation:\n\nThe paper proposes a novel and effective method for visual reinforcement learning that addresses a crucial shortcoming in existing methods. The authors provide a clear and concise explanation of the method and its components, and the results demonstrate significant improvements in sample efficiency and asymptotic performance. While there are some limitations and areas for future research, the paper makes a significant contribution to the field of visual RL and is worth considering for publication.\n\nRating: 8/10\n\n$$$",
        "peer_review_with_watermark": "$$$\n\nPaper Summary:\n\nThe paper presents DrM, a novel approach to visual reinforcement learning (RL) that addresses the issue of agents becoming motorically inactive during early training, hindering effective exploration. DrM introduces three core mechanisms to guide agents' exploration-exploitation trade-offs by actively minimizing the dormant ratio, which is a metric that measures inactivity in the RL agent's network. Empirically, the authors demonstrate that DrM achieves significant improvements in sample efficiency and asymptotic performance in three continuous control benchmark environments, including DeepMind Control Suite, MetaWorld, and Adroit. DrM is the first documented model-free algorithm that consistently solves tasks in both the Dog and Manipulator domains from the DeepMind Control Suite as well as three dexterous hand manipulation tasks without demonstrations in Adroit, all based on pixel observations.\n\nStrengths:\n\n1. DrM addresses a crucial issue in visual RL, which is the agents' tendency to become motorically inactive during early training, hindering effective exploration.\n2. The authors provide a clear and concise explanation of the problem and the proposed solution, making the paper easy to follow and understand.\n3. The experiments demonstrate the effectiveness of DrM in improving sample efficiency and asymptotic performance in various environments.\n4. The paper provides a detailed analysis of the dormant ratio and its correlation with the agents' behavior, which is a novel and insightful aspect of the work.\n5. The authors provide a clear explanation of the three core mechanisms of DrM and how they work together to achieve the desired outcome.\n\nWeaknesses:\n\n1. The paper assumes that the reader is familiar with visual RL and the concepts of exploration and exploitation. While the authors provide a clear explanation of the problem and the proposed solution, the paper may be challenging for readers who are new to the field.\n2. The paper does not provide a detailed analysis of the limitations of DrM and how they can be addressed in future work.\n3. The experiments are conducted in a controlled environment, and it is unclear how DrM would perform in more complex and dynamic environments.\n4. The paper does not provide a clear explanation of how DrM can be applied to other tasks and environments beyond the ones tested in the paper.\n\nSuggestions for Improvement:\n\n1. Provide a more detailed explanation of the problem and the proposed solution, including the assumptions and limitations of the work.\n2. Conduct more experiments to test the effectiveness of DrM in various environments and scenarios.\n3. Provide a more detailed analysis of the limitations of DrM and how they can be addressed in future work.\n4. Consider applying DrM to other tasks and environments beyond the ones tested in the paper to demonstrate its versatility and effectiveness.\n\nRecommendation:\n\nThe paper presents a novel and effective approach to visual RL that addresses a crucial issue in the field. While the paper has some limitations, the authors provide a clear and concise explanation of the problem and the proposed solution, and the experiments demonstrate the effectiveness of DrM in improving sample efficiency and asymptotic performance. I recommend accepting the paper for publication in the conference proceedings.\n\n$$$",
        "gr_score_with": 0.6112531969309463,
        "gr_score_without": 0.47043010752688175,
        "output_without": {
            "num_tokens_scored": 372,
            "num_green_tokens": 175,
            "green_fraction": 0.47043010752688175,
            "z_score": -1.1406468642034677,
            "p_value": 0.872991546609843
        },
        "output_with": {
            "num_tokens_scored": 391,
            "num_green_tokens": 239,
            "green_fraction": 0.6112531969309463,
            "z_score": 4.39977911559031,
            "p_value": 5.418055988844405e-06
        }
    },
    {
        "title": "ING VIA TASK-DRIVEN FEATURE SELECTION",
        "abstract": "This paper presents a data-driven, task-specific paradigm for experimental design, to shorten acquisition time, reduce costs, and accelerate the deployment of imaging devices. Current approaches in experimental design focus on model-parameter estimation and require specification of a particular model, whereas in imaging, other tasks may drive the design. Furthermore, such approaches often lead to intractable optimization problems in real-world imaging applications. Here we present a new paradigm for experimental design that simultaneously optimizes the design (set of image channels) and trains a machine-learning model to execute a userspecified image-analysis task. The approach obtains data densely-sampled over the measurement space (many image channels) for a small number of acquisitions, then identifies a subset of channels of prespecified size that best supports the task. We propose a method: TADRED for TAsk-DRiven Experimental Design in imaging, to identify the most informative channel-subset whilst simultaneously training a network to execute the task given the subset. Experiments demonstrate the potential of TADRED in diverse imaging applications: several clinicallyrelevant tasks in magnetic resonance imaging; and remote sensing and physiological applications of hyperspectral imaging. Results show substantial improvement over classical experimental design, two recent application-specific methods within the new paradigm, and state-of-the-art approaches in supervised feature selection. We anticipate further applications of our approach. Code is available: Code Link.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper presents a novel approach to experimental design in imaging applications, specifically for multi-channel imaging. The proposed method, TADRED, is a task-driven experimental design paradigm that simultaneously optimizes the design and trains a machine-learning model to execute a user-specified image-analysis task. TADRED uses a dual-network architecture, consisting of a scoring network and a task network, to identify the most informative channel-subset and train a high-performing network for the task. The paper demonstrates the effectiveness of TADRED in various imaging applications, including clinically relevant tasks in magnetic resonance imaging and remote sensing and physiological applications of hyperspectral imaging.\n\nStrengths:\n\n1. The paper presents a novel and innovative approach to experimental design in imaging applications, which is a significant contribution to the field.\n2. The proposed method, TADRED, is well-motivated and has a clear and logical structure.\n3. The paper provides a thorough evaluation of TADRED using various benchmark datasets and tasks, demonstrating its effectiveness in different imaging applications.\n4. The authors provide a comprehensive analysis of the strengths and limitations of TADRED, as well as comparisons with other state-of-the-art methods.\n\nWeaknesses:\n\n1. The paper assumes a priori knowledge of the task, which may not always be the case in real-world applications.\n2. The proposed method requires a large amount of training data, which may not be feasible in all scenarios.\n3. The paper does not provide a detailed explanation of the hyperparameter tuning process, which is crucial for the success of the method.\n4. The comparison with other methods is limited to a few benchmark datasets, and it would be beneficial to evaluate TADRED on a broader range of datasets and tasks.\n\nSuggestions for Improvement:\n\n1. Investigate the possibility of learning the task from the data, rather than relying on a priori knowledge.\n2. Explore alternative methods for hyperparameter tuning, such as Bayesian optimization or evolutionary algorithms.\n3. Provide a more detailed explanation of the hyperparameter tuning process and its impact on the performance of TADRED.\n4. Evaluate TADRED on a broader range of datasets and tasks to demonstrate its robustness and generalizability.\n\nRecommendation:\n\nThe paper presents a novel and innovative approach to experimental design in imaging applications, which has the potential to significantly impact the field. However, there are some limitations and areas for improvement that need to be addressed. With further development and evaluation, TADRED has the potential to become a widely used and effective method for experimental design in imaging applications.\n\n$$$\nNote: The review is based on the provided paper and does not include any external knowledge or information. The review is intended to provide a critical evaluation of the paper, highlighting its strengths and weaknesses, and suggesting areas for improvement.",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper presents TADRED, a novel approach for task-driven experimental design in imaging applications. TADRED is a feature selection algorithm that enables a new subsampling paradigm for experimental design, particularly in multi-channel imaging applications. The approach is based on a dual-network architecture that scores individual elements of the densely-sampled design for importance and trains a task network to execute the task driving the design. TADRED is demonstrated on six datasets/tasks in both clinically-relevant MRI and remote sensing and physiological applications in hyperspectral imaging, outperforming classical experimental design, recent application-specific published results, and state-of-the-art approaches in supervised feature selection.\n\nStrengths:\n\n1. TADRED presents a novel approach for task-driven experimental design in imaging applications, which is a significant contribution to the field.\n2. The approach is demonstrated on multiple datasets/tasks in both clinically-relevant MRI and remote sensing and physiological applications in hyperspectral imaging, showcasing its versatility and effectiveness.\n3. TADRED outperforms classical experimental design, recent application-specific published results, and state-of-the-art approaches in supervised feature selection, indicating its superiority in this domain.\n4. The approach is accompanied by extensive experimental results and analysis, providing a comprehensive evaluation of its performance and robustness.\n5. TADRED is implemented in a publicly available code repository, allowing for easy reproduction and extension of the work.\n\nWeaknesses:\n\n1. The approach is limited to imaging applications and may not be directly applicable to other domains.\n2. TADRED relies on dense sampling of the measurement space, which may not be feasible in all experimental settings.\n3. The approach requires extensive training and tuning of the dual-network architecture, which can be computationally expensive and time-consuming.\n4. The paper does not provide a detailed theoretical analysis of TADRED's performance and convergence properties.\n5. Some of the experimental results and analysis could be improved with more rigorous statistical testing and validation.\n\nSuggestions for Improvement:\n\n1. Investigate the applicability of TADRED to other domains beyond imaging applications.\n2. Develop more efficient and scalable methods for dense sampling of the measurement space.\n3. Provide more detailed theoretical analysis of TADRED's performance and convergence properties.\n4. Conduct more rigorous statistical testing and validation of the experimental results.\n5. Investigate the use of TADRED in combination with other experimental design approaches to further improve its performance and robustness.\n\nRecommendation:\n\nTADRED is a novel and effective approach for task-driven experimental design in imaging applications. Its versatility and effectiveness in multiple datasets/tasks make it a valuable tool for researchers and practitioners in this domain. However, its applicability and scalability beyond imaging applications need to be explored further. With some refinements and extensions, TADRED has the potential to become a widely used and influential approach in experimental design and machine learning.\n\nOverall, this paper is a significant contribution to the field of experimental design and machine learning, and it has the potential to impact various applications in imaging and beyond.",
        "gr_score_with": 0.6416040100250626,
        "gr_score_without": 0.5525672371638142,
        "output_without": {
            "num_tokens_scored": 409,
            "num_green_tokens": 226,
            "green_fraction": 0.5525672371638142,
            "z_score": 2.1262131586668396,
            "p_value": 0.016742757470674635
        },
        "output_with": {
            "num_tokens_scored": 399,
            "num_green_tokens": 256,
            "green_fraction": 0.6416040100250626,
            "z_score": 5.657075769835876,
            "p_value": 7.698690014292376e-09
        }
    },
    {
        "title": "DYST: TOWARDS DYNAMIC NEURAL SCENE REPRESENTATIONS ON REAL-WORLD VIDEOS",
        "abstract": "Visual understanding of the world goes beyond the semantics and flat structure of individual images. In this work, we aim to capture both the 3D structure and dynamics of real-world scenes from monocular real-world videos. Our Dynamic Scene Transformer (DyST) model leverages recent work in neural scene representation to learn a latent decomposition of monocular real-world videos into scene content, per-view scene dynamics, and camera pose. This separation is achieved through a novel co-training scheme on monocular videos and our new synthetic dataset DySO. DyST learns tangible latent representations for dynamic scenes that enable view generation with separate control over the camera and the content of the scene.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel approach to generative modeling of dynamic 3D visual scenes, called DyST, which admits separate control over the camera and the content of the scene. The model is trained using a synthetic dataset, DySO, and real-world videos, and it learns to disentangle camera pose and scene dynamics from monocular real-world videos. The authors demonstrate the effectiveness of DyST in view synthesis and scene control capabilities on real-world videos of dynamic scenes.\n\nStrengths:\n\n1. The paper proposes a novel approach to generative modeling of dynamic 3D visual scenes, which is a challenging task.\n2. The authors demonstrate the effectiveness of DyST in view synthesis and scene control capabilities on real-world videos of dynamic scenes.\n3. The paper presents a detailed analysis of the model and its learned latent representations for scene dynamics and camera pose.\n4. The authors propose a novel synthetic dataset, DySO, which is used for co-training DyST.\n\nWeaknesses:\n\n1. The paper assumes that the scene dynamics are known, which may not be the case in real-world scenarios.\n2. The authors use a simple set of camera and object motions in the synthetic dataset, which may not be sufficient to capture the complexity of real-world scenes.\n3. The paper does not provide a detailed analysis of the model's performance on more complex types of videos, such as videos with several independent moving objects or changing lighting conditions.\n4. The authors use a L2 loss for training the model, which may not be suitable for all types of scenes.\n\nSuggestions for Improvement:\n\n1. The authors could explore more complex types of videos and analyze the model's performance on these scenarios.\n2. The paper could benefit from a more detailed analysis of the model's performance on videos with changing lighting conditions.\n3. The authors could explore the use of more advanced loss functions, such as a perceptual loss or a adversarial loss, to improve the model's generative capabilities.\n4. The paper could benefit from a more detailed analysis of the model's learned latent representations for scene dynamics and camera pose.\n\nRecommendation:\n\nThe paper proposes a novel approach to generative modeling of dynamic 3D visual scenes, which is a challenging task. The authors demonstrate the effectiveness of DyST in view synthesis and scene control capabilities on real-world videos of dynamic scenes. However, the paper has some limitations, such as the assumption that the scene dynamics are known and the use of a simple set of camera and object motions in the synthetic dataset. To improve the paper, the authors could explore more complex types of videos, analyze the model's performance on these scenarios, and explore the use of more advanced loss functions.",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper introduces DyST, a novel approach to generative modeling of dynamic 3D visual scenes that allows for separate control over the camera and the content of the scene. The model learns a latent decomposition of monocular real-world videos into scene content, per-view scene dynamics, and camera pose, and can be used for view generation with separate control over the camera and the content of the scene. The paper proposes a novel latent control swap training scheme that enforces the separation of camera pose and scene dynamics, and demonstrates the effectiveness of the approach through experiments on real-world videos.\n\nStrengths:\n\n* The paper proposes a novel approach to generative modeling of dynamic 3D visual scenes that allows for separate control over the camera and the content of the scene.\n* The latent control swap training scheme is an innovative and effective approach to enforcing the separation of camera pose and scene dynamics.\n* The paper provides a thorough evaluation of the approach through experiments on real-world videos, including quantitative and qualitative results.\n* The paper is well-written and easy to follow, with clear explanations of the approach and the results.\n\nWeaknesses:\n\n* The paper assumes that the input videos are monocular, which may not be the case in all real-world scenarios.\n* The paper does not provide a detailed comparison with other state-of-the-art approaches to generative modeling of dynamic 3D visual scenes.\n* The paper assumes that the ground truth camera poses are not available, which may not be the case in all real-world scenarios.\n* The paper does not provide a detailed discussion on the potential limitations and future work on the approach.\n\nSuggestions for Improvement:\n\n* The paper should provide a more detailed comparison with other state-of-the-art approaches to generative modeling of dynamic 3D visual scenes.\n* The paper should discuss the potential limitations and future work on the approach, including the assumption that the input videos are monocular and the availability of ground truth camera poses.\n* The paper should provide more detailed results on the quantitative and qualitative evaluation of the approach.\n* The paper should discuss the potential applications of the approach, including the use of the approach for downstream tasks such as video editing and visual effects.\n\nRecommendation:\n\nThe paper is well-written and provides a thorough evaluation of the approach through experiments on real-world videos. However, the paper assumes that the input videos are monocular and the ground truth camera poses are not available, which may not be the case in all real-world scenarios. The paper should provide a more detailed comparison with other state-of-the-art approaches and discuss the potential limitations and future work on the approach. Overall, the paper is a good contribution to the field and provides a useful approach for generative modeling of dynamic 3D visual scenes.\n\nRecommendation for Publication:\n\nI recommend the paper for publication, but the authors should address the issues mentioned above.\n\nReviewer's Conflict of Interest:\n\nI have no conflict of interest.\n\nReviewer's Expertise:\n\nI am an expert in the field of computer vision and generative modeling.\n\nReviewer's Availability:\n\nI am available for any further questions or discussions.\n\nReviewer's Contact Information:\n\n[Your Name]\n[Your Email]\n[Your Phone Number]\n\n$$$",
        "gr_score_with": 0.6646706586826348,
        "gr_score_without": 0.5765124555160143,
        "output_without": {
            "num_tokens_scored": 281,
            "num_green_tokens": 162,
            "green_fraction": 0.5765124555160143,
            "z_score": 2.5651649409691424,
            "p_value": 0.005156338444357301
        },
        "output_with": {
            "num_tokens_scored": 334,
            "num_green_tokens": 222,
            "green_fraction": 0.6646706586826348,
            "z_score": 6.01893220681041,
            "p_value": 8.778568826174157e-10
        }
    },
    {
        "title": "LEARNING MULTI-FACETED PROTOTYPICAL USER INTERESTS",
        "abstract": "We seek to uncover the latent interest units from behavioral data to better learn user preferences under the VAE framework. Existing practices tend to ignore the multiple facets of item characteristics, which may not capture it at appropriate granularity. Moreover, current studies equate the granularity of item space to that of user interests, which we postulate is not ideal as user interests would likely map to a small subset of item space. In addition, the compositionality of user interests has received inadequate attention, preventing the modeling of interactions between explanatory factors driving a user\u2019s decision. To resolve this, we propose to align user interests with multi-faceted item characteristics. First, we involve prototype-based representation learning to discover item characteristics along multiple facets. Second, we compose user interests from uncovered item characteristics via binding mechanism, separating the granularity of user preferences from that of item space. Third, we design a dedicated bi-directional binding block, aiding the derivation of compositional user interests. On real-world datasets, the experimental results demonstrate the strong performance of our proposed method compared to a series of baselines.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel method called FACETVAE for learning multi-faceted prototypical user interests. The method aims to address the shortcomings of existing VAE-based disentangled recommendation models, including inadequate item space discovering, same level of granularity between user interests and item space assumption, and improper user interest complexity handling. FACETVAE is characterized by three main innovations: disentangling item space under a multi-faceted manner, binding compositional user interests from low-level ones discovered from item space, and effectively binding user interests via a bi-directional binding block. The authors demonstrate the effectiveness of FACETVAE on three real-world datasets, achieving state-of-the-art performance compared to several baselines.\n\nStrengths:\n\n1. The paper addresses a significant problem in recommendation systems, which is learning multi-faceted user interests.\n2. The proposed method, FACETVAE, is well-motivated and has a clear theoretical foundation.\n3. The authors provide a thorough evaluation of their method on three real-world datasets, demonstrating its effectiveness compared to several baselines.\n4. The paper is well-organized and easy to follow, with clear explanations of the methodology and experimental results.\n\nWeaknesses:\n\n1. The paper assumes that the number of facets and the number of clusters per facet are known, which may not be the case in practice.\n2. The authors do not provide a clear explanation of how to determine the number of facets and the number of clusters per facet in a data-driven manner.\n3. The paper assumes that the user interests are represented as a set of K vectors, which may not be the case in practice.\n4. The authors do not provide a clear explanation of how to handle the case where the user interests are not well-represented by a set of K vectors.\n\nSuggestions for Improvement:\n\n1. Provide a clear explanation of how to determine the number of facets and the number of clusters per facet in a data-driven manner.\n2. Discuss the limitations of the paper, including the assumption that the number of facets and the number of clusters per facet are known.\n3. Provide a clear explanation of how to handle the case where the user interests are not well-represented by a set of K vectors.\n4. Consider adding more experimental results to demonstrate the effectiveness of FACETVAE in different scenarios.\n\nRecommendation:\n\nThe paper is well-written and provides a thorough evaluation of the proposed method, FACETVAE. However, the authors should address the limitations of the paper and provide a clear explanation of how to handle the case where the user interests are not well-represented by a set of K vectors. With these improvements, the paper has the potential to make a significant contribution to the field of recommendation systems.\n\n$$$\nNote: The review is based on the provided paper and is intended to provide constructive feedback to the authors. The review is not intended to be a comprehensive evaluation of the paper, but rather a summary of the strengths and weaknesses of the paper, along with suggestions for improvement.",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel recommendation model, FACETVAE, which addresses the limitations of existing Variational AutoEncoder (VAE)-based disentangled recommendation models. The authors argue that existing models ignore the multiple facets of item characteristics and assume the same level of granularity between user interests and item space, which causes a dilemma. FACETVAE is designed to disentangle item space under a multi-faceted manner, bind compositional user interests from low-level ones discovered from item space, and effectively bind user interests via a bi-directional binding block.\n\nStrengths:\n\n1. The paper clearly articulates the limitations of existing VAE-based disentangled recommendation models and proposes a novel approach to address these limitations.\n2. The authors provide a comprehensive overview of the related work and clearly explain the differences between their proposed model and existing models.\n3. The paper includes a thorough experimental evaluation of FACETVAE on three real-world datasets, which demonstrates its effectiveness in improving recommendation accuracy compared to existing models.\n4. The authors provide a qualitative analysis of the results, including visualization of the item groups produced by FACETVAE, which demonstrates its ability to discover multi-faceted item space structure.\n\nWeaknesses:\n\n1. The paper assumes a pre-defined number of facets and the number of clusters per facet, which may not be optimal for all datasets.\n2. The authors do not provide a clear explanation of how to determine the optimal number of facets and the number of clusters per facet in a data-driven manner.\n3. The paper assumes a uniform facet distribution, which may not be realistic for all datasets.\n4. The authors do not provide a thorough analysis of the computational cost of FACETVAE and how it compares to existing models.\n\nSuggestions for Improvement:\n\n1. The authors should investigate how to determine the optimal number of facets and the number of clusters per facet in a data-driven manner.\n2. The paper should provide a more detailed explanation of how to handle the case where the number of facets and the number of clusters per facet are not pre-defined.\n3. The authors should investigate the robustness of FACETVAE to different facet distributions and how it can be adapted to handle non-uniform facet distributions.\n4. The paper should provide a more thorough analysis of the computational cost of FACETVAE and how it compares to existing models.\n\nRecommendation:\n\nThe paper proposes a novel and effective recommendation model that addresses the limitations of existing VAE-based disentangled recommendation models. The experimental results demonstrate its effectiveness in improving recommendation accuracy compared to existing models. However, the paper assumes a pre-defined number of facets and the number of clusters per facet, which may not be optimal for all datasets. The authors should investigate how to determine the optimal number of facets and the number of clusters per facet in a data-driven manner to further improve the model.\n\n$$$",
        "gr_score_with": 0.5700934579439252,
        "gr_score_without": 0.5135869565217391,
        "output_without": {
            "num_tokens_scored": 368,
            "num_green_tokens": 189,
            "green_fraction": 0.5135869565217391,
            "z_score": 0.5212860351426869,
            "p_value": 0.30108376387409785
        },
        "output_with": {
            "num_tokens_scored": 321,
            "num_green_tokens": 183,
            "green_fraction": 0.5700934579439252,
            "z_score": 2.511655074836764,
            "p_value": 0.006008323820918708
        }
    },
    {
        "title": "WIN-WIN: TRAINING HIGH-RESOLUTION VISION TRANSFORMERS",
        "abstract": "Transformers have become the standard in state-of-the-art vision architectures, achieving impressive performance on both image-level and dense pixelwise tasks. However, training vision transformers for high-resolution pixelwise tasks has a prohibitive cost. Typical solutions boil down to hierarchical architectures, fast and approximate attention, or training on low-resolution crops. This latter solution does not constrain architectural choices, but it leads to a clear performance drop when testing at resolutions significantly higher than that used for training, thus requiring ad-hoc and slow post-processing schemes. In this paper, we propose a novel strategy for efficient training and inference of high-resolution vision transformers: the key principle is to mask out most of the high-resolution inputs during training, keeping only N random windows. This allows the model to learn local interactions between tokens inside each window, and global interactions between tokens from different windows. As a result, the model can directly process the high-resolution input at test time without any special trick. We show that this strategy is effective when using relative positional embedding such as rotary embeddings. It is 4 times faster to train than a full-resolution network, and it is straightforward to use at test time compared to existing approaches. We apply this strategy to two dense prediction tasks with high resolution data. First, we show on the task of semantic segmentation that a simple setting with 2 windows performs best, hence the name of our method: Win-Win. To demonstrate the generality of our contribution, we further extend it to the binocular task of optical flow, reaching state-of-the-art performance on the Spring benchmark that contains Full-HD images with an inference time an order of magnitude faster than the best competitor. 0 10 20 30 40 50 60 Training time (hours) 45 50 55 60 m ea n Io U Semantic segmentation on BDD100k Win-Win (31GB) Full-res. (58GB) Full-res ViTDet (32GB) 0 25 50 75 100 125 150 175 Training time (hours) 1.6 2.0 2.4 2.8 3.2 En dPo in t E rro r ( EP E) Optical flow estimation on MPI-Sintel-clean Win-Win (14GB) Full-res. (28GB) Full-res ViT-Det (21GB) 80 100 120 140 160 180 Training time (hours) 0.0 0.5 1.0 1.5 In fe re nc e tim e (s ec on ds ) Optical flow estimation on MPI-Sintel-clean Full-res ViT Full-res ViT-Det Win-Win ViT + Tiling Figure 1: Validation performance vs. training time on semantic segmentation (left) and optical flow (middle). We compare our two-window training (Win-Win) to a standard full-resolution training as well as a sparsification of the attention following ViT-Det (Li et al., 2022a). We indicate the memory usage in parenthesis in the legend. Compared to full-resolution training, Win-Win allows to reduce the training time by a factor 3-4 and to half the memory usage while reaching a similar performance. Training and inference times on optical flow, for Win-Win vs. other strategies (right). ViT+Tiling corresponds to a setup similar to CroCo-Flow (Weinzaepfel et al., 2023) where the model is trained on random crops, but requires a tiling strategy at inference. While Win-Win is as fast to train as the latter, it can directly process full-resolution inputs at test time.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel strategy for efficient training and inference of high-resolution vision transformers, called Win-Win. The key principle of Win-Win is to mask out most of the high-resolution inputs during training, keeping only N random windows. This allows the model to learn local interactions between tokens inside each window, and global interactions between tokens from different windows. As a result, the model can directly process the high-resolution input at test time without any special trick. The authors show that this strategy is effective when using relative positional embedding such as rotary embeddings, and is 4 times faster to train than a full-resolution network.\n\nStrengths:\n\n* The paper proposes a novel and efficient strategy for training high-resolution vision transformers.\n* The Win-Win approach allows the model to learn local and global interactions, which is key for dense prediction tasks.\n* The paper shows that the Win-Win approach can achieve state-of-the-art performance on two dense prediction tasks: semantic segmentation and optical flow estimation.\n* The authors provide a thorough experimental evaluation of the Win-Win approach, including comparisons to other baselines and ablation studies.\n\nWeaknesses:\n\n* The paper assumes that the input images are already preprocessed, which may not be the case in real-world scenarios.\n* The authors do not provide a detailed analysis of the computational cost of the Win-Win approach, which may be a concern for large-scale applications.\n* The paper does not provide a clear explanation of why the Win-Win approach works, which may make it difficult for readers to understand and replicate the results.\n\nSuggestions for Improvement:\n\n* Provide a more detailed analysis of the computational cost of the Win-Win approach, including a discussion of the trade-offs between training speed and inference speed.\n* Provide a more thorough evaluation of the Win-Win approach on other tasks and datasets, to demonstrate its generality and robustness.\n* Provide a more detailed explanation of why the Win-Win approach works, including a discussion of the theoretical foundations and the empirical evidence.\n\nRecommendation:\n\nThe paper proposes a novel and efficient strategy for training high-resolution vision transformers, and provides a thorough experimental evaluation of the approach. While there are some limitations and weaknesses, the paper is well-written and well-organized, and the results are impressive. I recommend this paper for publication in a top-tier conference.\n\nGrade: B+\n\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel strategy, called Win-Win, for efficient training and inference of high-resolution vision transformers. The key principle of Win-Win is to mask out most of the high-resolution inputs during training, keeping only N random windows. This allows the model to learn local interactions between tokens inside each window and global interactions between tokens from different windows. As a result, the model can directly process the high-resolution input at test time without any special trick. The authors demonstrate the effectiveness of Win-Win on two dense prediction tasks with high-resolution data, semantic segmentation and optical flow estimation, and show that it outperforms other state-of-the-art approaches in terms of both accuracy and efficiency.\n\nStrengths:\n\n* The paper proposes a novel and effective approach for training high-resolution vision transformers, which is applicable to a wide range of dense prediction tasks.\n* The authors provide comprehensive experiments and comparisons with other state-of-the-art approaches, demonstrating the superiority of Win-Win in terms of accuracy and efficiency.\n* The paper is well-written and easy to follow, with clear explanations of the proposed approach and its benefits.\n* The authors provide detailed experimental settings and hyperparameters, making it easier for readers to reproduce the results.\n\nWeaknesses:\n\n* The paper assumes that the input data is already preprocessed and that the model is trained on a large-scale dataset, which may not be the case in all scenarios.\n* The authors do not provide a detailed analysis of the computational cost of Win-Win, which may be a concern for large-scale applications.\n* While the paper focuses on the benefits of Win-Win, it would be helpful to provide more insights into the limitations and potential risks of the approach, such as the potential for overfitting or the impact of window size on performance.\n* The paper assumes that the model is trained on a single image at a time, which may not be the case in all scenarios, such as video or sequence data.\n\nSuggestions for Improvement:\n\n* Provide more detailed analysis of the computational cost of Win-Win, including the memory and CPU requirements.\n* Investigate the impact of window size on performance and provide guidance on how to choose the optimal window size.\n* Explore the application of Win-Win to other tasks, such as image classification or object detection, and provide results and insights.\n* Consider providing more insights into the limitations and potential risks of the approach, such as the potential for overfitting or the impact of window size on performance.\n* Provide more detailed explanations of the experimental settings and hyperparameters, including the preprocessing and data augmentation techniques used.\n\nRecommendation:\n\nThe paper proposes a novel and effective approach for training high-resolution vision transformers, which is applicable to a wide range of dense prediction tasks. While there are some limitations and areas for improvement, the paper is well-written and easy to follow, with clear explanations of the proposed approach and its benefits. Therefore, I recommend this paper for publication in the conference proceedings, with the suggestions for improvement in mind.\n\nRating: 7.5/10\n\nReviewer's Expertise: Computer Vision, Deep Learning, Neural Networks\n\nReviewer's Affiliation: [Reviewer's Affiliation]\n\nReviewer's Contact Information: [Reviewer's Contact Information]\n\nDate: [Date]\n\n$$$",
        "gr_score_with": 0.6972477064220184,
        "gr_score_without": 0.5572289156626506,
        "output_without": {
            "num_tokens_scored": 332,
            "num_green_tokens": 185,
            "green_fraction": 0.5572289156626506,
            "z_score": 2.0855209398041166,
            "p_value": 0.01851101971620811
        },
        "output_with": {
            "num_tokens_scored": 436,
            "num_green_tokens": 304,
            "green_fraction": 0.6972477064220184,
            "z_score": 8.237306052901902,
            "p_value": 8.80657575035382e-17
        }
    },
    {
        "title": "FAKE IT TILL MAKE IT: FEDERATED LEARNING WITH CONSENSUS-ORIENTED GENERATION",
        "abstract": "In federated learning (FL), data heterogeneity is one key bottleneck that causes model divergence and limits performance. Addressing this, existing methods often regard data heterogeneity as an inherent property and propose to mitigate its adverse effects by correcting models. In this paper, we seek to break this inherent property by generating data to complement the original dataset to fundamentally mitigate heterogeneity level. As a novel attempt from the perspective of data, we propose federated learning with consensus-oriented generation (FedCOG). FedCOG consists of two key components at the client side: complementary data generation, which generates data extracted from the shared global model to complement the original dataset, and knowledge-distillation-based model training, which distills knowledge from global model to local model based on the generated data to mitigate over-fitting the original heterogeneous dataset. FedCOG has two critical advantages: 1) it can be a plug-and-play module to further improve the performance of most existing FL methods, and 2) it is naturally compatible with standard FL protocols such as Secure Aggregation since it makes no modification in communication process. Extensive experiments on classical and real-world FL datasets show that FedCOG consistently outperforms state-of-the-art methods .",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel federated learning algorithm, called FedCOG, to tackle the issue of data heterogeneity in FL. FedCOG consists of two key components: complementary data generation and knowledge-distillation-based model training. The complementary data generation module generates data from the shared global model to complement the original dataset, reducing the heterogeneity level. The knowledge-distillation-based model training module distills knowledge from the global model to the local model based on the generated data, mitigating the effects of heterogeneity. FedCOG is plug-and-play, compatible with standard FL protocols, and does not compromise on communication cost and privacy. The authors conduct extensive experiments on classical and real-world FL datasets, showing that FedCOG consistently outperforms state-of-the-art methods.\n\nStrengths:\n\n1. The paper addresses a critical issue in FL, data heterogeneity, from a novel perspective of modifying local dataset.\n2. FedCOG is a well-designed algorithm that consists of two key components, complementary data generation and knowledge-distillation-based model training, which are both effective in mitigating the effects of heterogeneity.\n3. The paper provides a comprehensive analysis of the benefits of FedCOG, including its plug-and-play property, compatibility with standard FL protocols, and lack of compromise on communication cost and privacy.\n4. The authors conduct extensive experiments on classical and real-world FL datasets, providing convincing evidence of the effectiveness of FedCOG.\n\nWeaknesses:\n\n1. The paper assumes that the global model is accurate and reliable, which may not be the case in real-world scenarios where the global model may be biased or inaccurate.\n2. The authors do not provide a detailed analysis of the computational cost of FedCOG, which may be a concern in large-scale FL settings.\n3. The paper does not discuss the potential limitations of FedCOG, such as its sensitivity to the choice of hyperparameters or its ability to handle non-IID data distributions.\n4. The authors do not provide a clear explanation of how FedCOG can be adapted to handle more complex FL scenarios, such as non-convex losses or non-IID data distributions.\n\nSuggestions for Improvement:\n\n1. The authors should provide a more detailed analysis of the computational cost of FedCOG and discuss potential strategies for reducing the computational cost.\n2. The paper should include a more detailed discussion of the potential limitations of FedCOG and how they can be addressed.\n3. The authors should provide more insight into how FedCOG can be adapted to handle more complex FL scenarios, such as non-convex losses or non-IID data distributions.\n4. The paper should include more experiments to evaluate the robustness of FedCOG to different hyperparameter settings and data distributions.\n\nRecommendation:\n\nThe paper presents a novel and effective approach to tackling data heterogeneity in FL. While there are some limitations and potential areas for improvement, the paper provides a comprehensive analysis of the benefits of FedCOG and extensive experiments to demonstrate its effectiveness. I recommend this paper for publication in a top-tier conference in the field of machine learning and FL.\n\n$$$",
        "peer_review_with_watermark": "$$\n\\textbf{Paper Summary:}\nThe paper proposes a novel federated learning (FL) algorithm called Federated Learning with Consensus-Oriented Generation (FedCOG) to address the issue of data heterogeneity in FL. FedCOG generates data to complement the original dataset at each client, reducing the heterogeneity levels, and uses knowledge distillation to refine the local model training. The proposed algorithm is plug-and-play, compatible with standard FL protocols, and does not compromise on communication cost and privacy.\n\n\\textbf{Strengths:}\n1. The paper proposes a novel approach to tackle data heterogeneity in FL by generating data to complement the original dataset, which is orthogonal to existing methods that focus on model correction.\n2. The proposed FedCOG algorithm is plug-and-play, compatible with standard FL protocols, and does not compromise on communication cost and privacy.\n3. The paper conducts extensive experiments on classical and real-world FL datasets, showing that FedCOG consistently outperforms state-of-the-art methods.\n\n\\textbf{Weaknesses:}\n1. The paper assumes that the global model is available at each client, which may not be the case in practice.\n2. The proposed algorithm requires the clients to generate data, which may be computationally expensive and may not be feasible for large datasets.\n3. The paper does not provide a thorough analysis of the computational cost and scalability of the proposed algorithm.\n\n\\textbf{Suggestions for Improvement:}\n1. The authors should provide more details on how the global model is shared among clients and how the clients generate data without compromising on communication cost and privacy.\n2. The authors should provide more analysis on the computational cost and scalability of the proposed algorithm, including the time complexity and space complexity.\n3. The authors should provide more experiments on larger datasets and more realistic scenarios to demonstrate the effectiveness of the proposed algorithm.\n\n\\textbf{Recommendation:}\nThe paper proposes a novel and effective approach to tackle data heterogeneity in FL, and the proposed FedCOG algorithm is plug-and-play, compatible with standard FL protocols, and does not compromise on communication cost and privacy. However, the paper has some limitations and weaknesses, and the authors should address these issues to make the paper more comprehensive and convincing. Overall, the paper is well-written, and the results are impressive, but the authors should provide more details and analysis to make the paper more robust.\n\n$$",
        "gr_score_with": 0.6875,
        "gr_score_without": 0.5328282828282829,
        "output_without": {
            "num_tokens_scored": 396,
            "num_green_tokens": 211,
            "green_fraction": 0.5328282828282829,
            "z_score": 1.3065491598369756,
            "p_value": 0.09568293639285846
        },
        "output_with": {
            "num_tokens_scored": 304,
            "num_green_tokens": 209,
            "green_fraction": 0.6875,
            "z_score": 6.53834841531101,
            "p_value": 3.110094237048688e-11
        }
    },
    {
        "title": "GIM: LEARNING GENERALIZABLE IMAGE MATCHER",
        "abstract": "Image matching is a fundamental computer vision problem. While learning-based methods achieve state-of-the-art performance on existing benchmarks, they generalize poorly to in-the-wild images. Such methods typically need to train separate models for different scene types (e.g., indoor vs. outdoor) and are impractical when the scene type is unknown in advance. One of the underlying problems is the limited scalability of existing data construction pipelines, which limits the diversity of standard image matching datasets. To address this problem, we propose GIM, a self-training framework for learning a single generalizable model based on any image matching architecture using internet videos, an abundant and diverse data source. Given an architecture, GIM first trains it on standard domain-specific datasets and then combines it with complementary matching methods to create dense labels on nearby frames of novel videos. These labels are filtered by robust fitting, and then enhanced by propagating them to distant frames. The final model is trained on propagated data with strong augmentations. Not relying on complex 3D reconstruction makes GIM much more efficient and less likely to fail than standard SfM-and-MVS based frameworks. We also propose ZEB, the first zero-shot evaluation benchmark for image matching. By mixing data from diverse domains, ZEB can thoroughly assess the cross-domain generalization performance of different methods. Experiments demonstrate the effectiveness and generality of GIM. Applying GIM consistently improves the zero-shot performance of 3 state-of-theart image matching architectures as the number of downloaded videos increases (Fig. 1 (a)); with 50 hours of YouTube videos, the relative zero-shot performance improves by 8.4% \u2212 18.1%. GIM also enables generalization to extreme crossdomain data such as Bird Eye View (BEV) images of projected 3D point clouds (Fig. 1 (c)). More importantly, our single zero-shot model consistently outperforms domain-specific baselines when evaluated on downstream tasks inherent to their respective domains. The code will be released upon acceptance.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\nThe paper proposes a novel framework, GIM, for learning generalizable image matching models using self-training on diverse internet videos. GIM first trains a model on standard domain-specific datasets and then uses the trained model to generate dense labels on nearby frames of downloaded videos. The final model is trained on the propagated data with strong augmentations. The authors also propose a new zero-shot evaluation benchmark, ZEB, which consists of data from 8 real-world and 4 simulated domains. Experiments demonstrate the effectiveness and generality of GIM, showing consistent improvements in zero-shot performance for three state-of-the-art image matching architectures.\n\nStrengths:\n1. The paper proposes a novel and effective approach to learning generalizable image matching models using self-training on diverse internet videos.\n2. The authors provide a thorough evaluation of the proposed method on a new zero-shot benchmark, ZEB, which is more comprehensive than existing in-domain benchmarks.\n3. The paper demonstrates the generality of GIM by applying it to three state-of-the-art architectures and showing consistent improvements in zero-shot performance.\n4. The authors provide a detailed analysis of the effect of different GIM components, including the importance of generating supervision signals on diverse videos and the role of label propagation.\n\nWeaknesses:\n1. The paper assumes the availability of a large amount of internet videos, which may not be feasible in all scenarios.\n2. The authors do not provide a detailed analysis of the computational efficiency of GIM, which is an important consideration for practical applications.\n3. The paper focuses primarily on image matching and does not explore other applications of GIM, such as object detection or segmentation.\n4. The authors do not provide a clear explanation of how to select the best architecture for GIM, which may be a challenge in practice.\n\nSuggestions for Improvement:\n1. The authors could provide a more detailed analysis of the computational efficiency of GIM and explore ways to optimize its performance.\n2. The paper could be expanded to explore other applications of GIM, such as object detection or segmentation.\n3. The authors could provide a clear explanation of how to select the best architecture for GIM and provide guidance on how to tune its hyperparameters.\n4. The paper could be improved by providing a more comprehensive evaluation of GIM on a wider range of datasets and tasks.\n\nRecommendation:\nThe paper proposes a novel and effective approach to learning generalizable image matching models using self-training on diverse internet videos. The authors provide a thorough evaluation of the proposed method on a new zero-shot benchmark, ZEB, and demonstrate its generality by applying it to three state-of-the-art architectures. While there are some limitations to the paper, it makes a significant contribution to the field of computer vision and is worth publishing.",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThis paper presents GIM, a self-training framework for learning a single generalizable image matcher from any image matching architecture using internet videos as a virtually unlimited and diverse data source. GIM aims to address the issue of poor generalization of existing learning-based image matching methods to in-the-wild images by learning from diverse and large-scale visual data. The framework first trains an image matching architecture on standard domain-specific datasets and then uses the trained model to generate dense labels on nearby frames of downloaded videos. These labels are filtered by robust fitting and enhanced by propagating them to distant frames. The final model is trained on propagated data with strong augmentations. GIM is compared to standard SfM-and-MVS-based frameworks, which have limited efficiency and are prone to fail on in-the-wild videos. Experiments demonstrate the effectiveness and generality of GIM, and show that it consistently improves the zero-shot performance of 3 state-of-the-art image matching architectures as the number of downloaded videos increases.\n\nStrengths:\n\n* GIM addresses the issue of poor generalization of existing learning-based image matching methods to in-the-wild images by learning from diverse and large-scale visual data.\n* GIM uses internet videos as a virtually unlimited and diverse data source, making it more efficient and scalable than existing methods.\n* GIM improves the performance of existing image matching architectures and enables generalization to extreme cross-domain data such as Bird Eye View (BEV) images of projected 3D point clouds.\n* GIM consistently outperforms domain-specific baselines when evaluated on downstream tasks inherent to their respective domains.\n\nWeaknesses:\n\n* GIM relies on the quality of the downloaded videos and may not perform well if the videos are of poor quality or have limited diversity.\n* GIM may require significant computational resources to process large amounts of video data.\n* GIM assumes that the image matching architecture used is a good starting point for learning a generalizable image matcher, and may not perform well if the architecture is not well-suited for the task.\n\nSuggestions for Improvement:\n\n* Investigate the use of other data sources, such as user-generated content or social media platforms, to further increase the diversity and scalability of GIM.\n* Develop more efficient methods for processing and annotating large amounts of video data to reduce the computational resources required for GIM.\n* Explore the use of transfer learning or meta-learning to enable GIM to learn more generalizable image matchers that can perform well across multiple domains and tasks.\n\nRecommendation:\n\nThis paper presents a novel and effective approach to learning generalizable image matchers from internet videos, and demonstrates the potential of GIM to improve the performance of existing image matching architectures and enable generalization to extreme cross-domain data. The framework is well-motivated, and the experiments are thorough and well-presented. However, further investigation into the limitations and weaknesses of GIM is required to fully understand its potential and to identify opportunities for improvement.",
        "gr_score_with": 0.5812917594654788,
        "gr_score_without": 0.46920821114369504,
        "output_without": {
            "num_tokens_scored": 341,
            "num_green_tokens": 160,
            "green_fraction": 0.46920821114369504,
            "z_score": -1.137213758255153,
            "p_value": 0.8722755315926164
        },
        "output_with": {
            "num_tokens_scored": 449,
            "num_green_tokens": 261,
            "green_fraction": 0.5812917594654788,
            "z_score": 3.4450830007359636,
            "p_value": 0.00028544203188828347
        }
    },
    {
        "title": "VERA: VECTOR-BASED RANDOM MATRIX ADAPTATION",
        "abstract": "Low-rank adapation (LoRA) is a popular method that reduces the number of trainable parameters when finetuning large language models, but still faces acute storage challenges when scaling to even larger models or deploying numerous peruser or per-task adapted models. In this work, we present Vector-based Random Matrix Adaptation (VeRA)1, which significantly reduces the number of trainable parameters compared to LoRA, yet maintains the same performance. It achieves this by using a single pair of low-rank matrices shared across all layers and learning small scaling vectors instead. We demonstrate its effectiveness on the GLUE and E2E benchmarks, image classification tasks, and show its application in instruction-tuning of 7B and 13B language models.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper presents Vector-based Random Matrix Adaptation (VeRA), a novel parameter-efficient finetuning method for large language models. VeRA reduces the number of trainable parameters compared to the state-of-the-art LoRA method, while maintaining comparable results. The method employs a single pair of frozen random matrices shared across all layers and learns small scaling vectors instead. VeRA achieves significant memory savings, making it suitable for scenarios that require frequent swapping of numerous finetuned models, such as cloud-based AI services personalized for individual users.\n\nStrengths:\n\n1. VeRA achieves significant memory savings compared to LoRA, making it suitable for scenarios that require frequent swapping of numerous finetuned models.\n2. The method is parameter-efficient, requiring fewer trainable parameters while maintaining comparable results to LoRA.\n3. VeRA is easy to implement and can be used with various architectures and domains.\n4. The method is well-suited for cloud-based AI services personalized for individual users.\n\nWeaknesses:\n\n1. The paper lacks a thorough analysis of the trade-offs involved in parameter scalability for VeRA and LoRA.\n2. The ablation study is limited to a few experiments, and more comprehensive studies are needed to understand the impact of individual components of VeRA.\n3. The paper does not provide a clear explanation of how VeRA can be extended to other architectures and domains.\n4. The performance of VeRA may benefit from additional refinements, such as dynamic parameter budget allocation or different initialization and regularization techniques.\n\nSuggestions for Improvement:\n\n1. Conduct a more comprehensive analysis of the trade-offs involved in parameter scalability for VeRA and LoRA.\n2. Perform more extensive ablation studies to understand the impact of individual components of VeRA.\n3. Provide a clear explanation of how VeRA can be extended to other architectures and domains.\n4. Investigate the performance of VeRA with different initialization and regularization techniques.\n\nRecommendation:\n\nThe paper presents a novel and efficient finetuning method for large language models. While there are some limitations and areas for improvement, the method shows promising results and has the potential to be a valuable addition to the field. I recommend accepting the paper for publication after addressing the suggestions for improvement.\n\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel parameter-efficient finetuning method called Vector-based Random Matrix Adaptation (VeRA) for large language models. VeRA aims to address the issue of efficient adaptation for specific tasks by reducing the number of trainable parameters required during finetuning. The method utilizes a pair of frozen random matrices shared across all layers and learns small scaling vectors to adapt the model for a new task. VeRA is shown to achieve comparable results to the state-of-the-art LoRA method while reducing the number of trainable parameters by an order of magnitude.\n\nStrengths:\n\n*   The paper proposes a novel and efficient finetuning method for large language models.\n*   VeRA achieves comparable results to the state-of-the-art LoRA method while reducing the number of trainable parameters by an order of magnitude.\n*   The method is particularly well-suited for scenarios that require frequent swapping of numerous finetuned models, such as cloud-based AI services personalized for individual users.\n\nWeaknesses:\n\n*   The paper relies heavily on the effectiveness of the frozen random matrices and scaling vectors, which may not generalize to all scenarios or models.\n*   The method may not be as effective for models with a large number of layers or a high-dimensional feature space.\n*   The performance of the method may benefit from additional refinements, such as dynamic parameter budget allocation or different initialization and regularization techniques.\n\nSuggestions for Improvement:\n\n*   To further improve the performance of the method, the authors could explore the use of more advanced initialization and regularization techniques for the frozen random matrices and scaling vectors.\n*   The authors could also investigate the use of dynamic parameter budget allocation to adapt the number of trainable parameters based on the specific task or model.\n*   To demonstrate the generalizability of the method, the authors could evaluate VeRA on a broader range of models and tasks.\n\nRecommendation:\n\nThe paper proposes a novel and efficient finetuning method for large language models, which achieves comparable results to the state-of-the-art LoRA method while reducing the number of trainable parameters by an order of magnitude. However, the method relies heavily on the effectiveness of the frozen random matrices and scaling vectors, which may not generalize to all scenarios or models. To address these limitations, the authors could explore the use of more advanced initialization and regularization techniques for the frozen random matrices and scaling vectors, as well as the use of dynamic parameter budget allocation to adapt the number of trainable parameters based on the specific task or model. Based on these considerations, I recommend the paper for publication in a high-impact conference or journal.\n\n$$$",
        "gr_score_with": 0.6204620462046204,
        "gr_score_without": 0.5217391304347826,
        "output_without": {
            "num_tokens_scored": 299,
            "num_green_tokens": 156,
            "green_fraction": 0.5217391304347826,
            "z_score": 0.7518094115561123,
            "p_value": 0.22608284067509615
        },
        "output_with": {
            "num_tokens_scored": 303,
            "num_green_tokens": 188,
            "green_fraction": 0.6204620462046204,
            "z_score": 4.19374042423641,
            "p_value": 1.3719597941213199e-05
        }
    },
    {
        "title": "FANTASTIC GENERALIZATION MEASURES",
        "abstract": "We study the notion of a generalization bound being uniformly tight, meaning that the difference between the bound and the population loss is small for all learning algorithms and all population distributions. Numerous generalization bounds have been proposed in the literature as potential explanations for the ability of neural networks to generalize in the overparameterized setting. However, in their paper \u201cFantastic Generalization Measures and Where to Find Them,\u201d Jiang et al. (2020) examine more than a dozen generalization bounds, and show empirically that none of them are uniformly tight. This raises the question of whether uniformly-tight generalization bounds are at all possible in the overparameterized setting. We consider two types of generalization bounds: (1) bounds that may depend on the training set and the learned hypothesis (e.g., margin bounds). We prove mathematically that no such bound can be uniformly tight in the overparameterized setting; (2) bounds that may in addition also depend on the learning algorithm (e.g., stability bounds). For these bounds, we show a trade-off between the algorithm\u2019s performance and the bound\u2019s tightness. Namely, if the algorithm achieves good accuracy on certain distributions, then no generalization bound can be uniformly tight for it in the overparameterized setting. We explain how these formal results can, in our view, inform research on generalization bounds for neural networks, while stressing that other interpretations of these results are also possible.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper studies the notion of uniformly tight generalization bounds in the overparameterized setting, which is a setting where the number of parameters in a neural network is much larger than the number of examples in the training set. The authors investigate two types of generalization bounds: (1) bounds that depend solely on the training set and the learned hypothesis, and (2) bounds that also depend on the learning algorithm. The paper shows that neither type of bound can be uniformly tight in the overparameterized setting, under certain assumptions. Specifically, the authors prove that no hypothesis class can be estimable in the overparameterized setting, and that there is a trade-off between learning performance and estimability.\n\nStrengths:\n\n1. The paper provides a comprehensive analysis of the limitations of generalization bounds in the overparameterized setting.\n2. The authors introduce a new framework for studying generalization bounds, which is based on the concept of estimability.\n3. The paper provides a detailed mathematical analysis of the trade-off between learning performance and estimability.\n4. The authors provide concrete examples of how their results apply to specific types of generalization bounds.\n\nWeaknesses:\n\n1. The paper assumes that the hypothesis class is finite, which may not be the case in practice.\n2. The authors' definition of an overparameterized setting may not capture all possible scenarios in which generalization bounds may be loose.\n3. The paper does not provide a clear roadmap for how to obtain uniformly tight generalization bounds in the overparameterized setting.\n4. The authors' results may not be directly applicable to all types of generalization bounds.\n\nSuggestions for Improvement:\n\n1. The authors should provide a more detailed discussion of the assumptions underlying their definition of an overparameterized setting.\n2. The paper should provide a more comprehensive analysis of the limitations of generalization bounds in the overparameterized setting, including a discussion of the trade-off between learning performance and estimability.\n3. The authors should provide a clear roadmap for how to obtain uniformly tight generalization bounds in the overparameterized setting.\n4. The paper should provide a more detailed discussion of the implications of their results for the development of generalization bounds.\n\nRecommendation:\n\nThe paper provides a valuable contribution to the field of machine learning, particularly in the area of generalization bounds. However, the authors should address the weaknesses mentioned above to make the paper more comprehensive and applicable to a wider range of scenarios. With some revisions, the paper has the potential to be a top-tier contribution to the field.\n\n$$$\nNote: The above review is based on the provided text and does not include any external knowledge or references.",
        "peer_review_with_watermark": "$$$\nPaper Summary:\n\nThe paper studies the concept of generalization bounds in the context of overparameterized neural networks. The authors aim to understand why current generalization bounds are often weak or vacuous, despite the strong generalization capabilities of neural networks. They introduce the concept of estimability, which measures the ability of a generalization bound to accurately estimate the population loss for a given hypothesis class and distribution. The paper proves two main theorems: Theorem 2, which shows that no hypothesis class is estimable in the overparameterized setting, and Theorem 3, which establishes a trade-off between learnability and estimability for algorithm-dependent generalization bounds.\n\nStrengths:\n\n* The paper provides a rigorous and formal analysis of the concept of estimability, which is a key contribution to the field of generalization bounds.\n* The authors present two main theorems, Theorem 2 and Theorem 3, which provide a clear and concise statement of the limitations of generalization bounds in the overparameterized setting.\n* The paper provides a thorough discussion of the implications of the theorems, including the trade-off between learnability and estimability for algorithm-dependent generalization bounds.\n\nWeaknesses:\n\n* The paper assumes a specific definition of overparameterization, which may not hold in all cases, and the authors acknowledge this limitation in the discussion.\n* The paper focuses on the limitations of generalization bounds, but does not provide a clear path forward for developing new bounds that are uniformly tight in the overparameterized setting.\n* The paper assumes a specific type of estimator, the constant estimator, which may not be the most general or realistic estimator in practice.\n\nSuggestions for Improvement:\n\n* The authors could provide a more detailed discussion of the implications of Theorem 2 and Theorem 3, including the trade-off between learnability and estimability for algorithm-dependent generalization bounds.\n* The paper could benefit from a more detailed comparison with existing generalization bounds, such as the VC bound or the Rademacher bound, to understand the limitations of these bounds in the overparameterized setting.\n* The authors could provide a clear path forward for developing new generalization bounds that are uniformly tight in the overparameterized setting, such as by introducing new assumptions or estimator types.\n\nRecommendation:\n\nThe paper provides a rigorous and formal analysis of the concept of estimability, and the two main theorems, Theorem 2 and Theorem 3, are a significant contribution to the field of generalization bounds. However, the paper assumes a specific definition of overparameterization, and the limitations of the theorems are not fully explored. To improve the paper, the authors could provide a more detailed discussion of the implications of the theorems, compare the paper's results with existing generalization bounds, and provide a clear path forward for developing new bounds that are uniformly tight in the overparameterized setting. With these improvements, the paper could be considered for publication in a top-tier conference or journal in the field of machine learning.\n\nRating: 7/10\n\nRecommendation for Publication: Yes\n\nReviewer's Confidence: High\n\nReviewer's Expertise: The reviewer has expertise in the field of machine learning, with a focus on generalization bounds and overparameterization. The reviewer has read and understood the paper, and has provided a detailed evaluation of the paper's strengths, weaknesses, and suggestions for improvement. The reviewer is confident in the evaluation, and believes that the paper has the potential to make a significant contribution to the field of machine learning.",
        "gr_score_with": 0.675392670157068,
        "gr_score_without": 0.509493670886076,
        "output_without": {
            "num_tokens_scored": 316,
            "num_green_tokens": 161,
            "green_fraction": 0.509493670886076,
            "z_score": 0.3375263702778072,
            "p_value": 0.3678600683136254
        },
        "output_with": {
            "num_tokens_scored": 382,
            "num_green_tokens": 258,
            "green_fraction": 0.675392670157068,
            "z_score": 6.856036435295121,
            "p_value": 3.5398663769759336e-12
        }
    },
    {
        "title": "STEVE-EYE: EQUIPPING LLM-BASED EMBOD-",
        "abstract": "Recent studies have presented compelling evidence that large language models (LLMs) can equip embodied agents with the self-driven capability to interact with the world, which marks an initial step toward versatile robotics. However, these efforts tend to overlook the visual richness of open worlds, rendering the entire interactive process akin to \u201ca blindfolded text-based game.\u201d Consequently, LLMbased agents frequently encounter challenges in intuitively comprehending their surroundings and producing responses that are easy to understand. In this paper, we propose Steve-Eye, an end-to-end trained large multimodal model to address this limitation. Steve-Eye integrates the LLM with a visual encoder to process visual-text inputs and generate multimodal feedback. We adopt a semi-automatic strategy to collect an extensive dataset comprising 850K open-world instruction pairs, enabling our model to encompass three essential functions for an agent: multimodal perception, foundational knowledge base, and skill prediction and planning. Lastly, we develop three open-world evaluation benchmarks, then carry out experiments from a wide range of perspectives to validate our model\u2019s capability to strategically act and plan. Codes and datasets will be released.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes Steve-Eye, a large multimodal model that enables embodied agents to interact with open-world environments through visual-text interfaces. The model combines a pre-trained large language model (LLM) with a visual encoder to process visual-text inputs and generate multimodal feedback. The authors collect an extensive dataset of 850K open-world instruction pairs and develop three open-world evaluation benchmarks to validate the model's capability to strategically act and plan. The paper presents experiments on these benchmarks, demonstrating the advantages of Steve-Eye over a wide range of perspectives.\n\nStrengths:\n\n1. The paper presents a well-structured and clear introduction to the problem of open-world embodied agents and the limitations of current text-only approaches.\n2. The authors propose a novel solution by combining a pre-trained LLM with a visual encoder, which is a promising approach for multimodal interaction.\n3. The paper presents a comprehensive evaluation of the model on three open-world benchmarks, demonstrating its advantages over a wide range of perspectives.\n4. The authors provide a detailed description of the dataset collection process and the model architecture, making it easier for readers to replicate the results.\n\nWeaknesses:\n\n1. The paper assumes that the visual encoder and LLM are pre-trained, which may not be the case in all scenarios. The authors should provide more information on how to train these components from scratch.\n2. The paper does not provide a thorough comparison with other state-of-the-art models, such as Plan4MC and DEPS, which are also designed for open-world embodied agents.\n3. The authors rely heavily on the performance of the visual encoder, which may not be robust in all scenarios. They should provide more information on how to improve the robustness of the visual encoder.\n4. The paper does not provide a clear explanation of how the model handles uncertainty and ambiguity in the input data.\n\nSuggestions for Improvement:\n\n1. Provide more information on how to train the visual encoder and LLM from scratch, including the training data and hyperparameters.\n2. Compare the performance of Steve-Eye with other state-of-the-art models, such as Plan4MC and DEPS, on the same benchmarks.\n3. Provide more information on how to improve the robustness of the visual encoder, such as using ensemble methods or attention mechanisms.\n4. Develop a more comprehensive evaluation framework that includes more diverse and challenging scenarios.\n\nRecommendation:\n\nThe paper presents a promising approach for multimodal interaction in open-world environments, and the experiments demonstrate the advantages of Steve-Eye over a wide range of perspectives. However, the paper has some limitations that need to be addressed, such as the reliance on pre-trained models and the lack of comparison with other state-of-the-art models. With some modifications and improvements, the paper has the potential to make a significant contribution to the field of artificial intelligence and robotics.\n\nRating: 7.5/10\n\nRecommendation for publication: Yes, with some revisions to address the limitations mentioned above.",
        "peer_review_with_watermark": "$$$\nPaper Summary:\nThe paper proposes Steve-Eye, a large multimodal model that integrates a pre-trained large language model (LLM) with a visual encoder to enable embodied agents to interact with the open world via visual-text interfaces. Steve-Eye is equipped with three indispensable functions: multimodal perception, foundational knowledge base, and skill prediction and planning. The authors develop a semi-automatic strategy to collect an extensive dataset of 850K open-world instruction pairs and conduct extensive experiments to validate the model's capability to strategically act and plan.\n\nStrengths:\n1. The paper proposes a novel multimodal model, Steve-Eye, that integrates a pre-trained LLM with a visual encoder to enable embodied agents to interact with the open world.\n2. The authors develop a semi-automatic strategy to collect an extensive dataset of 850K open-world instruction pairs, which is a significant contribution to the field.\n3. The paper conducts extensive experiments to validate the model's capability to strategically act and plan, which provides a comprehensive evaluation of the proposed model.\n4. The paper proposes three open-world evaluation benchmarks to evaluate the agent's interaction ability in an open world.\n\nWeaknesses:\n1. The paper assumes that the visual encoder can accurately capture the visual information from the environment, which may not always be the case.\n2. The paper relies heavily on the quality of the instruction-following data, which may not be representative of real-world scenarios.\n3. The paper does not provide a thorough comparison of the proposed model with other state-of-the-art models.\n4. The paper assumes that the agent can always receive the correct information from the environment, which may not be the case in real-world scenarios.\n\nSuggestions for Improvement:\n1. To improve the accuracy of the visual encoder, the authors can consider using more advanced visual encoder architectures or fine-tuning the existing visual encoder on a larger dataset.\n2. To improve the quality of the instruction-following data, the authors can consider collecting more data from real-world scenarios or using more advanced data collection strategies.\n3. To provide a more thorough comparison with other state-of-the-art models, the authors can consider conducting additional experiments or including a comparison with other models in the paper.\n4. To make the paper more applicable to real-world scenarios, the authors can consider adding more discussion on the potential limitations and challenges of the proposed model.\n\nRecommendation:\nThe paper proposes a novel multimodal model, Steve-Eye, that integrates a pre-trained LLM with a visual encoder to enable embodied agents to interact with the open world. The paper develops a semi-automatic strategy to collect an extensive dataset of 850K open-world instruction pairs and conducts extensive experiments to validate the model's capability to strategically act and plan. While the paper has some limitations, it provides a significant contribution to the field and has the potential to be a valuable tool for researchers and practitioners working in the area of embodied agents and multimodal interaction. Therefore, I recommend accepting the paper for publication in the conference proceedings.",
        "gr_score_with": 0.5903954802259888,
        "gr_score_without": 0.5307125307125307,
        "output_without": {
            "num_tokens_scored": 407,
            "num_green_tokens": 216,
            "green_fraction": 0.5307125307125307,
            "z_score": 1.2392039927415242,
            "p_value": 0.10763498115338999
        },
        "output_with": {
            "num_tokens_scored": 354,
            "num_green_tokens": 209,
            "green_fraction": 0.5903954802259888,
            "z_score": 3.401561622097497,
            "p_value": 0.0003350101051899003
        }
    },
    {
        "title": "PERCEPTUAL GROUP TOKENIZER: BUILDING PERCEPTION WITH ITERATIVE GROUPING",
        "abstract": "Human visual recognition system shows astonishing capability of compressing visual information into a set of tokens containing rich representations without label supervision. One critical driving principle behind it is perceptual grouping (Palmer, 2002; Wagemans et al., 2012; Herzog, 2018). Despite being widely used in computer vision in the early 2010s, it remains a mystery whether perceptual grouping can be leveraged to derive a neural visual recognition backbone that generates as powerful representations. In this paper, we propose the Perceptual Group Tokenizer, a model that entirely relies on grouping operations to extract visual features and perform self-supervised representation learning, where a series of grouping operations are used to iteratively hypothesize the context for pixels or superpixels to refine feature representations. We show that the proposed model can achieve competitive performance compared to state-of-the-art vision architectures, and inherits desirable properties including adaptive computation without re-training, and interpretability. Specifically, Perceptual Group Tokenizer achieves 80.3% on ImageNet-1K self-supervised learning benchmark with linear probe evaluation, establishing a new milestone for this paradigm.",
        "peer_review_without_watermark": "$$$\nPaper Summary:\nThe paper proposes a novel visual recognition architecture called Perceptual Group Tokenizer (PGT), which entirely relies on perceptual grouping principles to extract visual features and perform self-supervised representation learning. The model consists of a series of grouping operations that iteratively hypothesize the context for pixels or superpixels to refine feature representations. The authors show that PGT can achieve competitive performance compared to state-of-the-art vision architectures on self-supervised learning benchmarks, including ImageNet-1K.\n\nStrengths:\n1. The paper presents a novel and innovative approach to visual recognition, which is based on perceptual grouping principles.\n2. The authors provide a thorough analysis of the strengths and weaknesses of their approach and compare it to existing methods.\n3. The paper includes a comprehensive evaluation of the proposed method on various benchmarks, including ImageNet-1K.\n4. The authors provide a detailed explanation of the model architecture and the grouping operation.\n\nWeaknesses:\n1. The paper lacks a clear explanation of the theoretical foundations of the proposed method, particularly the perceptual grouping principles.\n2. The authors do not provide a detailed comparison of the computational cost of the proposed method with existing methods.\n3. The paper includes a limited number of ablation studies, which makes it difficult to fully understand the contributions of the proposed method.\n4. The authors do not provide a clear explanation of how the proposed method can be extended to more complex tasks, such as object detection or segmentation.\n\nSuggestions for Improvement:\n1. Provide a more detailed explanation of the theoretical foundations of the proposed method, particularly the perceptual grouping principles.\n2. Include a more comprehensive comparison of the computational cost of the proposed method with existing methods.\n3. Conduct more extensive ablation studies to fully understand the contributions of the proposed method.\n4. Provide a clear explanation of how the proposed method can be extended to more complex tasks, such as object detection or segmentation.\n\nRecommendation:\nThe paper presents a novel and innovative approach to visual recognition, which shows promising results on self-supervised learning benchmarks. However, the paper lacks a clear explanation of the theoretical foundations of the proposed method and a comprehensive comparison of the computational cost with existing methods. Therefore, I recommend that the authors address these limitations in future work. With these improvements, the paper can make a significant contribution to the field of computer vision.\n\nRating: 7/10",
        "peer_review_with_watermark": "$$$\nPaper Summary:\nThis paper proposes the Perceptual Group Tokenizer (PGT), a novel visual recognition architecture that entirely relies on perceptual grouping principles for self-supervised representation learning. The PGT model generates many hypothesized contexts through iterative grouping operations and uses them as cues to refine the feature representation of each patch. The authors demonstrate the competitive performance of PGT on the ImageNet-1K benchmark, achieving 80.3% top-1 accuracy with linear probe evaluation, and highlight its desirable properties, including adaptive computation without re-training and high model interpretability.\n\nStrengths:\n1. The PGT model demonstrates competitive performance on the ImageNet-1K benchmark, rivaling state-of-the-art vision architectures.\n2. The authors provide a clear and well-motivated explanation of the perceptual grouping principles and their connections to traditional factor graphs in probabilistic graphical models.\n3. The PGT model's adaptive computation ability allows for flexible customization of the number of group tokens during inference, which can be beneficial for scenarios where computational resources are limited.\n4. The authors provide a comprehensive set of experiments, including ablation studies, to investigate the design choices of PGT and its generalization ability on semantic segmentation tasks.\n\nWeaknesses:\n1. The PGT model's computational cost is relatively expensive due to the iterative grouping processes, which might be a limitation for real-world applications.\n2. The authors acknowledge that the \"parts-to-whole with data augmentation\" training loss might lead to fragmented groupings, which can be less desirable for certain applications.\n3. The PGT model's performance on more complex tasks, such as object detection and segmentation, is not extensively evaluated in the paper.\n4. The authors do not provide a detailed comparison of the PGT model's performance on different variants of the ImageNet-1K benchmark, such as the more challenging ImageNet-R or ImageNet-V2.\n\nSuggestions for Improvement:\n1. The authors could explore more efficient grouping operations, such as those with closed-form solutions, to reduce the computational cost of the PGT model.\n2. To improve the model's performance on more complex tasks, the authors could investigate the use of additional training data, such as object detection and segmentation datasets, or more advanced training objectives.\n3. To better understand the limitations of the PGT model, the authors could conduct more detailed comparisons with state-of-the-art vision architectures on different variants of the ImageNet-1K benchmark.\n4. To improve the model's interpretability, the authors could provide more visualizations of the group tokens and their connections to the input tokens, as well as more detailed explanations of the model's decision-making processes.\n\nRecommendation:\nThis paper presents a novel and competitive visual recognition architecture that relies on perceptual grouping principles for self-supervised representation learning. The PGT model's adaptive computation ability and high model interpretability make it a promising direction for future research. However, the authors should address the limitations mentioned above, including the computational cost and the fragmented groupings, to make the PGT model more viable for real-world applications.\n$$$",
        "gr_score_with": 0.5909090909090909,
        "gr_score_without": 0.4261168384879725,
        "output_without": {
            "num_tokens_scored": 291,
            "num_green_tokens": 124,
            "green_fraction": 0.4261168384879725,
            "z_score": -2.5207046415703616,
            "p_value": 0.994143994306836
        },
        "output_with": {
            "num_tokens_scored": 418,
            "num_green_tokens": 247,
            "green_fraction": 0.5909090909090909,
            "z_score": 3.7172815091383407,
            "p_value": 0.00010068900698825296
        }
    },
    {
        "title": "FOSI: Hybrid First and Second Order Optimization",
        "abstract": "Popular machine learning approaches forgo second-order information due to the difficulty of computing curvature in high dimensions. We present FOSI, a novel meta-algorithm that improves the performance of any base first-order optimizer by efficiently incorporating second-order information during the optimization process. In each iteration, FOSI implicitly splits the function into two quadratic functions defined on orthogonal subspaces, then uses a second-order method to minimize the first, and the base optimizer to minimize the other. We formally analyze FOSI\u2019s convergence and the conditions under which it improves a base optimizer. Our empirical evaluation demonstrates that FOSI improves the convergence rate and optimization time of first-order methods such as Heavy-Ball and Adam, and outperforms second-order methods (K-FAC and L-BFGS).",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes FOSI, a hybrid optimization algorithm that combines a first-order base optimizer with Newton's method to improve the convergence of any base first-order optimizer. FOSI iteratively splits the optimization problem into two quadratic problems on orthogonal subspaces, uses Newton's method to minimize one, and the base optimizer to minimize the other. The algorithm is designed to efficiently incorporate second-order information without computing the entire Hessian, making it suitable for large-scale optimization problems. The paper formally analyzes FOSI's convergence and the conditions under which it improves a base optimizer. Empirical evaluation demonstrates that FOSI improves the convergence rate and optimization time of first-order methods and outperforms second-order methods on various deep neural network training tasks.\n\nStrengths:\n\n1. FOSI is a hybrid optimization algorithm that combines the benefits of first-order and second-order methods, making it a robust and efficient optimization technique.\n2. The algorithm is designed to efficiently incorporate second-order information without computing the entire Hessian, making it suitable for large-scale optimization problems.\n3. The paper provides a thorough analysis of FOSI's convergence and the conditions under which it improves a base optimizer.\n4. Empirical evaluation demonstrates that FOSI improves the convergence rate and optimization time of first-order methods and outperforms second-order methods on various deep neural network training tasks.\n\nWeaknesses:\n\n1. The algorithm requires the number of Lanczos iterations (m) to be set, which can be a hyperparameter that needs to be tuned.\n2. The paper assumes that the Hessian is symmetric and positive definite, which may not be the case in all optimization problems.\n3. The algorithm requires the use of a base first-order optimizer, which may not be the best choice for all optimization problems.\n4. The paper does not provide a thorough analysis of the computational complexity of FOSI.\n\nSuggestions for Improvement:\n\n1. Investigate methods for automatically tuning the number of Lanczos iterations (m) and other hyperparameters of FOSI.\n2. Consider relaxing the assumption that the Hessian is symmetric and positive definite to make FOSI more applicable to a wider range of optimization problems.\n3. Investigate the use of other base first-order optimizers, such as stochastic gradient descent, to see if they can be improved by FOSI.\n4. Provide a thorough analysis of the computational complexity of FOSI and compare it to other optimization algorithms.\n\nRecommendation:\n\nFOSI is a promising optimization algorithm that combines the benefits of first-order and second-order methods. While there are some limitations and areas for improvement, the algorithm shows promising results on various deep neural network training tasks. I recommend further investigation and development of FOSI to make it a more robust and efficient optimization technique.\n\n$$$",
        "peer_review_with_watermark": "$$$\nPaper Summary:\nThe paper proposes FOSI, a hybrid optimization method that improves the performance of any base first-order optimizer by incorporating second-order information. FOSI works by implicitly splitting the optimization problem into two quadratic problems on orthogonal subspaces and using a second-order method to minimize one and a first-order optimizer to minimize the other. The paper presents a detailed description of the FOSI algorithm, a thorough spectral analysis of its preconditioner, and an empirical evaluation demonstrating its effectiveness on various deep neural networks. FOSI is shown to improve the convergence rate and optimization time of first-order methods and outperform second-order methods.\n\nStrengths:\n1. FOSI is a hybrid optimization method that improves the performance of any base first-order optimizer by incorporating second-order information, making it a versatile and effective optimization technique.\n2. The paper presents a detailed description of the FOSI algorithm and a thorough spectral analysis of its preconditioner, which provides a solid foundation for understanding the method's behavior and performance.\n3. The empirical evaluation demonstrates the effectiveness of FOSI on various deep neural networks, including image classification, language modeling, and autoencoding tasks.\n4. FOSI is shown to improve the convergence rate and optimization time of first-order methods and outperform second-order methods, making it a promising optimization technique for deep learning applications.\n\nWeaknesses:\n1. The paper assumes that the Hessian matrix is symmetric and positive definite, which may not always be the case in practice, especially for ill-conditioned or non-convex optimization problems.\n2. The Lanczos algorithm used in FOSI requires an accurate estimation of the Hessian matrix, which can be challenging in practice, especially for large-scale optimization problems.\n3. The paper does not provide a comprehensive comparison of FOSI with other optimization methods, including state-of-the-art first-order and second-order methods.\n4. The empirical evaluation is limited to a few deep neural networks, and the results may not generalize to other optimization problems or applications.\n\nSuggestions for Improvement:\n1. To address the assumption of a symmetric and positive definite Hessian matrix, the authors could explore alternative methods, such as using a diagonal or block-diagonal approximation of the Hessian matrix.\n2. To improve the accuracy of the Lanczos algorithm, the authors could explore alternative methods, such as using a more accurate estimation of the Hessian matrix or using a different optimization technique, such as quasi-Newton methods.\n3. To provide a more comprehensive comparison of FOSI with other optimization methods, the authors could include additional experiments and results, such as a comparison with state-of-the-art first-order and second-order methods.\n4. To demonstrate the generality of FOSI, the authors could explore its application to a wider range of optimization problems and applications, including non-convex optimization, ill-conditioned optimization, and large-scale optimization.\n\nRecommendation:\nThe paper presents a promising optimization technique, FOSI, which improves the performance of any base first-order optimizer by incorporating second-order information. While the paper assumes a symmetric and positive definite Hessian matrix and requires an accurate estimation of the Hessian matrix, the results demonstrate the effectiveness of FOSI on various deep neural networks. To address the limitations, the authors could explore alternative methods and provide a more comprehensive comparison with other optimization methods.",
        "gr_score_with": 0.6350974930362117,
        "gr_score_without": 0.525679758308157,
        "output_without": {
            "num_tokens_scored": 331,
            "num_green_tokens": 174,
            "green_fraction": 0.525679758308157,
            "z_score": 0.9344045068798316,
            "p_value": 0.17504763690913966
        },
        "output_with": {
            "num_tokens_scored": 359,
            "num_green_tokens": 228,
            "green_fraction": 0.6350974930362117,
            "z_score": 5.119464195501817,
            "p_value": 1.5320246620832762e-07
        }
    },
    {
        "title": "UNLEASHING LARGE-SCALE VIDEO GENERATIVE PRE-TRAINING FOR VISUAL ROBOT MANIPULATION",
        "abstract": "Generative pre-trained models have demonstrated remarkable effectiveness in language and vision domains by learning useful representations. In this paper, we extend the scope of this effectiveness by showing that visual robot manipulation can significantly benefit from large-scale video generative pre-training. We introduce GR-1, a GPT-style model designed for multi-task language-conditioned visual robot manipulation. GR-1 takes as inputs a language instruction, a sequence of observation images, and a sequence of robot states. It predicts robot actions as well as future images in an end-to-end manner. Thanks to a flexible design, GR-1 can be seamlessly finetuned on robot data after pre-trained on a large-scale video dataset. We perform extensive experiments on the challenging CALVIN benchmark and a real robot. On CALVIN benchmark, our method outperforms state-of-the-art baseline methods and improves the success rate from 88.9% to 94.9%. In the setting of zero-shot unseen scene generalization, GR-1 improves the success rate from 53.3% to 85.4%. In real robot experiments, GR-1 also outperforms baseline methods and shows strong potentials in generalization to unseen scenes and objects. We provide inaugural evidence that a unified GPT-style transformer, augmented with large-scale video generative pre-training, exhibits remarkable generalization to multi-task visual robot manipulation. Project page: https://GR1-Manipulation.github.io",
        "peer_review_without_watermark": "$$$\nPaper Summary:\n\nThe paper proposes a novel approach to visual robot manipulation by leveraging large-scale video generative pre-training. The authors introduce GR-1, a GPT-style transformer model that takes as inputs a language instruction, a sequence of observation images, and a sequence of robot states, and predicts robot actions and future images in an end-to-end manner. GR-1 is first pre-trained on language-conditioned video prediction with a large-scale video dataset and then finetuned on robot data. The authors demonstrate the effectiveness of GR-1 on the challenging CALVIN benchmark and a real robot, outperforming state-of-the-art baseline methods in various settings, including multi-task learning, zero-shot unseen scene generalization, small dataset, and zero-shot unseen language generalization.\n\nStrengths:\n\n* The paper presents a novel approach to visual robot manipulation by leveraging large-scale video generative pre-training, which is a promising direction for future research.\n* The authors demonstrate the effectiveness of GR-1 on the challenging CALVIN benchmark and a real robot, outperforming state-of-the-art baseline methods in various settings.\n* The paper provides a comprehensive evaluation of GR-1, including multi-task learning, zero-shot unseen scene generalization, small dataset, and zero-shot unseen language generalization.\n\nWeaknesses:\n\n* The paper relies heavily on pre-training on a large-scale video dataset, which may not be feasible for all applications or domains.\n* The authors do not provide a thorough analysis of the trade-offs between pre-training and finetuning, which may be important for practical applications.\n* The paper assumes access to a large-scale video dataset, which may not be available for all researchers or applications.\n\nSuggestions for Improvement:\n\n* Provide a more detailed analysis of the trade-offs between pre-training and finetuning, including the impact on performance, computational resources, and data requirements.\n* Explore alternative approaches to pre-training, such as using smaller datasets or different types of data, to make the method more widely applicable.\n* Provide more information about the computational resources required for pre-training and finetuning, including the number of parameters, training time, and hardware requirements.\n\nRecommendation:\n\nThe paper presents a novel and promising approach to visual robot manipulation by leveraging large-scale video generative pre-training. While there are some limitations and areas for improvement, the paper provides a comprehensive evaluation of GR-1 and demonstrates its effectiveness on challenging benchmarks. I recommend this paper for publication in a top-tier conference, with the understanding that the authors will address the suggested improvements in future work.\n\nRating: 8/10\n\nReviewers should be aware that the paper has a strong theoretical foundation and demonstrates promising results on challenging benchmarks. However, the paper relies heavily on pre-training on a large-scale video dataset, which may not be feasible for all applications or domains. The authors should provide a more detailed analysis of the trade-offs between pre-training and finetuning and explore alternative approaches to make the method more widely applicable.\n\n$$$",
        "peer_review_with_watermark": "$$$\n\n**Paper Summary**\n\nThis paper proposes a novel approach to enhance visual robot manipulation learning by leveraging large-scale video generative pre-training. The authors introduce GR-1, a GPT-style transformer that takes as inputs a language instruction, a sequence of observation images, and robot states, and outputs actions and future images in an end-to-end manner. GR-1 is first pre-trained on language-conditioned video prediction with a large-scale video dataset, and then seamlessly finetuned on robot data. The authors demonstrate the effectiveness of GR-1 on both CALVIN benchmark and real robot experiments, improving state-of-the-art methods in multi-task learning, zero-shot unseen scene generalization, small dataset, and zero-shot unseen language generalization.\n\n**Strengths**\n\n1. The paper proposes a novel approach to enhance visual robot manipulation learning by leveraging large-scale video generative pre-training, which is a significant contribution to the field.\n2. The authors provide extensive experiments on both CALVIN benchmark and real robot, demonstrating the effectiveness of GR-1 in various settings.\n3. The paper presents a flexible GPT-style transformer model, GR-1, which allows large-scale video generative pre-training and robot data finetuning with a unified model.\n4. The authors conduct thorough analysis on the video prediction performance of GR-1, which serves as a strong guide for action prediction.\n\n**Weaknesses**\n\n1. The paper assumes access to a large-scale video dataset, which may not be available or feasible for some researchers.\n2. The authors do not provide a clear explanation on how GR-1 generalizes to unseen scenes, objects, and language instructions, which is an important aspect of visual robot manipulation learning.\n3. The paper does not provide a thorough comparison with other pre-training methods, such as masked image modeling or contrastive learning, which are commonly used in computer vision tasks.\n4. The authors do not discuss the potential limitations of GR-1, such as its sensitivity to hyperparameters or its ability to handle complex scenes.\n\n**Suggestions for Improvement**\n\n1. Provide more details on how GR-1 generalizes to unseen scenes, objects, and language instructions, which is an essential aspect of visual robot manipulation learning.\n2. Conduct thorough comparisons with other pre-training methods, such as masked image modeling or contrastive learning, to demonstrate the superiority of GR-1.\n3. Discuss potential limitations of GR-1, such as its sensitivity to hyperparameters or its ability to handle complex scenes.\n4. Provide more qualitative analysis on the video prediction performance of GR-1, which is essential for understanding its potential applications.\n\n**Recommendation**\n\nThis paper presents a novel approach to enhance visual robot manipulation learning by leveraging large-scale video generative pre-training. While there are some weaknesses and limitations, the paper demonstrates the effectiveness of GR-1 in various settings, which makes it a valuable contribution to the field. Therefore, I recommend this paper for publication, with some revisions to address the weaknesses and limitations mentioned above.\n\n$$$",
        "gr_score_with": 0.5305555555555556,
        "gr_score_without": 0.44352617079889806,
        "output_without": {
            "num_tokens_scored": 363,
            "num_green_tokens": 161,
            "green_fraction": 0.44352617079889806,
            "z_score": -2.1519419124340597,
            "p_value": 0.9842990351712552
        },
        "output_with": {
            "num_tokens_scored": 360,
            "num_green_tokens": 191,
            "green_fraction": 0.5305555555555556,
            "z_score": 1.1595018087284057,
            "p_value": 0.12312584984626351
        }
    }
]