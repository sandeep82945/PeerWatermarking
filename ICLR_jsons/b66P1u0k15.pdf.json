{
    "abstractText": "Deep long-tailed recognition (DLTR) has attracted much attention due to its close touch with realistic scenarios. Recent advances have focused on re-balancing across various aspects, e.g., sampling strategy, loss re-weighting, logit adjustment, and input/parameter perturbation, etc. However, few studies have considered dynamic re-balancing to address intrinsic optimization conflicts, which are identified as prevalent and critical issues in this study. In this paper, we empirically establish the severity of the optimization conflict issue in the DLTR scenario, which leads to a degradation of representation learning. This observation serves as the motivation for pursuing Pareto optimal solutions. Unfortunately, a straightforward integration of multi-objective optimization (MOO) with DLTR methods is infeasible due to the disparity between multi-task learning (MTL) and DLTR. Therefore, we propose effective alternatives by decoupling MOO-based MTL from a temporal perspective rather than a structural one. Furthermore, we enhance the integration of MOO and DLTR by investigating the generalization and convergence problems. Specifically, we propose optimizing the variability collapse loss, guided by the derived MOObased DLTR generalization bound, to improve generalization. Additionally, we anticipate worst-case optimization to ensure convergence. Building upon the proposed MOO framework, we introduce a novel method called Pareto deep LOngTailed recognition (PLOT). Extensive evaluations demonstrate that our method not only generally improves mainstream pipelines, but also achieves an augmented version to realize state-of-the-art performance across multiple benchmarks. Code is available at https://github.com/zzpustc/PLOT.",
    "authors": [
        {
            "affiliations": [],
            "name": "Zhipeng Zhou"
        },
        {
            "affiliations": [],
            "name": "Liu Liu"
        },
        {
            "affiliations": [],
            "name": "Peilin Zhao"
        },
        {
            "affiliations": [],
            "name": "Wei Gong"
        }
    ],
    "id": "SP:891b902672bc9366bfd92643f0e7113b5ccde1f6",
    "references": [
        {
            "authors": [
                "REFERENCES Santiago A Cadena",
                "Marissa A Weis",
                "Leon A Gatys",
                "Matthias Bethge",
                "Alexander S Ecker"
            ],
            "title": "Diverse feature visualizations reveal invariances in early layers of deep neural networks",
            "venue": "In Proceedings of the European Conference on Computer Vision (ECCV),",
            "year": 2018
        },
        {
            "authors": [
                "Jiarui Cai",
                "Yizhou Wang",
                "Hung-Min Hsu",
                "Jenq-Neng Hwang",
                "Kelsey Magrane",
                "Craig S Rose"
            ],
            "title": "Luna: Localizing unfamiliarity near acquaintance for open-set long-tailed recognition",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "Jiequan Cui",
                "Zhisheng Zhong",
                "Shu Liu",
                "Bei Yu",
                "Jiaya Jia"
            ],
            "title": "Parametric contrastive learning",
            "venue": "In Proceedings of the IEEE/CVF international conference on computer vision,",
            "year": 2021
        },
        {
            "authors": [
                "Jiequan Cui",
                "Shu Liu",
                "Zhuotao Tian",
                "Zhisheng Zhong",
                "Jiaya Jia"
            ],
            "title": "Reslt: Residual learning for long-tailed recognition",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "Pierre Foret",
                "Ariel Kleiner",
                "Hossein Mobahi",
                "Behnam Neyshabur"
            ],
            "title": "Sharpness-aware minimization for efficiently improving generalization",
            "venue": "arXiv preprint arXiv:2010.01412,",
            "year": 2020
        },
        {
            "authors": [
                "Youngkyu Hong",
                "Seungju Han",
                "Kwanghee Choi",
                "Seokjun Seo",
                "Beomsu Kim",
                "Buru Chang"
            ],
            "title": "Disentangling label distribution for long-tailed visual recognition",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Jie Hu",
                "Liujuan Cao",
                "Tong Tong",
                "Qixiang Ye",
                "Shengchuan Zhang",
                "Ke Li",
                "Feiyue Huang",
                "Ling Shao",
                "Rongrong Ji"
            ],
            "title": "Architecture disentanglement for deep neural networks",
            "venue": "In Proceedings of the IEEE/CVF international conference on computer vision,",
            "year": 2021
        },
        {
            "authors": [
                "Martin Jaggi"
            ],
            "title": "Revisiting frank-wolfe: Projection-free sparse convex optimization",
            "venue": "In International conference on machine learning,",
            "year": 2013
        },
        {
            "authors": [
                "Bingyi Kang",
                "Saining Xie",
                "Marcus Rohrbach",
                "Zhicheng Yan",
                "Albert Gordo",
                "Jiashi Feng",
                "Yannis Kalantidis"
            ],
            "title": "Decoupling representation and classifier for long-tailed recognition",
            "year": 1910
        },
        {
            "authors": [
                "Mengke Li",
                "Yiu-ming Cheung",
                "Yang Lu"
            ],
            "title": "Long-tailed visual recognition via gaussian clouded logit adjustment",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Ziwei Liu",
                "Zhongqi Miao",
                "Xiaohang Zhan",
                "Jiayun Wang",
                "Boqing Gong",
                "Stella X Yu"
            ],
            "title": "Largescale long-tailed recognition in an open world",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Maithra Raghu",
                "Justin Gilmer",
                "Jason Yosinski",
                "Jascha Sohl-Dickstein"
            ],
            "title": "Svcca: Singular vector canonical correlation analysis for deep learning dynamics and interpretability",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Harsh Rangwani",
                "Sumukh K Aithal",
                "Mayank Mishra"
            ],
            "title": "Escaping saddle points for effective generalization on class-imbalanced data",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Jiawei Ren",
                "Cunjun Yu",
                "Xiao Ma",
                "Haiyu Zhao",
                "Shuai Yi"
            ],
            "title": "Balanced meta-softmax for long-tailed visual recognition",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "Laurens Van der Maaten",
                "Geoffrey Hinton"
            ],
            "title": "Visualizing data using t-sne",
            "venue": "Journal of machine learning research,",
            "year": 2008
        },
        {
            "authors": [
                "Jianfeng Wang",
                "Thomas Lukasiewicz",
                "Xiaolin Hu",
                "Jianfei Cai",
                "Zhenghua Xu"
            ],
            "title": "Rsg: A simple but effective module for learning imbalanced datasets",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Songyang Zhang",
                "Zeming Li",
                "Shipeng Yan",
                "Xuming He",
                "Jian Sun"
            ],
            "title": "Distribution alignment: A unified framework for long-tail visual recognition",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Zhisheng Zhong",
                "Jiequan Cui",
                "Shu Liu",
                "Jiaya Jia"
            ],
            "title": "Improving calibration for long-tailed recognition",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Boyan Zhou",
                "Quan Cui",
                "Xiu-Shen Wei",
                "Zhao-Min Chen"
            ],
            "title": "Bbn: Bilateral-branch network with cumulative learning for long-tailed visual recognition",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Jianggang Zhu",
                "Zheng Wang",
                "Jingjing Chen",
                "Yi-Ping Phoebe Chen",
                "Yu-Gang Jiang"
            ],
            "title": "Balanced contrastive learning for long-tailed visual recognition",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Roland S Zimmermann",
                "Judy Borowski",
                "Robert Geirhos",
                "Matthias Bethge",
                "Thomas Wallis",
                "Wieland Brendel"
            ],
            "title": "How well do feature visualizations support causal understanding of cnn activations",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Nowadays success of machine learning (ML) techniques are largely attributed to the growing scale of the training dataset, as well as the assumption of it being independent and identically distributed (i.i.d) with the test distribution. However, such an assumption can hardly hold in many realistic scenarios where training sets show an imbalanced or even long-tailed distribution, raising a critical challenge to the traditional ML community (Zhang et al., 2021b). To address this issue, recent researches devoted on deep long-tailed recognition (DLTR) has gained increasing interests, which strives to mitigate the bias toward certain categories and generalize well on a balanced test dataset.\nPlenty of approaches have been proposed to realize re-balancing from various aspects in DLTR (Zhang et al., 2021b): sampling strategy (Zang et al., 2021; Cai et al., 2021), loss function (Wang et al., 2013; Ren et al., 2020; Tan et al., 2020), logit adjustment (Cao et al., 2019; Li et al., 2022), data augmentation (Kim et al., 2020; Wang et al., 2021), input/parameter perturbation (Rangwani et al., 2022; Zhou et al., 2023), decoupling learning regime (Kang et al., 2019), and diverse experts (Wang et al., 2020b; Guo & Wang, 2021), etc. Usually, these works design fixed re-balancing strategies according to the prior of the class frequency to ensure all categories are generally equally optimized.\nSeveral very recent researches (Ma et al., 2023; Sinha & Ohashi, 2023; Tan et al., 2023) empirically indicate that a dynamic re-balancing strategy is required, and achieve it by designing a quantitative\n\u2020 Corresponding authors. Work done when Z. Zhou works as an intern in Tencent AI Lab.\nC0 C1 C2 C3 C4 C5 C6 C7 C8 C9\nC0 C1 C2 C3 C4 C5 C6 C7 C8 C9\n1.00\n0.75\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n(a) ERM C0 C1 C2 C3 C4 C5 C6 C7 C8 C9\nC0 C1 C2 C3 C4 C5 C6 C7 C8 C9\n1.00\n0.75\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n(b) LDAM-DRW C0 C1 C2 C3 C4 C5 C6 C7 C8 C9\nC0 C1 C2 C3 C4 C5 C6 C7 C8 C9\n1.00\n0.75\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n(c) Bal. Softmax C0 C1 C2 C3 C4 C5 C6 C7 C8 C9\nC0 C1 C2 C3 C4 C5 C6 C7 C8 C9\n1.00\n0.75\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n(d) M2m C0 C1 C2 C3 C4 C5 C6 C7 C8 C9\nC0 C1 C2 C3 C4 C5 C6 C7 C8 C9\n1.00\n0.75\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n(e) MiSLAS C0 C1 C2 C3 C4 C5 C6 C7 C8 C9\nC0 C1 C2 C3 C4 C5 C6 C7 C8 C9\n1.00\n0.75\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n(f) GCL\nFigure 1: Gradient conflicts among categories. \u2018Bal. Softmax\u2019 is short for Balanced Softmax. The horizontal and vertical coordinates are for each category and the heat map represents the gradient similarity.\n0 200 400 600 800 Training Steps\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nCo sin\ne Si\nm ila\nrit y\n0 4 9\n(a) ERM\n0 200 400 600 800 Training Steps\n0.0\n0.1\n0.2\n0.3\n0.4\nCo sin\ne Si\nm ila\nrit y\n0 4 9\n(b) LDAM-DRW\n0 100 200 300 400 500 600 700 800 Training Steps\n0.1\n0.2\n0.3\n0.4\nCo sin\ne Si\nm ila\nrit y\n0 4 9\n(c) Bal. Softmax\n0 200 400 600 800 Training Steps\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nCo sin\ne Si\nm ila\nrit y\n0 4 9\n(d) M2m\n0 100 200 300 400 500 600 700 800 Training Steps\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nCo sin\ne Si\nm ila\nrit y\n0 4 9\n(e) MiSLAS\n0 100 200 300 400 500 600 700 800 Training Steps\n0.0\n0.2\n0.4\n0.6\n0.8\nCo sin\ne Si\nm ila\nrit y\n0 4 9\n(f) GCL\nFigure 2: Gradient similarities during optimization. \u20180\u2019, \u20184\u2019, and \u20189\u2019 denote the corresponding categories in CIFAR10-LT, belonging to the \u2018head\u2019, \u2018medium\u2019, \u2018tail\u2019 classes. Please refer to the gradient norm examination in Section 4.5 of the Appendix.\nmeasurement of semantic scale imbalance and a meta module to learn from logit, etc. All these works take the instant rather than prior imbalance into consideration, enabling them to reach a competitive performance across various imbalanced scenarios. Nevertheless, a question is naturally raised:"
        },
        {
            "heading": "Is instant imbalance enough for designing a dynamic re-balancing strategy?",
            "text": "We then delve into the optimization of representative DLTR models and present related observations from the perspective of multi-objective optimization (MOO) in Fig. 1 and Fig. 2. As depicted, intrinsic optimization conflicts among categories are prevalent and might be aggravated due to the dominated trajectories of certain categories, which would lead to sub-optimal solutions for the remaining ones. Such an issue is rarely discussed for the above question and cannot be addressed by current dynamic strategies due to their lack of design nature (Refer to Section 3 for more details).\nTo fill this gap, we approach DLTR from a new angle, i.e., mitigate optimization conflicts via dynamic re-balancing, which is usually neglected in past works. We first identify the existing intrinsic gradient conflicts among categories in the optimization of prevailing DLTR methods and show their connection with the adopted fix re-balancing strategies. To prevent the representation from being overwhelmed by dominated categories\u2019 properties, we introduce MOO in MTL to mine the shared features among categories. Unfortunately, a na\u00efve combination is not applicable due to the structure difference between MTL and DLTR as illustrated in Fig. 6. Specifically, MOO-based MTL usually assumes that the model architecture is consist of a backbone network and several separate task-specific branches on top of the backbone network, and strives to learn task-shared features with backbone network via MOO algorithms. While DLTR targets only one task and owns only one branch. Hence a critical challenge appears:\nHow to engage MOO into DLTR?\nAs depicted in Fig. 6, we tackle this challenge with two key enablers: (1) Regarding a multiclassification task as multiple binary classification tasks, (2) transform the shared feature extraction and task-specific optimization from structural to temporal. Besides, by investigating several popular MOO approaches and choosing a stable one, we provide instructions on the integration of DLTR and MOO, propose variability collapse loss, and anticipate worst-case optimization to ensure generalization and convergence. It should be noted that our goal is to provide a distinct angle of re-balancing rather than design a new instant imbalance metric or MOO method, thus comparing our approach with these counterparts is beyond the scope of this paper.\nContributions: Our contributions can mainly be summarized as four-fold:\n\u2022 Through the lens of MOO, we empirically identify the phenomena of optimization conflicts among categories and establish its severity for representation learning in DLTR.\n\u2022 To mitigate the above issues, we endow prevailing re-balancing models with Pareto property via innovatively transforming the MOO-based MTL from structural to temporal, enabling the application of MOO algorithm in DLTR without model architecture modifications.\n\u2022 Moreover, two theoretical motivated operations, i.e., variability collapse loss, and anticipating worst-case optimization are proposed to further ensure the generalization and convergence of MOO-based DLTR.\n\u2022 Extensive evaluations have demonstrated that our method, PLOT, can significantly enhance the performance of mainstream DLTR methods, and achieve state-of-the-art results across multiple benchmarks compared to its advanced counterparts."
        },
        {
            "heading": "2 PRELIMINARIES",
            "text": "Problem Setup: Taking a K-way classification task for example, assume we are given a long-tailed training set S = (xi,yi|i = 1, . . . , n) for the DLTR problem. And the corresponding per-class sample numbers are {n1, n2, ..., nK}, n = \u2211K i ni. Without loss of generality, we assume ni < nj if i < j, and usually nK \u226b n1. Following the general DLTR setting, all models are finally evaluated on a balanced test dataset.\nPareto Concept: Our framework hinges on MOO-based MTL, which strives to achieve the Pareto optimum under the MTL situation. Formally, assume that there are N tasks at hand, and their differentiable loss functions are Li(\u03b8), i \u2208 [N ]. The weighted loss is L\u03c9 = \u2211N i=1 \u03c9iLi(\u03b8),\u03c9 \u2208 W , where \u03b8 is the parameter of the model and W is the probability simplex on [N ]. A point \u03b8\u2032 is said to Pareto dominate \u03b8, only if \u2200i,Li(\u03b8\u2032) \u2264 Li(\u03b8). And therefore the Pareto optimal is the situation that no \u03b8\u2032 can be found that holds \u2200i,Li(\u03b8\u2032) \u2264 Li(\u03b8) for the point \u03b8. All points that satisfy the above conditions are called Pareto sets, and their solutions are so-called Pareto fronts. Another concept called Pareto stationary, which requires min\u03c9\u2208W \u2225g\u03c9\u2225 = 0, where g\u03c9 is the weighted gradient. In this paper, since we regard the K-way classification task as K binary tasks, N is assigned as K. Definition 2.1 (Gradient Similarity). Denote \u03d5ij as the angle between two task gradients gi and gj , then we define the gradient similarity as cos\u03c6ij and the gradients as conflicting when cos\u03d5ij < 0. Definition 2.2 (Dominated Conflicting). For task gradients gi and gj , assume their average gradient as g0, and \u2225gi\u2225 < \u2225gj\u2225. Then we define the gradients as dominated conflicting when cos\u03d50i < 0."
        },
        {
            "heading": "3 MOTIVATION AND EMPIRICAL OBSERVATIONS",
            "text": "Intrinsic Property in Definition and Difference with MTL: As outlined in Section 2, a DLTR model is trained on an imbalanced dataset but is expected to generalize well to all categories, which aligns with the motivation of Pareto optimality, i.e., improving all individual tasks (categories). However, unlike MTL, which employs a distinct structure where the backbone and corresponding branches are responsible for shared feature extraction and task-specific optimization, respectively, the structures in DLTR are attributed to all categories. This difference impedes DLTR models from achieving Pareto properties. Therefore, in Section 4, we introduce the MOO-based DLTR pipeline. Optimization Conflicts under Imbalanced Scenarios: As depicted in Fig. 3, it is evident that\ngi\ngj\nconflictingnon-conflicting\ngi\ngj\ngmeangmean\n(a) Balanced Scenarios.\ngi\ngj\ndominated conflictingnon-conflicting\ngi\ngj\ngmeangmean\ngi\ngj\nconflicting\ngmean\n(b) Imbalanced Scenarios.\nFigure 3: Illustration of gradient conflict scenarios.\neach task exhibits improvement when optimized using the average gradient, i.e., gmean, in balanced\nTable 1: Benefits of MOO methods for mainstream DLTR models on CIFAR10-LT. We re-implement all models via their publicly released code, and all results are reported over 3 random seeds experiments. / indicates outperforms/underperforms their vanilla versions, while the early stop version is colored and the na\u00efve integration version is underlined.\nImb. cRT+Mixup LDAM-DRW\nVanilla w/ EPO w/ MGDA w/ CAGrad Vanilla w/ EPO w/ MGDA w/ CAGrad\n200 73.06 33.45 76.24 68.05 75.98 75.15 76.02 71.38 56.04 73.64 67.18 74.08 55.80 73.28 100 79.15 34.27 79.69 73.71 79.26 79.58 80.16 77.71 66.49 77.25 73.70 77.79 66.49 76.86 50 84.21 36.53 83.79 79.27 84.15 83.52 84.49 81.78 72.60 81.62 78.24 81.58 69.26 81.85\nImb. Balanced Softmax M2m\nVanilla w/ EPO w/ MGDA w/ CAGrad Vanilla w/ EPO w/ MGDA w/ CAGrad\n200 81.33 45.37 81.40 74.13 80.90 79.20 80.93 73.43 51.90 73.07 57.14 72.63 70.95 73.84 100 84.90 44.33 85.30 79.06 85.10 83.77 85.40 77.55 57.89 76.57 52.37 76.48 76.24 77.95 50 89.17 41.43 88.97 79.43 88.90 88.00 89.27 80.94 42.07 81.19 46.38 80.66 78.19 81.11\nImb. MiSLAS GCL\nVanilla w/ EPO w/ MGDA w/ CAGrad Vanilla w/ EPO w/ MGDA w/ CAGrad\n200 76.59 36.62 76.97 63.40 76.12 76.30 77.43 79.25 62.08 79.73 75.43 80.03 78.73 80.08 100 81.33 39.92 81.22 68.09 82.00 82.10 82.47 82.85 74.78 82.75 79.01 82.81 82.48 83.48 50 85.23 44.78 84.60 70.20 84.84 85.20 85.33 86.00 78.42 84.55 81.89 85.58 85.31 85.90\nscenarios where conflicts arise. However, in imbalanced scenarios, the utilization of gmean tends to favor the dominant tasks. This preference becomes particularly pronounced in extreme cases, where even when gmean and gj are in conflict (referred to as Dominated Conflicting in Definition 2.2), the optimization of task i leads to an enhancement in its performance at the expense of task j. In order to investigate the presence of optimization conflict issues in DLTR, we meticulously analyze several re-balancing regimes: (1) Cost-sensitive loss approaches, such as LDAM-DRW (Cao et al., 2019) and BalancedSoftmax (Ren et al., 2020); (2) Augmentation techniques, such as M2m (Kim et al., 2020); and (3) Decoupling methods, including cRT + Mixup (Kang et al., 2019), MiSLAS (Zhong et al., 2021), and GCL (Li et al., 2022). By computing the cosine similarities among gradients (referred to as Gradient Similarity in Definition 2.1) associated with different categories, we illustrate the conflict status of these methods in Fig. 1 1. As depicted, all the selected methods exhibit varying degrees of gradient conflicts, which persist in the early stages of training (refer to Section 4.2 in the Appendix). Furthermore, we examine the optimization preference of DLTR models in Fig. 2, revealing that certain categories dominate the overall optimization process. Additionally, we provide statistical analysis on the frequency of dominated conflicting instances in Fig. 5, establishing a roughly positive correlation between the frequency of dominated conflicting and the imbalance ratio.\n0 10 20 30 40 50 Eigenvalue\n10 6\n10 4\n10 2\n100\nDe ns\nity (L\nog S\nca le\n)\n(a) Class 0 in vanilla.\n0 200 400 600 Eigenvalue\n10 6\n10 4\n10 2\n100\nDe ns\nity (L\nog S\nca le\n)\n(b) Class 9 in vanilla.\n0 5 10 15 20 25 30 Eigenvalue\n10 6\n10 4\n10 2\n100\nDe ns\nity (L\nog S\nca le\n)\n(c) Class 0 in addressed one.\n0 100 200 300 400 Eigenvalue\n10 6\n10 4\n10 2\n100\nDe ns\nity (L\nog S\nca le\n)\n(d) Class 9 in addressed one.\nFigure 4: Hessian spectrum analysis of before and after addressing optimization conflict issue.\nThe Benefit of Addressing Optimization Conflicts: Here we provide a preview of the advantages achieved by addressing optimization conflicts through the utilization of our temporal design, as outlined in Section 4.1. We present the benefits from two perspectives: (1) representation analysis and (2) performance improvements. To gain insights into the impact of addressing the optimization conflict issue on representation learning, we conducted a Hessian spectrum analy-\n1Mainstream DLTR methods usually employ the SGD optimizer for implementation. Therefore, our analysis does not encompass the results obtained by utilizing alternative optimizers such as Adam.\n\u22ef\nShared Feature Extraction Shared Feature Extraction Task-specific OptimizationTask-specific Optimization\n\u22ef\nepoch = 1 epoch = E+1\u22ef\n(b) MOO-based DLTR(a) MOO-based MTL\nTask 1 Task 2 Task 3\nB a ckb o n e\nB a ckb o n e\nB a ckb o n e branch branch branch cla ssifie r\nclassifie r\nClass 1 Class 2 Class 3\nepoch = E\nFigure 6: Comparison of MOO-based MTL and MOO-based DLTR.\nsis (Rangwani et al., 2022) and visualized the results in Fig. 4. Our analysis reveals that addressing optimization conflicts results in flatter minima for each class, thereby mitigating the risk of being trapped at saddle points and facilitating the acquisition of more generalized representations. Furthermore, we demonstrate the performance benefits achieved by employing various MOO approaches in Table 1. The results effectively showcase the potential of integrating MOO with DLTR.\n0\n2\n4\n6\n8\n10\n12\n14\nERM LDAM Bal. Soft. M2m MiSLAS GCL\nD o\nm in\na te\nd C\no n\nfl ic\nt R\na ti\no \uff08\n%\uff09\n10 200\nFigure 5: Statistical of dominated conflicts.\nUrgency of Conflict-Averse Strategy: Currently, our MOO-based DLTR framework can primarily be classified as a specialized dynamic re-balancing strategy, formally\nformulated as L(x,y) = \u2211K k=1 \u03c9k\u00b7Bj \u00b7l(x k \u2217,y k \u2217 )\nB . Here B is the batch size, B\u2217 and \u03c9\u2217 represent the frequency and dynamic re-weighting factor of class \u2217, respectively, and l(xk\u2217,y k \u2217 ) is the average loss of class \u2217. While there are existing studies that explore the concept of dynamic rebalancing (Tan et al., 2023; Sinha & Ohashi, 2023; Ma et al., 2023), none of them address the issue of optimization conflicts from a comprehensive perspective. Consequently, the intrinsic optimization conflicts among categories cannot be effectively mitigated (See Section 4.4 in the Appendix). Fortunately, our work bridges this gap and offers a solution to this problem."
        },
        {
            "heading": "4 PARETO DEEP LONG-TAILED RECOGNITION",
            "text": "Building on the aforementioned analysis, we present a detailed design for integrating MOO into DLTR, which encompasses its adaptation from MTL to DLTR and an augmented version to ensure generalization and convergence. For complete proofs of the proposed theorems, please refer to Section 1 of the Appendix."
        },
        {
            "heading": "4.1 MOO: FROM MTL TO DLTR",
            "text": "As stated previously, a straightforward integration of MOO is not feasible for DLTR scenarios due to differences in task properties and architectures. Upon revisiting the function of each component in MOO-based MTL, they can be categorized into two aspects: (1) Shared feature extraction (SFE) and (2) Task-specific optimization (TSO). SFE aims to extract shared representations among distinct tasks, while TSO is responsible for the corresponding task performance with the independent branch. In this study, we approach the multi-classification task by treating it as multiple binary classification tasks. Each binary classification task is considered as a single objective in MOO, and we re-design SFE and TSO from a temporal perspective during the training stage, rather than a structural one. Specifically, we implement SFE in the first E epochs by applying MOO algorithms in DLTR models, but release it in the subsequent stages, as illustrated in Fig. 6. This approach can also be interpreted as an early stopping operation, inspired by previous research (Cadena et al., 2018; Hu et al., 2021) suggesting that the early layers of neural networks undergo fewer changes in the later stages of training. To validate the effectiveness of this design, we employ three representative MOO algorithms, i.e., MGDA (D\u00e9sid\u00e9ri, 2012), EPO (Mahapatra & Rajan, 2020), and CAGrad (Liu et al., 2021a), to\nequip them on the aforementioned six DLTR models, and the results are presented in Table. 1. The results demonstrate that our design enables MOO to enhance DLTR models in most cases, which also highlights the potential benefits of addressing the optimization conflict problem. Moreover, the performance would significantly deteriorate without an early stop (na\u00efve integration version), indicating class-specific feature degradation. It is also noteworthy that CAGrad exhibits a relatively stable performance across various baselines, thus we select it as the fundamental framework for further enhancement2. Remark (No Modifications on Model Architecture). Once again, it is important to emphasize that our approach does not involve any modifications to the model architecture. Rather, our method represents an effective learning paradigm for the application of MOO in DLTR."
        },
        {
            "heading": "4.2 CHALLENGES OF CAGRAD UNDER DLTR",
            "text": "Generalization Problem: Prior to delving into the additional technical designs of PLOT, it is necessary to establish the learning guarantees for the MOO-based DLTR framework. To this end, we introduce \u03c9k into the definition of Rademacher complexity (Cortes et al., 2020), which can be reformulated as follows:\nRS(G,\u03c9) = E \u03c3 [ sup h\u2208H K\u2211 k=1 \u03c9k 1 mk mk\u2211 i=1 \u03c3i \u00b7 l(h(xki ),yki ) ] (1)\nwhere G is associated to the hypothesis set as H : {G : (x,y) 7\u2192 l(h(x),y) : \u2200h \u2208 H}; \u03c3i is the independent uniformly distributed random variables taking values in {\u22121,+1}. From this definition, we have the following theorem: Theorem 4.1. (MOO-based DLTR Generalization Bound) If the loss function lk belonging to kth category is Mk-Lipschitz, and \u2200(x,y), (x\u2032,y\u2032) \u2208 X \u00d7 Y , \u2200h \u2208 H: \u2225[h(x),y]\u2212 [h(x\u2032),y\u2032]\u2225 \u2264 DH, assume MkDH is bounded by M , then for any \u03f5 > 0 and \u03b4 > 0, with probability at least 1\u2212 \u03b4, the following inequality holds for \u2200h \u2208 H and \u2200\u03c9 \u2208 W:\nL\u03c9(h) \u2264 L\u0302\u03c9(h) + 2RS(G,\u03c9) + K\u2211\nk=1\n\u03c9kM \u221a log 1\u03b4 2\nThe above derived generalization bound indicates that we should minimize L\u0302\u03c9(h) as well as constrain the intra-class loss variability M . With this theoretical insight, we design the following variability collapse loss:\nLvc = 1\nK K\u2211 k=1 Std(l\u0303(xk\u2217,y k \u2217)) (2)\nwhere Std(\u00b7) is the standard deviation function and l\u0303(xk\u2217,yk\u2217 ) is the loss set of the kth category in a mini-batch. It is worth noting that our proposed design shares a similar concept with a recent study (Liu et al., 2023), which aims to induce Neural Collapse in the DLTR setting. However, our approach is distinct in that we propose it from the perspective of MOO with theoretical analysis.\n0 10 20 300\n5\n10\n15\n20\n25\n30\n35\nLoss Contours around Trained Model\n0 3 6 9 12 15 18 21 24 27\n(a) Head 0 10 20 300\n5\n10\n15\n20\n25\n30\n35\nLoss Contours around Trained Model\n0 3 6 9 12 15 18 21 24 27\n(b) Tail\nFigure 7: Loss landscape of LDAM. Convergence Problem: On the other hand, although CAGrad exhibits stability, it may not always yield improvements, as evidenced by Table 1. Consequently, we delve deeper into CAGrad and demonstrate its limitations in the DLTR scenario. Based on the convergence analysis of CAGrad, we present the following theorem: Theorem 4.2. (Convergence of CAGrad in DLTR) With a fix step size \u03b1 and the assumption of H-Lipschitz on gradients, i.e., \u2225\u25bdLi(\u03b8)\u2212\u25bdLi(\u03b8\u2032)\u2225 \u2264 H \u2225\u03b8 \u2212 \u03b8\u2032\u2225 for i = 1, 2, ..., K. Denote d\u2217(\u03b8t) as the optimization direction of CAGrad at step t, then we have:\nL(\u03b8t+1)\u2212 L(\u03b8t) \u2264 \u2212 \u03b1\n2 (1\u2212 c2) \u2225g0(\u03b8t)\u22252 +\n\u03b1 2 (H\u03b1\u2212 1) \u2225d\u2217(\u03b8t)\u22252 ,\n2Nonetheless, the objective of this paper is to explore the potential of the MOO framework in addressing the DLTR problem and to propose an effective algorithm for enhancing mainstream DLTR methods. Therefore, we defer the development and integration of more advanced MOO algorithms to future research.\nwhere c \u2208 (0, 1) and g0(\u03b8t) is the corresponding average gradient of \u03b8t. The convergence of CAGrad is inherently influenced by the value of H , as observed in our experiments. This observation is further supported by a related study (Fernando et al., 2022), which introduces random noise to the optimization trajectory of CAGrad and demonstrates convergence failures. Additionally, it is widely acknowledged that achieving a small value of H for tail classes in DLTR models is often unattainable (Rangwani et al., 2022; Zhou et al., 2023). To visually illustrate this point, we provide a depiction of the LDAM-DRW loss landscape in Fig. 7 (for more visual illustrations, please refer to Section 7.2 in the Appendix). In this particular case, the loss landscape of the tail class exhibits a sharp minimum, indicating a large value of H and consequently posing challenges for achieving convergence when integrating CAGrad with DLTR models. To solve this problem, we constrain H by anticipating worst-case optimization (Foret et al., 2020), i.e., Sharpness aware minimization (SAM):\nmin \u03b8 max \u03f5(\u03b8) L(\u03b8 + \u03f5(\u03b8)),where \u2225\u03f5(\u03b8)\u22252 \u2264 \u03c1, (3)\nwhere the inner optimization can be approximated via the first order Taylor expansion, which results in the following solution (\u03c1 is a hyper-parameter):\n\u03f5\u0302(\u03b8) = \u03c1\u2207\u03b8L(\u03b8)/ ( \u2225\u2207\u03b8L(\u03b8)\u222522 ) 1 2\n(4)\nOverall Optimization Procedure: At the tth step of the SFE stage, we first compute the original loss L(\u03b8) for a mini-batch, and obtain the perturbative loss LSAM = L(\u03b8 + \u03f5\u0302(\u03b8)) according to Eqn. 4, as well as the variability collapse loss Lvc defined in Eqn. 2 based on perturbative loss. Thus we have the average gradient g0 and the class-specific gradient gi, i \u2208 {1, 2, ...,K} by back propagating Lmoo = LSAM + Lvc. Finally, the dynamic class weights \u03c9 = {\u03c91, \u03c92, ..., \u03c9K} is obtained by solving CAGrad (Liu et al., 2021a):\nmin \u03c9\u2208W\nF (\u03c9) := g\u22a4\u03c9g0 + \u221a \u03d5 \u2225g\u03c9\u2225 ,where \u03d5 = c2 \u2225g0\u22252 , (5)\nand update the model via: \u03b8t = \u03b8t\u22121 \u2212 \u03b1 ( g0 + \u03d51/2\n\u2225g\u03c9\u2225g\u03c9\n) , g\u03c9 = \u2211K i \u03c9i \u2217 gi. The overall pseudo\nalgorithm is summarized in the Section 6.2 of the Appendix."
        },
        {
            "heading": "4.3 IMPLEMENTATION DETAILS",
            "text": "We implement our code with Python 3.8 and PyTorch 1.4.0, while all experiments are carried out on Tesla V100 GPUs. We train each model with batch size of 64 (for CIFAR10-LT and CIFAR100-LT) / 128 (for Places-LT) / 256 (for ImageNet-LT and iNaturalist), SGD optimizer with momentum of 0.9.\n5 EVALUATION Table 2: Performance on CIFAR datasets.\nCIFAR10-LT CIFAR100-LT\nImb. 200 100 50 200 100 50\nLDAM-DRW 71.38 77.71 81.78 36.50 41.40 46.61 LDAM-DRW + PLOT 74.32 78.19 82.09 37.31 42.31 47.04\nM2m 73.43 77.55 80.94 35.81 40.77 45.73 M2m + PLOT 74.48 78.42 81.79 38.43 43.00 47.19\ncRT + Mixup 73.06 79.15 84.21 41.73 45.12 50.86 cRT + Mixup + PLOT 78.99 80.55 84.58 43.80 47.59 51.43\nLogit Adjustment - 78.01 - - 43.36 - Logit Adjustment + PLOT - 79.40 - - 44.19 -\nMiSLAS 76.59 81.33 85.23 42.97 47.37 51.42 MiSLAS + PLOT 77.73 81.88 85.70 44.28 47.91 52.66\nGCL 79.25 82.85 86.00 44.88 48.95 52.85 GCL + PLOT 80.08 83.35 85.90 45.61 49.50 53.05 Following the mainstream protocols, we conduct experiments on popular DLTR benchmarks: CIFAR10-/CIFAR100-LT, Places-LT (Liu et al., 2019), ImageNet-LT (Liu et al., 2019) and iNaturalist2018 (Van Horn et al., 2018). To show the versatility of PLOT, we equip it with the aforementioned popular re-balancing regimes under various imbalance scenarios. Moreover, PLOT achieves the state-of-the-art (SOTA) performance by augmenting the advanced baseline across large scale datasets. Micro benchmarks are elaborated to show the effectiveness of each components finally. For fair comparison, we exclude ensemble or pre-training models in our experiments.\n5.1 VERSATILITY VERIFICATION\nTable 3: Performance on large-scale Datasets.\nDataset Method Backbone Overall\nPlaces-LT\nCE ResNet-152 30.2 Decouple-\u03c4 -norm ResNet-152 37.9 Balanced Softmax ResNet-152 38.6 LADE ResNet-152 38.8 RSG ResNet-152 39.3 DisAlign ResNet-152 39.3 ResLT ResNet-152 39.8 GCL ResNet-152 40.6 cRT + Mixup ResNet-152 38.5 cRT + Mixup + PLOT ResNet-152 41.0 MiSLAS ResNet-152 40.2 MiSLAS + PLOT ResNet-152 40.5\nImageNet-LT\nCE ResNeXt-50 44.4 Decouple-\u03c4 -norm ResNet-50 46.7 Balanced Softmax ResNeXt-50 52.3 LADE ResNeXt-50 52.3 RSG ResNeXt-50 51.8 DisAlign ResNet-50 52.9 ResNeXt-50 53.4 ResLT ResNeXt-50 52.9 LDAM-DRW + SAM ResNet-50 53.1 GCL ResNet-50 54.9 cRT + Mixup ResNet-50 51.7 cRT + Mixup + PLOT ResNeXt-50 54.3 MiSLAS ResNet-50 52.7 MiSLAS + PLOT ResNet-50 53.5\niNat-2018\nCE ResNet-50 61.7 Decouple-\u03c4 -norm ResNet-50 65.6 Balanced Softmax ResNet-50 70.6 LADE ResNet-50 70.0 RSG ResNet-50 70.3 DisAlign ResNet-50 70.6 ResLT ResNet-50 70.2 LDAM-DRW + SAM ResNet-50 70.1 GCL ResNet-50 72.0 cRT + Mixup ResNet-50 69.5 cRT + Mixup + PLOT ResNet-50 71.3 MiSLAS ResNet-50 71.6 MiSLAS + PLOT ResNet-50 72.1\nGiven the inherent optimization conflicts in advanced DLTR models, PLOT can serve as a valuable augmentation technique. Our experimental results, presented in Table 2, demonstrate that PLOT brings improvements in most scenarios by addressing the problem from a new dimension that is orthogonal to current solutions. Notably, cRT + Mixup and LDAM-DRW exhibit the most conflict scenarios and gain the most from PLOT. In fact, cRT + Mixup even achieves competitive performance compared to the state-of-the-art under certain imbalance ratio settings, highlighting the efficacy of PLOT in addressing optimization conflict problems. We also observe a marginal effect of this augmentation, as GCL exhibits marginal improvement or even degradation, owing to the absence of significant optimization conflicts (see Fig. 1)."
        },
        {
            "heading": "5.2 COMPARISONS WITH SOTA",
            "text": "We further evaluate the effectiveness of PLOT on large-scale datasets, i.e., Places-LT, ImageNetLT, and iNaturalist, and compare it against mainstream methods in Table 3. Through augmenting two advanced baselines (cRT + Mixup and MiSLAS), PLOT achieves state-of-the-art performance. Specifically, our approach exhibits a substantial performance advantage over other DLTR models on Places-LT and iNaturalist, two recognized challenging benchmarks due to their high imbalance ratios.\n5.3 ABLATION STUDY\nTable 4: Ablation studies on CIFAR10-LT when imbalance ratio is set as 200.\ncRT + Mixup w/ temp w/ anti. w/ var. Acc.\n\" 73.06 \" \" 76.02 \" \" \" 77.79 \" \" \" \" 78.99\nOur system comprises multiple components, and we aim to demonstrate their individual effectiveness. To this end, we conduct ablation studies and present the relationship between each component and the final performance in Table 4. Our results indicate that the proposed operations, i.e., temporal design (temp), variability collapse loss (var.) and anticipate worst-case optimization (anti.), can significantly enhance the system\u2019s performance."
        },
        {
            "heading": "5.4 OPTIMIZATION TRAJECTORY ANALYSIS",
            "text": "Figure 8: Gradient similarity with the aggregated gradient before / after applying PLOT on LDAM-DRW.\n(a) Gradient similarities of LDAM-DRW.\n0 200 400 600 800 Training Steps\n0.0 0.2 0.4 0.6\nCo sin\ne Si\nm ila\nrit y 0\n4 9\n(b) Gradient similarities of PLOT.\n0 200 400 600 800 Training Steps\n0.0 0.2 0.4 0.6\nCo sin\ne Si\nm ila\nrit y 0\n4 9 We capture the optimization trajectories of different categories in LDAM-DRW + PLOT and present them in Fig. 8. In the left figure, the gradient similarity is computed between each category and the average gradient, while in the right figure, it is calculated between each category and the gradient aggregated by MOO. By comparison, the original LDAM-DRW approach exhibits a dominance of head classes in representation learning, resulting in a deterioration of shared feature extraction. In contrast, our augmented version with PLOT demonstrates relatively comparable and stable similarities among categories, indicating the potential for effective extraction of shared features across categories."
        },
        {
            "heading": "6 RELATED WORKS",
            "text": ""
        },
        {
            "heading": "6.1 DEEP LONG-TAILED RECOGNITION",
            "text": "Recent advancements in DLTR have been driven by three distinct design philosophies: (1) rebalancing strategies on various aspects, (2) ensemble learning, and (3) representation learning. In the first category, considerable efforts have been dedicated to re-sampling (Wang et al., 2019; Zang et al., 2021; Cai et al., 2021; Wei et al., 2021), re-weighting (Park et al., 2021; Kini et al., 2021), re-margining (Feng et al., 2021; Cao et al., 2019; Koltchinskii & Panchenko, 2002), logit adjustment (Menon et al., 2020; Zhang et al., 2021a), and information augmentation (Kim et al., 2020; Yang & Xu, 2020; Zang et al., 2021), etc. As anticipated, these approaches aim to manually re-balance the model by addressing sample number (through sampling and augmentation), cost sensitivity, prediction margin/logit, and other factors, thereby reducing the bias towards major classes. Ensemble learning-based approaches strive to leverage the expertise of multiple models. Generally, there are several methods for aggregating these models. BBN (Zhou et al., 2020) and SimCAL (Wang et al., 2020a) train experts using both long-tailed and uniformly distributed data and aggregate their outputs. On the other hand, ACE (Cai et al., 2021), ResLT (Cui et al., 2022), and BAGS (Li et al., 2020) train experts on different subsets of categories. SADE (Zhang et al., 2022) employs diverse experts, including long-tailed, uniform, and inverse long-tailed, and adaptively aggregates them using a self-supervised objective.\nRecent efforts in representation learning have emerged in decoupling and contrastive learning, which employ distinct regimes to obtain general representations for all categories. Decoupling-based methods (Kang et al., 2019; Zhong et al., 2021; Li et al., 2022) have shown that the representation learned via random sampling strategies is powerful enough, and additional effort devoted to the second stage, i.e., classifier adjustment, can help achieve advanced performance. A recent study (Liu et al., 2021b) has empirically found that contrastive learning-based methods are less sensitive to imbalance scenarios. Thus, these methods (Cui et al., 2021; Zhu et al., 2022) extract general representations via supervised contrastive learning and achieve competitive performance. Our work takes a new approach to DLTR by developing a gradient conflict-averse solution, which is almost orthogonal to current solutions and has been verified to be effective."
        },
        {
            "heading": "6.2 MOO-BASED MTL",
            "text": "Multi-task learning (MTL), particularly MOO-based MTL, has garnered significant attention in the machine learning community as a fundamental and practical task. MGDA-UB (Sener & Koltun, 2018) achieves Pareto optimality by optimizing a derived upper bound in large-scale MTL scenarios. PCGrad (Yu et al., 2020) mitigates conflict challenges by projecting gradients on the corresponding orthogonal directions. In contrast, CAGrad (Liu et al., 2021a) develops a provably convergent solution by optimizing the worst relative individual task and constraining it around the average solution. Additionally, EPO (Mahapatra & Rajan, 2020) proposes a preference-guided method that can search for Pareto optimality tailored to the prior. Our work represents the first attempt to integrate MOO into DLTR. We bridge the gap between MTL and DLTR and propose two improvements for further augmentation. Although evaluating PLOT under the MTL setting would be a satisfactory choice, it is beyond the scope of this paper and is left for future investigation."
        },
        {
            "heading": "7 CONCLUSION",
            "text": "This paper have presented a novel approach to bridging the gap between MTL and DLTR. Specifically, we proposed a re-design of the MOO paradigm from structural to temporal, with the aim of addressing the challenge of optimization conflicts. To further ensure the convergence and generalization of the MOO algorithm, we optimized the derived MOO-based DLTR generation bound and seek a flatter minima. Our experimental results demonstrated the benefits of injecting the Pareto property across multiple benchmarks. We hope that our findings provide valuable insights for researchers studying the integration of MOO and DLTR, which has been shown to hold great promise. Our future works lie in developing adaptive strategies to apply MOO algorithm more efficiently."
        },
        {
            "heading": "8 ACKNOWLEDGEMENTS",
            "text": "We thank anonymous reviewers for their valuable comments. This work was supported by the NSFC under Grants 61932017 and 61971390."
        },
        {
            "heading": "9 REPRODUCIBILITY STATEMENT",
            "text": "Further implementation details can be found in Section 2 of the Appendix. Specifically, the supplementary material includes the attached code, which serves as a reference and provides additional information. The provided code demo consists of a prototype trained on the CIFAR10-/100-LT datasets."
        },
        {
            "heading": "APPENDIX FOR: PARETO DEEP LONG-TAILED RECOGNITION: A CONFLICT-AVERSE SOLUTION",
            "text": "Anonymous authors Paper under double-blind review\nCONTENTS"
        },
        {
            "heading": "1 Theoretical proofs 2",
            "text": "1.1 Proof of Theorem 4.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n1.2 Proof of Theorem 4.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2"
        },
        {
            "heading": "2 Details of Implementations 3",
            "text": "2.1 DLTR Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n2.2 MOO-based MTL Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n2.3 Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5"
        },
        {
            "heading": "3 Open Long-Tailed Recognition Evaluation 5",
            "text": ""
        },
        {
            "heading": "4 Additional Experiment Results 5",
            "text": "4.1 Identify Optimization Conflict under Various Conditions . . . . . . . . . . . . . . . . . . . . 5\n4.2 Gradient Conflicts in the Early Training Stage . . . . . . . . . . . . . . . . . . . . . . . . . 6\n4.3 Frequency vs. Loss Value . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n4.4 Gradient Conflicts Status of Dynamic Re-weighting Approach . . . . . . . . . . . . . . . . . 7\n4.5 Gradient Norm Examination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n4.6 Gradient Similarity Examination after PLOT augmentation . . . . . . . . . . . . . . . . . . . 8\n4.7 Apply PLOT on Different Layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n4.8 Gradient Conflicts Status under the Balanced Setting . . . . . . . . . . . . . . . . . . . . . . 8"
        },
        {
            "heading": "5 Limitation 8",
            "text": ""
        },
        {
            "heading": "6 Computational Complexity and Scalability Analysis 9",
            "text": "6.1 Computational Complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n6.2 Scalability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9"
        },
        {
            "heading": "7 Visualizations 10",
            "text": "7.1 Feature Representation Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n7.2 Loss Landscape of DLTR models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n7.3 Embedding Visualization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n7.4 Canonical Correlation Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n8 Detailed Results on Mainstream Datasets 12"
        },
        {
            "heading": "1 THEORETICAL PROOFS",
            "text": ""
        },
        {
            "heading": "1.1 PROOF OF THEOREM 4.1",
            "text": "Theorem 1. (MOO-based DLTR Generalization Bound) If the loss function lk belonging to kth category is Mk-Lipschitz, and \u2200(x,y), (x\u2032,y\u2032) \u2208 X \u00d7 Y , \u2200h \u2208 H: \u2225[h(x),y]\u2212 [h(x\u2032),y\u2032]\u2225 \u2264 DH, assume MkDH is bounded by M , then for any \u03f5 > 0 and \u03b4 > 0, with probability at least 1\u2212 \u03b4, the following inequality holds for \u2200h \u2208H and \u2200\u03c9 \u2208W:\nL\u03c9(h) \u2264 L\u0302\u03c9(h) + 2RS(G,\u03c9) + K\u2211\nk=1\n\u03c9kM \u221a log 1\u03b4 2\nProof. \u2200\u03c9 \u2208W and sample S = {(x1,y1), ..., (xN ,yN )}, let \u03a6(S) = suph\u2208HL\u03c9(h)\u2212 L\u0302\u03c9(h). And assume S\u2032 is another sample set that contain only one point (x\u2032,y\u2032) different from S. Thus, we have\n\u03a6(S\u2032)\u2212 \u03a6(S) = suph\u2208H[L\u03c9(h)\u2212 L\u0302\u2032\u03c9(h)]\u2212 suph\u2208H[L\u03c9(h)\u2212 L\u0302\u03c9(h)] \u2264 suph\u2208H[L\u03c9(h)\u2212 L\u0302\u2032\u03c9(h)\u2212 L\u03c9(h) + L\u0302\u03c9(h)] = suph\u2208H[L\u0302\u03c9(h)\u2212 L\u0302\u2032\u03c9(h)]\n= suph\u2208H\n[ K\u2211\nk=1\n\u03c9k 1\nmk mk\u2211 i=1 l(x\u2032i,y \u2032 i)\u2212 K\u2211 k=1 \u03c9k 1 mk mk\u2211 i=1 l(xi,yi)\n]\n= suph\u2208H K\u2211 k=1 \u03c9k 1 mk [l(x\u2032i,y \u2032 i)\u2212 l(xi,yi)]\n= suph\u2208H K\u2211 k=1 \u03c9k 1 mk [l(x\u2032i,y \u2032 i)\u2212 l(xi,yi)]\n\u2264 suph\u2208H K\u2211\nk=1\n\u03c9k 1\nmk Mk \u2225[h(x),y]\u2212 [h(x\u2032),y\u2032]\u2225\n\u2264 suph\u2208H K\u2211\nk=1\n\u03c9k 1\nmk MkDH\n\u2264 suph\u2208H K\u2211\nk=1\n\u03c9kM\nAccording to McDiarmid\u2019s inequality, for any \u03b4 > 0 with probability at least 1\u2212 \u03b4 for any h \u2208H, we have:\nL\u03c9(h) \u2264 L\u0302\u03c9(h) + E [ suph\u2208HL\u03c9(h)\u2212 L\u0302\u03c9(h) ] + K\u2211 k=1 \u03c9kM \u221a log 1\u03b4 2\n\u2264 L\u0302\u03c9(h) + 2RS(G,\u03c9) + K\u2211\nk=1\n\u03c9kM \u221a log 1\u03b4 2"
        },
        {
            "heading": "1.2 PROOF OF THEOREM 4.2",
            "text": "Pseudo Code of CAGrad:\nAlgorithm 1: Training Paradigm of CAGrad Input: Initial model parameter \u03b8, differentiable loss functions are Li(\u03b8), i \u2208 [N ] , a constant c \u2208 [0, 1] and learning rate \u03b1 \u2208 R+. Output: Model trained with CAGrad while not converged do\nAt the tth optimization step, define g0 = 1K \u2211K\ni=1\u25bd\u03b8Li(\u03b8t\u22121) and \u03d5 = c2 \u2225g0\u2225. Solve\nmin \u03c9\u2208W\nF (\u03c9) := g\u22a4\u03c9g0 + \u221a \u03d5 \u2225g\u03c9\u2225 ,where \u03d5 = c2 \u2225g0\u22252\nUpdate \u03b8t = \u03b8t\u22121 \u2212 \u03b1 ( g0 + \u03d51/2\n\u2225g\u03c9\u2225g\u03c9\n) .\nTheorem 2. (Convergence of CAGrad in DLTR) With a fix step size \u03b1 and the assumption of HLipschitz on gradients, i.e., \u2225\u25bdLi(\u03b8)\u2212\u25bdLi(\u03b8\u2032)\u2225 \u2264 H \u2225\u03b8 \u2212 \u03b8\u2032\u2225 for i = 1, 2, ..., K. Denote d\u2217(\u03b8t) as the optimization direction of CAGrad at step t, then we have:\nL(\u03b8t+1)\u2212 L(\u03b8t) \u2264 \u2212 \u03b1\n2 (1\u2212 c2) \u2225g0(\u03b8t)\u22252 +\n\u03b1 2 (H\u03b1\u2212 1) \u2225d\u2217(\u03b8t)\u22252\nProof.\nL(\u03b8t+1)\u2212 L(\u03b8t) = L(\u03b8t \u2212 \u03b1d\u2217(\u03b8t))\u2212 L(\u03b8t)\n\u2264 \u2212\u03b1g0(\u03b8t)\u22a4d\u2217(\u03b8t)+ H\u03b12\n2 \u2225d\u2217(\u03b8t)\u22252\n\u2264 \u2212\u03b1 2\n( \u2225g0(\u03b8t)\u22252 + \u2225d\u2217(\u03b8t)\u22252 \u2212 \u2225g0(\u03b8t)\u2212 d\u2217(\u03b8t)\u22252 ) + H\u03b12\n2 \u2225d\u2217(\u03b8t)\u22252\n= \u2212\u03b1 2\n( \u2225g0(\u03b8t)\u22252 \u2212 \u2225g0(\u03b8t)\u2212 d\u2217(\u03b8t)\u22252 ) + H\u03b12\n2 \u2225d\u2217(\u03b8t)\u22252 \u2212\n\u03b1 2 \u2225d\u2217(\u03b8t)\u22252\n\u2264 \u2212\u03b1 2 (1\u2212 c2) \u2225g0(\u03b8t)\u22252 + \u03b1 2 (H\u03b1\u2212 1) \u2225d\u2217(\u03b8t)\u22252"
        },
        {
            "heading": "2 DETAILS OF IMPLEMENTATIONS",
            "text": "We conduct all experiments according to their publicly released code if applicable, please refer to these code for more details. Our early stop hyper-parameter E is selected from {10, 30, 50, 80}, while anticipating worst-case optimization hyper-parameter \u03c1 is searched over {1.0e-3, 1.0e-4, 1.0e-5}."
        },
        {
            "heading": "2.1 DLTR METHODS",
            "text": "LDAM-DRW. LDAM-DRW re-balances the model via logit adjustment. It enforces the theoretical derived margins that is class frequency-related to achieve cost-sensitive learning. Its publicly released code can be found at https://github.com/kaidic/LDAM-DRW.\nBalanced Softmax. Balanced Softmax is another cost-sensitive learning approach, which re-formulate softmax function in with the combination of link function and Bayesian inference. Its publicly released code can be found at https://github.com/jiawei-ren/ BalancedMetaSoftmax-Classification.\nM2m. M2m takes advantage of generating adversarial samples from major to minor classes and thus re-balance via augmentation. Its publicly released code can be found at https://github.com/ alinlab/M2m.\ncRT + Mixup. cRT is a milestone decoupling method, which re-trains the classifier with a balanced sampling strategy in the second stage. Despite the official implementation is available, it does not\ninclude a version that utilizes ResNet-32 and is evaluated on CIFAR10-/CIFAR100-LT, which are the mainstream protocols. Therefore, we have re-implemented the method and achieved similar performance to that reported in GCL. In our implementation, we have adopted the same learning rate decay strategy as GCL, which involves multiplying the learning rate by 0.1 after the 160th and 180th epochs.\nMiSLAS. MiSLAS follows the decoupling regime and adopts a class-frequency related label smoothing operation to achieve both the improvement of accuracy and calibration. Its publicly released code can be found at https://github.com/dvlab-research/MiSLAS.\nGCL. Likewise, GCL is also a pioneer two-stage method, which observes the problem of softmax saturation and proposes to tackle it by Gaussian perturbation of different class logits with varied amplitude. Its publicly released code can be found at https://github.com/Keke921/GCLLoss.\ndifficultyNet. As a dynamic re-balancing method, difficultyNet employs meta learning to learn the adjustment of class re-weighting from logits. Its publicly released code can be found at https: //github.com/hitachi-rd-cv/Difficulty_Net.\nBBN. BBN Zhou et al. (2020) takes care of both representation learning and classifier learning by equipping with a novel cumulative learning strategy on two branches. Its publicly released code can be found at https://github.com/megvii-research/BBN.\nPaCo. PaCo Cui et al. (2021) introduces a set of parametric class-wise learnable centers to rebalance from an optimization perspective, addressing the bias on high-frequency classes in supervised contrastive loss. Its publicly released code can be found at https://github.com/ dvlab-research/Parametric-Contrastive-Learning.\nBCL. BCL Zhu et al. (2022) proposes class-averaging and class-complement methods to help form a regular simplex for representation learning in supervised contrastive learning. Its publicly released code can be found at https://github.com/FlamieZhu/ Balanced-Contrastive-Learning."
        },
        {
            "heading": "2.2 MOO-BASED MTL METHODS",
            "text": "MGDA. MGDA is a classical baseline for MOO-based MTL. This approach is particularly appealing due to its ability to guarantee convergence to a Pareto stationary point under mild conditions. Building upon this foundation, MGDA-UP introduces an upper bound on the multi-objective loss, aiming to optimize it and thereby achieve the Pareto optimal solution. In practice, it suggests task weighting based on the Frank-Wolfe algorithm (Jaggi, 2013). We conduct evaluations with the re-implementation in the publicly released code of CAGrad.\nEPO. Different from the general MOO-based MTL, EPO provides a preference-specific MOO frameworks, which can effectively finds the expected Pareto front from the Pareto set by carefully controlling ascent to traverse the Pareto front in a principled manner. Generally, the re-balancing purpose also requires a preference for MOO. Its publicly released code can be found at https: //github.com/dbmptr/EPOSearch.\nCAGrad. CAGrad improves MGDA mainly by the ideas of worst-case optimization and convergence guarantee. It strikes a balance between Pareto optimality and globe convergence by regulating the combined gradients in proximity to the average gradient.:\nmax d\u2208Rm min \u03c9\u2208W\ng\u22a4\u03c9 d s.t. \u2225d\u2212 g0\u2225 \u2264 c \u2225g0\u2225 (1)\nwhere d represents the combined gradient, while g0 denotes the averaged gradient, and c is the hyperparameter. Its publicly released code can be found at https://github.com/Cranial-XIX/ CAGrad.\nWhy we choose CAGrad as the baseline? CAGrad is widely recognized as a robust baseline in MOO -based MTL. In contrast to MGDA, which consistently favors individuals with smaller gradient norms, CAGrad achieves a delicate balance between Pareto optimality and global convergence. This unique characteristic allows CAGrad to preserve the Pareto property while maximizing individual progress. Conversely, EPO necessitates manual tuning of the preference hyper-parameter, which plays a crucial role in its performance but proves challenging to optimize in practical scenarios, particularly\nfor classification tasks with a large number of categories. In comparison, CAGrad requires less effort in terms of hyper-parameter tuning."
        },
        {
            "heading": "2.3 DATASETS",
            "text": "CIFAR10-/CIFAR100-LT. CIFAR10-/CIFAR100-LT is a subset of CIFAR10/CIFAR100, which is formed by sampling from the original 50,000 training images to create a long-tailed distribution. In our evaluation, we set the imbalance ratio \u03b2 = nmaxnmin to {200, 100, 50}, where nmax and nmin represent the sample numbers of the most and least frequent classes, respectively.\nPlaces-LT & ImageNet-LT. Places-LT and ImageNet-LT are long-tailed variants of Places-365 and ImageNet, respectively. Places-LT comprises a total of 62.5K training images distributed across 365 classes, resulting in an imbalance ratio of 996. Similarly, ImageNet-LT consists of 115.8K training images spanning 1000 classes, with an imbalance ratio of 256.\niNaturalist 2018. iNaturalist 2018 is a naturally occurring long-tailed classification dataset that comprises 437.5K training images distributed across 8142 categories, resulting in an imbalance ratio of 512. In our evaluations, we have followed the official split."
        },
        {
            "heading": "3 OPEN LONG-TAILED RECOGNITION EVALUATION",
            "text": "To further demonstrate the robustness of the learned representations by PLOT, we conduct an evaluation known as open long-tailed recognition (OLTR) (Liu et al., 2019) on Places-LT and ImageNet-LT datasets. The results are presented in Table 1. Based on the comparison of F-measures, our method achieves state-of-the-art performance in OLTR. It is worth noting that we employ a cosine similarity measurement between incoming representations and prototypes proposed by (Liu et al., 2019), which allows us to compete favorably against bells and whistles OLTR methods (e.g., LUNA (Cai et al., 2022)). This highlights the superiority of the mechanism proposed by PLOT for representation learning."
        },
        {
            "heading": "4 ADDITIONAL EXPERIMENT RESULTS",
            "text": ""
        },
        {
            "heading": "4.1 IDENTIFY OPTIMIZATION CONFLICT UNDER VARIOUS CONDITIONS",
            "text": "Generally, the optimization objectives of samples from different classes tend to exhibit some conflicts, as they need to learn class-specific features in addition to the shared features across classes. In the case of a balanced training set, this conflict does not significantly impact the simultaneous optimization of individual classes. However, in an imbalanced scenario, the model optimization becomes dominated by the majority class, exacerbating this conflict issue. Consequently, the performance of the minority class is compromised in favor of optimizing the majority class. This outcome hinders the effective learning of category-sharing features. Importantly, this problem is intuitively independent of hyperparameters, optimizers, and other related factors.\nTo validate the aforementioned hypothesis, we have conducted an extensive investigation into the gradient conflict and dominated categories issues by thoroughly examining LDAM-DRW across various experimental settings. These settings encompassed diverse mini-batch sizes, learning rates, and optimizers. The meticulous presentation of our findings is shown in Fig. 1 and Fig. 2. Notably, Fig. 1 provides a snapshot of the instantaneous gradient conflict status at an early stage, while Fig. 2 illustrates the continuous gradient similarity status throughout the optimization process. It is important to emphasize that Figs. 2 (a) and (b) are presented on a larger scale in their axes, resulting in a less apparent discrepancy. However, it should be noted that these subfigures do not differ significantly from the other subfigures when placed on the same scale.\nC0 C1 C2 C3 C4 C5 C6 C7 C8 C9\nC0 C1 C2 C3 C4 C5 C6 C7 C8 C9\n1.00\n0.75\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n(a) SGD-128-0.1 C0 C1 C2 C3 C4 C5 C6 C7 C8 C9\nC0 C1 C2 C3 C4 C5 C6 C7 C8 C9\n1.00\n0.75\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n(b) Adam-128-0.1 C0 C1 C2 C3 C4 C5 C6 C7 C8 C9\nC0 C1 C2 C3 C4 C5 C6 C7 C8 C9\n1.00\n0.75\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n(c) SGD-256-0.1 C0 C1 C2 C3 C4 C5 C6 C7 C8 C9\nC0 C1 C2 C3 C4 C5 C6 C7 C8 C9\n1.00\n0.75\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n(d) SGD-512-0.1 C0 C1 C2 C3 C4 C5 C6 C7 C8 C9\nC0 C1 C2 C3 C4 C5 C6 C7 C8 C9\n1.00\n0.75\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n(e) SGD-128-0.01 C0 C1 C2 C3 C4 C5 C6 C7 C8 C9\nC0 C1 C2 C3 C4 C5 C6 C7 C8 C9\n1.00\n0.75\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n(f) SGD-128-1e-3\n(a) Adam-128-0.1\n(b) Adam-128-1e3\n(c) SGD-256-0.1\n(d) SGD-512-0.1\n(e) SGD-128-0.01\n(f) SGD-128-1e-3\nFigure 2: Continual gradient similarity status of LDAM-DRW under various conditions. Each sub-figure is named as (Optimizer)-(Batch-Size)-(Learning-Rate).\nAs anticipated, we have observed the presence of the gradient conflict and dominated categories issues in all tested scenarios. These findings significantly contribute to validating the universality of the gradient conflict issue. If deemed applicable, we are fully committed to providing additional evidence and conducting further analysis in the updated version to reinforce the robustness of our findings.\nC0 C1 C2 C3 C4 C5 C6 C7 C8 C9\nC0 C1 C2 C3 C4 C5 C6 C7 C8 C9"
        },
        {
            "heading": "4.2 GRADIENT CONFLICTS IN THE EARLY TRAINING STAGE",
            "text": "Here we further present the existing of optimization conflicts at different steps in Fig. 3. As depicted, such conflicts remain for a long time in the early stage."
        },
        {
            "heading": "4.3 FREQUENCY VS. LOSS VALUE",
            "text": "In Fig. 4, we present our observations of class-wise weighted loss, denoted as Bk\u00b7l(x k \u2217,y k \u2217 )\nB , to compare the norms ofB\u2217/B and l(xk\u2217,y k \u2217 ). Our results indicate that BalancedSoftmax, which functions as a re-balancing method by adjusting the loss function, is still dominated by class frequency, i.e., B\u2217/B. Conversely, LDAM-DRW exhibits a balanced weighted loss for both head and tail classes, thereby demonstrating the effectiveness of its re-balancing strategy."
        },
        {
            "heading": "4.4 GRADIENT CONFLICTS STATUS OF DYNAMIC RE-WEIGHTING APPROACH",
            "text": "As a form of dynamic re-weighting method, we further investigate the optimization conflicts associated with other dynamic re-weighting approaches to showcase our distinct research perspective. In this regard, we employ difficultyNet as the baseline for conducting a verification experiment, and the results are depicted in Fig. 5. It is evident that difficultyNet fails to address optimization conflicts during its early training stage, primarily due to its inherent lack of design nature."
        },
        {
            "heading": "4.5 GRADIENT NORM EXAMINATION",
            "text": "In this section, we expand our analysis by conducting a thorough investigation into the phenomenon of gradient norm domination within mainstream DLTR approaches. To quantify this domination, we calculate the mean gradient of the corresponding category and present the results of our examination in Figure 6(a-f). As depicted, all the examined approaches demonstrate a consistent pattern, mirroring the tendency observed in Figure 2 of the main text. Specifically, we observe that the tail class is extremely under-optimized, indicating the explicit dominance of specific categories during the optimization process. These compelling findings provide strong support for the motivation underlying our proposed method, which aims to effectively mitigate such domination and its associated adverse effects. For comparative purposes, we also provide the PLOT-augmented gradient norm examinations in Figure 6(g-l). As expected, the results reveal that no individuals (categories) exhibit explicit domination during the early stage of representation learning.\n0 200 400 600 800 Training Steps\n0 15 30 45 60 No rm R at io\n0 4 9\n(a) ERM\n0 200 400 600 800 Training Steps\n0 15 30 45 60 No rm\nR at\nio\n0 4 9\n(b) LDAM-DRW\n0 200 400 600 800 Training Steps\n0\n40\n80\n120\n160\nNo rm\nR at\nio\n0 4 9\n(c) Bal. Softmax\n0 200 400 600 800 Training Steps\n0 15 30 45 60 No rm\nR at\nio\n0 4 9\n(d) M2m\n0 200 400 600 800 Training Steps\n0\n15\n30\n45\n60\nNo rm\nR at\nio\n0 4 9\n(e) MiSLAS\n0 200 400 600 800 Training Steps\n0 15 30 45 60 No rm R at io\n0 4 9\n(f) GCL\n0.00 0.25 0.50 0.75 1.00 No rm R at io\n0 4 9\n0.0 2.5 5.0 7.5\n10.0 No rm\nR at\nio\n0 4 9\n0.0\n2.5\n5.0\n7.5\n10.0\nNo rm\nR at\nio\n0 4 9\n0.0\n2.5\n5.0\n7.5\n10.0\nNo rm\nR at\nio\n0 4 9\n0.0 2.5 5.0 7.5\n10.0\nNo rm\nR at\nio\n0 4 9\n0.0\n2.5\n5.0\n7.5\n10.0\nNo rm\nR at\nio\n0 4 9"
        },
        {
            "heading": "4.6 GRADIENT SIMILARITY EXAMINATION AFTER PLOT AUGMENTATION",
            "text": "To substantiate the effectiveness of the PLOT, which facilitates simultaneous progress for all individuals, we compute the cosine similarities between individuals and the gradient derived from MOO. These cosine similarities are then compared with the corresponding vanilla results presented in Figure 2 of the main text. The comparative results are depicted in Figure 7. As observed, the DLTR methods augmented with PLOT exhibit a more balanced cosine similarity, indicating that all individuals achieve more equitable progress and improvements.\n4.7 APPLY PLOT ON DIFFERENT LAYERS"
        },
        {
            "heading": "4.8 GRADIENT CONFLICTS STATUS UNDER THE BALANCED SETTING",
            "text": "We investigate the gradient conflict and similarity status in a balanced setting to motivate the integration of MOO and DLTR. To this end, we train ERM 1 with the full (roughly balanced) CIFAR10 dataset for 200 epochs and achieve a final accuracy of 92.84%. We record the class-wise gradient and compute their similarities. As shown in Fig 9, gradients among categories also exhibit conflict cases but play a roughly equal role during optimization 2.\n5 LIMITATION Figure 9: Gradient conflicts and similar-ity of ERM.\n(a) Gradient conflicts.\nC0 C1 C2 C3 C4 C5 C6 C7 C8 C9\nC0 C1 C2 C3 C4 C5 C6 C7 C8 C9\n1.00\n0.75\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n(b) Gradient sim.\n0 100 200 300 400 500 600 700 800 Training Steps\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\nCo sin\ne Si\nm ila\nrit y\n0 4 9 The limitations of PLOT can be attributed to two main factors. Firstly, the approach incurs additional computational overhead due to multiple gradient backpropagation and MOO. To address this issue, we propose applying PLOT to select layers rather than the entire model, which serves as an efficient alternative. Additionally, we randomly sample a small set of categories to participate in MOO for largescale datasets. Secondly, the early stopping mechanism is currently controlled by a hyper-parameter, which introduces additional tuning complexities. To simplify this process, we select the hyper-parameter from a fixed set of values.\n1We utilize WideResNets (Foret et al., 2020) as the backbone network without ShakeShake regularization or additional augmentations. Therefore, our reported result is slightly lower than the generally reported accuracy. Notably, our focus is on observing the class-wise gradient status rather than realizing a re-implementation.\n2While this conclusion is straightforward, it is worth comparing with DLTR results."
        },
        {
            "heading": "6 COMPUTATIONAL COMPLEXITY AND SCALABILITY ANALYSIS",
            "text": ""
        },
        {
            "heading": "6.1 COMPUTATIONAL COMPLEXITY",
            "text": "As noted in the Limitations section, our method is more complex than its baselines. However, we would like to emphasize that our approach only applies MOO to a subset of the model parameters in a mini-batch, which contains fewer classes. This results in a lower time cost than expected. Additionally, we only apply MOO in the early stage of DLTR training for shared feature extraction. For large-scale datasets such as ImageNet-LT, we further adopt a class sampling strategy to reduce the computation cost. We believe that these optimizations help to mitigate the complexity of our approach while maintaining its effectiveness in addressing the long-tailed recognition problem. Here we provide a simple comparison of the time cost of running on a Tesla T4 GPU:"
        },
        {
            "heading": "6.2 SCALABILITY",
            "text": "As previous research has indicated (Cadena et al., 2018; Hu et al., 2021; Zimmermann et al., 2021; Liu et al., 2019), the parameters of backbone layers tend to be more stable in the later stages of training. Therefore, our temporal-style MOO learning paradigm is designed to address the gradient conflict problem that occurs during the early stages of representation learning. This approach enables compatibility with mainstream DLTR models. Here, we provide examples of how our approach can be integrated with Decoupling using pseudo code, as shown in Algorithm 2 (Please refer Eqns. 2, 3, 4 in the maintext):\nAlgorithm 2: Representation Training Paradigm of Decoupling + PLOT\nInput: Training Dataset S \u223c ps(x,y) = ps(x|y)ps(y) Output: Model trained with PLOT Stage SFE: Initialize \u03b8 randomly while epoch \u2264 E do\nforeach batch Bi in S do Compute empirical loss LS with Bi and obtain its gradient gS Perturb \u03b8 with gS according to Eqn. 3 and Eqn. 4 Compute the perturbative loss LSAM and the variability collapse loss Lvc according to\nEqn. 2. Estimate the class-specific gradient set G = {g1, g2, ..., gk} with respect to Lmoo = LSAM + Lvc\nUpdate \u03b8 by solving Eqn. 6: \u03b8 \u2190 \u03b8 \u2212 \u03b1 ( g0 + \u03d51/2\n\u2225g\u03c9\u2225g\u03c9\n) .\nStage TSO: while epoch > E do\nforeach batch Bi in S do Computing empirical loss LS with Bi Update \u03b8: \u03b8 \u2190 \u03b8 \u2212\u25bd\u03b8LS(\u03b8)"
        },
        {
            "heading": "7 VISUALIZATIONS",
            "text": ""
        },
        {
            "heading": "7.1 FEATURE REPRESENTATION ANALYSIS",
            "text": "More class-specific Hessian spectral analysis 3 are provided in Figs. 10 11, which align with the conclusion in the main text, i.e., PLOT leads to a flatter minima for each class, thereby reducing the risk of getting stuck at saddle points."
        },
        {
            "heading": "7.2 LOSS LANDSCAPE OF DLTR MODELS",
            "text": "To further illustrate the unattainable small value of H in the DLTR models, we have included additional loss landscape visualizations in Fig. 12. These visualizations reveal that the tail classes of the models exhibit sharp minima, with the exception of M2m. Additionally, we observe that PLOT displays flat minima in both head and tail classes.\n3https://github.com/val-iisc/Saddle-LongTail"
        },
        {
            "heading": "7.3 EMBEDDING VISUALIZATION",
            "text": "In addition, we present visualizations of the extracted embeddings from both the vanilla and PLOTaugmented approaches by projecting them into a 2D plane using t-SNE Van der Maaten & Hinton (2008). The corresponding visualizations can be found in Figure 13 (a)(b). As anticipated, the tail classes of the cRT + Mixup + PLOT approach exhibit increased separability compared to the vanilla approach. This observation suggests that the incorporation of PLOT enhances the representation of all categories, as intended."
        },
        {
            "heading": "7.4 CANONICAL CORRELATION ANALYSIS",
            "text": "To further investigate the shared feature representation across categories in the early stage, we examine the Canonical Correlation Analysis (CCA) scores (Raghu et al., 2017) of representations between head and tail categories in CIFAR10-LT, as learned by both the standard and PLOT enpowered LDAM-DRW. As illustrated in Fig. 13 (c), the PLOT augmented version exhibits a greater degree of similarity among categories in comparison to the conventional model, thereby substantiating the efficacy of our conflict-averse solution."
        },
        {
            "heading": "8 DETAILED RESULTS ON MAINSTREAM DATASETS",
            "text": "In order to demonstrate the generalization of PLOT and its impact on different subsets, we provide more detailed results in this section. Specifically, we compare PLOT with two state-of-the-art DLTR approaches, namely BBN and PaCo, by augmenting them with PLOT. The consistent improvements observed in Table 4 indicate that PLOT can effectively enhance various types of DLTR approaches. Furthermore, we present detailed results on large-scale datasets in Table 3, which empirically illustrate that PLOT successfully augments medium and tail classes without significantly compromising the performance of major classes."
        }
    ],
    "title": "PARETO DEEP LONG-TAILED RECOGNITION: A CONFLICT-AVERSE SOLUTION"
}