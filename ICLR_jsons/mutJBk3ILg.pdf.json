{
    "abstractText": "Supervised learning methods have been found to exhibit inductive biases favoring simpler features. When such features are spuriously correlated with the label, this can result in suboptimal performance on minority subgroups. Despite the growing popularity of methods which learn from unlabeled data, the extent to which these representations rely on spurious features for prediction is unclear. In this work, we explore the impact of spurious features on Self-Supervised Learning (SSL) for visual representation learning. We first empirically show that commonly used augmentations in SSL can cause undesired invariances in the image space, and illustrate this with a simple example. We further show that classical approaches in combating spurious correlations, such as dataset re-sampling during SSL, do not consistently lead to invariant representations. Motivated by these findings, we propose LATETVG to remove spurious information from these representations during pretraining, by regularizing later layers of the encoder via pruning. We find that our method produces representations which outperform the baselines on several benchmarks, without the need for group or label information during SSL.",
    "authors": [],
    "id": "SP:e92332bd96ae1c8bb1a958dbe0b2ccb949fd6c6d",
    "references": [
        {
            "authors": [
                "Samira Abnar",
                "Mostafa Dehghani",
                "Behnam Neyshabur",
                "Hanie Sedghi"
            ],
            "title": "Exploring the limits of large scale pre-training",
            "venue": "arXiv preprint arXiv:2110.02095,",
            "year": 2021
        },
        {
            "authors": [
                "Sandhini Agarwal",
                "Gretchen Krueger",
                "Jack Clark",
                "Alec Radford",
                "Jong Wook Kim",
                "Miles Brundage"
            ],
            "title": "Evaluating clip: towards characterization of broader capabilities and downstream implications",
            "venue": "arXiv preprint arXiv:2108.02818,",
            "year": 2021
        },
        {
            "authors": [
                "Martin Arjovsky",
                "L\u00e9on Bottou",
                "Ishaan Gulrajani",
                "David Lopez-Paz"
            ],
            "title": "Invariant risk minimization",
            "venue": "arXiv preprint arXiv:1907.02893,",
            "year": 2019
        },
        {
            "authors": [
                "Florian Bordes",
                "Randall Balestriero",
                "Quentin Garrido",
                "Adrien Bardes",
                "Pascal Vincent"
            ],
            "title": "Guillotine regularization: Why removing layers is needed to improve generalization in self-supervised learning",
            "venue": "Transactions on Machine Learning Research,",
            "year": 2023
        },
        {
            "authors": [
                "Cristian S Calude",
                "Giuseppe Longo"
            ],
            "title": "The deluge of spurious correlations in big data",
            "venue": "Foundations of science,",
            "year": 2017
        },
        {
            "authors": [
                "Mathilde Caron",
                "Ishan Misra",
                "Julien Mairal",
                "Priya Goyal",
                "Piotr Bojanowski",
                "Armand Joulin"
            ],
            "title": "Unsupervised learning of visual features by contrasting cluster assignments",
            "venue": "arXiv preprint arXiv:2006.09882,",
            "year": 2020
        },
        {
            "authors": [
                "Mathilde Caron",
                "Hugo Touvron",
                "Ishan Misra",
                "Herv\u00e9 J\u00e9gou",
                "Julien Mairal",
                "Piotr Bojanowski",
                "Armand Joulin"
            ],
            "title": "Emerging properties in self-supervised vision transformers",
            "venue": "In Proceedings of the IEEE/CVF international conference on computer vision,",
            "year": 2021
        },
        {
            "authors": [
                "Ting Chen",
                "Simon Kornblith",
                "Mohammad Norouzi",
                "Geoffrey Hinton"
            ],
            "title": "A simple framework for contrastive learning of visual representations",
            "venue": "In International conference on machine learning,",
            "year": 2020
        },
        {
            "authors": [
                "Ting Chen",
                "Calvin Luo",
                "Lala Li"
            ],
            "title": "Intriguing properties of contrastive losses",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Xinlei Chen",
                "Kaiming He"
            ],
            "title": "Exploring Simple Siamese Representation Learning",
            "venue": "arXiv e-prints, art",
            "year": 2020
        },
        {
            "authors": [
                "Xinlei Chen",
                "Haoqi Fan",
                "Ross Girshick",
                "Kaiming He"
            ],
            "title": "Improved baselines with momentum contrastive learning",
            "venue": "arXiv preprint arXiv:2003.04297,",
            "year": 2020
        },
        {
            "authors": [
                "Elliot Creager",
                "J\u00f6rn-Henrik Jacobsen",
                "Richard Zemel"
            ],
            "title": "Environment inference for invariant learning",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Alex J DeGrave",
                "Joseph D Janizek",
                "Su-In Lee"
            ],
            "title": "Ai for radiographic covid-19 detection selects shortcuts over signal",
            "venue": "Nature Machine Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "Jia Deng",
                "Wei Dong",
                "Richard Socher",
                "Li-Jia Li",
                "Kai Li",
                "Li Fei-Fei"
            ],
            "title": "Imagenet: A large-scale hierarchical image database",
            "venue": "IEEE conference on computer vision and pattern recognition,",
            "year": 2009
        },
        {
            "authors": [
                "Carl Doersch",
                "Abhinav Gupta",
                "Alexei A Efros"
            ],
            "title": "Unsupervised visual representation learning by context prediction",
            "venue": "In Proceedings of the IEEE international conference on computer vision,",
            "year": 2015
        },
        {
            "authors": [
                "John C Duchi",
                "Tatsunori Hashimoto",
                "Hongseok Namkoong"
            ],
            "title": "Distributionally robust losses against mixture covariate shifts",
            "venue": "Under review,",
            "year": 2019
        },
        {
            "authors": [
                "Jianqing Fan",
                "Fang Han",
                "Han Liu"
            ],
            "title": "Challenges of big data analysis",
            "venue": "National science review,",
            "year": 2014
        },
        {
            "authors": [
                "Irena Gao",
                "Shiori Sagawa",
                "Pang Wei Koh",
                "Tatsunori Hashimoto",
                "Percy Liang"
            ],
            "title": "Out-of-domain robustness via targeted augmentations",
            "venue": "arXiv preprint arXiv:2302.11861,",
            "year": 2023
        },
        {
            "authors": [
                "Robert Geirhos",
                "Patricia Rubisch",
                "Claudio Michaelis",
                "Matthias Bethge",
                "Felix A Wichmann",
                "Wieland Brendel"
            ],
            "title": "Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness",
            "venue": "arXiv preprint arXiv:1811.12231,",
            "year": 2018
        },
        {
            "authors": [
                "Jean-Bastien Grill",
                "Florian Strub",
                "Florent Altch\u00e9",
                "Corentin Tallec",
                "Pierre H. Richemond",
                "Elena Buchatskaya",
                "Carl Doersch",
                "Bernardo Avila Pires",
                "Zhaohan Daniel Guo",
                "Mohammad Gheshlaghi Azar",
                "Bilal Piot",
                "Koray Kavukcuoglu",
                "R\u00e9mi Munos",
                "Michal Valko"
            ],
            "title": "Bootstrap your own latent: A new approach to self-supervised Learning",
            "venue": "arXiv e-prints, art",
            "year": 2020
        },
        {
            "authors": [
                "Suchin Gururangan",
                "Swabha Swayamdipta",
                "Omer Levy",
                "Roy Schwartz",
                "Samuel R Bowman",
                "Noah A Smith"
            ],
            "title": "Annotation artifacts in natural language inference data",
            "venue": "arXiv preprint arXiv:1803.02324,",
            "year": 2018
        },
        {
            "authors": [
                "Jeff Z HaoChen",
                "Colin Wei",
                "Adrien Gaidon",
                "Tengyu Ma"
            ],
            "title": "Provable guarantees for self-supervised deep learning with spectral contrastive loss",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Tatsunori Hashimoto",
                "Megha Srivastava",
                "Hongseok Namkoong",
                "Percy Liang"
            ],
            "title": "Fairness without demographics in repeated loss minimization",
            "venue": "In International Conference on Machine Learning,",
            "year": 2018
        },
        {
            "authors": [
                "Kaiming He",
                "Haoqi Fan",
                "Yuxin Wu",
                "Saining Xie",
                "Ross Girshick"
            ],
            "title": "Momentum contrast for unsupervised visual representation learning",
            "year": 1911
        },
        {
            "authors": [
                "Sara Hooker",
                "Aaron Courville",
                "Gregory Clark",
                "Yann Dauphin",
                "Andrea Frome"
            ],
            "title": "What do compressed deep neural networks forget",
            "year": 1911
        },
        {
            "authors": [
                "Badr Youbi Idrissi",
                "Martin Arjovsky",
                "Mohammad Pezeshki",
                "David Lopez-Paz"
            ],
            "title": "Simple data balancing achieves competitive worst-group-accuracy",
            "venue": "arXiv preprint arXiv:2110.14503,",
            "year": 2021
        },
        {
            "authors": [
                "Ziyu Jiang",
                "Tianlong Chen",
                "Ting Chen",
                "Zhangyang Wang"
            ],
            "title": "Improving contrastive learning on imbalanced data via open-world sampling",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Ziyu Jiang",
                "Tianlong Chen",
                "Bobak J Mortazavi",
                "Zhangyang Wang"
            ],
            "title": "Self-damaging contrastive learning",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Longlong Jing",
                "Yingli Tian"
            ],
            "title": "Self-supervised visual feature learning with deep neural networks: A survey",
            "venue": "IEEE transactions on pattern analysis and machine intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "Siddharth Joshi",
                "Yu Yang",
                "Yihao Xue",
                "Wenhan Yang",
                "Baharan Mirzasoleiman"
            ],
            "title": "Towards mitigating spurious correlations in the wild: A benchmark & a more realistic dataset",
            "year": 2023
        },
        {
            "authors": [
                "Polina Kirichenko",
                "Pavel Izmailov",
                "Andrew Gordon Wilson"
            ],
            "title": "Last layer re-training is sufficient for robustness to spurious correlations",
            "venue": "arXiv preprint arXiv:2204.02937,",
            "year": 2022
        },
        {
            "authors": [
                "Pang Wei Koh",
                "Shiori Sagawa",
                "Henrik Marklund",
                "Sang Michael Xie",
                "Marvin Zhang",
                "Akshay Balsubramani",
                "Weihua Hu",
                "Michihiro Yasunaga",
                "Richard Lanas Phillips",
                "Irena Gao"
            ],
            "title": "Wilds: A benchmark of in-the-wild distribution shifts",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Preethi Lahoti",
                "Alex Beutel",
                "Jilin Chen",
                "Kang Lee",
                "Flavien Prost",
                "Nithum Thain",
                "Xuezhi Wang",
                "Ed H. Chi"
            ],
            "title": "Fairness without demographics through adversarially reweighted learning, 2020",
            "year": 2020
        },
        {
            "authors": [
                "Yoonho Lee",
                "Annie S Chen",
                "Fahim Tajwar",
                "Ananya Kumar",
                "Huaxiu Yao",
                "Percy Liang",
                "Chelsea Finn"
            ],
            "title": "Surgical fine-tuning improves adaptation to distribution shifts",
            "venue": "arXiv preprint arXiv:2210.11466,",
            "year": 2022
        },
        {
            "authors": [
                "Yoonho Lee",
                "Huaxiu Yao",
                "Chelsea Finn"
            ],
            "title": "Diversify and disambiguate: Learning from underspecified data",
            "venue": "arXiv preprint arXiv:2202.03418,",
            "year": 2022
        },
        {
            "authors": [
                "Weixin Liang",
                "James Zou"
            ],
            "title": "Metashift: A dataset of datasets for evaluating contextual distribution shifts and training conflicts",
            "venue": "arXiv preprint arXiv:2202.06523,",
            "year": 2022
        },
        {
            "authors": [
                "Evan Z Liu",
                "Behzad Haghgoo",
                "Annie S Chen",
                "Aditi Raghunathan",
                "Pang Wei Koh",
                "Shiori Sagawa",
                "Percy Liang",
                "Chelsea Finn"
            ],
            "title": "Just train twice: Improving group robustness without training group information",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Hong Liu",
                "Jeff Z HaoChen",
                "Adrien Gaidon",
                "Tengyu Ma"
            ],
            "title": "Self-supervised learning is more robust to dataset imbalance",
            "venue": "arXiv preprint arXiv:2110.05025,",
            "year": 2021
        },
        {
            "authors": [
                "Ziwei Liu",
                "Ping Luo",
                "Xiaogang Wang",
                "Xiaoou Tang"
            ],
            "title": "Deep learning face attributes in the wild",
            "venue": "In Proceedings of the IEEE international conference on computer vision,",
            "year": 2015
        },
        {
            "authors": [
                "R Thomas McCoy",
                "Ellie Pavlick",
                "Tal Linzen"
            ],
            "title": "Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference",
            "year": 1902
        },
        {
            "authors": [
                "Casey Meehan",
                "Florian Bordes",
                "Pascal Vincent",
                "Kamalika Chaudhuri",
                "Chuan Guo"
            ],
            "title": "Do ssl models have d\u00e9j\u00e0 vu? a case of unintended memorization in self-supervised learning, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Aditya Krishna Menon",
                "Ankit Singh Rawat",
                "Sanjiv Kumar"
            ],
            "title": "Overparameterisation and worst-case generalisation: friend or foe",
            "venue": "In International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "Mazda Moayeri",
                "Sahil Singla",
                "Soheil Feizi"
            ],
            "title": "Hard imagenet: Segmentations for objects with strong spurious cues",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Vaishnavh Nagarajan",
                "Anders Andreassen",
                "Behnam Neyshabur"
            ],
            "title": "Understanding the failure modes of out-of-distribution generalization",
            "venue": "arXiv preprint arXiv:2010.15775,",
            "year": 2020
        },
        {
            "authors": [
                "Junhyun Nam",
                "Hyuntak Cha",
                "Sungsoo Ahn",
                "Jaeho Lee",
                "Jinwoo Shin"
            ],
            "title": "Learning from failure: De-biasing classifier from biased classifier",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Aaron van den Oord",
                "Yazhe Li",
                "Oriol Vinyals"
            ],
            "title": "Representation learning with contrastive predictive coding",
            "venue": "arXiv preprint arXiv:1807.03748,",
            "year": 2018
        },
        {
            "authors": [
                "Maxime Oquab",
                "Timoth\u00e9e Darcet",
                "Th\u00e9o Moutakanni",
                "Huy Vo",
                "Marc Szafraniec",
                "Vasil Khalidov",
                "Pierre Fernandez",
                "Daniel Haziza",
                "Francisco Massa",
                "Alaaeldin El-Nouby"
            ],
            "title": "Dinov2: Learning robust visual features without supervision",
            "venue": "arXiv preprint arXiv:2304.07193,",
            "year": 2023
        },
        {
            "authors": [
                "Joshua Robinson",
                "Li Sun",
                "Ke Yu",
                "Kayhan Batmanghelich",
                "Stefanie Jegelka",
                "Suvrit Sra"
            ],
            "title": "Can contrastive learning avoid shortcut solutions",
            "venue": "arXiv preprint arXiv:2106.11230,",
            "year": 2021
        },
        {
            "authors": [
                "Elan Rosenfeld",
                "Pradeep Ravikumar",
                "Andrej Risteski"
            ],
            "title": "Domain-adjusted regression or: Erm may already learn features sufficient for out-of-distribution generalization",
            "venue": "arXiv preprint arXiv:2202.06856,",
            "year": 2022
        },
        {
            "authors": [
                "Shiori Sagawa",
                "Pang Wei Koh",
                "Tatsunori B. Hashimoto",
                "Percy Liang"
            ],
            "title": "Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization, 2020a",
            "year": 2020
        },
        {
            "authors": [
                "Shiori Sagawa",
                "Aditi Raghunathan",
                "Pang Wei Koh",
                "Percy Liang"
            ],
            "title": "An investigation of why overparameterization exacerbates spurious correlations",
            "venue": "In International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Hadi Salman",
                "Saachi Jain",
                "Andrew Ilyas",
                "Logan Engstrom",
                "Eric Wong",
                "Aleksander Madry"
            ],
            "title": "When does bias transfer in transfer learning",
            "venue": "arXiv preprint arXiv:2207.02842,",
            "year": 2022
        },
        {
            "authors": [
                "Marin Scalbert",
                "Maria Vakalopoulou",
                "Florent Couzini\u00e9-Devy"
            ],
            "title": "Improving domain-invariance in self-supervised learning via batch styles standardization",
            "venue": "arXiv preprint arXiv:2303.06088,",
            "year": 2023
        },
        {
            "authors": [
                "Ramprasaath R Selvaraju",
                "Abhishek Das",
                "Ramakrishna Vedantam",
                "Michael Cogswell",
                "Devi Parikh",
                "Dhruv Batra"
            ],
            "title": "Grad-cam: Why did you say that",
            "venue": "arXiv preprint arXiv:1611.07450,",
            "year": 2016
        },
        {
            "authors": [
                "Harshay Shah",
                "Kaustav Tamuly",
                "Aditi Raghunathan",
                "Prateek Jain",
                "Praneeth Netrapalli"
            ],
            "title": "The pitfalls of simplicity bias in neural networks",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Kendrick Shen",
                "Robbie M Jones",
                "Ananya Kumar",
                "Sang Michael Xie",
                "Jeff Z HaoChen",
                "Tengyu Ma",
                "Percy Liang"
            ],
            "title": "Connect, not collapse: Explaining contrastive learning for unsupervised domain adaptation",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Sahil Singla",
                "Soheil Feizi"
            ],
            "title": "Salient imagenet: How to discover spurious features in deep learning",
            "venue": "arXiv preprint arXiv:2110.04301,",
            "year": 2021
        },
        {
            "authors": [
                "Jiaming Song",
                "Pratyusha Kalluri",
                "Aditya Grover",
                "Shengjia Zhao",
                "Stefano Ermon"
            ],
            "title": "Learning controllable fair representations",
            "venue": "In The 22nd International Conference on Artificial Intelligence and Statistics,",
            "year": 2019
        },
        {
            "authors": [
                "Alex Tamkin",
                "Vincent Liu",
                "Rongfei Lu",
                "Daniel Fein",
                "Colin Schultz",
                "Noah Goodman"
            ],
            "title": "Dabs: A domain-agnostic benchmark for self-supervised learning",
            "venue": "arXiv preprint arXiv:2111.12062,",
            "year": 2021
        },
        {
            "authors": [
                "Antonio Torralba",
                "Alexei A Efros"
            ],
            "title": "Unbiased look at dataset bias",
            "year": 2011
        },
        {
            "authors": [
                "Yao-Hung Hubert Tsai",
                "Yue Wu",
                "Ruslan Salakhutdinov",
                "Louis-Philippe Morency"
            ],
            "title": "Demystifying self-supervised learning: An information-theoretical framework",
            "venue": "arXiv e-prints, pp. arXiv\u20132006,",
            "year": 2020
        },
        {
            "authors": [
                "Lifu Tu",
                "Garima Lalwani",
                "Spandana Gella",
                "He He"
            ],
            "title": "An empirical study on robustness to spurious correlations using pre-trained language models",
            "venue": "Transactions of the Association for Computational Linguistics,",
            "year": 2020
        },
        {
            "authors": [
                "Grant Van Horn",
                "Elijah Cole",
                "Sara Beery",
                "Kimberly Wilber",
                "Serge Belongie",
                "Oisin Mac Aodha"
            ],
            "title": "Benchmarking representation learning for natural world image collections",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Tan Wang",
                "Zhongqi Yue",
                "Jianqiang Huang",
                "Qianru Sun",
                "Hanwang Zhang"
            ],
            "title": "Self-supervised learning disentangled group representation as feature",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Zhao Wang",
                "Aron Culotta"
            ],
            "title": "Identifying spurious correlations for robust text classification",
            "venue": "arXiv preprint arXiv:2010.02458,",
            "year": 2020
        },
        {
            "authors": [
                "Yuzhe Yang",
                "Haoran Zhang",
                "Dina Katabi",
                "Marzyeh Ghassemi"
            ],
            "title": "Change is hard: A closer look at subpopulation shift",
            "venue": "In International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Jure Zbontar",
                "Li Jing",
                "Ishan Misra",
                "Yann LeCun",
                "St\u00e9phane Deny. Barlow"
            ],
            "title": "twins: Self-supervised learning via redundancy reduction",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "John R Zech",
                "Marcus A Badgeley",
                "Manway Liu",
                "Anthony B Costa",
                "Joseph J Titano",
                "Eric Karl Oermann"
            ],
            "title": "Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: a cross-sectional study",
            "venue": "PLoS medicine,",
            "year": 2018
        },
        {
            "authors": [
                "Dinghuai Zhang",
                "Kartik Ahuja",
                "Yilun Xu",
                "Yisen Wang",
                "Aaron Courville"
            ],
            "title": "Can subnetwork structure be the key to out-of-distribution generalization",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Michael Zhang",
                "Nimit S Sohoni",
                "Hongyang R Zhang",
                "Chelsea Finn",
                "Christopher R\u00e9"
            ],
            "title": "Correct-ncontrast: A contrastive approach for improving robustness to spurious correlations",
            "venue": "arXiv preprint arXiv:2203.01517,",
            "year": 2022
        },
        {
            "authors": [
                "Hattie Zhou",
                "Ankit Vani",
                "Hugo Larochelle",
                "Aaron Courville"
            ],
            "title": "Fortuitous forgetting in connectionist networks",
            "venue": "arXiv preprint arXiv:2202.00155,",
            "year": 2022
        },
        {
            "authors": [
                "Shen"
            ],
            "title": "The set of four sets of eigenvectors would be as below: \u2022 For eigenvalue \u03bb1 = \u03c1+ \u03b2 + \u03b1+ \u03b3, the eigenvector is",
            "year": 2022
        },
        {
            "authors": [
                "Liang",
                "Zou"
            ],
            "title": "2022) We consider the Cats vs Dogs task where Background (indoor, outdoor) is spuriously correlated with pet type (cat, dog)",
            "year": 2022
        },
        {
            "authors": [
                "Grad-CAM Selvaraju"
            ],
            "title": "2016) to compare the SSL-base and SSL-LATETVG . We consider the representations that SSL-base and SSL-LATETVG learn for metashift, and use that to visualize the final layer of the encoder. We choose the best-performing LATETVG model based on downstream worst-group accuracy. We visualize the parts of the image that both SSL-Base and LATETVG attend",
            "year": 2016
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Standard supervised machine learning models exhibit high overall performance but often perform poorly on minority subgroups (Shah et al., 2020; McCoy et al., 2019; Gururangan et al., 2018). One potential cause is the presence of spurious correlations, which are features that are only correlated with the label for specific subsets of data. For instance, a machine learning model tasked with predicting bird species from images across different habitats may use the background the bird commonly appears in as a \u201cshortcut\u201d, instead of core features specific to the bird such as the shape of their beak or plumage. This results in poor performance on bird groups that appear in unexpected environments (Sagawa et al., 2020a). Identifying spurious correlations in the supervised learning setting has been well studied, where empirical risk minimization has been shown to exploit spurious correlations and result in poor performance for minority subgroups (Hashimoto et al., 2018). Because downstream tasks are explicitly defined, the label can be used to distinguish between core and spurious features (Liu et al., 2021a; Zhang et al., 2022). Recent work has proposed various methods to identify and mitigate the effects of spurious features, such as learning multiple prediction heads (Lee et al., 2022b), causal inference (Creager et al., 2021), data augmentation (Gao et al., 2023) and targeted strategies such as importance weighting (Lahoti et al., 2020), re-sampling Idrissi et al. (2021); Tu et al. (2020), or approaches based on group distributionally robust optimization (Sagawa et al., 2020a; Duchi et al., 2019).\nMore recently, self-supervised learning (SSL) has emerged as a common form of pre-training for task-agnostic learning with large, unlabeled datasets (Chen et al., 2020a; He et al., 2019; Grill et al., 2020; Chen & He, 2020; Caron et al., 2020; Zbontar et al., 2021; Chen et al., 2020b). SSL methods learn representations from unlabeled datasets by solving an auxiliary pretext task (Doersch et al., 2015), such as inducing invariance between the representations of two augmented views of the same image (He et al., 2019; Chen et al., 2020a). These methods have shown impressive results for a wide range of downstream tasks and datasets (Liu et al., 2021b; Jaiswal et al., 2020; Tamkin et al., 2021).\nCapturing core features \u2013 rather than spurious features \u2013 is essential for learning effective representations that can be used in downstream tasks, but is particularly difficult in the case of SSL due to the absence of labeled data during the pre-training process. Given only unlabeled data, we define spurious features as those that strongly correlate with core features for most examples in the training set, but are not useful for downstream tasks. For example, when training an SSL model on\nmulti-object images, larger objects may interfere with the learning of smaller objects (Chen et al., 2021). If the downstream task involves only the prediction of smaller objects, the larger (spurious) object may suppress the smaller (core) object from being learned. Large-scale unlabeled datasets that are commonly used in machine learning are inevitably imbalanced (Van Horn et al., 2021), have been found to be biased towards spuriously correlated sensitive attributes (Calude & Longo, 2017) such as gender or race (Agarwal et al., 2021), and can also include label-irrelevant but transferable features (Torralba & Efros, 2011; Fan et al., 2014).\nIn this paper, we investigate the impact of spurious correlations on SSL pre-training. We first show that the image augmentations used in SSL pre-training can lead to spurious connectivity when learning representations, causing the model to fail to predict the label using core features in downstream tasks. We empirically evaluate spurious connectivity, and then show that existing approaches for utilizing group information in ERM based approaches do not provide an analogous improvement in SSL pre-training. We then propose Late-layer Transformation-based View Generation or LATETVG \u2013 a method that induces invariance to spurious features in the representation space by regularizing final layers of the featurizer via pruning. Importantly, since our approach addresses SSL pre-training, we do not assume that model developers know apriori the identity or values of the spurious features that exist in the data. We first connect our method to the theoretical analysis by showing that LATETVG models empirically exhibit lower spurious connectivity, and then evaluate LATETVG on several popular benchmarks for spurious feature learning. Our method demonstrates improved discriminative ability, especially over minority subgroups, for downstream predictive tasks, without access to group or label information. We make the following contributions:\n\u2022 We provide theoretical arguments (Sec 3.3) that illustrate how common augmentations used in SSL pre-training affect the model\u2019s ability to rely on spurious features, for downstream linear classifiers.\n\u2022 We explore the extent of spurious learning in self-supervised representations through the lens of downstream worst-group performance. We empirically show that known techniques for avoiding spurious correlations, such as re-sampling of the training set given group information, do not consistently improve core feature representations (Sec 4.4).\n\u2022 We propose LATETVG \u2013 an approach that corrects for the biases caused by augmentations, by modifying views of samples in the representation space (Sec 5.1). We find that LATETVG effectively improves worst-group performance in downstream tasks on four datasets by enforcing core feature learning (Sec 5.2)."
        },
        {
            "heading": "2 RELATED WORK",
            "text": "Spurious Correlations Spurious correlations arise in supervised learning models Koh et al. (2021); Joshi et al. (2023); Singla & Feizi (2021) in a variety of domains, from medical imaging (Zech et al., 2018; DeGrave et al., 2021) to natural language processing (Tu et al., 2020; Wang & Culotta, 2020). A variety of approaches have been proposed to learn classifiers which do not make use of spurious information. Methods like GroupDRO (Sagawa et al., 2020a) and DFR (Kirichenko et al., 2022) require group information during training, while methods like JTT (Liu et al., 2021a), LfF (Nam et al., 2020), CVaR DRO (Duchi et al., 2019), and CnC (Zhang et al., 2022) do not. However, all methods require group information for model selection.\nSelf-supervised Representation Learning Self-supervised learning methods learn representations from large-scale unlabeled datasets where annotations are scarce. In vision applications, the pretext task is typically to maximize similarity between two augmented views of the same image (Jing & Tian, 2020). This can be done in a contrastive fashion using the InfoNCE loss (Oord et al., 2018), such as in Chen et al. (2020a) and Chen et al. (2020b), or without the need for negative samples at all, as in Grill et al. (2020); Caron et al. (2020); Chen & He (2020); Caron et al. (2021); Oquab et al. (2023); Zbontar et al. (2021). Prior work has shown that SSL models may learn to spuriously associate certain foreground items with certain backgrounds (Meehan et al., 2023), In this work, we explore one potential mechanism for this phenomenon, both theoretically and empirically.\nRepresentation Learning under Dataset Imbalance and Shortcuts Self-supervised models have demonstrated increased robustness to dataset imbalance (Liu et al., 2021b; Jiang et al., 2021b;a), and the dominance of easier or larger features suppressing the learning of other features (Chen et al., 2021). Some prior work has addressed shortcut learning in contrastive learning through adversarial feature modification without group labels (Robinson et al., 2021). However, other approaches to group robustness or fairness in self-supervised learning require group information or labels (Tsai\net al., 2020; Song et al., 2019; Wang et al., 2021; Bordes et al., 2023; Scalbert et al., 2023). This paper focuses on learning representations from an unlabeled dataset with spurious correlations, encompassing both dataset imbalance and features of varying difficulty.\nRegularization in Self-supervised Learning The concept of regularizing a specific subset of the network is relatively unexplored in self-supervised learning but finds motivation in recent findings from supervised settings, such as addressing minority examples (Hooker et al., 2019), out-ofdistribution generalization (Zhang et al., 2021), late-layer regularizations through head weight-decay (Abnar et al., 2021), and initialization (Zhou et al., 2022). Additionally, Lee et al. (2022a) propose surgically fine-tuning specific layers of the network to handle distribution shifts in particular categories. These studies provide support for the approach of targeting a specific component of the network in self-supervised learning."
        },
        {
            "heading": "3 SPURIOUS CONNECTIVITY INDUCES DOWNSTREAM FAILURES",
            "text": "In this section, we introduce a toy setting to demonstrate that common augmentations used in SSL pre-training affect a model\u2019s ability to rely on spurious features for downstream linear classifiers. We consider a binary classification problem with a binary spurious attribute, with an equal number of samples per group (Section 3.2). We show that augmentations applied during SSL pre-training can introduce undesired invariances in the representation space learned by a contrastive objective, making the downstream linear classifier trained on representations more reliant on the spurious feature (Section 3.3)."
        },
        {
            "heading": "3.1 BACKGROUND AND SETUP",
            "text": "Setup. We consider learning representations from unlabeled population data X generated from an underlying latent feature space Z \u2208 Rm := {zcore, zspur, . . . , zm}, where zcore and zspur are correlated features. For a given downstream task with labeled samples, we assume that each x \u2208 X belongs to a class given by the ground-truth labeling function y : X \u2192 Y where zcore determines the labels y for our downstream task of interest, while zspur determines the spurious attribute a, which is easier to learn, and is not of interest for downstream tasks. We can define deterministic attribute function a : X \u2192 S where each x \u2208 X takes a value in attribute a. Let g = (y(x), a(x)) denote the subgroup of a given sample x, where G = Y \u00d7 S is the set of all possible subgroups. Figure 1 illustrates the subgroups on the Waterbirds dataset, where the background is a spurious feature that correlates with the bird species.\nContrastive learning. We aim to learn representations by bringing together data-augmented views of the same input, which we refer to as positive pairs, using a contrastive objective. Let P+ be the distribution of positive pairs, which can be defined as the marginal probability of generating the augmented pair x and x\u2032 from the same image in the (natural) population data. Thus the distribution P+ relies both on original data distribution and the choice of SSL augmentations. To analyze the representation space learned in contrastive learning and core feature predictivity of the representations, consider a weighted graph with vertex set X where the undirected edge (x, x\u2032) has weight wxx\u2032 = P+(x, x\u2032) similar to augmentation graph in HaoChen et al. (2021).\nAlthough the augmentation graph learns semantically similar structures enabling generalization to new domains (Shen et al., 2022), the inductive biases set by these augmentations is not well studied. In this work, we draw attention to cases where augmentations can create spurious connectivities within subgroups of the data, and when and why these connectivities can cause the downstream linear model to rely on the spurious feature."
        },
        {
            "heading": "3.2 SPURIOUS CONNECTIVITY IN A TOY SETUP",
            "text": "In this section, we introduce a setting in which contrastive objectives can learn representations that linear downstream models fail on. To begin with, we investigate how augmentations can transform the samples such that the subgroup assignment changes.\nDefinition 3.1. Subgroup connectivity. Define the average subgroup connectivity given two disjoint subsets G1, G2 \u2286 X as w(G1, G2) = 1|G1|.|G2| \u2211 x\u2208G1,x\u2032\u2208G2 wxx\u2032 . where wxx\u2032 is the probability of generating the augmented pair x and x\u2032 from the same image in the natural population data.\nIntuitively, this subgroup connectivity is the average proportion of edges connecting G1 to G2, and is proportional to the probability of a sample x \u2208 G1 being transformed to a sample x\u2032 \u2208 G2 via augmentations. See Appendix C for further details.\nWe specifically define the following terms to be the expected value of w(G1, G2) from Definition 3.1, when subgroups G1 and G2 have the following properties:\n\u2022 Spurious connectivity \u03b1: G1 and G2 share the same spurious attribute but differ in class \u2022 Invariant connectivity \u03b2: G1 and G2 share the same class but differ in spurious attribute \u2022 Opposite connectivity \u03b3: G1 and G2 differ both in the spurious attribute and the label\nWhere \u03b1, \u03b2, \u03b3 are average values estimated across a dataset consisting of subgroups.\nToy Setup. We consider a downstream classification problem where a spurious attribute is present, and both the input and the spurious attribute take binary values. We define the probability of sampling a positive pair (x, x\u2032) based on the expected connectivity terms \u03b1toy, \u03b2toy, \u03b3toy, and \u03c1toy as follows:\nP+(x, x \u2032) =  \u03b1toy, if a(x) \u0338= a(x\u2032) and y(x) = y(x\u2032) \u03b2toy, if a(x) = a(x\u2032) and y(x) \u0338= y(x\u2032) \u03b3toy, if a(x) \u0338= a(x\u2032) and y(x) \u0338= y(x\u2032) \u03c1toy, if a(x) = a(x\u2032) and y(x) = y(x\u2032)\nNote that the average subgroup connectivity for this setup, would be exactly the same as the corresponding connectivity variable. Thus in our running example we have \u03b1 = \u03b1toy, \u03b2 = \u03b2toy, \u03b3 = \u03b3toy, and we can use them interchangeably. For this simplified augmentation graph, the expected connectivity terms between groups are a property of the graph, and independent of the model or architecture we use for learning representations. Combined with a contrastive objective, the expected connectivity can be a proxy for how close different subgroups are going to be in the representation space."
        },
        {
            "heading": "3.3 ANALYSIS OF THE TOY SETTING",
            "text": "In Section 4.2, we empirically show that common augmentations used in contrastive learning can be detrimental to learning invariant representations, as they implicitly encourage samples to cluster primarily based on the spurious feature. Based on this observation, we make the following assumption. Assumption 3.2. Given a spurious attribute function a : X \u2192 |G| which is defined for all x \u2208 X , we assume that for a data point x \u223c X , the probability of distorting the labeling of the augmented images sampled from the augmentation distribution A(\u00b7|x\u0304), is greater than the probability of distorting the attribute. More formally,\nPr x\u0303\u223cA(\u00b7|x) (y(x\u0303) \u0338= y(x), a(x\u0303) = a(x)) \u2265 Pr x\u0303\u223cA(\u00b7|x) (a(x\u0303) \u0338= a(x), y(x\u0303) = y(x))\nLemma 3.3. Consider the set of (unlabeled) population data X in a binary-class setting where the spurious attribute takes binary values, consisting of |G| = 4 groups, with the same number of\nexamples per group. Consider a simplified augmentation graph with parameters \u03b1, \u03b2, \u03c1, \u03b3 defined as in 3.2, and assume that augmentations are more likely to change either class or attribute, than to change neither of the two (\u03b1 > \u03b3, \u03b2 > \u03b3), and that augmentations are less likely to change both at the same time (\u03c1 > \u03b1, \u03c1 > \u03b2).\nUnder these conditions, the spectral contrastive loss recovers both invariant and spurious features, and for each sample in the population data, the spurious feature is bounded by constant Bsp = \u221a \u03b2 \u2212 \u03b1\u2212 \u03b3 + \u03c1, while the invariant feature is bounded by Binv = \u221a \u03b1\u2212 \u03b2 \u2212 \u03b3 + \u03c1, in the representation space. Proof in the appendix C Corollary 3.4. Given assumption 3.2, where \u03b1 > \u03b2 in the simplified augmentation graph, the margin of the spurious classifier is Bsp, and is less than the margin of the invariant classifier Binv, and the max-margin classifier trained on representations given by spectral clustering, converges to the spurious classifier.\nThis suggests that even with the same number of samples across different groups during pre-training, downstream linear classifiers can rely on the spurious feature to make predictions, where the representations are determined by the simplified augmentation graph and the spectral contrastive loss."
        },
        {
            "heading": "4 EXPLORING SPURIOUS LEARNING IN REPRESENTATIONS",
            "text": "In this section, we investigate the performance of downstream linear models trained on self-supervised representations, empirically verify our assumption regarding spurious and invariant connectivity, and show that in practice \u2013 similar to our toy analysis \u2013 having the same number of examples across groups in the presence of spurious connectivity does not lead to performance gains."
        },
        {
            "heading": "4.1 EXPERIMENTAL SETUP",
            "text": "Datasets We evaluate methods on five commonly used benchmarks in spurious correlations \u2013 CelebA (Liu et al., 2015), CMNIST (Arjovsky et al., 2019), MetaShift (Liang & Zou, 2022), Spurious CIFAR-10 (Nagarajan et al., 2020), and Waterbirds (Wah et al., 2011) (See Appendix D.1 for dataset descriptions). For each dataset, we train an encoder with an SSL-based pre-training step followed by a supervised training of a linear model that probes the representations learned using SSL for the downstream task.\nSSL Pre-training For the SSL pre-training, we train SimSiam (Chen & He, 2020) models with a ResNet backbone throughout the paper. The training split used during the pre-training stage are unbalanced and contain spuriously correlated data. The group/label counts for each dataset and split is shown in Appendix D.1. The backbone network used for most of our experiments are initialized with random weights, unless specified otherwise. In Section 5.2.1, we additionally report results for SimCLR (Chen et al., 2020a) models.\nDownstream Task For downstream task prediction, we train a linear layer using logistic regression on top of the pretrained embeddings. Note that the backbone is frozen during this finetuning phase and only the linear layer is updated. We use a balanced dataset for training where the spurious correlation does not hold. To create this downstream training dataset, we subsample majority groups (Sagawa et al., 2020b; Idrissi et al., 2021), to avoid the geometrical skews (Nagarajan et al., 2020) of the linear classifier on representations. Then, we evaluate the learned representations on the standard test split of each dataset, where group information is given. For each run, we report the average and worst-group accuracy.\nEmpirical Evaluation of Spurious Connectivity To evaluate the connectivity term for each pair of subgroups in datasets exhibiting spurious correlations, we conduct an empirical analysis similar to Shen et al. (2022). Specifically, we train a classifier to distinguish between each pair of subgroups and evaluate its performance on a subset of the data that has been augmented with SSL augmentations. The error of the classifier represents the probability that the augmentation module alters the subgroup assignment for each example between the two subgroups, making them indistinguishable. Figure 1 illustrates this procedure.\nThe Role of Initialization In representation learning, encoders are not typically trained from scratch but initialized from a model pretrained on larger datasets, such as ImageNet (Deng et al., 2009). Recent work in transfer learning (Geirhos et al., 2018; Salman et al., 2022) has questioned this assumption and pointed out that biases in pretrained models linger even after finetuning on downstream target tasks. In this section and more broadly in our work, we focus on performing SSL pre-training from randomly initialized weights. In addition, since the datasets considered in this work\nare similar to Imagenet, their off-the-shelf performance is expected to be higher. For completeness, we have added these results to Appendix G.2."
        },
        {
            "heading": "4.2 HIGH LEVELS OF SPURIOUS CONNECTIVITY IN PRACTICE",
            "text": "We measure connectivity across four datasets in Table 4, and on all of them, we find that the average spurious connectivity is higher than invariant connectivity. We also confirm that both these values are higher than the probability of simultaneously changing both spurious attributes and invariant attributes. This means that the samples within the training set are more likely to be connected to each other through the spurious attribute, rather than the core feature. This suggests that the contrastive loss prefers alignment based on the spurious attribute instead of the class.\nWe compute the connectivity terms by training classifiers to distinguish augmented data from each combination of the two groups in the dataset and reporting their error rates. The details of the choice of augmentations and training for this step can be found in Appendix E."
        },
        {
            "heading": "4.3 SSL MODELS LEARN SPURIOUS FEATURES",
            "text": "To measure the reliance of downstream models to spurious correlations, we measure the accuracy of the downstream model on each group in the test set, and use the worst-performing group accuracy as a lens to reason about spurious correlations. We find across all datasets, SSL models exhibit gaps between worst-group and average accuracy when predicting the core feature (Table 5 in Appendix D.3).\nThese results indicate that even when spurious correlation does not hold for downstream tasks, the learned features are more predictive of the spurious feature in comparison to the core one. This is in contrast with supervised learning (Menon et al., 2021; Kirichenko et al., 2022; Rosenfeld et al., 2022), where such models contain enough core information to perform well on all subgroups, and only need re-training of the final layer on a balanced validation."
        },
        {
            "heading": "4.4 RESAMPLING DURING SSL DOES NOT IMPROVE DOWNSTREAM PERFORMANCE",
            "text": "To probe the effect of availability of such group information during the SSL pre-training stage, we examine whether classical approaches for combating spurious correlations, such as re-sampling training examples (Idrissi et al., 2021), are effective in removing spurious information during SSL pre-training. Assuming that group information is available, we train SimSiam on datasets re-sampled using the following strategies: (i) Balancing groups by resampling training examples to match the downstream validation distribution. (ii) Downsampling examples in majority groups to have the same number of examples in all groups. (iii) Upsampling minority examples to have the same number of examples in all groups.\nWe find that re-sampling during self-supervised pre-training does not improve downstream worstgroup accuracy in a consistent manner as in Table 2. We do see minor improvements for metashift\nand celebA, but contrast this with large drops for spurcifar10 and cmnist. Given that the downstream linear model is trained on a downsampled dataset where such correlations do not exist, this means that re-sampling during self-supervised training does not necessarily improve the linear separability of representations with respect to the core feature, even in balanced datasets. This is analogous to our findings in the toy setting in Section 3.3."
        },
        {
            "heading": "5 CREATING ROBUST REPRESENTATIONS VIA FEATURE SPACE AUGMENTATIONS",
            "text": "In the previous sections, we showed that augmentation mechanisms used in SSL result in poor performance under spuriously correlated features in the training set. Instead of curating specific image augmentations that corrects for these biases in the image space, we propose an approach to target spurious connectivity in the representation space by modifying positive pairs. In this section, we describe our approach, LATETVG that improves performance of SSL models by introducing pruning based regularization to the later layers of the encoder.\n5.1 LATE-LAYER TRANSFORMATION-BASED VIEW GENERATION\nMotivated by improved SSL model invariance when trained with augmentations in image space (Chen et al., 2020a), we propose a model transformation module that specifically targets augmentations that modify the spurious feature in representation space. We propose Late-layer Transformation-based View Generation - LATETVG , which uses feature space transformations to mitigate spurious learning in SSL models and improve learning of the core feature.\nFormally, we propose using a model transformation module U , that transforms any given model f\u03b8 parameterized by \u03b8 = {W1, . . . ,Wn} to f\u03b8\u0303. At each step, we draw a transformation \u03d5M,\u03b8\u2032 \u223c U to obtain the transformed encoder. Each model transformation can be defined with a mask M \u2208 {0, 1}|\u03b8| , where we transform the unmasked weights (1 \u2212M) \u2299 \u03b8\u2032 by \u03d5, and keep the rest of the weights M \u2299 \u03b8 the same to obtain \u03b8\u0303. Here, we propose a specific transformation module U .\nTransformations For mitigating spurious connectivity, we choose a simple transformation targeted towards regularizing the final layers of the encoder. In our experiments, we consider a threshold pruning transformation module, which uses magnitude pruning on a% of the weights in all layers deeper than L. More specifically, we use the following model transformation module: U Prune, L, a = {\u03d5ML,a,\u03b80 ; \u03b80 = (0)|\u03b8|} where ML,a = {M lL \u2299 Topa(Wl) | l \u2208 [n]} and Topa(Wl)i,j = I(|Wl(i,j) | in top a% of \u03b8). Note that in this specific setting, the module transformation is deterministic, though our formalization also allows for random transformations such as randomized pruning or re-initialization.\nTo learn these representations, given two random augmentations t, t\u2032 \u223c T from the augmentation module T , two views x1 = t(x) and x2 = t\u2032(x) are generated from an input image x. At each step, given a feature encoder f , and an augmentation module U , we obtain a transformed model f\u0303 = \u03d5(f), \u03d5 \u223c U . During training, examples x1 and x2 are respectively passed through the normal encoder v1 = f(x1), and the transformed encoder v\u03032 = f\u0303(x2). Encoded feature v\u03032 is now a positive example that should be close to v1 in the representation space. An algorithmic representation of the method can be found in Appendix B.\nIntuition for LateTVG When learning a discriminative process that maps data to a separable space, the variance among different subpopulations is stored in distinct regions of the network (Lee et al., 2022a). As a result, both spurious and core features, which describe the high-level data distribution, tend to reside at the end of a neural network. Thus, in LATETVG , we aim to encourage the final layers to learn more difficult features, by applying a model transformation that targets these layers, and causing the model to be invariant to final layer transformations. As pruning in supervised models have been shown to affect minority examples more than majority ones (Hooker et al., 2019), we hypothesize that our transformation can be considered as a curated view generating operation for the minority groups. In particular, pruning would contribute to \u201cforgetting\u201d the minority examples from the network, resulting in upweighting the loss for these examples."
        },
        {
            "heading": "5.2 EXPERIMENTS",
            "text": "In this section, we demonstrate the efficacy of LATETVG in mitigating the dependence on spurious correlations. We use the same experimental setup as described in Section 4.1. For evaluation of LATETVG , we use our SSL-LATETVG approach during the pre-training stage. We compare this performance to SSL models pre-trained with the standard SSL-base trained with either SimSiam or SimCLR."
        },
        {
            "heading": "5.2.1 LATETVG IMPROVES SSL WORST-GROUP PERFORMANCE",
            "text": "The goal of this experiment is to understand how LATETVG affects worst-group performance in downstream tasks that use SSL representations. We compare the worst group accuracy of two approaches, SSL-Base and SSL-LATETVG on 5 different datasets. Both models used similar hyper-parameter grids and model selection criteria as noted previously. The results are presented in Table 3. We show the performance of the best hyperparameter combination here, and have provided figures of performance gains for all hyperparameters in Appendix D.2. It can be clearly observed that SSL-LATETVG outperforms the base model by large margins across most datasets and for both SimSiam and SimCLR. On cmnist, our performance is very close to the baseline model and we do not see significant improvement. We hypothesize that this is due to the fact that the base encoder on the easier cmnist dataset is already quite performant. On datasets where the base encoder performs poorly such as metashift and spurcifar10, our approach improves the performance by at least 10% over base SimSiam. On a dataset of a larger scale like celebA, LATETVG still improves upon a strong encoder baseline.\nFurther, we find that LATETVG closes the gap in performance to supervised pretraining (Table 8). We emphasize that this is an unfair comparison to begin with, since supervised pretraining requires labeled data whereas SSL does not, hence reducing the annotation budget drastically. Regardless,\nwe find that LATETVG narrows the gap between the SSL baseline and the ERM model significantly \u2013 17% relative improvement for cmnist to 50% in the case of spurcifar10. In the case of celebA, we even outperform the ERM baseline."
        },
        {
            "heading": "5.2.2 SSL DOWNSTREAM LINEAR PERFORMANCE IS LESS RELIANT ON A BALANCED DOWNSTREAM DATASET",
            "text": "Traditional approaches that mitigate spurious correlations in ERM-based settings assume that the downstream training set is balanced (Kirichenko et al., 2022). However, this still requires knowledge of the spurious feature, which we may not always have in practice. In this experiment, we challenge this assumption and analyze how SSL models behave when the downstream training set is imbalanced.\nWe vary the proportion of minority groups in the downstream training set, by first downsampling the training set to have the same number of samples across groups, and second randomly sampling minority groups with weight \u03bb (x-axis in Figure 3) and majority groups with weights 1 \u2212 \u03bb. We measure the worst group accuracy of the trained linear models for each dataset. We show the results on metashift in Figure 3, comparing the performance of SSL-Base and SSL-LATETVG . We can observe that LATETVG outperforms the baseline across a range of minority weights \u2013 implying that LATETVG is more robust to imbalances in downstream training data. This is a crucial aspect where LATETVG differs from other approaches in the supervised pretraining literature, such as DFR (Kirichenko et al., 2022), which requires a balanced training set for the reweighting strategy to be successful. Similar results for other datasets and linear models are provided in in Appendix F.5."
        },
        {
            "heading": "5.2.3 LATETVG REDUCES SPURIOUS CONNECTIVITY IN THE REPRESENTATION SPACE",
            "text": "Finally, we relate our method back to the theoretical analysis presented in Section 3, by computing the connectivity of the representation space learned by the SSL models, using the procedure outlined in Section E. In Table 4, we find that LATETVG empirically reduces the spurious connectivity, while increasing the invariant connectivity, for all datasets. Thus, we have shown that LATETVG successfully augments the representation space to induce desired invariances."
        },
        {
            "heading": "6 CONCLUSION",
            "text": "In this paper, we have investigated the impact of spurious correlations on self-supervised learning (SSL) pre-training and proposed a new approach, called LATETVG to address the issue. Our experiments demonstrated that spurious correlations caused by data augmentation can lead to spurious connectivity and hinder the model\u2019s ability to learn core features, which ultimately impacts downstream task performance. We have shown that traditional debiasing techniques, such as re-sampling, are not effective in mitigating the impact of spurious correlations in SSL pre-training. In contrast, LATETVG effectively improves the worst-group performance in downstream tasks by inducing invariance to spurious features in the representation space throughout training. Our approach does not require access to group or label information during training and can be applied to large-scale, imbalanced datasets with spurious correlations. We believe our work will help advance the field of SSL pre-training and encourage future research in developing methods that are robust to spurious correlations."
        },
        {
            "heading": "A LIMITATIONS",
            "text": "In this work, we validated our method on several benchmark datasets containing spurious correlations from prior work (Sagawa et al., 2020a; Liang & Zou, 2022; Yang et al., 2023). However, we recognize that the scale of these datasets are small, relative to typical SSL training corpora (e.g. ImageNet (Deng et al., 2009)). As these large datasets do not contain annotations of spurious features, we are unable to evaluate our method in these settings. In addition, we primarily focus on SimSiam Chen & He (2020) in our experiments, as it does not rely on large batch sizes and shows improved performance for smaller datasets. Moreover, we expect LATETVG to perform best in cases where Siamese encoders coupled with stop-gradient operation are used when learning the representations."
        },
        {
            "heading": "B LATETVG ALGORITHM BOX",
            "text": "We provide an algorithm representation of our proposed method LATETVG in Section 5.1 as follows.\nAlgorithm 1 Self-supervised Learning with LATETVG 1: Inputs: Encoder f parameterized by \u03b8 = {W1, . . . ,Wn}, Projection head and predictor g,\nAugmentation module T , Threshold L, Pruning rate a, Training epochs N . 2: Initialize f\u0303 with \u03b8\n3: for all i = 1 \u2192 N do 4: Stage 1: Self-supervised Training 5: for all i = 1 \u2192 N do 6: Draw two random augmentations t, t\u2032 \u223c T 7: x1 = t(x), x2 = t\u2032(x) \u25b7 Generate views x1, x2 from input x using augmentation t 8: v1 = f(x1) \u25b7 Obtain encoded features from normal encoder f 9: v\u03032 = f\u0303(x2) \u25b7 Obtain encoded features from transformed encoder f\u0303 10: L = Loss(v1, v\u03032; g) \u25b7 Calculate contrastive loss given views v1 and v\u03032 11: Update f, g to minimize L \u25b7 Update the encoder and other SSL parameters\n12: Stage 2: Model Transformation 13: Compute the mask ML,a = {M lL \u2299 Topa(Wl) | l \u2208 [n]} where Topa(Wl)i,j = I(|Wl(i,j) | in top a% of \u03b8) 14: Update f\u0303 with parameters \u03b8\u0303 = ML,a \u2299 \u03b8 \u25b7 Magnitude pruning of weights 15: Return encoder f\u0303"
        },
        {
            "heading": "C THEORETICAL ANALYSIS OF SPURIOUS CONNECTIVITY",
            "text": "Setup We consider the pre-text task of learning representations from unlabeled population data X consisting of unknown groups G which are not equally represented. For a given downstream task with labeled samples, we assume that each x \u2208 X belongs to one of c = |Y| classes, and let y : X \u2192 [c] denote the ground-truth labeling function. Let us define a : X \u2192 [m] as the deterministic attribute function creating groups (of potential different sizes) as G = Y \u00d7 S.\nSpectral Contrastive Learning In order to investigate why the invariant feature can be suppressed in contrastive learning, we consider the setting from HaoChen et al. (2021) \u2013 Spectral Contrastive learning, which achieves similar empirical results to other contrastive learning methods and is easier for theoretical analysis.\nGiven the set of all natural data or data without any augmentation X , we use A(\u00b7|x\u0304) to denote the distribution of augmentations of x\u0304 \u2208 X . For instance, when x\u0304 represents an image, A(\u00b7|x\u0304) can be the distribution of common augmentations that includes Gaussian blur, color distortion and random cropping.\nLet PX be the population distribution over X from which we draw training data and test our final performance. For any two augmented data points x, x\u2032 \u2208 X , the weight between a pair wxx\u2032 is the marginal probability of generating the pair x and x\u2032 from a random data point x\u0304 \u223c PX :\nwxx\u2032 = Ex\u0304\u223cPX [A(x|x\u0304)A(x \u2032|x\u0304)]\nDefine expansion between two sets similar to HaoChen et al. (2021) as below:\n\u03d5(S1, S2) =\n\u2211 x\u2208S1,x\u2032\u2208S2 wxx\u2032\u2211\nx\u2208S1 wx where wx = \u2211\nx\u2032\u2208S wxx\u2032 . We note that this is similar to our definition of connectivity, where we have assumed the marginal distribution over x is uniform, or wx = 1N .\nToy Setup Let the ground-truth labeling function y and the deterministic attribute function a, determine the subgroup g = (y(x), a(x)) of a given sample x. We suppose we have n samples from each subgroup, and that labels and attributes take binary values1.\nSuppose that each edge in the augmentation graph is given by connectivity terms \u03b1, \u03b2, \u03c1, \u03b3 as below: \u2200x, x\u2032 \u2208 X : P+(x, x\u2032) = 1(a(x) = a(x\u2032), y(x) = y(x\u2032))\u03c1\n+ 1(a(x) \u0338= a(x\u2032), y(x) = y(x\u2032))\u03b1 + 1(a(x) = a(x\u2032), y(x) \u0338= y(x\u2032))\u03b2 + 1(a(x) \u0338= a(x\u2032), y(x) \u0338= y(x\u2032))\u03b3\nWe suppose that each edge in the augmentation graph is deterministically equal to one of the connectivity terms, and make the following assumptions:\n1. \u03b1 > \u03b3, \u03b2 > \u03b3 \u2013 The probability that augmentation changes the spurious attribute only, or the class only is both greater than the probability that augmentation changes both attribute and class (at the same time).\n2. \u03c1 > \u03b1, \u03c1 > \u03b2 \u2013 The probability that augmentation that keeps both attribute and class is greater than the probability that it changes the spurious attribute only, or the class only is both higher than the probability that augmentation changes both domain and class (at the same time).\n3. \u03b1 > \u03b2 or Assumption 3.2 \u2013 The probability that augmentation changes the spurious feature is higher than the probability of it changing the class, as observed in 4.\nC.1 PROOF OF LEMMA 3.3\nProof. Let the A \u2208 R4n\u00d74n be the adjacency matrix of the simplified augmentation graph. It is easy to show that A is equivalent to adjacency matrix A\u0304 up to a rotation where:\nA\u0304 =(\u03b2 \u2212 \u03b3) \u00b7 I2 \u2297 ( 121 \u22a4 2 ) \u2297 ( 1n1 \u22a4 n ) + (\u03b1\u2212 \u03b3) \u00b7 ( 121 \u22a4 2 ) \u2297 I2 \u2297 ( 1n1 \u22a4 n\n) + (\u03c1\u2212 \u03b2 \u2212 \u03b1+ \u03b3) \u00b7 I4 \u2297 ( 1n1 \u22a4 n\n) + \u03b3 \u00b7 ( 141 \u22a4 4 ) \u2297 ( 1n1 \u22a4 n\n) Where 1k is used to denote the all-one vector of dimension k and let 1\u0304k be the normalized version.\nFor the case of n = 1, it is easy to show that the matrix is reduced to an adjacency matrix of 4 nodes, each in one group, where the first two rows/columns correspond to samples with the same spurious attribute, and odd or even rows correspond to samples that are from the same class, based on the placements of \u03b1 and \u03b2 in the matrix.\nLet F be an embedding matrix with ux on the x-th row which corresponds to the embeddings of sample x, and consider the matrix factorization based form of the spectral contrastive loss as below\nmin F\u2208RN\u00d7k\nLmf(F ) := \u2225\u2225A\u0304\u2212 FF\u22a4\u2225\u22252\nF\nIt is enough to compute the eigenvectors of A\u0304, to obtain F . It is easy to compute the eigenvectors of A\u0304 similar to Shen et al. (2022). The set of four sets of eigenvectors would be as below:\n\u2022 For eigenvalue \u03bb1 = \u03c1+ \u03b2 + \u03b1+ \u03b3, the eigenvector is 1\u03042 \u2297 1\u03042 \u2297 1\u0304n. 1For an ease of notation and operations\n\u2022 For eigenvalue \u03bb2 = \u03c1+ \u03b2 \u2212 \u03b1\u2212 \u03b3 the eigenvectors are [1 \u2212 1]T \u2297 1\u03042 \u2297 1\u0304n.\n\u2022 For eigenvalue \u03bb3 = \u03c1\u2212 \u03b2 + \u03b1\u2212 \u03b3 the eigenvectors are 1\u03042 \u2297 [1 \u2212 1]T \u2297 1\u0304n.\n\u2022 \u03bb4 = \u03c1 \u2212 \u03b2 \u2212 \u03b1 + \u03b3 which is smaller than the first three eigenvalues, given the above assumptions.\nThus F would be a rank-3 matrix with columns equal to \u221a \u03bbi multiplied by each eigenvector. Given the case of n = 1 explained above and by induction, it is easy to show that \u03bb2 corresponds to the spurious attribute subspace, and \u03bb3 corresponds to the class. Projecting samples in A\u0304 with representations as rows of F , onto the spurious subspace suggests that the spurious feature takes two values {\u2212 \u221a \u03bb2, \u221a \u03bb2}, and similarly, the invariant feature takes two values {\u2212 \u221a \u03bb3, \u221a \u03bb3} in the representation space learned by spectral contrastive loss.\nIntuitively, this means that with higher spurious connectivity \u2014or higher weights on edges connecting images that only share the same spurious attribute\u2014 spectral clustering will learn representations of the population data based on the spurious feature, rather than the invariant feature."
        },
        {
            "heading": "D DATA AND MODELS",
            "text": "D.1 DATASETS\nWe make use of the following four image datasets:\n\u2022 celebA (Liu et al., 2015): Gender (Male, Female) is spuriously correlated with Hair color (blond hair, not blond hair).\n\u2022 waterbirds (Sagawa et al., 2020a): Background (land, water) is spuriously correlated with bird type (landbird, waterbird).\n\u2022 cmnist (Colored MNIST): The color of the digit on the images is spuriously correlated with the binary class based on the number inspired by (Arjovsky et al., 2019), with no label slipping.\n\u2022 spurcifar10 (Spurious CIFAR10) (Nagarajan et al., 2020): The color of lines on the images spuriously correlated with the class.\n\u2022 metashift (Liang & Zou, 2022) We consider the Cats vs Dogs task where Background (indoor, outdoor) is spuriously correlated with pet type (cat, dog).\nNote that for each dataset, we have access to both labels (or core attribute) y, and spurious attribute a. We then use the group information g = (y, a) to partition dataset splits into groups.\nD.2 METHODS AND HYPERPARAMETERS\nWe use SimSiam (Chen & He, 2020) with ResNet encoders to train both base models and LATETVG . We select ResNet-18 models as the backbone for all datasets except for celebA, which we use ResNet-50 models.\nFor each dataset, we use the following set of hyperparameters for SimSiam training.\nDataset Learning Rate Batch Size Weight Decay Number of Epochs celebA 0.01 128 1e-4 400 cmnist 1e-3 128 1e-5 1000 metashift 0.05 256 0.001 400 spurcifar10 0.02 128 5e-4 800 waterbirds 0.01 64 1e-3 800\nThe specific augmentations that we used for learning the representations, are exactly similar to the SimSiam Chen & He (2020) paper but without color jitter.\nNote that the model architecture and parameters for SSL-BASE and SSL-LATE-TVG are exactly the same, but SSL-LATE-TVG uses the pruning hyperparameters to prune the encoder during training.\nComputational Cost The SSL-LateTVG model updates the same number of parameters as SSLBase during training, with the forward pass keeping both the original and pruned encoder. The pruning operation is cost O(n) where n is the number of parameters. So any FLOPs used for the extra pruning mechanism will be very small compared to a single forward pass.\nD.3 THE ROLE OF DOWNSTREAM REGULARIZATION\nWe investigate the impact of regularization techniques during downstream Linear probing. Interestingly, we find that the presence and type of regularization has a notable effect on the accuracy of the worst-performing group, with improvements of approximately 10% on the celebA dataset and 7% on the metashift dataset. We hypothesize that the minority samples contribute more to the variance of the linear models, and the additional regularization helps penalize them, leading to a reduction in the variance of the downstream models."
        },
        {
            "heading": "E MEASURING SPURIOUS CONNECTIVITY IN AUGMENTATIONS",
            "text": "In this section, we present our methodology for measuring spurious connectivity in augmentations. We conduct experiments on four datasets, and our goal is to quantify the extent to which samples within the training set are connected to each other through the spurious attribute, as opposed to the core feature.\nTo estimate the average connectivity between two groups, denoted as g1 and g2, specified by classattribute pairs (y, a) and (y\u2032, a\u2032), we follow the algorithm outlined below:\nInitially, we label all training examples belonging to group g1 or class y and attribute a as 0, and all training examples belonging to group g2. Next, we train a classifier to distinguish between the two groups. The error of this classifier would be a proxy for \u201cthe probability of augmented images being assigned to the other group\u201d, or how close they are in the augmentation space. Instead of training a large classifier from scratch for each pair, we use CLIP\u2019s representations in Section 4.2, and assume that it is extracting all necessary features for distinguishing between the two groups. In Section 5.2.3, we instead use the representations learned by each SSL model.\nWe train a linear model on these features to distinguish between each of the two groups. It is important to note that the augmentations used in our experiments are the classical augmentations commonly employed in SimSiam, excluding Gaussian blur. Subsequently, we create the test set following a similar process, where images are labeled based on their group or class-attribute pairs. The trained linear classifier is evaluated on this strongly augmented test set. The test error of the classifier serves as an estimate for the connectivity between the two pairs, providing insights into the degree of connectivity based on the spurious attribute.\nBy applying this methodology to all four datasets, we obtain results regarding the average spurious connectivity compared to the invariant connectivity. Table 4 summarizes the findings, revealing that, across all datasets, the average spurious connectivity is higher than the invariant connectivity. Furthermore, we validate that both these connectivity values are higher than the probability of simultaneously changing both the spurious attribute and the invariant attribute. These observations indicate that the samples within the training set are more likely to be connected to each other through the spurious attribute, rather than the core feature. This finding suggests a preference of the contrastive loss for alignment based on the spurious attribute rather than class alignment."
        },
        {
            "heading": "F ADDITIONAL RESULTS FOR LATETVG",
            "text": "F.1 LATETVG REDUCES BACKGROUND RELIANCE IN HARD IMAGENET\nWe evaluate LATETVG on the Hard ImageNet dataset (Moayeri et al., 2022), which consists of 15 challenging ImageNet classes where models rely heavily on spurious correlations. The authors provide spuriousness rankings that enable creating a balanced subset.\nIn our experiments, we train the SSL model on the full Hard ImageNet train split, and train the linear classifier on the spurious-balanced subset. This tests the model\u2019s ability to learn representations without exploiting spurious cues.\nWe then evaluate the downstream classifier on four different dataset splits as below:\n\u2022 None: Original test split\n\u2022 Gray: The object region is grayed out by replacing RGB values with the mean RGB value. This removes texture/color cues.\n\u2022 Gray BBox: The object region is removed by replacing it with the mean RGB value of the surrounding bounding box region. This ablates shape cues.\n\u2022 Tile: The object region is replaced by tiling the surrounding bounding box region. This also ablates shape cues.\nA classifier relying on the spurious (i.e. non-object) features will achieve high performance in all evaluation splits. However, a classifier relying on the invariant features should perform decently on the original test split, but exhibit greatly reduced accuracy on the other splits. Thus, we desire high accuracy for the None split, and low accuracy for the other three splits.\nComparing the results to section 7 from (Moayeri et al., 2022), we find that the gap between None and other three splits is already large in SSL-base, and SSL-LateTVG is further decreasing the accuracy in the spurious datasets. This shows that the SSL-LateTVG encoder relies less on the spurious feature to predict the labels, which degrades the performance on splits that try remove the core feature.\nWe do not tune the hyperparameters in this experiment, but we find that for all sets of hyperparameters, SSL-LateTVG results in lower downstream accuracy on Gray, Gray BBox, and Tile splits as shown in Table 6.\nF.2 LATETVG CLOSES THE GAP TO SUPERVISED PRE-TRAINING\nSelf-supervised pretraining has shown a lot of promise in bridging the gap to supervised approaches in general representation learning. In this section, we explore whether this trend holds true for pre-training with data containing spurious correlations. To perform this analysis, we start with the same encoder model and vary only the pretraining strategy while fixing other aspects of the training, such hyperparameter selection and model selection.\nWe emphasize that this is an unfair comparison to begin with, since supervised pretraining requires labeled data whereas SSL does not, hence reducing the annotation budget drastically as shown in table 7. However, the goal of this experiment to understand to what extent do SSL models and specifically LATETVG , compare with ERM based supervised pretraining strategies.\nTable 8 shows the results of our experiment \u2013 we have compared both average and worst group accuracies for the SSL-based and ERM-based encoders across all our evaluation datasets. In terms of worst group accuracy it is clear that LATETVG narrows the gap between the SSL baseline and the ERM model significantly \u2013 17% relative improvement for cmnist to 50% in the case of spurcifar10. In the case of celebA, we even outperform the ERM baseline. Similar to previous experiments, the relative boost in performance from LATETVG is higher for cases where the base encoder is weaker, indicating the strength of our final layer augmentation in extracting useful signal relevant to the core features during pretraining.\nF.3 SSL-LATETVG OUTPERFORMS BASELINE ACROSS HYPER-PARAMETER SETTINGS\nDisrupting the features and creating new views of the pairs is possible even with small amounts of pruning. We run a grid-search over the last three to five convolutional layers of ResNet models depending on the dataset, and choose pruning percentages varying between [0.5, 0.7, 0.8, 0.9, 0.95]. We find that in the metashift dataset, all hyperparameter settings improve the worst-group accuracy and outperform the baseline. Average and worst-group accuracies of different pruning hyperparameters on the metashift and celebA datasets is show in in figure 4.\nAdditionally, instead of choosing the best-performing model, we consider top 5 models across different pruning hyperparameters, and report the performance in Table 9. Even in this scenario, we observe large performance gains with LATETVG .\nF.4 WHAT FEATURES DOES LATETVG LEARN?\nRecall that we motivated LATETVG by explaining that more difficult features could be learned in the later layers of an encoder, and by removing the spurious feature from the encoder, we force the model to learn more complex features. In this section, we use Grad-CAM Selvaraju et al. (2016) to compare the SSL-base and SSL-LATETVG . We consider the representations that SSL-base and SSL-LATETVG learn for metashift, and use that to visualize the final layer of the encoder. We choose the best-performing LATETVG model based on downstream worst-group accuracy. We visualize the parts of the image that both SSL-Base and LATETVG attend to, in majority 5, and minority 6 groups.\nF.5 ADDITIONAL DOWNSTREAM IMBALANCE RESULTS\nFor both the best downstream linear model chosen based on worst-group accuracy, and linear models with no regularization, we observe the same trend for the datasets shown in Figure 7."
        },
        {
            "heading": "G SPURIOUS LEARNING IN SELF-SUPERVISED REPRESETATIONS",
            "text": "G.1 ADDITIONAL RE-SAMPLING RESULTS\nWe present the complete table from experiment in section 4.4.\nG.2 IMAGENET PRE-TRAINED SELF-SUPERVISED MODELS\nWe obtain pre-trained ResNet50 encoders with SimSiam, SimCLR, and CLIP training strategies, and evaluate the accuracy of core feature prediction similar to the previous sections."
        }
    ],
    "title": "VIEWS CAN BE DECEIVING: IMPROVED SSL THROUGH FEATURE SPACE AUGMENTATION",
    "year": 2023
}