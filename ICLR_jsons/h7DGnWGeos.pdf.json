{
    "abstractText": "Retrosynthetic planning is a sequential decision-making process of identifying synthetic routes from the available building block materials to reach a desired target molecule. Though existing planning approaches show promisingly high solving rates and route qualities, the trivial route quality evaluation via pre-trained forward reaction prediction models certainly falls short of real-world chemical practice. An alternative option is to annotate the actual quality of a route, such as yield, through chemical experiments or input from chemists, but this often leads to substantial query costs. In order to strike the balance between query costs and route quality evaluation, we propose an Active Retrosynthetic Planning (ARP) framework that remains compatible with the established retrosynthetic planners. On one hand, the proposed ARP trains an actor that decides whether to query the quality of a reaction; on the other hand, it resorts to a critic to estimate the value of a molecule with its preceding reaction quality as input. Those molecules with high reaction qualities are preferred to expand first. We apply our framework to different existing approaches on both the benchmark and an expert dataset and demonstrate that it outperforms the existing state-of-the-art approach by 6.2% in route quality while reducing the query cost by 12.8%. In addition, ARP consistently plans high-quality routes with either abundant or sparse annotations.",
    "authors": [
        {
            "affiliations": [],
            "name": "Luotian Yuan"
        },
        {
            "affiliations": [],
            "name": "Yemin Yu"
        },
        {
            "affiliations": [],
            "name": "Ying Wei"
        },
        {
            "affiliations": [],
            "name": "Yongwei Wang"
        },
        {
            "affiliations": [],
            "name": "Zhihua Wang"
        },
        {
            "affiliations": [],
            "name": "Fei Wu"
        }
    ],
    "id": "SP:05565fb4d3b7f685d0e91de7f888730636b86c6b",
    "references": [
        {
            "authors": [
                "Colin Bellinger",
                "Rory Coles",
                "Mark Crowley",
                "Isaac Tamblyn"
            ],
            "title": "Active measure reinforcement learning for observation cost minimization",
            "venue": "CoRR, abs/2005.12697,",
            "year": 2020
        },
        {
            "authors": [
                "Binghong Chen",
                "Chengtao Li",
                "Hanjun Dai",
                "Le Song"
            ],
            "title": "Retro*: Learning retrosynthetic planning with neural guided a* search",
            "venue": "Proceedings of the 37th International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Shuan Chen",
                "Yousung Jung"
            ],
            "title": "Deep retrosynthetic reaction prediction using local reactivity and global attention",
            "venue": "JACS Au,",
            "year": 2021
        },
        {
            "authors": [
                "Paul Christiano",
                "Jan Leike",
                "Tom B. Brown",
                "Miljan Martic",
                "Shane Legg",
                "Dario Amodei"
            ],
            "title": "Deep reinforcement learning from human preferences, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Connor W. Coley",
                "Luke Rogers",
                "William H. Green",
                "Klavs F. Jensen"
            ],
            "title": "Computer-assisted retrosynthesis based on molecular similarity",
            "venue": "ACS Central Science,",
            "year": 2017
        },
        {
            "authors": [
                "Hanjun Dai",
                "Chengtao Li",
                "Connor W. Coley",
                "Bo Dai",
                "Le Song"
            ],
            "title": "Retrosynthesis Prediction with Conditional Graph Logic Network",
            "venue": "Curran Associates Inc., Red Hook, NY,",
            "year": 2019
        },
        {
            "authors": [
                "Christian Daniel",
                "Malte Viering",
                "Jan Metz",
                "Oliver Kroemer",
                "Jan Peters"
            ],
            "title": "Active reward learning",
            "venue": "In Proceedings of Robotics: Science and Systems",
            "year": 2014
        },
        {
            "authors": [
                "Zhongliang Guo",
                "Stephen Wu",
                "Mitsuru Ohno",
                "Ryo Yoshida"
            ],
            "title": "Bayesian algorithm for retrosynthesis",
            "venue": "Journal of Chemical Information and Modeling,",
            "year": 2020
        },
        {
            "authors": [
                "Siqi Hong",
                "Hankz Hankui Zhuo",
                "Kebing Jin",
                "Guang Shao",
                "Zhanwen Zhou"
            ],
            "title": "Retrosynthetic planning with experience-guided Monte Carlo tree search",
            "venue": "Communications Chemistry,",
            "year": 2023
        },
        {
            "authors": [
                "Shoichi Ishida",
                "Kei Terayama",
                "Ryosuke Kojima",
                "Kiyosei Takasu",
                "Yasushi Okuno"
            ],
            "title": "Ai-driven synthetic route design incorporated with retrosynthesis knowledge",
            "venue": "Journal of Chemical Information and Modeling,",
            "year": 2022
        },
        {
            "authors": [
                "Yinjie Jiang",
                "Yemin Yu",
                "Ming Kong",
                "Yu Mei",
                "Luotian Yuan",
                "Zhengxing Huang",
                "Kun Kuang",
                "Zhihua Wang",
                "Huaxiu Yao",
                "James Zou",
                "Connor W. Coley",
                "Ying Wei"
            ],
            "title": "Artificial intelligence for retrosynthesis prediction",
            "venue": "doi: https://doi.org/10.1016/j.eng.2022.04.021. URL https://www.sciencedirect.com/science/article/pii/S2095809922005665",
            "year": 2022
        },
        {
            "authors": [
                "Junsu Kim",
                "Sungsoo Ahn",
                "Hankook Lee",
                "Jinwoo Shin"
            ],
            "title": "Self-improved retrosynthetic planning",
            "venue": "CoRR, abs/2106.04880,",
            "year": 2021
        },
        {
            "authors": [
                "Junsu Kim",
                "Sungsoo Ahn",
                "Hankook Lee",
                "Jinwoo Shin"
            ],
            "title": "Self-improved retrosynthetic planning",
            "venue": "Proceedings of the 38th International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "W. Bradley Knox",
                "Peter Stone"
            ],
            "title": "Interactively shaping agents via human reinforcement: The tamer framework",
            "venue": "In Proceedings of the Fifth International Conference on Knowledge Capture,",
            "year": 2009
        },
        {
            "authors": [
                "David Krueger",
                "Jan Leike",
                "Owain Evans",
                "John Salvatier"
            ],
            "title": "Active reinforcement learning: Observing rewards at a cost",
            "venue": "CoRR, abs/2011.06709,",
            "year": 2020
        },
        {
            "authors": [
                "Kangjie Lin",
                "Youjun Xu",
                "Jianfeng Pei",
                "Luhua Lai"
            ],
            "title": "Automatic retrosynthetic route planning using template-free models",
            "venue": "Chem. Sci.,",
            "year": 2020
        },
        {
            "authors": [
                "Yingfu Lin",
                "Rui Zhang",
                "Di Wang",
                "Tim Cernak"
            ],
            "title": "Computer-aided key step generation in alkaloid total synthesis",
            "venue": "Science, 379(6631):453\u2013457,",
            "year": 2023
        },
        {
            "authors": [
                "Guoqing Liu",
                "Di Xue",
                "Shufang Xie",
                "Yingce Xia",
                "Austin Tripp",
                "Krzysztof Maziarz",
                "Marwin Segler",
                "Tao Qin",
                "Zongzhang Zhang",
                "Tie-Yan Liu"
            ],
            "title": "Retrosynthetic planning with dual value networks, 2023a",
            "year": 2023
        },
        {
            "authors": [
                "Songtao Liu",
                "Zhengkai Tu",
                "Minkai Xu",
                "Zuobai Zhang",
                "Lu Lin",
                "Rex Ying",
                "Jian Tang",
                "Peilin Zhao",
                "Dinghao Wu"
            ],
            "title": "Fusionretro: Molecule representation fusion via in-context learning for retrosynthetic planning, 2023b",
            "year": 2023
        },
        {
            "authors": [
                "John Mayfield",
                "Daniel Lowe",
                "Roger Sayle"
            ],
            "title": "Pistachio: Search and faceting of large reaction databases. In ABSTRACTS OF PAPERS OF THE AMERICAN CHEMICAL SOCIETY, volume 254",
            "venue": "AMER CHEMICAL SOC 1155 16TH ST, NW,",
            "year": 2003
        },
        {
            "authors": [
                "Mikohaj Sacha",
                "Mikolaj Blaz",
                "Piotr Byrski",
                "Pawel Dabrowski-Tumanski",
                "Mikolaj Chrominski",
                "Rafal Loska",
                "Pawel Wlodarczyk-Pruszynski",
                "Stanislaw Jastrzebski"
            ],
            "title": "Molecule edit graph attention network: Modeling chemical reactions as sequences of graph edits",
            "venue": "Journal of Chemical Information and Modeling,",
            "year": 2021
        },
        {
            "authors": [
                "William Saunders",
                "Girish Sastry",
                "Andreas Stuhlm\u00fcller",
                "Owain Evans"
            ],
            "title": "Trial without error: Towards safe reinforcement learning via human intervention",
            "venue": "In Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems,",
            "year": 2018
        },
        {
            "authors": [
                "John S. Schreck",
                "Connor W. Coley",
                "Kyle J.M. Bishop"
            ],
            "title": "Learning retrosynthetic planning through simulated experience",
            "venue": "ACS Central Science,",
            "year": 2019
        },
        {
            "authors": [
                "Sebastian Schulze",
                "Owain Evans"
            ],
            "title": "Active reinforcement learning with monte-carlo tree search",
            "venue": "CoRR, abs/1803.04926,",
            "year": 2018
        },
        {
            "authors": [
                "Philippe Schwaller",
                "Teodoro Laino",
                "Th\u00e9ophile Gaudin",
                "Peter Bolgar",
                "Christopher A. Hunter",
                "Costas Bekas",
                "Alpha A. Lee"
            ],
            "title": "Molecular transformer: A model for uncertainty-calibrated chemical reaction prediction",
            "venue": "ACS Central Science,",
            "year": 2019
        },
        {
            "authors": [
                "Philippe Schwaller",
                "Riccardo Petraglia",
                "Valerio Zullo",
                "Vishnu H. Nair",
                "Rico Andreas Haeuselmann",
                "Riccardo Pisoni",
                "Costas Bekas",
                "Anna Iuliano",
                "Teodoro Laino"
            ],
            "title": "Predicting retrosynthetic pathways using transformer-based models and a hyper-graph exploration strategy",
            "venue": "Chem. Sci.,",
            "year": 2020
        },
        {
            "authors": [
                "Philippe Schwaller",
                "Alain C Vaucher",
                "Teodoro Laino",
                "Jean-Louis Reymond"
            ],
            "title": "Prediction of chemical reaction yields using deep learning",
            "venue": "Machine Learning: Science and Technology,",
            "year": 2021
        },
        {
            "authors": [
                "Marwin H.S. Segler",
                "Mark P. Waller"
            ],
            "title": "Neural-symbolic machine learning for retrosynthesis and reaction prediction",
            "venue": "Chemistry \u2013 A European Journal,",
            "year": 2017
        },
        {
            "authors": [
                "Chence Shi",
                "Minkai Xu",
                "Hongyu Guo",
                "Ming Zhang",
                "Jian Tang"
            ],
            "title": "A graph to graphs framework for retrosynthesis prediction",
            "venue": "Proceedings of the 37th International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Vignesh Ram Somnath",
                "Charlotte Bunne",
                "Connor W. Coley",
                "Andreas Krause",
                "Regina Barzilay"
            ],
            "title": "Learning graph models for template-free retrosynthesis",
            "venue": "CoRR, abs/2006.07038,",
            "year": 2020
        },
        {
            "authors": [
                "Kaushik Subramanian",
                "Charles L. Isbell",
                "Andrea L. Thomaz"
            ],
            "title": "Exploration from demonstration for interactive reinforcement learning",
            "venue": "In Proceedings of the 2016 International Conference on Autonomous Agents & Multiagent Systems,",
            "year": 2016
        },
        {
            "authors": [
                "Austin Tripp",
                "Krzysztof Maziarz",
                "Sarah Lewis",
                "Marwin Segler",
                "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
            ],
            "title": "Retrofallback: retrosynthetic planning in an uncertain world, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Garrett Warnell",
                "Nicholas Waytowich",
                "Vernon Lawhern",
                "Peter Stone"
            ],
            "title": "Deep tamer: Interactive agent shaping in high-dimensional state spaces",
            "venue": "In Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence,",
            "year": 2018
        },
        {
            "authors": [
                "Shufang Xie",
                "Rui Yan",
                "Peng Han",
                "Yingce Xia",
                "Lijun Wu",
                "Chenjuan Guo",
                "Bin Yang",
                "Tao Qin"
            ],
            "title": "Retrograph: Retrosynthetic planning with graph search",
            "venue": "In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,",
            "year": 2022
        },
        {
            "authors": [
                "Shufang Xie",
                "Rui Yan",
                "Junliang Guo",
                "Yingce Xia",
                "Lijun Wu",
                "Tao Qin"
            ],
            "title": "Retrosynthesis prediction with local template retrieval, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Chaochao Yan",
                "Qianggang Ding",
                "Peilin Zhao",
                "Shuangjia Zheng",
                "Jinyu Yang",
                "Yang Yu",
                "Junzhou Huang"
            ],
            "title": "Retroxpert: Decompose retrosynthesis prediction like a chemist",
            "venue": "In Proceedings of the 34th International Conference on Neural Information Processing Systems, NIPS\u201920, Red Hook, NY, USA,",
            "year": 2020
        },
        {
            "authors": [
                "Yemin Yu",
                "Ying Wei",
                "Kun Kuang",
                "Zhengxing Huang",
                "Huaxiu Yao",
                "Fei Wu"
            ],
            "title": "Grasp: Navigating retrosynthetic planning with goal-driven policy",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Yemin Yu",
                "Luotian Yuan",
                "Ying Wei",
                "Hanyu Gao",
                "Xinhai Ye",
                "Zhihua Wang",
                "Fei Wu"
            ],
            "title": "Retroood: Understanding out-of-distribution generalization in retrosynthesis prediction, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Zipeng Zhong",
                "Jie Song",
                "Zunlei Feng",
                "Tiantao Liu",
                "Lingxiang Jia",
                "Shaolun Yao",
                "Min Wu",
                "Tingjun Hou",
                "Mingli Song"
            ],
            "title": "Root-aligned smiles: a tight representation for chemical reaction prediction",
            "venue": "Chem. Sci.,",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Planning a retrosynthetic route is a central challenge in organic synthesis, requiring the break-down of a target molecule into available building block materials through a sequence of reactions. This process comprises two main components: (1) single-step reaction prediction predicting feasible reactions in a single step, (2) multi-step planning recursively selecting optimal molecules and reactions across multiple steps, where evaluating and ranking routes are of pivotal importance in shaping the planning policy. Previous efforts on multi-step planning have focused on quickly accessing building block materials in a limited number of single-step calls, resulting in an up to a 99.47% success rate Xie et al. (2022) on specific benchmarks. Regrettably, this emphasis on evaluating search aspects overlooks the chemical practicability of planned routes, i.e., whether a route is quality-effective in practice. For example, there is a short but low-quality route in Fig. 1. The crux revolves around the definition of reaction quality, which is simply the predictive probability of a reaction according to a pre-trained forward single-step prediction model in approaches such as Retro* Chen et al. (2020) and GRASP Yu et al. (2022). This single-step model is trained to predict feasibility rather\n*These authors contributed equally to this work. \u2020Corresponding authors.\nthan the quality of reactions, thereby being biased towards highly feasible and frequent reactions instead of those with high qualities. An analysis illustrate this issue in Appendix B. The ideal reaction qualities that meet real-world chemical practicability, e.g., yield of a reaction, can be either annotated experimentally in a laboratory or by experienced chemists. Yet, annotating each reaction requires labor-intensive lab verification or expert annotations, compounded by the task of soliciting qualities for all reactions along a retrosynthetic route with route lengths ranging from 2.0 to 8.0(Yu et al. (2022),Liu et al. (2023a)). As verifying every reaction quality in the lab causes time delays and hinders automation, a quality metric is required which is expensive but not prohibitively so. In the real-life scenarios, such as online softwares like SYNTHIA(Lin et al. (2023)), it is an ideal candidate to integrate chemists into the AI planning process. Online annotations by chemists not only introduce minimal time delays and manageable labor costs, but also contribute valuable insights beyond mere reaction yields, such as toxicity, material costs, and work-up difficulty.\nWe are motivated to pursue a framework that strikes a balance between enhancing practical planning performance and minimizing annotation costs. The core idea of the proposed reinforcement learning-based Active Retrosynthetic Planning (ARP) framework constitutes an actor that decides whether to query the quality of a reaction or not and a critic that evaluates whether to expand a molecule or not. Concretely, the actor takes the current reaction as input; observing in Fig. 2 that a molecule with a high preceding reaction quality should be prioritized to expand first, the critic takes both the current molecule and its preceding reaction quality as input. It is noteworthy that the estimated molecule values by existing retrosynthetic planning methods can also be readily incorporated into our critic network. The critic network predicts a value that reflects the molecule\u2019s synthesizability together with the expectation of initializing a high-quality route. Simultaneously, the actor is trained to make the decision regarding the quality-effectiveness of querying for the annotated reaction qualities. Since querying for the reaction quality is a non-trivial task that induces an additional cost during annotation, we enforce a query cost to be paid whenever a query decision is made by the model. Given the diverse referential values of different reaction qualities during planning, we dynamically adjust the query cost to enhance the model\u2019s capability of identifying those reactions whose query results prove to be most quality-effective, thereby addressing the trade-off issue between query cost and the planning quality. The key contributions of our paper are outlined below. (1) Practical efficacy: we, for the first time, draw an insight into the disappointing practicality of existing retrosynthetic planners that regard single-step probabilities as reaction qualities. The ARP framework addresses the issue and improves quality of planned routes by 6.2% on a benchmark and by 4.9% on an annotated dataset. (2) Generality: The ARP framework is also compatible with arbitrary off-the-shelf planners and further boosts their chemical practicality."
        },
        {
            "heading": "2 RELATED WORK",
            "text": "Single-step prediction Existing single-step methods can be divided into three main categories, templatebased, template-free, and semi-template-based. Template-based methods pre-define reaction transformations as templates and select appropriate template candidates (Coley et al. (2017), Segler & Waller (2017), Dai et al. (2019),Chen & Jung (2021), Xie et al. (2023)). Template-free methods predict the reactants in the representation of SMILES sequences(Schwaller et al. (2019),Zhong et al. (2022)) or molecular graphs (Sacha et al. (2021)). Semi-template-based methods decompose the task into two stages, center identification, and synthon completion (Shi et al. (2020), Yan et al. (2020), Somnath et al. (2020)). Chen & Jung (2021) solves the identify-and-complete processes into a local template prediction through a global attention mechanism. Furthermore, Xie et al. (2023) address the issue that fxed parameters might be sub-optimal by the robust non-parametric local reaction template retrieval. Zhong et al. (2022) fixes the problem that SMILES neglects the characteristics of molecular graph topology and reaction atom transformations. Yu et al. (2023) sorts out two types of distribution shifts in retrosynthesis prediction.\nMulti-step planning Lin et al. (2020) takes advantage of a single-step seq2seq model and Ishida et al. (2022) further introduces domain knowledge to guide the search direction. Chen et al. (2020) designs a neural-based A\u21e4-like algorithm. Rather than a tree-search policy, Xie et al. (2022) proposes to combine a graph-based search policy with the traditional A\u21e4 algorithm. Kim et al. (2021b) perform two self-improved iteration algorithms to imitate successful trajectories and find an optimal search policy. Afterward, Yu et al. (2022) is capable of biasing the retrosynthetic planning toward a favorable goal prescribed by chemists. Schreck et al. (2019) and Liu et al. (2023a) consider the cost for each reaction as a uniform 1 and optimize towards shortest routes. However, a short route might have a lower yield than a long route. Liu et al. (2023b) introduces a novel multi-step planning approach via in-context learning, departing from conventional search algorithms. However, the primary objective of Liu et al. (2023a) and Liu et al. (2023b) is still evaluating success rates of planned routes. They do not consider the real-world reaction qualities. Tripp et al. (2023), which shares a comparable motivation with ours, addresses the uncertainty of the stochastic retrosynthetic planning processes and focuses on finding several routes to complement their respective shortcomings. The methodologies above require the annotation of costs for every reaction along a route. In the pursuit of incorporating reliable reaction qualities derived from chemists or lab experimentation, which entail significant costs, these methods tend to be economically impractical for real-world deployment."
        },
        {
            "heading": "3 METHODS",
            "text": ""
        },
        {
            "heading": "3.1 ACTIVE RETROSYNTHETIC PLANNING MDP",
            "text": "In our work, we consider the active retrosynthetic planning scenario modeled as a Markov decision process (MDP), represented by M = {S, (Ar, Aq),P,R, c}. Specifically, S denotes the state space comprising chemical molecules, Ar refers to the action space of candidate reactions, and Aq = {0, 1} represents the action space for query decisions. At time step t, given a molecule state st, the agent opts for a decision through a basic action pair (art , a q t ), where art denotes a candidate reaction and a q t indicates the agent\u2019s decision to query (or not) for the annotated reaction quality. The agent observes the reaction quality ut of a r t only if a q t = 1. The P represents the deterministic state transition function from st to st+1 via execution of reaction art . R denotes our reward function and c is the constant query cost. Contrary to prior studies that employed a binary reward function (yielding a reward of 1 if the reaction reaches the building block materials, and 0 otherwise), this work associates the successful reward with both route quality and the query cost, as outlined in Eq. 1.\nR(s, ar, aq) =\n8 <\n:\n+ u + 1 Nqc if a r reach I\n0 otherwise (1)\nI denotes the building block materials. cr represents the route quality, defined as the cumulative product of reaction qualities Q t=0 ut. Both route and reaction qualities fall within the interval [0, 1]. Nq is the number\nof the annotated reactions, calculated by P\nt=0 a q t . is a hyperparameter employed to stabilize the training\nwhen the agent obtains a success route with extremely small u."
        },
        {
            "heading": "3.2 MODEL FRAMEWORK AND TRAINING PROCEDURE",
            "text": "We employ an actor-critic framework for the approach. Given a reaction ar, the actor \u21e1 : Ar ! Aq is responsible for making a query decision aq , determining whether to query the reaction quality u or not. The observation function O transforms the reaction and the query action to a dM -dimensional embedding of the reaction qualities as expressed in Eq. 2. We use a binning strategy B to discretize the continuous reaction quality values into NM buckets and obtain the associated bucket embedding. The bins are constructed in order to cover a similar amount of reactions individually. In addition, we regard M as a separate bucket embedding. Details are given in Appendix C\nO(ar, aq) =\n\u21e2 B(u) if aq = 1\nM if aq = 0 (2)\nFor a given molecule s with its corresponding reaction quality u , the critic Q\u2713(s, u) estimates the value of s. The predicted values are used to access the value of the next state selection during RL roll-outs. To integrate existing retrosynthetic planners, a standard molecule estimator E : S ! R is assumed within existing algorithms, whose task is to evaluate the values of molecules within their specific search frameworks. As summarized in Appendix A, existing methods can be roughly divided into offline and online categories. Offline methods, such as neural-based A* search in Chen et al. (2020) and Somnath et al. (2020), train the estimator on the extracted routes from the publicly available reaction databases in an offline manner, including the United States Patent Office (USPTO) or Pistachio(Mayfield et al. (2017)). In contrast, online methods such as Yu et al. (2022) leverage routes generated by online roll-outs. We design the critic network Q\u2713(E(s), u) = READOUT (E(s), u) as architecture A shown in Fig. 3. In this design, arbitrary pretrained offline planners can be seamlessly integrated into the critic. Additionally, online planners can be trained simultaneously with ARP training, simplifying the critic architecture to architecture B in Fig. 3.\nAlgorithm 1: Training algorithm Initialize the estimator E , the actor policy \u21e1 , the critic value function Q\u2713, the initial state s0 for t=0 to T do\nObserve reaction action space {ari }ki=1 of st from environment Make query decisions {aqi } k i=1 and observe reaction qualities {ui = O(ari , a q i )} k i=1 Observe the next step states {sit+1}ki=1 Select the next state st+1 by argmax1ik Q\u2713(E(sit+1), ui) Compute reward rt = R(st, art , a q t ) Append (st, ut 1, (art , a q t ), rt, st+1) to the buffer\nend Update \u21e1 and Q\u2713 by Eq. 3 and Eq. 4\nSuch synergistic optimization not only conserves training resources for route collection but also substantially enhances both the solving rate and route quality compared in comparison to the two-stage training process.\nAt time step t, the agent observes state st along with a batch of reaction candidates {ari }ki=1. The actor chooses query actions {aqi } k i=1 and observes the corresponding reaction qualities {ui = O(ari , a q i )} k i=1. Subsequently, the respective next states {sit+1}ki=1 of reaction candidates are obtained by employing the state transition function P . The next state st+1 is then selected with the critic by argmax1ik Q\u2713(E(sit+1), ui). This comprises a complete step for executing a single step roll-outs, and a step reward rt = R(s, ar, aq) is determined by the reward function in Eq. 1. The training procedure performs recursive roll-outs to collect trajectories for training and terminates each roll-out whenever it reaches dead/building-block molecules or maximum depth. We store the transition tuple (st, ut 1, (art , a q t ), rt, st+1) into the replay buffer for training.\nThe actor-critic framework is trained using the TD3 algorithm. The target critic network is updated through the one-step TD equation where Q0 and \u21e10 denote the target critic and actor networks, respectively, which is initialized using the same parameter from the main critic and actor networks Q\u2713 and \u21e1 but updated through an asynchronous manner. Utilizing the TD target yi, the mean square error loss across the batch is computed for the original critic network Q\u2713 as follows:\ny td = rt + Q 0(E(st+1),O(a r t ,\u21e1 0(art ))) L(\u2713) = 1\nN\nX\ni\n(ytd Q\u2713(E(st), ut 1)) (3)\nGiven the actor\u2019s objective is aligned toward maximizing the total return, and the critic network aims to approximate this cumulative return, the actor \u21e1 is trained by maximizing the Q-value, which is achieved through the minimization of loss in Eq. 4. If E is an offline estimator such as the value estimator in Retro*, it is trained before implementation in our framework. The parameters of E are frozen and not evolved in training of the critic and E 0 = ;. If E is an online estimator, it can be regarded as part of the critic parameters and is wrapped with the other critic parameters for training and E 0 = E . The algorithm is summarized in Algorithm 1.\nL( , E 0) = 1\nN\nX\ni\n( Q\u2713(E(st),O(a r t ,\u21e1 (a r t )))) (4)"
        },
        {
            "heading": "3.3 INFERENCE PROCEDURE FOR ACTIVE RETROSYNTHETIC SEARCH",
            "text": "This section demonstrates the inference procedure for planning with partial observation of reaction qualities. In the inference stage, the reaction qualities are annotated by either a surrogate model or a chemist expert. We combine the actor \u21e1\u2713 and the critic Q\u2713 into the Monte-Carlo tree search (MCTS) on the AND-OR search\ntree. The molecule nodes are \u2019OR\u2019 nodes and the reaction nodes are \u2019AND\u2019 nodes. Moreover, we define a non-building block molecule node to be expandable when it is a leaf node or has an expandable child reaction node. None of the building block molecule nodes are expandable. A reaction node is expandable when there is any expandable child molecule node and none of the children are dead nodes. Molecule nodes are dead when they reach the maximum horizon or there are no reactions proposed by the single-step model. Let ch(\u00b7|T ) denote the expandable children nodes of a molecule or reaction node.\nThere are three steps for each rollout during the active retrosynthetic search: selection, expansion, and update. A function Q\u21e4(st, art ) in Eq. 5 presents the molecule synthesizability involves exploration. We use a UCT(Upper Confidence Bound applied to Trees) function(Kocsis et al. (2006)) to balance between exploitation of the route with the maximum Q and exploration of those less frequently visited routes. is a hyper-parameter. Q(st, art ) is a value initialized by Q\u2713(st+1,O(art ,\u21e1 (art ))) and updated afterward. A visit count number is denoted by N(s, ar) and initialized as 1.\nQ \u21e4(st, a r t ) = Q(st, a r t ) +\np N(st 1, art 1)\n1 +N(st, art ) (5)\nSelection The search tree T starts with a single target root molecule node s0. We recursively perform a reaction action selection art = argmaxar2ch(st|T ) Q\n\u21e4(st, ar) and obtain the next state st+1 by tranition function P until reaching a leaf molecule node.\nExpansion In the expansion step, we expand an AND-OR stump under the selected molecule node st by referring to the single-step model. Every candidate reaction proposed is appended as a child reaction node of st. For a newly generated reaction node art , we assign its reaction quality observation by O(art ,\u21e1 (art )). Each newly generated reaction node then expands children with the reactant molecule nodes.\nUpdate During the update step, we perform Q(st, art ) values and visit counts N(\u00b7|T ) backward traversal following the path from the selected leaf node back to the root node. Q0 is the Q values of newly added state-action pairs. We use a simple moving average for the update with a discount factor by Eq. 6.\nQ 0(st, a r t ) = Q(st, a r t ) +\n1\nN(st, at) ( Q0 Q(st, a r t )) N 0(st, a r t ) = N(st, a r t ) + 1 (6)"
        },
        {
            "heading": "4 EXPERIMENTS",
            "text": ""
        },
        {
            "heading": "4.1 EXPERIMENT SETUP",
            "text": "Baselines. We compare solving rate and route quality against various open-source baselines including a beam-search-like algorithm guided hyper-graph search method HgSearch(Schwaller et al. (2020)), bestfirst A*-like algorithm guided AND-OR tree search methods Retro* and Retro*-0(Chen et al. (2020)), and an experience-guided MCTS-based method EG-MCTS(Hong et al. (2023)). We apply ARP on an offline algorithm Retro*+(Kim et al. (2021a)) and an online one: GRASP(Yu et al. (2022)). Retro*+ is based on Retro* with a self-improved single-step retrosynthetic model. GRASP applies a goal-driven actor-critic RL agent. As all of the existing methods rely on the reaction quality for calculating the search heuristics, we set their default query rate to 100%. We change the resource of reaction qualities from the single-step probabilities to our reaction qualities when testing the baselines.\nMaterials and RL environment. We use two test sets to evaluate our methods. The first one is a widely used USPTO-50k benchmark dataset that has 178 hard molecules raised in Chen et al. (2020). However, the scale of the benchmark dataset is small. Therefore, we include an additional expert dataset that has 8000 molecules and each molecule has a literature reference route extracted by chemist experts. The expert dataset is designed to emphasize retrosynthetic strategies with more challenging but strategically similar molecules. We partition the expert dataset as 0.8/0.1/0.1 into train/valid/test sets. The training set is used as the target molecules. For the single-step retrosynthesis model, we use a similar template-based model in Chen et al. (2020) which is a 2-layer MLP using the Morgan fingerprint as input. We adopt the top50 single-step reaction candidates and set the maximum number of single-step inference calls as 100. We use the commercially available molecules dataset eMolecules as the building block materials. As for the hyper-parameters, we set the maximum route depth as 6 and in Eq. 1 as 4.\nReaction quality annotation Unfortunately, there is no established large-scale available reaction data set with respective reaction qualities or promising reaction performance, e.g. yield, prediction model(Jiang et al. (2022)), and both lab verification and expert annotations are expensive and time-consuming. We adopt a surrogate model to provide reaction quality annotations. Initially, the method in Guo et al. (2020) is employed to pre-train a model utilizing the USPTO-MIT dataset, followed by the fine-tuning of the model in reactions derived from the high-quality, expert-annotated dataset. Conceptually, the model, when trained on the expert-annotated dataset, prioritizes the identification of high-yield reactions over high-frequency reactions. More details about the training of surrogate model are in Appendix D. We provide an experiment to demonstrate a significant correlation between our surrogate model and reaction yields in Appendix E. Dur-\ning deployment, it is practical to replace the surrogate model with a chemist to provide online annotations, e.g. a coarse-grained quality rating from 0 to 10.\nEvaluation metrics. We use three main metrics to comprehensively evaluate the performance of different search algorithms. 1. Success rate: The success rate is defined as the percentage of solved molecules in the entire test set. 2. Query rate: The query rate is defined as the percentage of reactions that are annotated with the reaction qualities in the inference stage. 3. Normalized route quality: Given a route, we compute the route quality by a cumulative product of reaction qualities. Both the reactions and route qualities range in [0, 1] and a larger value refers to a higher quality, also a lower quality. We introduce the normalized route quality to evaluate the route quality performance. For each target molecule in the inference test set, we perform an exhaustive brute-force search in limited depth and acquire the maximum umax and minimum route quality umin for the success route. Especially, if there is only one successful route, we assume the single route quality as umin and umax = umin + 0.01. We further define the normalized route quality as Eq. 7 of a route quality u to eliminate the impact of different target molecules.\nQualitynorm = umax u\numax umin (7)"
        },
        {
            "heading": "4.2 RESULTS",
            "text": "Comparision with baselines The performance of all methods are presented in Table. 1. Concerning both the normalized route quality and the query rate metrics, our approach achieves the best performance on both datasets. The best existing method in the normalized route quality metric is identified as Retro*. In the benchmark dataset, our approach outperforms Retro* by a margin of 6.2 %, while achieving a reduction in the query rate by 12.8%. Similarly, within the expert dataset, our approach outperforms Retro* by 4.9 % and lowers the query rate by 9.2%. Regarding the success rate, both Retro* and GRASP achieve a moderately higher success rate compared to the original results, primarily due to the influence of the preceding reaction quality as a potential molecular feature in predicting molecular synthesizability.\nActive query capability We evaluate the performance of ARP for balancing the trade-off between the query costs and reaction qualities. In the context of the active query setting, the models are tested under diverse query cost settings. Intuitively, setting a high query cost is to simulate a sparse-annotated environment, compelling the planner to rely on less annotated reactions. Conversely, a near-zero query cost emulates an abundant-annotated setting. The experimental results on both the benchmark and expert datasets are listed in the left columns of Tab. 2 and Tab. 3, respectively. As we increase the query cost, we observe a decline in the query rate, which mildly impacts the success rate and normalized route quality. The phenomenon reflects that our approach is capable of actively selecting reactions that contribute most significantly to the reaction qualities in retrosynthetic planning. To further explore the active query capability of our approach, we conduct an ablation study where the planner chooses to query the reaction quality of a reaction with a fixed random rate p as Eq. 8 instead of employing the trained actor-network for making query decisions.\na q i\n\u21e2 1 p\n0 1 p (8)\nWe adjust the fixed probability p as the same query rate obtained from the baseline result under varied query cost settings in order to eliminate the confounding effect of different query numbers. The results are listed in the right columns of Tab. 2 and Tab. 3 and demonstrate that the actor adeptly selects the most informative reactions to enhance the planning performance. As the random rate p escalates, the critic can utilize more annotated reactions, improving the precision of value estimation and, thereby, optimizing the search process toward discovering routes with higher quality. We observe that the success rate does not increase monotonically with the query rate. Optimizing the success rate and the route quality together can lead to certain trade-offs, as demonstrated by a case study in Appendix F. Additionally, the actor is specifically trained to identify and query the most informative reactions in order to achieve a higher route quality. As a result, when the trade-off appears between the success rate and the route quality, the actor+critic approach might not improve but suppress the success rate when compared to the random+critic baseline."
        },
        {
            "heading": "5 CONCLUSION",
            "text": "The paper proposed ARP, a novel retrosynthetic planning framework aware of the route quality. Unlike existing approaches using a labor-free but trivial reaction evaluation which is biased to the high-frequent reactions, ARP adopts a route-quality evaluation approach aware of chemical practicability Moreover, there exists a trade-off between enhancing the planning performance and saving the query costs of acquiring reaction and is able to perform an active selection of the most informative reactions to observe their reaction qualities. Experimental results demonstrate ARP\u2019s capability of capturing high-quality routes under either abundant or sparse-annotation environments."
        },
        {
            "heading": "6 ACKNOWLEDGEMENT",
            "text": "This work is funded by National Natural Scientific Foundation of China (No. 62037001), the Starry Night Science Fund at Shanghai Institute for Advanced Study (Zhejiang University) and Shanghai AI Laboratory."
        }
    ],
    "title": "ACTIVE RETROSYNTHETIC PLANNING AWARE OF ROUTE QUALITY",
    "year": 2024
}